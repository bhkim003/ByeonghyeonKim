{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a76c116a59452d8d1e5846f5ae492c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113509888915966, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250307_152826-uztyvmmr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/uztyvmmr' target=\"_blank\">cerulean-brook-1416</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/uztyvmmr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/uztyvmmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '2', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.75, 'v_threshold': 0.5, 'v_reset': 10000.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250307_152824_829', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION5_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (1): Linear(in_features=200, out_features=480, bias=False)\n",
      "      (2): ReLU()\n",
      "      (3): SSBH_DimChanger_for_conv1()\n",
      "      (4): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): ReLU()\n",
      "      (6): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (7): ReLU()\n",
      "      (8): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250307_152824_829\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.01673743, loss_normal : 0.01247297, loss_coarse : 0.05562596, min_loss : 0.01673743, min_loss_normal : 0.01247297, min_loss_coarse : 0.05562596, wrong_element_sum : 10680184.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.505초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 84.58%, kmeans average accuracy : 84.58147834%, total [0.9712578258394992, 0.9721749006246451, 0.9695139488064424, 0.9559585492227979, 0.956891495601173, 0.9454545454545454, 0.8973907944884199, 0.7257515598411798, 0.9370381318356489, 0.8213457076566125, 0.6598502304147466, 0.5509666080843585, 0.9592746730083235, 0.9067013287117274, 0.6982558139534883, 0.6052104208416834]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.93897824 0.91187559 0.91237362 0.85920926 0.89502488 0.84292453\n",
      " 0.81452014 0.67215428 0.72264246 0.58984375 0.56177606 0.41211519\n",
      " 0.80193483 0.77546072 0.64705882 0.57190635]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.06%, post_traincycle_acc : 74.56%, total_acc : 74.76196880%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 74.56%\n",
      "accuracy_check 실행 시간: 26.428초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.00716751, loss_normal : 0.00954590, loss_coarse : 0.04196214, min_loss : 0.00716751, min_loss_normal : 0.00954590, min_loss_coarse : 0.04196214, wrong_element_sum : 8056732.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.701초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318390%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 86.11%, kmeans average accuracy : 86.11482308%, total [0.972965281730222, 0.9738784781374219, 0.9723899913718723, 0.9597006332757628, 0.9563049853372434, 0.9491477272727272, 0.9108765757842275, 0.7549631310266591, 0.9488619568430388, 0.8868909512761021, 0.7168778801843319, 0.6036906854130053, 0.9574910820451843, 0.9015020219526285, 0.7116279069767442, 0.6012024048096193]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96783349 0.95994345 0.947039   0.89537126 0.91691542 0.88396226\n",
      " 0.81054202 0.76857949 0.74029249 0.64013672 0.63996139 0.42999007\n",
      " 0.85794297 0.77934045 0.62205882 0.59245103]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.80%, post_traincycle_acc : 77.83%, total_acc : 77.81758251%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.83%\n",
      "accuracy_check 실행 시간: 25.334초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.00649434, loss_normal : 0.00930655, loss_coarse : 0.03928607, min_loss : 0.00649434, min_loss_normal : 0.00930655, min_loss_coarse : 0.03928607, wrong_element_sum : 7542926.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.097초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.27113498%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6014886916690524]\n",
      "save model\n",
      "kmeans average accuracy best : 86.57%, kmeans average accuracy : 86.56730481%, total [0.9732498577120091, 0.9735945485519591, 0.9706643658326143, 0.9602763385146805, 0.956891495601173, 0.9485795454545455, 0.9032541776605101, 0.7192285876347135, 0.9580254212237659, 0.8802204176334106, 0.7200460829493087, 0.6048623315758641, 0.9586801426872771, 0.9182553437319468, 0.7255813953488373, 0.6793587174348698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96688742 0.95994345 0.93355802 0.91031823 0.91293532 0.89481132\n",
      " 0.83291895 0.69379116 0.77458396 0.66357422 0.5984556  0.41857001\n",
      " 0.88645621 0.80649855 0.6377451  0.62302914]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.12%, post_traincycle_acc : 78.21%, total_acc : 78.58016859%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.21%\n",
      "accuracy_check 실행 시간: 25.333초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.00626389, loss_normal : 0.00922765, loss_coarse : 0.03835831, min_loss : 0.00626389, min_loss_normal : 0.00922765, min_loss_coarse : 0.03835831, wrong_element_sum : 7364796.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 105.107초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.25672712%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.600629831090753]\n",
      "kmeans average accuracy best : 86.57%, kmeans average accuracy : 85.60042640%, total [0.9721115537848606, 0.9721749006246451, 0.9677883232671843, 0.9513529073114565, 0.9563049853372434, 0.9488636363636364, 0.9038405159777192, 0.7002268859897901, 0.9565474430978421, 0.8796403712296984, 0.6682027649769585, 0.6025190392501465, 0.9598692033293698, 0.9225880993645291, 0.7130813953488372, 0.6209561981105067]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.96512724 0.92970631 0.89440694 0.93482587 0.91273585\n",
      " 0.85678767 0.7144873  0.79525971 0.64697266 0.62451737 0.43644489\n",
      " 0.91038697 0.77691562 0.65343137 0.62016245]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.14%, post_traincycle_acc : 79.01%, total_acc : 79.06373793%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.21%\n",
      "accuracy_check 실행 시간: 25.305초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.00615561, loss_normal : 0.00918217, loss_coarse : 0.03775159, min_loss : 0.00615561, min_loss_normal : 0.00918217, min_loss_coarse : 0.03775159, wrong_element_sum : 7248306.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.539초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.26936073%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 86.57%, kmeans average accuracy : 86.25873879%, total [0.9732498577120091, 0.9718909710391823, 0.9686511360368133, 0.9510650546919976, 0.955425219941349, 0.95, 0.910583406625623, 0.7044809982983551, 0.9559562518474727, 0.884860788863109, 0.7324308755760369, 0.5363210310486233, 0.9580856123662307, 0.8951473136915078, 0.8151162790697675, 0.6381334096764959]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96452223 0.9594722  0.94077997 0.90308582 0.92288557 0.92075472\n",
      " 0.82595724 0.67826905 0.76651538 0.64648438 0.68098456 0.43098312\n",
      " 0.9185336  0.76091174 0.68431373 0.61156235]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.49%, post_traincycle_acc : 78.85%, total_acc : 79.10707294%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.21%\n",
      "accuracy_check 실행 시간: 25.224초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.00604563, loss_normal : 0.00914080, loss_coarse : 0.03716522, min_loss : 0.00604563, min_loss_normal : 0.00914080, min_loss_coarse : 0.03716522, wrong_element_sum : 7135722.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.994초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.24789092%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 86.75%, kmeans average accuracy : 86.74836417%, total [0.9732498577120091, 0.9710391822827938, 0.9651998849582973, 0.9484743811168682, 0.9551319648093841, 0.9505681818181818, 0.9079448841981823, 0.7192285876347135, 0.950931126219332, 0.8709396751740139, 0.6592741935483871, 0.517867603983597, 0.9637336504161712, 0.9332755632582322, 0.8665697674418604, 0.7263097623819067]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499527 0.96512724 0.9364468  0.89440694 0.91492537 0.88113208\n",
      " 0.85131775 0.70649106 0.76500252 0.62158203 0.63223938 0.4245283\n",
      " 0.91293279 0.81959263 0.69656863 0.6411849 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.37%, post_traincycle_acc : 78.93%, total_acc : 79.10795205%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.93%\n",
      "accuracy_check 실행 시간: 26.382초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.00596950, loss_normal : 0.00911366, loss_coarse : 0.03679310, min_loss : 0.00596950, min_loss_normal : 0.00911366, min_loss_coarse : 0.03679310, wrong_element_sum : 7064276.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.729초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.26213338%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.600629831090753]\n",
      "save model\n",
      "kmeans average accuracy best : 87.09%, kmeans average accuracy : 87.09009096%, total [0.9726807057484348, 0.9718909710391823, 0.9649122807017544, 0.9490500863557858, 0.9551319648093841, 0.9519886363636364, 0.9102902374670184, 0.7285876347135565, 0.9456104049660065, 0.8752900232018561, 0.6719470046082949, 0.5389572349150556, 0.9625445897740785, 0.9442518775274408, 0.8744186046511628, 0.7168622960206127]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.9604147  0.94029851 0.89392478 0.88109453 0.90849057\n",
      " 0.85529587 0.59172154 0.77155825 0.66308594 0.63030888 0.42899702\n",
      " 0.93177189 0.76382153 0.69264706 0.61729575]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.83%, post_traincycle_acc : 78.10%, total_acc : 78.39185580%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.10%\n",
      "accuracy_check 실행 시간: 25.349초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.00594061, loss_normal : 0.00909379, loss_coarse : 0.03647582, min_loss : 0.00594061, min_loss_normal : 0.00909379, min_loss_coarse : 0.03647582, wrong_element_sum : 7003358.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.414초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.24970778%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 87.09%, kmeans average accuracy : 86.83212311%, total [0.9726807057484348, 0.9730266893810335, 0.9657750934713834, 0.9542314335060449, 0.9551319648093841, 0.946590909090909, 0.9082380533567869, 0.732274532047646, 0.948566361217854, 0.8723897911832946, 0.6664746543778802, 0.5872876391329819, 0.9631391200951248, 0.9361640670132871, 0.8587209302325581, 0.6524477526481535]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9640492  0.95475966 0.9311507  0.8852459  0.94577114 0.91792453\n",
      " 0.8677275  0.76152399 0.79525971 0.68896484 0.61534749 0.43098312\n",
      " 0.92107943 0.82783705 0.70686275 0.6526517 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.38%, post_traincycle_acc : 80.42%, total_acc : 80.40438899%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.10%\n",
      "accuracy_check 실행 시간: 26.067초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.00584283, loss_normal : 0.00906623, loss_coarse : 0.03604229, min_loss : 0.00584283, min_loss_normal : 0.00906623, min_loss_coarse : 0.03604229, wrong_element_sum : 6920120.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.849초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.24782986%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5983395362152877]\n",
      "save model\n",
      "kmeans average accuracy best : 87.33%, kmeans average accuracy : 87.32790872%, total [0.9732498577120091, 0.9716070414537195, 0.9672131147540983, 0.9530800230282096, 0.955425219941349, 0.9457386363636363, 0.9061858692465553, 0.7353942144072604, 0.9441324268400828, 0.8718097447795824, 0.7128456221198156, 0.5685413005272407, 0.9661117717003567, 0.9448295782784517, 0.8709302325581395, 0.685370741482966]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96215705 0.96229972 0.93307655 0.88572806 0.93084577 0.92216981\n",
      " 0.85827946 0.72577611 0.76298538 0.67333984 0.65299228 0.41807349\n",
      " 0.901222   0.79243453 0.65882353 0.65504061]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.51%, post_traincycle_acc : 79.35%, total_acc : 79.41419098%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.35%\n",
      "accuracy_check 실행 시간: 29.152초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.00586340, loss_normal : 0.00907329, loss_coarse : 0.03615275, min_loss : 0.00584283, min_loss_normal : 0.00906623, min_loss_coarse : 0.03604229, wrong_element_sum : 6941328.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.824초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 88.20%, kmeans average accuracy : 88.19990965%, total [0.972965281730222, 0.9730266893810335, 0.9703767615760713, 0.9591249280368451, 0.9560117302052786, 0.9463068181818182, 0.9076517150395779, 0.7461712989222915, 0.9459060005911912, 0.8854408352668214, 0.746831797235023, 0.6136496777973052, 0.9655172413793104, 0.9480069324090121, 0.8767441860465116, 0.6982536501574578]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96783349 0.96371348 0.93307655 0.89922854 0.9318408  0.90424528\n",
      " 0.86126305 0.73753528 0.81593545 0.66357422 0.62934363 0.4245283\n",
      " 0.90274949 0.85499515 0.74166667 0.62637363]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.44%, post_traincycle_acc : 80.36%, total_acc : 80.39085433%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.36%\n",
      "accuracy_check 실행 시간: 25.359초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.00581950, loss_normal : 0.00905917, loss_coarse : 0.03590748, min_loss : 0.00581950, min_loss_normal : 0.00905917, min_loss_coarse : 0.03590748, wrong_element_sum : 6894236.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.777초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 88.20%, kmeans average accuracy : 87.63643370%, total [0.9735344336937962, 0.9724588302101079, 0.9692263445498993, 0.9565342544617156, 0.9557184750733138, 0.9477272727272728, 0.9070653767223688, 0.7339761769710721, 0.942654448714159, 0.875, 0.7289746543778802, 0.5902167545401289, 0.9646254458977408, 0.9448295782784517, 0.8790697674418605, 0.6802175780131692]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95695364 0.94580584 0.92489167 0.88813886 0.94278607 0.91273585\n",
      " 0.85231228 0.72718721 0.77609682 0.61230469 0.59459459 0.42601787\n",
      " 0.92464358 0.85790495 0.68529412 0.68275203]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.98%, post_traincycle_acc : 79.44%, total_acc : 79.66028272%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.36%\n",
      "accuracy_check 실행 시간: 25.768초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.00578083, loss_normal : 0.00905702, loss_coarse : 0.03586574, min_loss : 0.00578083, min_loss_normal : 0.00905702, min_loss_coarse : 0.03586574, wrong_element_sum : 6886222.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 133.482초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.23317572%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.7991791263559074, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 88.20%, kmeans average accuracy : 88.18357055%, total [0.9732498577120091, 0.9735945485519591, 0.9698015530629853, 0.9565342544617156, 0.955425219941349, 0.9460227272727273, 0.9079448841981823, 0.7439024390243902, 0.9464971918415608, 0.8709396751740139, 0.75, 0.6165787932044523, 0.9658145065398336, 0.9471403812824957, 0.8799418604651162, 0.7059833953621529]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96452223 0.95994345 0.92296582 0.87897782 0.93432836 0.89386792\n",
      " 0.83142715 0.75587959 0.76601109 0.61181641 0.65057915 0.43942403\n",
      " 0.94144603 0.80310378 0.7        0.66220736]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.68%, post_traincycle_acc : 79.48%, total_acc : 79.56277978%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.36%\n",
      "accuracy_check 실행 시간: 25.948초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.00575765, loss_normal : 0.00905191, loss_coarse : 0.03574223, min_loss : 0.00575765, min_loss_normal : 0.00905191, min_loss_coarse : 0.03574223, wrong_element_sum : 6862508.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.167초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.81%, kmeans average accuracy : 88.80504339%, total [0.9732498577120091, 0.9733106189664963, 0.9703767615760713, 0.9582613701784686, 0.9557184750733138, 0.9508522727272727, 0.9161536206391088, 0.7586500283607487, 0.9491575524682234, 0.8935614849187935, 0.7658410138248848, 0.616871704745167, 0.9652199762187872, 0.9474292316580012, 0.8723837209302325, 0.7417692527912969]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96546831 0.96701225 0.9417429  0.89537126 0.91890547 0.91981132\n",
      " 0.86176032 0.73000941 0.80181543 0.64794922 0.56949807 0.40119166\n",
      " 0.92515275 0.77206596 0.68627451 0.64357382]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.23%, post_traincycle_acc : 79.05%, total_acc : 79.11894116%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.05%\n",
      "accuracy_check 실행 시간: 25.608초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.00573904, loss_normal : 0.00904249, loss_coarse : 0.03562948, min_loss : 0.00573904, min_loss_normal : 0.00904249, min_loss_coarse : 0.03562948, wrong_element_sum : 6840860.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.995초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25131332%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 88.81%, kmeans average accuracy : 88.42662653%, total [0.9735344336937962, 0.9730266893810335, 0.9715271786022434, 0.9608520437535981, 0.956891495601173, 0.9519886363636364, 0.9123424215772501, 0.7833238797504254, 0.950931126219332, 0.888631090487239, 0.7799539170506913, 0.5931458699472759, 0.964922711058264, 0.9485846331600231, 0.8744186046511628, 0.6641855138849126]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96168401 0.96277097 0.93307655 0.88235294 0.92487562 0.87169811\n",
      " 0.83092989 0.75823142 0.79021684 0.62988281 0.59893822 0.41708044\n",
      " 0.93075356 0.80261882 0.70441176 0.6383182 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.89%, post_traincycle_acc : 78.99%, total_acc : 78.94800393%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.05%\n",
      "accuracy_check 실행 시간: 26.507초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.00576912, loss_normal : 0.00904765, loss_coarse : 0.03571578, min_loss : 0.00573904, min_loss_normal : 0.00904249, min_loss_coarse : 0.03562948, wrong_element_sum : 6857430.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.088초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219934%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 88.81%, kmeans average accuracy : 88.65514315%, total [0.972965281730222, 0.9741624077228848, 0.9723899913718723, 0.9605641911341393, 0.9560117302052786, 0.9505681818181818, 0.9141014365288772, 0.7657402155416903, 0.9405852793378658, 0.87877030162413, 0.7618087557603687, 0.6423550087873462, 0.9658145065398336, 0.9459849797804737, 0.8758720930232559, 0.7071285427998855]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96688742 0.96512724 0.93548387 0.89054966 0.90099502 0.90471698\n",
      " 0.86275485 0.73095014 0.71507816 0.65673828 0.58445946 0.42999007\n",
      " 0.9114053  0.8171678  0.65784314 0.66268514]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.99%, post_traincycle_acc : 78.71%, total_acc : 78.81847137%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.05%\n",
      "accuracy_check 실행 시간: 25.968초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.00566457, loss_normal : 0.00902018, loss_coarse : 0.03529201, min_loss : 0.00566457, min_loss_normal : 0.00902018, min_loss_coarse : 0.03529201, wrong_element_sum : 6776066.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.070초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.26929847%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6009161179501861]\n",
      "kmeans average accuracy best : 88.81%, kmeans average accuracy : 88.27929970%, total [0.9735344336937962, 0.9744463373083475, 0.9712395743457003, 0.9605641911341393, 0.955425219941349, 0.9497159090909091, 0.9085312225153914, 0.7609188882586501, 0.942654448714159, 0.8677494199535963, 0.7315668202764977, 0.6303456356180434, 0.9664090368608799, 0.9462738301559792, 0.8773255813953489, 0.7079874033781849]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.95475966 0.94077997 0.8828351  0.93134328 0.91650943\n",
      " 0.8463451  0.73095014 0.75895108 0.61962891 0.60086873 0.40913605\n",
      " 0.91955193 0.86517944 0.71323529 0.64452938]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.21%, post_traincycle_acc : 79.39%, total_acc : 79.31631534%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.05%\n",
      "accuracy_check 실행 시간: 25.964초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.00562447, loss_normal : 0.00900846, loss_coarse : 0.03512053, min_loss : 0.00562447, min_loss_normal : 0.00900846, min_loss_coarse : 0.03512053, wrong_element_sum : 6743142.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.615초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.26030857%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.62%, kmeans average accuracy : 89.62086892%, total [0.9746727376209448, 0.9741624077228848, 0.9715271786022434, 0.9617156016119747, 0.9565982404692082, 0.95, 0.9167399589563178, 0.7773681225184345, 0.9467927874667454, 0.8900812064965197, 0.7681451612903226, 0.6499707088459286, 0.9673008323424495, 0.950895436164067, 0.8869186046511628, 0.7964500429430289]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96972564 0.96795476 0.9417429  0.90983607 0.93880597 0.87216981\n",
      " 0.84833416 0.70696143 0.79072113 0.625      0.64285714 0.41112214\n",
      " 0.92311609 0.80358875 0.69901961 0.64166269]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.45%, post_traincycle_acc : 79.33%, total_acc : 79.37745220%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.33%\n",
      "accuracy_check 실행 시간: 25.359초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.00561198, loss_normal : 0.00900471, loss_coarse : 0.03508622, min_loss : 0.00561198, min_loss_normal : 0.00900471, min_loss_coarse : 0.03508622, wrong_element_sum : 6736554.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.902초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26393060%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.62%, kmeans average accuracy : 89.05677688%, total [0.9735344336937962, 0.9735945485519591, 0.9692263445498993, 0.959412780656304, 0.9548387096774194, 0.9508522727272727, 0.9135150982116681, 0.7631877481565513, 0.9524091043452557, 0.8921113689095128, 0.7880184331797235, 0.5957820738137083, 0.9652199762187872, 0.9439630271519353, 0.8752906976744186, 0.7781276839393072]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.96135721 0.93740973 0.89103182 0.88955224 0.88349057\n",
      " 0.85579314 0.74929445 0.77962683 0.63769531 0.62982625 0.39275074\n",
      " 0.93126273 0.81765276 0.69754902 0.63592929]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.33%, post_traincycle_acc : 79.15%, total_acc : 79.21703429%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.33%\n",
      "accuracy_check 실행 시간: 25.821초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.00558948, loss_normal : 0.00900433, loss_coarse : 0.03504104, min_loss : 0.00558948, min_loss_normal : 0.00900433, min_loss_coarse : 0.03504104, wrong_element_sum : 6727880.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.962초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.62%, kmeans average accuracy : 89.08990877%, total [0.9735344336937962, 0.9733106189664963, 0.9692263445498993, 0.9571099597006333, 0.9565982404692082, 0.95, 0.9108765757842275, 0.761769710720363, 0.948566361217854, 0.8868909512761021, 0.7574884792626728, 0.6206795547744581, 0.9664090368608799, 0.9491623339110341, 0.8860465116279069, 0.7867162897223018]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96641438 0.96229972 0.93163216 0.88379942 0.94079602 0.8509434\n",
      " 0.84336151 0.73189087 0.7175996  0.59033203 0.61052124 0.42403178\n",
      " 0.93635438 0.79873909 0.66960784 0.64500717]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.00%, post_traincycle_acc : 78.15%, total_acc : 78.08826455%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.33%\n",
      "accuracy_check 실행 시간: 25.403초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.00556860, loss_normal : 0.00899768, loss_coarse : 0.03496456, min_loss : 0.00556860, min_loss_normal : 0.00899768, min_loss_coarse : 0.03496456, wrong_element_sum : 6713196.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.576초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26752291%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6009161179501861]\n",
      "kmeans average accuracy best : 89.62%, kmeans average accuracy : 88.00418303%, total [0.9746727376209448, 0.9744463373083475, 0.9721023871153293, 0.9597006332757628, 0.9557184750733138, 0.9482954545454545, 0.9088243916739959, 0.7595008508224617, 0.943836831214898, 0.8723897911832946, 0.7361751152073732, 0.6183362624487405, 0.9670035671819263, 0.9503177354130561, 0.8857558139534883, 0.6535929000858861]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96452223 0.96182846 0.9258546  0.87849566 0.93930348 0.89056604\n",
      " 0.86921929 0.75211665 0.7695411  0.61962891 0.62017375 0.43942403\n",
      " 0.93482688 0.785645   0.71764706 0.61920688]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.55%, post_traincycle_acc : 79.30%, total_acc : 79.40060531%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.33%\n",
      "accuracy_check 실행 시간: 25.870초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.00557742, loss_normal : 0.00900200, loss_coarse : 0.03501327, min_loss : 0.00556860, min_loss_normal : 0.00899768, min_loss_coarse : 0.03496456, wrong_element_sum : 6722548.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.253초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318100%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.62%, kmeans average accuracy : 89.13793497%, total [0.9746727376209448, 0.9738784781374219, 0.9680759275237274, 0.9553828439838803, 0.9557184750733138, 0.9497159090909091, 0.919671650542363, 0.784458309699376, 0.9373337274608335, 0.855568445475638, 0.7560483870967742, 0.6280023432923257, 0.9664090368608799, 0.9471403812824957, 0.8895348837209303, 0.800458058975093]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.96229972 0.9205585  0.8780135  0.91691542 0.8995283\n",
      " 0.83142715 0.74553151 0.73373676 0.60839844 0.63996139 0.408143\n",
      " 0.9185336  0.81522793 0.72647059 0.64166269]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.87%, post_traincycle_acc : 78.86%, total_acc : 78.85956559%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.33%\n",
      "accuracy_check 실행 시간: 25.898초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.00560269, loss_normal : 0.00900675, loss_coarse : 0.03503203, min_loss : 0.00556860, min_loss_normal : 0.00899768, min_loss_coarse : 0.03496456, wrong_element_sum : 6726150.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.579초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.24785078%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8913922588099364, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 89.73%, kmeans average accuracy : 89.72537648%, total [0.9741035856573705, 0.9747302668938104, 0.9715271786022434, 0.9625791594703512, 0.9563049853372434, 0.95, 0.9176194664321313, 0.787861599546228, 0.9476795743422998, 0.8767401392111369, 0.7724654377880185, 0.6461628588166374, 0.9678953626634959, 0.9506065857885615, 0.8933139534883721, 0.8064700830231892]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.96371348 0.93211363 0.88813886 0.93532338 0.89764151\n",
      " 0.84286425 0.75917215 0.75441251 0.62890625 0.65444015 0.42204568\n",
      " 0.94551935 0.86323957 0.70735294 0.64739608]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.65%, post_traincycle_acc : 80.05%, total_acc : 79.88668015%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.05%\n",
      "accuracy_check 실행 시간: 27.994초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.00554252, loss_normal : 0.00898653, loss_coarse : 0.03472813, min_loss : 0.00554252, min_loss_normal : 0.00898653, min_loss_coarse : 0.03472813, wrong_element_sum : 6667802.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.359초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313600%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5997709705124534]\n",
      "kmeans average accuracy best : 89.73%, kmeans average accuracy : 89.50623321%, total [0.9735344336937962, 0.9721749006246451, 0.9686511360368133, 0.9588370754173863, 0.9563049853372434, 0.9511363636363637, 0.9184989739079449, 0.7850255246738513, 0.9506355305941472, 0.8915313225058005, 0.7767857142857143, 0.6625659050966608, 0.9643281807372176, 0.9534950895436164, 0.8822674418604651, 0.755224735184655]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9692526  0.95994345 0.92103996 0.89778206 0.93532338 0.90754717\n",
      " 0.8562904  0.75493885 0.84266263 0.65478516 0.63561776 0.39721946\n",
      " 0.91700611 0.81668283 0.69803922 0.63592929]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.96%, post_traincycle_acc : 80.00%, total_acc : 79.98479992%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.05%\n",
      "accuracy_check 실행 시간: 25.855초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.00556940, loss_normal : 0.00899916, loss_coarse : 0.03491311, min_loss : 0.00554252, min_loss_normal : 0.00898653, min_loss_coarse : 0.03472813, wrong_element_sum : 6703318.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.889초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.73%, kmeans average accuracy : 89.68510937%, total [0.9735344336937962, 0.9724588302101079, 0.9698015530629853, 0.9617156016119747, 0.9545454545454546, 0.9517045454545454, 0.9246555262386397, 0.7977878615995462, 0.9476795743422998, 0.8752900232018561, 0.7721774193548387, 0.6631517281780902, 0.9655172413793104, 0.9494511842865395, 0.8834302325581396, 0.7867162897223018]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96830653 0.96559849 0.92633606 0.8804243  0.92636816 0.88113208\n",
      " 0.85181502 0.71966134 0.75895108 0.62304688 0.65009653 0.41857001\n",
      " 0.92362525 0.78758487 0.72009804 0.66316292]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.21%, post_traincycle_acc : 79.15%, total_acc : 79.17787020%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.05%\n",
      "accuracy_check 실행 시간: 27.852초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.00557009, loss_normal : 0.00899863, loss_coarse : 0.03492244, min_loss : 0.00554252, min_loss_normal : 0.00898653, min_loss_coarse : 0.03472813, wrong_element_sum : 6705108.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 134.554초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.24773395%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5997709705124534]\n",
      "kmeans average accuracy best : 89.73%, kmeans average accuracy : 89.45703825%, total [0.9735344336937962, 0.9733106189664963, 0.9715271786022434, 0.9628670120898101, 0.9551319648093841, 0.9519886363636364, 0.9228965112870126, 0.7892796369824163, 0.9488619568430388, 0.8776102088167054, 0.7716013824884793, 0.6493848857644992, 0.9646254458977408, 0.9456961294049683, 0.8726744186046511, 0.7821356999713713]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97256386 0.96324222 0.93740973 0.88669238 0.92238806 0.875\n",
      " 0.86076579 0.74317968 0.7730711  0.67919922 0.67712355 0.42999007\n",
      " 0.92362525 0.74054316 0.70294118 0.6440516 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.70%, post_traincycle_acc : 79.57%, total_acc : 79.62667169%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.05%\n",
      "accuracy_check 실행 시간: 29.173초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.00553306, loss_normal : 0.00898497, loss_coarse : 0.03469710, min_loss : 0.00553306, min_loss_normal : 0.00898497, min_loss_coarse : 0.03469710, wrong_element_sum : 6661844.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 133.975초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.25859621%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.73%, kmeans average accuracy : 89.35454235%, total [0.9732498577120091, 0.9724588302101079, 0.9700891573195284, 0.9608520437535981, 0.9551319648093841, 0.9522727272727273, 0.9223101729698036, 0.8167895632444696, 0.9441324268400828, 0.8619489559164734, 0.7618087557603687, 0.6294669009958992, 0.9619500594530321, 0.9436741767764298, 0.875, 0.7955911823647295]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96688742 0.9604147  0.92489167 0.88138862 0.939801   0.90896226\n",
      " 0.87319741 0.73095014 0.75895108 0.67724609 0.63561776 0.40714995\n",
      " 0.89714868 0.81619787 0.6377451  0.6469183 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.34%, post_traincycle_acc : 79.15%, total_acc : 79.22339725%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.05%\n",
      "accuracy_check 실행 시간: 25.269초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.00553669, loss_normal : 0.00898693, loss_coarse : 0.03474297, min_loss : 0.00553306, min_loss_normal : 0.00898497, min_loss_coarse : 0.03469710, wrong_element_sum : 6670650.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.664초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.22776643%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.7991791263559074, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.73%, kmeans average accuracy : 89.14664115%, total [0.972965281730222, 0.9733106189664963, 0.9695139488064424, 0.9599884858952217, 0.9545454545454546, 0.9522727272727273, 0.9205511580181764, 0.8043108338060124, 0.9447236180904522, 0.8604988399071926, 0.7459677419354839, 0.6241944932630346, 0.9631391200951248, 0.9451184286539572, 0.8784883720930232, 0.7938734612081305]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499527 0.95240339 0.91718825 0.8587271  0.92935323 0.89386792\n",
      " 0.85131775 0.74976482 0.73272819 0.61474609 0.56805019 0.39126117\n",
      " 0.91598778 0.75606208 0.71323529 0.66268514]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.40%, post_traincycle_acc : 77.95%, total_acc : 78.13525506%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.05%\n",
      "accuracy_check 실행 시간: 25.404초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.00550888, loss_normal : 0.00897650, loss_coarse : 0.03453274, min_loss : 0.00550888, min_loss_normal : 0.00897650, min_loss_coarse : 0.03453274, wrong_element_sum : 6630286.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.315초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.76%, kmeans average accuracy : 89.76047118%, total [0.9735344336937962, 0.9733106189664963, 0.9689387402933564, 0.957685664939551, 0.9551319648093841, 0.9525568181818181, 0.9231896804456171, 0.8295519001701644, 0.949748743718593, 0.8857308584686775, 0.7764976958525346, 0.6239015817223199, 0.9646254458977408, 0.9485846331600231, 0.8802325581395349, 0.798454050959061]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.96324222 0.93500241 0.88813886 0.93781095 0.875\n",
      " 0.86524117 0.74882408 0.73121533 0.67382812 0.63513514 0.42552135\n",
      " 0.90020367 0.785645   0.71078431 0.63449594]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.00%, post_traincycle_acc : 79.23%, total_acc : 79.13720447%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.23%\n",
      "accuracy_check 실행 시간: 26.156초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.00554506, loss_normal : 0.00898413, loss_coarse : 0.03467894, min_loss : 0.00550888, min_loss_normal : 0.00897650, min_loss_coarse : 0.03453274, wrong_element_sum : 6658356.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.049초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.76%, kmeans average accuracy : 89.61783479%, total [0.9735344336937962, 0.9733106189664963, 0.9729651998849583, 0.9617156016119747, 0.9548387096774194, 0.9514204545454545, 0.9211374963353856, 0.8074305161656268, 0.9453148093408218, 0.8773201856148491, 0.7672811059907834, 0.6537785588752196, 0.963436385255648, 0.939052570768342, 0.875, 0.8013169195533925]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499527 0.94957587 0.92681753 0.87753134 0.93830846 0.89481132\n",
      " 0.84733963 0.76105362 0.7619768  0.62695312 0.64044402 0.42502483\n",
      " 0.91802444 0.78758487 0.70588235 0.63688485]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.26%, post_traincycle_acc : 79.15%, total_acc : 79.19107495%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.23%\n",
      "accuracy_check 실행 시간: 29.642초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.00549923, loss_normal : 0.00897365, loss_coarse : 0.03447018, min_loss : 0.00549923, min_loss_normal : 0.00897365, min_loss_coarse : 0.03447018, wrong_element_sum : 6618274.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.426초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.23519786%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.76%, kmeans average accuracy : 88.76871072%, total [0.972965281730222, 0.9710391822827938, 0.9683635317802703, 0.9548071387449626, 0.9557184750733138, 0.9514204545454545, 0.9187921430665494, 0.7932501418037436, 0.9388117055867573, 0.8718097447795824, 0.7606566820276498, 0.5975395430579965, 0.9625445897740785, 0.9416522241478914, 0.8712209302325581, 0.7724019467506441]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96783349 0.96088596 0.93548387 0.89537126 0.93930348 0.8990566\n",
      " 0.86673297 0.72577611 0.77660111 0.68017578 0.68050193 0.40963257\n",
      " 0.92922607 0.78031038 0.68970588 0.64070712]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.80%, post_traincycle_acc : 79.86%, total_acc : 79.83370229%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.23%\n",
      "accuracy_check 실행 시간: 25.852초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.00553456, loss_normal : 0.00898164, loss_coarse : 0.03459901, min_loss : 0.00549923, min_loss_normal : 0.00897365, min_loss_coarse : 0.03447018, wrong_element_sum : 6643010.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.336초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.25302741%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8009381413075345, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.76%, kmeans average accuracy : 89.63889217%, total [0.9723961297666477, 0.9713231118682567, 0.9692263445498993, 0.9556706966033391, 0.9551319648093841, 0.9514204545454545, 0.9249486953972442, 0.8167895632444696, 0.946201596216376, 0.8819605568445475, 0.7819700460829493, 0.6567076742823668, 0.9643281807372176, 0.9433853264009243, 0.8700581395348838, 0.7807042656742056]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95884579 0.96418473 0.93355802 0.90019286 0.94477612 0.88820755\n",
      " 0.86424664 0.73753528 0.80786687 0.69921875 0.65009653 0.40019861\n",
      " 0.89256619 0.77352085 0.67303922 0.64882943]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.63%, post_traincycle_acc : 79.61%, total_acc : 79.61577314%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.23%\n",
      "accuracy_check 실행 시간: 25.273초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.00551043, loss_normal : 0.00897136, loss_coarse : 0.03443791, min_loss : 0.00549923, min_loss_normal : 0.00897136, min_loss_coarse : 0.03443791, wrong_element_sum : 6612078.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.084초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035782%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.09%, kmeans average accuracy : 90.08642131%, total [0.9681274900398407, 0.9718909710391823, 0.9712395743457003, 0.9631548647092688, 0.9557184750733138, 0.9525568181818181, 0.9287598944591029, 0.8352240499149177, 0.9512267218445167, 0.890661252900232, 0.7932027649769585, 0.6763327475102519, 0.9610582639714625, 0.9465626805314847, 0.8651162790697674, 0.7829945605496708]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.9604147  0.93885412 0.91224687 0.93681592 0.90141509\n",
      " 0.87419194 0.75352775 0.81391831 0.69433594 0.57866795 0.42750745\n",
      " 0.89256619 0.82201746 0.69411765 0.62971811]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.87%, post_traincycle_acc : 79.99%, total_acc : 79.94195472%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.99%\n",
      "accuracy_check 실행 시간: 25.933초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.00550928, loss_normal : 0.00896957, loss_coarse : 0.03445013, min_loss : 0.00549923, min_loss_normal : 0.00896957, min_loss_coarse : 0.03443791, wrong_element_sum : 6614426.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 133.628초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.09%, kmeans average accuracy : 90.07347176%, total [0.9732498577120091, 0.9724588302101079, 0.9703767615760713, 0.9620034542314335, 0.9557184750733138, 0.953125, 0.9252418645558487, 0.839194554736245, 0.9479751699674844, 0.894431554524362, 0.7926267281105991, 0.6675454012888108, 0.9622473246135553, 0.940785673021375, 0.8703488372093023, 0.7844259948468365]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96357616 0.96277097 0.93066923 0.89054966 0.92288557 0.88443396\n",
      " 0.83540527 0.75682032 0.82702975 0.64550781 0.62258687 0.40168818\n",
      " 0.89816701 0.78661494 0.65294118 0.59388438]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.79%, post_traincycle_acc : 78.60%, total_acc : 78.67837551%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.99%\n",
      "accuracy_check 실행 시간: 25.849초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.00555433, loss_normal : 0.00898449, loss_coarse : 0.03462494, min_loss : 0.00549923, min_loss_normal : 0.00896957, min_loss_coarse : 0.03443791, wrong_element_sum : 6647988.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 141.350초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.09%, kmeans average accuracy : 89.94770559%, total [0.9732498577120091, 0.9721749006246451, 0.9692263445498993, 0.9608520437535981, 0.9563049853372434, 0.9528409090909091, 0.9261213720316622, 0.8338060124787294, 0.9479751699674844, 0.8932714617169374, 0.7920506912442397, 0.6684241359109548, 0.9607609988109393, 0.9376083188908145, 0.8651162790697674, 0.7818494131119381]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96263009 0.96512724 0.93548387 0.89826422 0.94626866 0.89669811\n",
      " 0.876181   0.75634995 0.7619768  0.66650391 0.63754826 0.4061569\n",
      " 0.90224033 0.73617847 0.65539216 0.64214047]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.08%, post_traincycle_acc : 79.03%, total_acc : 79.05320440%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.99%\n",
      "accuracy_check 실행 시간: 25.443초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.00560792, loss_normal : 0.00899345, loss_coarse : 0.03481898, min_loss : 0.00549923, min_loss_normal : 0.00896957, min_loss_coarse : 0.03443791, wrong_element_sum : 6685244.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.924초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.26404969%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 90.10247349%, total [0.9715424018212863, 0.9704713231118682, 0.9677883232671843, 0.9585492227979274, 0.9545454545454546, 0.9528409090909091, 0.9340369393139841, 0.8471355643788996, 0.9467927874667454, 0.8831206496519721, 0.7793778801843319, 0.6739894551845342, 0.9613555291319857, 0.9439630271519353, 0.8755813953488372, 0.7953048955052963]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9640492  0.96182846 0.93259509 0.87897782 0.95223881 0.90518868\n",
      " 0.8662357  0.75117592 0.78265255 0.66650391 0.66361004 0.39622642\n",
      " 0.92260692 0.7628516  0.67598039 0.63401816]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.80%, post_traincycle_acc : 79.48%, total_acc : 79.60948920%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 26.288초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.00553189, loss_normal : 0.00896860, loss_coarse : 0.03447979, min_loss : 0.00549923, min_loss_normal : 0.00896860, min_loss_coarse : 0.03443791, wrong_element_sum : 6620120.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.420초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.26033817%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 89.61006324%, total [0.9723961297666477, 0.9707552526973311, 0.9675007190106414, 0.9507772020725389, 0.9557184750733138, 0.9534090909090909, 0.9261213720316622, 0.8216108905275099, 0.948566361217854, 0.8851508120649652, 0.7733294930875576, 0.6540714704159344, 0.9625445897740785, 0.9413633737723859, 0.876453488372093, 0.777841397079874]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96215705 0.96229972 0.92778045 0.87126326 0.9358209  0.87830189\n",
      " 0.86275485 0.73847601 0.82702975 0.64355469 0.63947876 0.40714995\n",
      " 0.92107943 0.73763337 0.67107843 0.63306259]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.04%, post_traincycle_acc : 78.87%, total_acc : 78.93614830%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 25.517초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.00549113, loss_normal : 0.00895783, loss_coarse : 0.03428819, min_loss : 0.00549113, min_loss_normal : 0.00895783, min_loss_coarse : 0.03428819, wrong_element_sum : 6583332.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 99.918초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.27479854%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5889976958525346, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 90.09957190%, total [0.9681274900398407, 0.9699034639409426, 0.9660626977279264, 0.9536557282671272, 0.9560117302052786, 0.9539772727272727, 0.9328642626795661, 0.8505388542257516, 0.9515223174697014, 0.8912412993039444, 0.7911866359447005, 0.6810193321616872, 0.9625445897740785, 0.940785673021375, 0.8715116279069768, 0.7749785284855425]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96215705 0.96324222 0.9311507  0.90260366 0.95223881 0.90849057\n",
      " 0.87071109 0.74412041 0.79778114 0.68554688 0.64478764 0.43048659\n",
      " 0.90885947 0.73908826 0.6754902  0.62589584]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.99%, post_traincycle_acc : 79.64%, total_acc : 79.78136232%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 29.852초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.00551265, loss_normal : 0.00896753, loss_coarse : 0.03441235, min_loss : 0.00549113, min_loss_normal : 0.00895783, min_loss_coarse : 0.03428819, wrong_element_sum : 6607172.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.498초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 89.65748102%, total [0.9678429140580534, 0.969335604770017, 0.9637618636755824, 0.9467472654001151, 0.955425219941349, 0.9539772727272727, 0.9302257402521255, 0.8315371525808282, 0.9512267218445167, 0.8929814385150812, 0.7897465437788018, 0.6616871704745168, 0.960166468489893, 0.9399191218948585, 0.8630813953488372, 0.7675350701402806]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96310312 0.95805844 0.91718825 0.87753134 0.94378109 0.91415094\n",
      " 0.87916459 0.75729069 0.82955119 0.66650391 0.66071429 0.46822244\n",
      " 0.91955193 0.79340446 0.66813725 0.60582895]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.17%, post_traincycle_acc : 80.14%, total_acc : 80.15219686%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 25.810초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.00557298, loss_normal : 0.00898060, loss_coarse : 0.03462123, min_loss : 0.00549113, min_loss_normal : 0.00895783, min_loss_coarse : 0.03428819, wrong_element_sum : 6647276.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.030초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.25672249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 89.55971190%, total [0.9692657939669892, 0.9684838160136287, 0.9643370721886684, 0.9530800230282096, 0.9571847507331378, 0.9548295454545455, 0.9308120785693345, 0.8437322745320477, 0.9544782737215489, 0.8863109048723898, 0.7785138248847926, 0.6499707088459286, 0.9598692033293698, 0.9312536106296938, 0.8607558139534883, 0.7666762095619811]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9640492  0.96135721 0.93355802 0.8948891  0.94925373 0.90849057\n",
      " 0.87518647 0.75070555 0.86585981 0.62939453 0.65009653 0.40367428\n",
      " 0.91496945 0.72599418 0.61421569 0.59245103]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.39%, post_traincycle_acc : 78.96%, total_acc : 79.13605571%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 30.549초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.00552749, loss_normal : 0.00896788, loss_coarse : 0.03439661, min_loss : 0.00549113, min_loss_normal : 0.00895783, min_loss_coarse : 0.03428819, wrong_element_sum : 6604150.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.026초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.26938408%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6009161179501861]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 90.09459411%, total [0.9695503699487763, 0.969335604770017, 0.9654874892148404, 0.9542314335060449, 0.955425219941349, 0.9551136363636363, 0.9331574318381706, 0.8567782189449802, 0.9512267218445167, 0.8889211136890951, 0.7825460829493087, 0.6804335090802578, 0.9613555291319857, 0.9410745233968805, 0.8715116279069768, 0.7789865445176066]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9640492  0.95758718 0.93066923 0.88138862 0.95373134 0.92075472\n",
      " 0.88264545 0.7841016  0.82198689 0.67138672 0.60569498 0.4245283\n",
      " 0.90631365 0.78273521 0.64313725 0.63592929]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.38%, post_traincycle_acc : 79.79%, total_acc : 80.03205312%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 25.820초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.00549516, loss_normal : 0.00896059, loss_coarse : 0.03430534, min_loss : 0.00549113, min_loss_normal : 0.00895783, min_loss_coarse : 0.03428819, wrong_element_sum : 6586626.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 132.801초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.24597461%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5986258230747209]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 90.03777407%, total [0.9675583380762663, 0.9687677455990914, 0.9646246764452114, 0.9476108232584917, 0.9560117302052786, 0.9556818181818182, 0.9337437701553797, 0.8601815087918321, 0.952113508720071, 0.888631090487239, 0.7831221198156681, 0.6883421206795548, 0.9598692033293698, 0.938474870017331, 0.8697674418604651, 0.7715430861723447]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96310312 0.96277097 0.93259509 0.88187078 0.95024876 0.93113208\n",
      " 0.8677275  0.74506115 0.85224407 0.62451172 0.38706564 0.43098312\n",
      " 0.90885947 0.77061106 0.64705882 0.61920688]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.50%, post_traincycle_acc : 77.97%, total_acc : 78.58398787%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 25.948초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.00547624, loss_normal : 0.00895455, loss_coarse : 0.03420282, min_loss : 0.00547624, min_loss_normal : 0.00895455, min_loss_coarse : 0.03420282, wrong_element_sum : 6566942.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.977초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 89.33522875%, total [0.9678429140580534, 0.9684838160136287, 0.9623238423928674, 0.9418537708693149, 0.9557184750733138, 0.9542613636363636, 0.9296394019349165, 0.8440158820192853, 0.9506355305941472, 0.8816705336426914, 0.7811059907834101, 0.672231985940246, 0.9598692033293698, 0.9318313113807047, 0.8563953488372092, 0.7357572287432007]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96310312 0.96371348 0.93307655 0.89874638 0.95323383 0.92924528\n",
      " 0.87717553 0.76246472 0.84669692 0.66552734 0.58108108 0.41658391\n",
      " 0.91649695 0.79437439 0.66470588 0.61920688]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.53%, post_traincycle_acc : 79.91%, total_acc : 80.15890909%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 27.366초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.00543482, loss_normal : 0.00894572, loss_coarse : 0.03406483, min_loss : 0.00543482, min_loss_normal : 0.00894572, min_loss_coarse : 0.03406483, wrong_element_sum : 6540448.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 135.764초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219934%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 89.91920716%, total [0.9652817302219693, 0.9673480976717774, 0.9623238423928674, 0.9447322970639033, 0.9574780058651027, 0.95625, 0.9334506009967751, 0.8638684061259218, 0.9527046999704404, 0.8863109048723898, 0.7943548387096774, 0.6906854130052724, 0.9583828775267539, 0.9321201617562103, 0.8656976744186047, 0.7560835957629545]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.9594722  0.93981704 0.89392478 0.93880597 0.91886792\n",
      " 0.88314272 0.74506115 0.82198689 0.67822266 0.43050193 0.43296922\n",
      " 0.93228106 0.77837051 0.63970588 0.62780698]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.77%, post_traincycle_acc : 78.67%, total_acc : 79.11223440%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 26.289초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.00546990, loss_normal : 0.00895497, loss_coarse : 0.03419138, min_loss : 0.00543482, min_loss_normal : 0.00894572, min_loss_coarse : 0.03406483, wrong_element_sum : 6564746.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.998초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 89.99894921%, total [0.9658508821855435, 0.967915956842703, 0.9631866551624964, 0.9473229706390328, 0.9571847507331378, 0.9542613636363636, 0.9340369393139841, 0.8672716959727736, 0.9506355305941472, 0.8892111368909513, 0.7914746543778802, 0.6874633860574106, 0.9607609988109393, 0.9274985557481225, 0.8622093023255814, 0.7735470941883767]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96310312 0.95994345 0.93452094 0.90115718 0.95422886 0.93018868\n",
      " 0.87667827 0.76575729 0.74533535 0.64697266 0.36486486 0.42949355\n",
      " 0.90784114 0.73811833 0.64068627 0.60774009]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.12%, post_traincycle_acc : 77.29%, total_acc : 77.62401518%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 31.611초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.00545713, loss_normal : 0.00895034, loss_coarse : 0.03409076, min_loss : 0.00543482, min_loss_normal : 0.00894572, min_loss_coarse : 0.03406483, wrong_element_sum : 6545426.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.731초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.10%, kmeans average accuracy : 88.75432213%, total [0.964712578258395, 0.9656445201590006, 0.9617486338797814, 0.945308002302821, 0.9583577712609971, 0.95625, 0.9363822925828202, 0.8706749858196257, 0.9550694649719185, 0.8958816705336426, 0.6042626728110599, 0.677211482132396, 0.9607609988109393, 0.939052570768342, 0.8593023255813953, 0.7500715717148583]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96168401 0.96088596 0.94029851 0.88621022 0.95223881 0.92122642\n",
      " 0.87220288 0.73236124 0.82854261 0.63525391 0.36486486 0.44637537\n",
      " 0.91089613 0.75751697 0.64264706 0.59245103]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.24%, post_traincycle_acc : 77.54%, total_acc : 77.81839001%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.48%\n",
      "accuracy_check 실행 시간: 25.834초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.00543006, loss_normal : 0.00894492, loss_coarse : 0.03399897, min_loss : 0.00543006, min_loss_normal : 0.00894492, min_loss_coarse : 0.03399897, wrong_element_sum : 6527802.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.960초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.26216613%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5889976958525346, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.15%, kmeans average accuracy : 90.15301874%, total [0.9669891861126921, 0.9687677455990914, 0.9611734253666955, 0.9412780656303973, 0.9571847507331378, 0.9542613636363636, 0.9334506009967751, 0.8633011911514464, 0.9580254212237659, 0.9019721577726219, 0.7955069124423964, 0.6789689513766842, 0.9607609988109393, 0.9404968226458694, 0.8625, 0.779845405095906]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96546831 0.96277097 0.93355802 0.8948891  0.95223881 0.9245283\n",
      " 0.87270015 0.74412041 0.84568835 0.66210938 0.36920849 0.40466733\n",
      " 0.93380855 0.80552861 0.68186275 0.61968466]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.69%, post_traincycle_acc : 78.58%, total_acc : 79.02693947%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.58%\n",
      "accuracy_check 실행 시간: 27.932초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.00545304, loss_normal : 0.00895063, loss_coarse : 0.03405534, min_loss : 0.00543006, min_loss_normal : 0.00894492, min_loss_coarse : 0.03399897, wrong_element_sum : 6538626.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.931초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.15%, kmeans average accuracy : 89.60978261%, total [0.9652817302219693, 0.9662123793299262, 0.9634742594190394, 0.9461715601611975, 0.9565982404692082, 0.9551136363636363, 0.9334506009967751, 0.8701077708451503, 0.9532958912208099, 0.8903712296983759, 0.771889400921659, 0.674282366725249, 0.9640309155766944, 0.9425187752744079, 0.8601744186046512, 0.7245920412253077]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96121097 0.95570217 0.93981704 0.89826422 0.95323383 0.93490566\n",
      " 0.88562904 0.74412041 0.86132123 0.70458984 0.54584942 0.44637537\n",
      " 0.92260692 0.75024248 0.65637255 0.60678452]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.77%, post_traincycle_acc : 79.79%, total_acc : 79.78510166%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.58%\n",
      "accuracy_check 실행 시간: 25.555초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.00541892, loss_normal : 0.00893634, loss_coarse : 0.03384683, min_loss : 0.00541892, min_loss_normal : 0.00893634, min_loss_coarse : 0.03384683, wrong_element_sum : 6498592.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.046초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.26399946%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5997709705124534]\n",
      "kmeans average accuracy best : 90.15%, kmeans average accuracy : 88.80658663%, total [0.9644280022766079, 0.966496308915389, 0.9605982168536095, 0.9418537708693149, 0.9580645161290322, 0.9576704545454545, 0.9352096159484022, 0.8672716959727736, 0.9530002955956252, 0.8953016241299304, 0.7914746543778802, 0.5951962507322789, 0.9574910820451843, 0.9072790294627383, 0.8322674418604651, 0.7254509018036072]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96168401 0.95617342 0.92970631 0.89199614 0.95422886 0.92358491\n",
      " 0.87916459 0.75258702 0.8623298  0.72412109 0.49517375 0.43793446\n",
      " 0.9114053  0.75509214 0.64068627 0.57716197]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.92%, post_traincycle_acc : 79.08%, total_acc : 79.01626185%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.58%\n",
      "accuracy_check 실행 시간: 28.979초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.00539539, loss_normal : 0.00893506, loss_coarse : 0.03380434, min_loss : 0.00539539, min_loss_normal : 0.00893506, min_loss_coarse : 0.03380434, wrong_element_sum : 6490434.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.737초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.25310536%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8913922588099364, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 90.20983629%, total [0.9658508821855435, 0.9667802385008518, 0.9611734253666955, 0.9404145077720207, 0.9563049853372434, 0.9559659090909091, 0.9375549692172384, 0.872093023255814, 0.952113508720071, 0.8999419953596288, 0.7920506912442397, 0.6942003514938488, 0.9604637336504162, 0.9393414211438474, 0.8709302325581395, 0.76839393071858]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96073794 0.96182846 0.9364468  0.89392478 0.95621891 0.9245283\n",
      " 0.89259075 0.76058325 0.85829551 0.65576172 0.55357143 0.46375372\n",
      " 0.9114053  0.75848691 0.63970588 0.6158624 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.23%, post_traincycle_acc : 79.65%, total_acc : 79.88242207%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 26.589초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.00540181, loss_normal : 0.00893522, loss_coarse : 0.03380034, min_loss : 0.00539539, min_loss_normal : 0.00893506, min_loss_coarse : 0.03380034, wrong_element_sum : 6489666.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.121초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.25319837%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 89.96844369%, total [0.9661354581673307, 0.966496308915389, 0.9597354040839804, 0.9392630972941853, 0.9595307917888563, 0.9588068181818182, 0.9387276458516564, 0.8808848553601815, 0.9532958912208099, 0.900522041763341, 0.7955069124423964, 0.643526654950205, 0.9628418549346016, 0.9350086655112652, 0.8659883720930233, 0.7686802175780132]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.95805844 0.92778045 0.89199614 0.95522388 0.94009434\n",
      " 0.89955246 0.77140169 0.85274836 0.65625    0.56756757 0.43445879\n",
      " 0.91802444 0.785645   0.60735294 0.61395127]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.48%, post_traincycle_acc : 79.62%, total_acc : 79.56567392%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 26.211초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.00542340, loss_normal : 0.00894336, loss_coarse : 0.03392289, min_loss : 0.00539539, min_loss_normal : 0.00893506, min_loss_coarse : 0.03380034, wrong_element_sum : 6513196.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.948초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.25490563%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 87.57360851%, total [0.9672737620944792, 0.9659284497444633, 0.9617486338797814, 0.9458837075417387, 0.9577712609970674, 0.9548295454545455, 0.9337437701553797, 0.8726602382302893, 0.9506355305941472, 0.8860208816705336, 0.6065668202764977, 0.6288810779144698, 0.9610582639714625, 0.9355863662622761, 0.7316860465116279, 0.751503006012024]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96641438 0.96512724 0.94222436 0.90356798 0.95422886 0.92924528\n",
      " 0.90054699 0.75023518 0.86838124 0.63232422 0.56611969 0.4409136\n",
      " 0.93228106 0.75751697 0.61372549 0.59770664]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.58%, post_traincycle_acc : 79.50%, total_acc : 79.53282641%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 25.828초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.00540279, loss_normal : 0.00894142, loss_coarse : 0.03389608, min_loss : 0.00539539, min_loss_normal : 0.00893506, min_loss_coarse : 0.03380034, wrong_element_sum : 6508048.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.536초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.25144684%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.5980532493558546]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 87.90106139%, total [0.9638588503130335, 0.9656445201590006, 0.9634742594190394, 0.9481865284974094, 0.9583577712609971, 0.9571022727272728, 0.9375549692172384, 0.8706749858196257, 0.9583210168489507, 0.9011020881670534, 0.6241359447004609, 0.6444053895723492, 0.9619500594530321, 0.9095898324667822, 0.7328488372093023, 0.7669624964214142]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96546831 0.96277097 0.93981704 0.9045323  0.95522388 0.91933962\n",
      " 0.88264545 0.77516463 0.84467978 0.64404297 0.56418919 0.43346574\n",
      " 0.90733198 0.79243453 0.6245098  0.58862876]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.23%, post_traincycle_acc : 79.40%, total_acc : 79.33081509%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 26.290초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.00538954, loss_normal : 0.00893403, loss_coarse : 0.03375320, min_loss : 0.00538954, min_loss_normal : 0.00893403, min_loss_coarse : 0.03375320, wrong_element_sum : 6480614.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.769초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 87.92518722%, total [0.964712578258395, 0.967915956842703, 0.9611734253666955, 0.9438687392055267, 0.9586510263929618, 0.9588068181818182, 0.9369686309000294, 0.871242200794101, 0.9547738693467337, 0.8793503480278422, 0.6105990783410138, 0.6602226127709432, 0.963436385255648, 0.9274985557481225, 0.7409883720930233, 0.7678213569997138]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.95994345 0.93885412 0.8997107  0.95422886 0.92971698\n",
      " 0.87966186 0.76246472 0.84467978 0.65185547 0.56853282 0.43992056\n",
      " 0.93380855 0.77643065 0.64852941 0.61634018]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.16%, post_traincycle_acc : 79.83%, total_acc : 79.55595812%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 27.724초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.00535920, loss_normal : 0.00892432, loss_coarse : 0.03360170, min_loss : 0.00535920, min_loss_normal : 0.00892432, min_loss_coarse : 0.03360170, wrong_element_sum : 6451526.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.207초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 89.94795077%, total [0.9658508821855435, 0.9659284497444633, 0.9614610296232384, 0.9418537708693149, 0.9586510263929618, 0.9573863636363636, 0.9393139841688655, 0.8732274532047646, 0.9568430387230269, 0.896461716937355, 0.7923387096774194, 0.6508494434680726, 0.9616527942925089, 0.9404968226458694, 0.8555232558139535, 0.7738333810478099]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499527 0.96135721 0.947039   0.90838959 0.95472637 0.93726415\n",
      " 0.87866733 0.77140169 0.85375693 0.73583984 0.56274131 0.45431976\n",
      " 0.92769857 0.81474297 0.64166667 0.6411849 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.57%, post_traincycle_acc : 80.97%, total_acc : 80.81050740%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 25.889초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.00534927, loss_normal : 0.00892108, loss_coarse : 0.03359503, min_loss : 0.00534927, min_loss_normal : 0.00892108, min_loss_coarse : 0.03359503, wrong_element_sum : 6450246.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.670초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315343%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 88.30522118%, total [0.9641434262948207, 0.9667802385008518, 0.9626114466494105, 0.9444444444444444, 0.9577712609970674, 0.9556818181818182, 0.9381413075344474, 0.8726602382302893, 0.949748743718593, 0.8874709976798144, 0.7710253456221198, 0.6364967779730522, 0.9604637336504162, 0.9358752166377816, 0.8555232558139535, 0.5699971371314057]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9602649  0.95852969 0.94029851 0.89633558 0.95373134 0.93820755\n",
      " 0.87667827 0.75211665 0.87594554 0.66162109 0.55984556 0.46375372\n",
      " 0.92566191 0.73617847 0.63039216 0.61347348]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.76%, post_traincycle_acc : 79.64%, total_acc : 79.69042003%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 26.291초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.00532442, loss_normal : 0.00891654, loss_coarse : 0.03347348, min_loss : 0.00532442, min_loss_normal : 0.00891654, min_loss_coarse : 0.03347348, wrong_element_sum : 6426908.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 132.163초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.26397781%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 86.64158146%, total [0.9672737620944792, 0.9670641680863146, 0.9620362381363244, 0.9412780656303973, 0.9571847507331378, 0.9579545454545455, 0.9375549692172384, 0.8681225184344866, 0.9476795743422998, 0.8973317865429234, 0.6117511520737328, 0.45547744581136496, 0.9622473246135553, 0.9199884459849798, 0.7436046511627907, 0.7661036358431148]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9640492  0.966541   0.9364468  0.90067502 0.95273632 0.94528302\n",
      " 0.87916459 0.75399812 0.84820978 0.63818359 0.56515444 0.44538232\n",
      " 0.91955193 0.76673133 0.66715686 0.60582895]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.37%, post_traincycle_acc : 79.72%, total_acc : 79.58212464%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 30.085초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.00533260, loss_normal : 0.00891625, loss_coarse : 0.03348830, min_loss : 0.00532442, min_loss_normal : 0.00891625, min_loss_coarse : 0.03347348, wrong_element_sum : 6429754.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.066초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.26214421%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 87.60079151%, total [0.9652817302219693, 0.9667802385008518, 0.9591601955708945, 0.932930339666091, 0.9592375366568915, 0.9590909090909091, 0.9399003224860745, 0.8675553034600113, 0.9530002955956252, 0.8889211136890951, 0.7917626728110599, 0.6423550087873462, 0.9631391200951248, 0.9321201617562103, 0.7369186046511628, 0.5579730890352133]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96357616 0.95994345 0.9364468  0.89199614 0.95472637 0.93066038\n",
      " 0.89507708 0.74835372 0.86787695 0.70410156 0.53909266 0.45084409\n",
      " 0.93126273 0.7900097  0.65735294 0.62732919]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.38%, post_traincycle_acc : 80.30%, total_acc : 80.33612799%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 25.865초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.00532995, loss_normal : 0.00891540, loss_coarse : 0.03344798, min_loss : 0.00532442, min_loss_normal : 0.00891540, min_loss_coarse : 0.03344798, wrong_element_sum : 6422012.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.053초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 89.28366780%, total [0.964712578258395, 0.9670641680863146, 0.9617486338797814, 0.9438687392055267, 0.956891495601173, 0.9573863636363636, 0.9396071533274699, 0.8783323879750425, 0.9500443393437777, 0.8953016241299304, 0.7897465437788018, 0.6115992970123023, 0.9595719381688466, 0.92894280762565, 0.8476744186046512, 0.7328943601488692]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96135721 0.94270583 0.90549662 0.95373134 0.94292453\n",
      " 0.86673297 0.74129821 0.83862834 0.66796875 0.54971042 0.44240318\n",
      " 0.92820774 0.72356935 0.60931373 0.58623985]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.17%, post_traincycle_acc : 78.87%, total_acc : 78.99254251%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 26.867초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.00533611, loss_normal : 0.00891814, loss_coarse : 0.03352828, min_loss : 0.00532442, min_loss_normal : 0.00891540, min_loss_coarse : 0.03344798, wrong_element_sum : 6437430.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.384초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.25135622%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 88.76505454%, total [0.9664200341491178, 0.9647927314026121, 0.9617486338797814, 0.9375359815774323, 0.9574780058651027, 0.9582386363636364, 0.9381413075344474, 0.8650028360748724, 0.9532958912208099, 0.8953016241299304, 0.6287442396313364, 0.6230228471001757, 0.9637336504161712, 0.9430964760254188, 0.8674418604651163, 0.7784139707987403]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96215705 0.9604147  0.9364468  0.91224687 0.95721393 0.93867925\n",
      " 0.88413725 0.77516463 0.85224407 0.69726562 0.55791506 0.43346574\n",
      " 0.94501018 0.7613967  0.60637255 0.59722886]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.55%, post_traincycle_acc : 79.86%, total_acc : 79.73553731%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 34.202초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.00532253, loss_normal : 0.00891562, loss_coarse : 0.03340666, min_loss : 0.00532253, min_loss_normal : 0.00891540, min_loss_coarse : 0.03340666, wrong_element_sum : 6414078.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.870초, 전체 시작 시간 20250307_152824_829\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.25493782%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "kmeans average accuracy best : 90.21%, kmeans average accuracy : 89.82027178%, total [0.9641434262948207, 0.9662123793299262, 0.9614610296232384, 0.9389752446747266, 0.9583577712609971, 0.9579545454545455, 0.9396071533274699, 0.8771979580260919, 0.9503399349689624, 0.8976218097447796, 0.7716013824884793, 0.6602226127709432, 0.963436385255648, 0.9312536106296938, 0.8598837209302326, 0.7729745204695104]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96357616 0.96371348 0.94607607 0.90935391 0.95422886 0.94009434\n",
      " 0.89607161 0.75587959 0.86485124 0.72021484 0.53426641 0.45332671\n",
      " 0.94297352 0.77061106 0.61715686 0.61538462]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.32%, post_traincycle_acc : 80.30%, total_acc : 80.30777110%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.65%\n",
      "accuracy_check 실행 시간: 25.701초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '2'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.75 # -cor\n",
    "v_threshold = 0.5 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250226_190044_204.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
