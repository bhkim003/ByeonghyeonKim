{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10750/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "    #         return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    input_argmin = input_slice.argmin(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient Î∞©Ìñ•ÏùÑ argmin Ï™ΩÏúºÎ°ú\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    ooo_fifo = 0\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "            #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "            #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 Ï§ë ÌïòÎÇò ÏÑ†ÌÉù\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                    optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch ÌÅ¨Í∏∞ ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "                        #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "                        #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250709_155101-ruyaiqqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ruyaiqqe' target=\"_blank\">warm-salad-12866</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ruyaiqqe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ruyaiqqe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': '20250709_155059_572', 'my_seed': 1, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.0625, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 6.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_20250704_185524_987.pth', 'learning_rate': 0.0001220703125, 'epoch_num': 1000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [], 'timestep_sums_threshold': 0} \n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[])\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.0625, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[])\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.0625, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0001220703125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-0   lr=['0.0001221'], tr/val_loss:  2.324086/  2.325333, val:  59.73%, val_best:  59.73%, tr:  55.26%, tr_best:  55.26%, epoch time: 64.37 seconds, 1.07 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2083 occurrences\n",
      "train - Value 1: 1949 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-1   lr=['0.0001221'], tr/val_loss:  2.322989/  2.337725, val:  64.60%, val_best:  64.60%, tr:  65.45%, tr_best:  65.45%, epoch time: 62.56 seconds, 1.04 minutes\n",
      "train - Value 0: 2095 occurrences\n",
      "train - Value 1: 1937 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 292 occurrences\n",
      "test - Value 1: 160 occurrences\n",
      "epoch-2   lr=['0.0001221'], tr/val_loss:  2.313538/  2.288837, val:  68.58%, val_best:  68.58%, tr:  69.02%, tr_best:  69.02%, epoch time: 64.02 seconds, 1.07 minutes\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-3   lr=['0.0001221'], tr/val_loss:  2.306445/  2.310518, val:  73.01%, val_best:  73.01%, tr:  77.28%, tr_best:  77.28%, epoch time: 61.87 seconds, 1.03 minutes\n",
      "train - Value 0: 2153 occurrences\n",
      "train - Value 1: 1879 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-4   lr=['0.0001221'], tr/val_loss:  2.305779/  2.335502, val:  63.94%, val_best:  73.01%, tr:  81.97%, tr_best:  81.97%, epoch time: 62.16 seconds, 1.04 minutes\n",
      "train - Value 0: 2100 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-5   lr=['0.0001221'], tr/val_loss:  2.303741/  2.327553, val:  64.16%, val_best:  73.01%, tr:  83.38%, tr_best:  83.38%, epoch time: 62.15 seconds, 1.04 minutes\n",
      "train - Value 0: 2087 occurrences\n",
      "train - Value 1: 1945 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-6   lr=['0.0001221'], tr/val_loss:  2.306056/  2.301476, val:  77.88%, val_best:  77.88%, tr:  87.08%, tr_best:  87.08%, epoch time: 64.98 seconds, 1.08 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-7   lr=['0.0001221'], tr/val_loss:  2.306530/  2.307699, val:  76.99%, val_best:  77.88%, tr:  89.61%, tr_best:  89.61%, epoch time: 63.00 seconds, 1.05 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-8   lr=['0.0001221'], tr/val_loss:  2.305689/  2.297281, val:  79.42%, val_best:  79.42%, tr:  90.30%, tr_best:  90.30%, epoch time: 62.44 seconds, 1.04 minutes\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-9   lr=['0.0001221'], tr/val_loss:  2.303994/  2.309996, val:  74.56%, val_best:  79.42%, tr:  90.23%, tr_best:  90.30%, epoch time: 64.09 seconds, 1.07 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-10  lr=['0.0001221'], tr/val_loss:  2.303157/  2.314945, val:  71.24%, val_best:  79.42%, tr:  91.39%, tr_best:  91.39%, epoch time: 73.33 seconds, 1.22 minutes\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-11  lr=['0.0001221'], tr/val_loss:  2.302906/  2.304780, val:  76.55%, val_best:  79.42%, tr:  91.15%, tr_best:  91.39%, epoch time: 75.15 seconds, 1.25 minutes\n",
      "train - Value 0: 2075 occurrences\n",
      "train - Value 1: 1957 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-12  lr=['0.0001221'], tr/val_loss:  2.302487/  2.307367, val:  74.34%, val_best:  79.42%, tr:  90.30%, tr_best:  91.39%, epoch time: 74.95 seconds, 1.25 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-13  lr=['0.0001221'], tr/val_loss:  2.302735/  2.305991, val:  69.69%, val_best:  79.42%, tr:  92.58%, tr_best:  92.58%, epoch time: 75.07 seconds, 1.25 minutes\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-14  lr=['0.0001221'], tr/val_loss:  2.302429/  2.301753, val:  78.32%, val_best:  79.42%, tr:  91.87%, tr_best:  92.58%, epoch time: 74.94 seconds, 1.25 minutes\n",
      "train - Value 0: 2113 occurrences\n",
      "train - Value 1: 1919 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-15  lr=['0.0001221'], tr/val_loss:  2.302692/  2.301798, val:  79.42%, val_best:  79.42%, tr:  93.03%, tr_best:  93.03%, epoch time: 75.02 seconds, 1.25 minutes\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-16  lr=['0.0001221'], tr/val_loss:  2.302983/  2.300457, val:  79.65%, val_best:  79.65%, tr:  93.48%, tr_best:  93.48%, epoch time: 74.71 seconds, 1.25 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-17  lr=['0.0001221'], tr/val_loss:  2.302959/  2.306767, val:  75.22%, val_best:  79.65%, tr:  93.90%, tr_best:  93.90%, epoch time: 74.94 seconds, 1.25 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-18  lr=['0.0001221'], tr/val_loss:  2.303203/  2.303324, val:  80.09%, val_best:  80.09%, tr:  95.16%, tr_best:  95.16%, epoch time: 74.85 seconds, 1.25 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-19  lr=['0.0001221'], tr/val_loss:  2.303104/  2.302740, val:  77.21%, val_best:  80.09%, tr:  95.36%, tr_best:  95.36%, epoch time: 74.82 seconds, 1.25 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-20  lr=['0.0001221'], tr/val_loss:  2.303903/  2.299886, val:  80.53%, val_best:  80.53%, tr:  96.13%, tr_best:  96.13%, epoch time: 74.80 seconds, 1.25 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-21  lr=['0.0001221'], tr/val_loss:  2.303444/  2.301553, val:  81.19%, val_best:  81.19%, tr:  96.68%, tr_best:  96.68%, epoch time: 75.03 seconds, 1.25 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-22  lr=['0.0001221'], tr/val_loss:  2.302984/  2.306909, val:  81.19%, val_best:  81.19%, tr:  95.46%, tr_best:  96.68%, epoch time: 75.11 seconds, 1.25 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-23  lr=['0.0001221'], tr/val_loss:  2.303523/  2.302067, val:  81.19%, val_best:  81.19%, tr:  96.88%, tr_best:  96.88%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-24  lr=['0.0001221'], tr/val_loss:  2.303444/  2.308742, val:  72.12%, val_best:  81.19%, tr:  96.68%, tr_best:  96.88%, epoch time: 74.84 seconds, 1.25 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-25  lr=['0.0001221'], tr/val_loss:  2.303727/  2.303521, val:  79.42%, val_best:  81.19%, tr:  97.35%, tr_best:  97.35%, epoch time: 75.00 seconds, 1.25 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-26  lr=['0.0001221'], tr/val_loss:  2.303663/  2.307864, val:  74.56%, val_best:  81.19%, tr:  97.50%, tr_best:  97.50%, epoch time: 74.90 seconds, 1.25 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-27  lr=['0.0001221'], tr/val_loss:  2.304208/  2.302326, val:  79.65%, val_best:  81.19%, tr:  97.40%, tr_best:  97.50%, epoch time: 74.66 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-28  lr=['0.0001221'], tr/val_loss:  2.303880/  2.307743, val:  70.13%, val_best:  81.19%, tr:  97.25%, tr_best:  97.50%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-29  lr=['0.0001221'], tr/val_loss:  2.303881/  2.304331, val:  84.73%, val_best:  84.73%, tr:  97.05%, tr_best:  97.50%, epoch time: 75.23 seconds, 1.25 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-30  lr=['0.0001221'], tr/val_loss:  2.303095/  2.302314, val:  76.11%, val_best:  84.73%, tr:  97.37%, tr_best:  97.50%, epoch time: 74.95 seconds, 1.25 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-31  lr=['0.0001221'], tr/val_loss:  2.303560/  2.306206, val:  83.19%, val_best:  84.73%, tr:  97.87%, tr_best:  97.87%, epoch time: 75.40 seconds, 1.26 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-32  lr=['0.0001221'], tr/val_loss:  2.303029/  2.299889, val:  82.52%, val_best:  84.73%, tr:  97.52%, tr_best:  97.87%, epoch time: 74.74 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-33  lr=['0.0001221'], tr/val_loss:  2.303380/  2.308041, val:  73.45%, val_best:  84.73%, tr:  97.89%, tr_best:  97.89%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-34  lr=['0.0001221'], tr/val_loss:  2.303615/  2.304632, val:  77.21%, val_best:  84.73%, tr:  98.31%, tr_best:  98.31%, epoch time: 74.90 seconds, 1.25 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-35  lr=['0.0001221'], tr/val_loss:  2.303869/  2.306291, val:  81.19%, val_best:  84.73%, tr:  98.34%, tr_best:  98.34%, epoch time: 74.97 seconds, 1.25 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-36  lr=['0.0001221'], tr/val_loss:  2.303583/  2.303108, val:  84.07%, val_best:  84.73%, tr:  98.12%, tr_best:  98.34%, epoch time: 75.16 seconds, 1.25 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-37  lr=['0.0001221'], tr/val_loss:  2.303670/  2.303897, val:  79.20%, val_best:  84.73%, tr:  98.56%, tr_best:  98.56%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-38  lr=['0.0001221'], tr/val_loss:  2.303838/  2.301980, val:  83.41%, val_best:  84.73%, tr:  98.14%, tr_best:  98.56%, epoch time: 75.02 seconds, 1.25 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-39  lr=['0.0001221'], tr/val_loss:  2.303832/  2.303963, val:  84.51%, val_best:  84.73%, tr:  98.51%, tr_best:  98.56%, epoch time: 75.32 seconds, 1.26 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-40  lr=['0.0001221'], tr/val_loss:  2.304160/  2.305405, val:  81.86%, val_best:  84.73%, tr:  98.91%, tr_best:  98.91%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-41  lr=['0.0001221'], tr/val_loss:  2.304122/  2.305391, val:  82.96%, val_best:  84.73%, tr:  98.44%, tr_best:  98.91%, epoch time: 75.18 seconds, 1.25 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-42  lr=['0.0001221'], tr/val_loss:  2.303993/  2.302006, val:  83.63%, val_best:  84.73%, tr:  98.86%, tr_best:  98.91%, epoch time: 74.68 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-43  lr=['0.0001221'], tr/val_loss:  2.304521/  2.305523, val:  81.42%, val_best:  84.73%, tr:  98.83%, tr_best:  98.91%, epoch time: 75.26 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-44  lr=['0.0001221'], tr/val_loss:  2.303995/  2.309624, val:  78.32%, val_best:  84.73%, tr:  98.81%, tr_best:  98.91%, epoch time: 75.23 seconds, 1.25 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-45  lr=['0.0001221'], tr/val_loss:  2.304152/  2.306290, val:  71.02%, val_best:  84.73%, tr:  98.88%, tr_best:  98.91%, epoch time: 74.75 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-46  lr=['0.0001221'], tr/val_loss:  2.304326/  2.302108, val:  84.96%, val_best:  84.96%, tr:  98.91%, tr_best:  98.91%, epoch time: 74.62 seconds, 1.24 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-47  lr=['0.0001221'], tr/val_loss:  2.303891/  2.306444, val:  68.81%, val_best:  84.96%, tr:  99.23%, tr_best:  99.23%, epoch time: 74.61 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-48  lr=['0.0001221'], tr/val_loss:  2.304260/  2.305786, val:  78.32%, val_best:  84.96%, tr:  98.88%, tr_best:  99.23%, epoch time: 75.23 seconds, 1.25 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-49  lr=['0.0001221'], tr/val_loss:  2.303894/  2.307154, val:  72.79%, val_best:  84.96%, tr:  99.33%, tr_best:  99.33%, epoch time: 75.25 seconds, 1.25 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-50  lr=['0.0001221'], tr/val_loss:  2.304240/  2.306602, val:  78.54%, val_best:  84.96%, tr:  98.93%, tr_best:  99.33%, epoch time: 74.56 seconds, 1.24 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-51  lr=['0.0001221'], tr/val_loss:  2.304016/  2.303909, val:  80.97%, val_best:  84.96%, tr:  99.16%, tr_best:  99.33%, epoch time: 75.40 seconds, 1.26 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-52  lr=['0.0001221'], tr/val_loss:  2.303978/  2.307514, val:  71.90%, val_best:  84.96%, tr:  99.08%, tr_best:  99.33%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-53  lr=['0.0001221'], tr/val_loss:  2.303750/  2.305059, val:  71.02%, val_best:  84.96%, tr:  99.08%, tr_best:  99.33%, epoch time: 75.19 seconds, 1.25 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-54  lr=['0.0001221'], tr/val_loss:  2.304226/  2.304100, val:  82.30%, val_best:  84.96%, tr:  99.13%, tr_best:  99.33%, epoch time: 74.53 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-55  lr=['0.0001221'], tr/val_loss:  2.303950/  2.306094, val:  80.31%, val_best:  84.96%, tr:  99.13%, tr_best:  99.33%, epoch time: 75.00 seconds, 1.25 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-56  lr=['0.0001221'], tr/val_loss:  2.303619/  2.304162, val:  74.34%, val_best:  84.96%, tr:  98.98%, tr_best:  99.33%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-57  lr=['0.0001221'], tr/val_loss:  2.303839/  2.306179, val:  85.62%, val_best:  85.62%, tr:  99.23%, tr_best:  99.33%, epoch time: 74.49 seconds, 1.24 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-58  lr=['0.0001221'], tr/val_loss:  2.303465/  2.300844, val:  85.18%, val_best:  85.62%, tr:  99.48%, tr_best:  99.48%, epoch time: 74.68 seconds, 1.24 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-59  lr=['0.0001221'], tr/val_loss:  2.304202/  2.304025, val:  84.29%, val_best:  85.62%, tr:  99.11%, tr_best:  99.48%, epoch time: 73.14 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-60  lr=['0.0001221'], tr/val_loss:  2.304144/  2.309980, val:  88.72%, val_best:  88.72%, tr:  99.33%, tr_best:  99.48%, epoch time: 73.65 seconds, 1.23 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-61  lr=['0.0001221'], tr/val_loss:  2.304083/  2.307024, val:  84.73%, val_best:  88.72%, tr:  99.28%, tr_best:  99.48%, epoch time: 75.14 seconds, 1.25 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-62  lr=['0.0001221'], tr/val_loss:  2.304223/  2.308140, val:  84.29%, val_best:  88.72%, tr:  99.16%, tr_best:  99.48%, epoch time: 74.62 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-63  lr=['0.0001221'], tr/val_loss:  2.304362/  2.307081, val:  83.85%, val_best:  88.72%, tr:  99.33%, tr_best:  99.48%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-64  lr=['0.0001221'], tr/val_loss:  2.303960/  2.304406, val:  80.31%, val_best:  88.72%, tr:  99.55%, tr_best:  99.55%, epoch time: 75.64 seconds, 1.26 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-65  lr=['0.0001221'], tr/val_loss:  2.304160/  2.303515, val:  82.74%, val_best:  88.72%, tr:  99.43%, tr_best:  99.55%, epoch time: 74.59 seconds, 1.24 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-66  lr=['0.0001221'], tr/val_loss:  2.304320/  2.303844, val:  80.31%, val_best:  88.72%, tr:  99.50%, tr_best:  99.55%, epoch time: 74.17 seconds, 1.24 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-67  lr=['0.0001221'], tr/val_loss:  2.304511/  2.309418, val:  83.19%, val_best:  88.72%, tr:  99.48%, tr_best:  99.55%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-68  lr=['0.0001221'], tr/val_loss:  2.304368/  2.307269, val:  68.14%, val_best:  88.72%, tr:  99.50%, tr_best:  99.55%, epoch time: 75.22 seconds, 1.25 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-69  lr=['0.0001221'], tr/val_loss:  2.304442/  2.307532, val:  73.67%, val_best:  88.72%, tr:  99.38%, tr_best:  99.55%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-70  lr=['0.0001221'], tr/val_loss:  2.304582/  2.301832, val:  88.50%, val_best:  88.72%, tr:  99.58%, tr_best:  99.58%, epoch time: 75.15 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-71  lr=['0.0001221'], tr/val_loss:  2.304678/  2.308525, val:  73.89%, val_best:  88.72%, tr:  99.58%, tr_best:  99.58%, epoch time: 75.04 seconds, 1.25 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-72  lr=['0.0001221'], tr/val_loss:  2.304764/  2.303209, val:  86.06%, val_best:  88.72%, tr:  99.38%, tr_best:  99.58%, epoch time: 75.66 seconds, 1.26 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-73  lr=['0.0001221'], tr/val_loss:  2.304634/  2.305768, val:  76.77%, val_best:  88.72%, tr:  99.68%, tr_best:  99.68%, epoch time: 74.72 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-74  lr=['0.0001221'], tr/val_loss:  2.304448/  2.305676, val:  85.62%, val_best:  88.72%, tr:  99.45%, tr_best:  99.68%, epoch time: 75.22 seconds, 1.25 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-75  lr=['0.0001221'], tr/val_loss:  2.304009/  2.304528, val:  80.53%, val_best:  88.72%, tr:  99.48%, tr_best:  99.68%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-76  lr=['0.0001221'], tr/val_loss:  2.303888/  2.305584, val:  83.63%, val_best:  88.72%, tr:  99.63%, tr_best:  99.68%, epoch time: 75.09 seconds, 1.25 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-77  lr=['0.0001221'], tr/val_loss:  2.303919/  2.305461, val:  84.73%, val_best:  88.72%, tr:  99.60%, tr_best:  99.68%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-78  lr=['0.0001221'], tr/val_loss:  2.303997/  2.303952, val:  78.98%, val_best:  88.72%, tr:  99.45%, tr_best:  99.68%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-79  lr=['0.0001221'], tr/val_loss:  2.303985/  2.302544, val:  85.62%, val_best:  88.72%, tr:  99.60%, tr_best:  99.68%, epoch time: 74.87 seconds, 1.25 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-80  lr=['0.0001221'], tr/val_loss:  2.303793/  2.306526, val:  83.19%, val_best:  88.72%, tr:  99.73%, tr_best:  99.73%, epoch time: 75.14 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-81  lr=['0.0001221'], tr/val_loss:  2.304634/  2.309578, val:  78.32%, val_best:  88.72%, tr:  99.83%, tr_best:  99.83%, epoch time: 74.92 seconds, 1.25 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-82  lr=['0.0001221'], tr/val_loss:  2.304041/  2.307513, val:  77.21%, val_best:  88.72%, tr:  99.48%, tr_best:  99.83%, epoch time: 74.64 seconds, 1.24 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-83  lr=['0.0001221'], tr/val_loss:  2.303610/  2.302410, val:  85.62%, val_best:  88.72%, tr:  99.88%, tr_best:  99.88%, epoch time: 74.83 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-84  lr=['0.0001221'], tr/val_loss:  2.303323/  2.303480, val:  79.87%, val_best:  88.72%, tr:  99.58%, tr_best:  99.88%, epoch time: 75.26 seconds, 1.25 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-85  lr=['0.0001221'], tr/val_loss:  2.304016/  2.307428, val:  77.21%, val_best:  88.72%, tr:  99.85%, tr_best:  99.88%, epoch time: 75.22 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-86  lr=['0.0001221'], tr/val_loss:  2.304039/  2.308405, val:  87.61%, val_best:  88.72%, tr:  99.78%, tr_best:  99.88%, epoch time: 74.79 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-87  lr=['0.0001221'], tr/val_loss:  2.303998/  2.304509, val:  80.09%, val_best:  88.72%, tr:  99.63%, tr_best:  99.88%, epoch time: 75.07 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-88  lr=['0.0001221'], tr/val_loss:  2.304214/  2.306254, val:  73.45%, val_best:  88.72%, tr:  99.75%, tr_best:  99.88%, epoch time: 75.17 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-89  lr=['0.0001221'], tr/val_loss:  2.303516/  2.302233, val:  84.96%, val_best:  88.72%, tr:  99.63%, tr_best:  99.88%, epoch time: 75.17 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-90  lr=['0.0001221'], tr/val_loss:  2.303613/  2.306199, val:  69.47%, val_best:  88.72%, tr:  99.78%, tr_best:  99.88%, epoch time: 75.16 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-91  lr=['0.0001221'], tr/val_loss:  2.304088/  2.307075, val:  82.96%, val_best:  88.72%, tr:  99.75%, tr_best:  99.88%, epoch time: 75.18 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-92  lr=['0.0001221'], tr/val_loss:  2.304589/  2.303796, val:  86.73%, val_best:  88.72%, tr:  99.80%, tr_best:  99.88%, epoch time: 74.77 seconds, 1.25 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-93  lr=['0.0001221'], tr/val_loss:  2.304239/  2.303373, val:  83.19%, val_best:  88.72%, tr:  99.58%, tr_best:  99.88%, epoch time: 75.34 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-94  lr=['0.0001221'], tr/val_loss:  2.304062/  2.310750, val:  73.45%, val_best:  88.72%, tr:  99.70%, tr_best:  99.88%, epoch time: 75.30 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-95  lr=['0.0001221'], tr/val_loss:  2.304258/  2.307250, val:  73.45%, val_best:  88.72%, tr:  99.58%, tr_best:  99.88%, epoch time: 75.10 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-96  lr=['0.0001221'], tr/val_loss:  2.304095/  2.306238, val:  72.12%, val_best:  88.72%, tr:  99.68%, tr_best:  99.88%, epoch time: 75.37 seconds, 1.26 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-97  lr=['0.0001221'], tr/val_loss:  2.304634/  2.303706, val:  80.31%, val_best:  88.72%, tr:  99.50%, tr_best:  99.88%, epoch time: 75.14 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-98  lr=['0.0001221'], tr/val_loss:  2.304003/  2.305195, val:  84.96%, val_best:  88.72%, tr:  99.63%, tr_best:  99.88%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-99  lr=['0.0001221'], tr/val_loss:  2.304125/  2.305899, val:  76.55%, val_best:  88.72%, tr:  99.63%, tr_best:  99.88%, epoch time: 75.61 seconds, 1.26 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-100 lr=['0.0001221'], tr/val_loss:  2.304571/  2.304059, val:  81.86%, val_best:  88.72%, tr:  99.55%, tr_best:  99.88%, epoch time: 75.21 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 54 occurrences\n",
      "test - Value 1: 398 occurrences\n",
      "epoch-101 lr=['0.0001221'], tr/val_loss:  2.304388/  2.309302, val:  61.95%, val_best:  88.72%, tr:  99.60%, tr_best:  99.88%, epoch time: 74.73 seconds, 1.25 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-102 lr=['0.0001221'], tr/val_loss:  2.304479/  2.306698, val:  74.56%, val_best:  88.72%, tr:  99.48%, tr_best:  99.88%, epoch time: 74.92 seconds, 1.25 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-103 lr=['0.0001221'], tr/val_loss:  2.303945/  2.305803, val:  84.07%, val_best:  88.72%, tr:  99.75%, tr_best:  99.88%, epoch time: 74.92 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-104 lr=['0.0001221'], tr/val_loss:  2.303710/  2.308923, val:  81.64%, val_best:  88.72%, tr:  99.60%, tr_best:  99.88%, epoch time: 74.95 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-105 lr=['0.0001221'], tr/val_loss:  2.304013/  2.312412, val:  68.58%, val_best:  88.72%, tr:  99.70%, tr_best:  99.88%, epoch time: 74.52 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-106 lr=['0.0001221'], tr/val_loss:  2.303946/  2.303063, val:  86.50%, val_best:  88.72%, tr:  99.75%, tr_best:  99.88%, epoch time: 74.98 seconds, 1.25 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-107 lr=['0.0001221'], tr/val_loss:  2.304555/  2.306253, val:  79.20%, val_best:  88.72%, tr:  99.78%, tr_best:  99.88%, epoch time: 75.03 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-108 lr=['0.0001221'], tr/val_loss:  2.304194/  2.309962, val:  76.77%, val_best:  88.72%, tr:  99.75%, tr_best:  99.88%, epoch time: 74.94 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-109 lr=['0.0001221'], tr/val_loss:  2.304622/  2.303911, val:  82.30%, val_best:  88.72%, tr:  99.80%, tr_best:  99.88%, epoch time: 74.39 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-110 lr=['0.0001221'], tr/val_loss:  2.304993/  2.306283, val:  84.07%, val_best:  88.72%, tr:  99.83%, tr_best:  99.88%, epoch time: 75.19 seconds, 1.25 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-111 lr=['0.0001221'], tr/val_loss:  2.304877/  2.306448, val:  78.32%, val_best:  88.72%, tr:  99.80%, tr_best:  99.88%, epoch time: 75.34 seconds, 1.26 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-112 lr=['0.0001221'], tr/val_loss:  2.304816/  2.304632, val:  82.74%, val_best:  88.72%, tr:  99.78%, tr_best:  99.88%, epoch time: 75.09 seconds, 1.25 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-113 lr=['0.0001221'], tr/val_loss:  2.305583/  2.306540, val:  76.33%, val_best:  88.72%, tr:  99.73%, tr_best:  99.88%, epoch time: 74.95 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-114 lr=['0.0001221'], tr/val_loss:  2.304916/  2.308321, val:  83.19%, val_best:  88.72%, tr:  99.93%, tr_best:  99.93%, epoch time: 75.05 seconds, 1.25 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-115 lr=['0.0001221'], tr/val_loss:  2.304359/  2.307675, val:  75.22%, val_best:  88.72%, tr:  99.75%, tr_best:  99.93%, epoch time: 75.16 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-116 lr=['0.0001221'], tr/val_loss:  2.304741/  2.305063, val:  85.18%, val_best:  88.72%, tr:  99.68%, tr_best:  99.93%, epoch time: 74.87 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-117 lr=['0.0001221'], tr/val_loss:  2.304623/  2.308609, val:  75.22%, val_best:  88.72%, tr:  99.90%, tr_best:  99.93%, epoch time: 75.34 seconds, 1.26 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-118 lr=['0.0001221'], tr/val_loss:  2.304929/  2.307876, val:  73.45%, val_best:  88.72%, tr:  99.73%, tr_best:  99.93%, epoch time: 75.02 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-119 lr=['0.0001221'], tr/val_loss:  2.304888/  2.306006, val:  84.51%, val_best:  88.72%, tr:  99.90%, tr_best:  99.93%, epoch time: 75.45 seconds, 1.26 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-120 lr=['0.0001221'], tr/val_loss:  2.305409/  2.307419, val:  83.41%, val_best:  88.72%, tr:  99.65%, tr_best:  99.93%, epoch time: 75.04 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-121 lr=['0.0001221'], tr/val_loss:  2.304740/  2.308548, val:  81.19%, val_best:  88.72%, tr:  99.75%, tr_best:  99.93%, epoch time: 74.94 seconds, 1.25 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-122 lr=['0.0001221'], tr/val_loss:  2.305076/  2.310154, val:  85.18%, val_best:  88.72%, tr:  99.88%, tr_best:  99.93%, epoch time: 75.42 seconds, 1.26 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-123 lr=['0.0001221'], tr/val_loss:  2.305171/  2.310812, val:  76.77%, val_best:  88.72%, tr:  99.78%, tr_best:  99.93%, epoch time: 75.26 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-124 lr=['0.0001221'], tr/val_loss:  2.305518/  2.309481, val:  77.21%, val_best:  88.72%, tr:  99.75%, tr_best:  99.93%, epoch time: 75.26 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-125 lr=['0.0001221'], tr/val_loss:  2.305253/  2.307034, val:  77.88%, val_best:  88.72%, tr:  99.98%, tr_best:  99.98%, epoch time: 75.56 seconds, 1.26 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-126 lr=['0.0001221'], tr/val_loss:  2.305094/  2.305908, val:  84.96%, val_best:  88.72%, tr:  99.88%, tr_best:  99.98%, epoch time: 75.30 seconds, 1.26 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-127 lr=['0.0001221'], tr/val_loss:  2.304933/  2.306575, val:  78.76%, val_best:  88.72%, tr:  99.80%, tr_best:  99.98%, epoch time: 75.39 seconds, 1.26 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-128 lr=['0.0001221'], tr/val_loss:  2.305074/  2.310922, val:  64.38%, val_best:  88.72%, tr:  99.85%, tr_best:  99.98%, epoch time: 74.82 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-129 lr=['0.0001221'], tr/val_loss:  2.305426/  2.308344, val:  80.75%, val_best:  88.72%, tr:  99.78%, tr_best:  99.98%, epoch time: 75.08 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-130 lr=['0.0001221'], tr/val_loss:  2.304647/  2.306940, val:  83.63%, val_best:  88.72%, tr:  99.88%, tr_best:  99.98%, epoch time: 75.25 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-131 lr=['0.0001221'], tr/val_loss:  2.304393/  2.307297, val:  69.91%, val_best:  88.72%, tr:  99.85%, tr_best:  99.98%, epoch time: 75.41 seconds, 1.26 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-132 lr=['0.0001221'], tr/val_loss:  2.305126/  2.307614, val:  75.22%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.09 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-133 lr=['0.0001221'], tr/val_loss:  2.304978/  2.305257, val:  79.42%, val_best:  88.72%, tr:  99.80%, tr_best:  99.98%, epoch time: 75.28 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-134 lr=['0.0001221'], tr/val_loss:  2.305357/  2.310643, val:  74.56%, val_best:  88.72%, tr:  99.88%, tr_best:  99.98%, epoch time: 75.18 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-135 lr=['0.0001221'], tr/val_loss:  2.304638/  2.304798, val:  82.74%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.07 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-136 lr=['0.0001221'], tr/val_loss:  2.304617/  2.304564, val:  85.84%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.12 seconds, 1.25 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-137 lr=['0.0001221'], tr/val_loss:  2.304715/  2.309721, val:  78.98%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-138 lr=['0.0001221'], tr/val_loss:  2.305055/  2.307780, val:  70.58%, val_best:  88.72%, tr:  99.85%, tr_best:  99.98%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-139 lr=['0.0001221'], tr/val_loss:  2.304478/  2.309661, val:  77.65%, val_best:  88.72%, tr:  99.80%, tr_best:  99.98%, epoch time: 74.74 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-140 lr=['0.0001221'], tr/val_loss:  2.304821/  2.308016, val:  77.21%, val_best:  88.72%, tr:  99.80%, tr_best:  99.98%, epoch time: 74.99 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-141 lr=['0.0001221'], tr/val_loss:  2.305033/  2.306588, val:  74.56%, val_best:  88.72%, tr:  99.88%, tr_best:  99.98%, epoch time: 75.10 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-142 lr=['0.0001221'], tr/val_loss:  2.304813/  2.310121, val:  74.78%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.08 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-143 lr=['0.0001221'], tr/val_loss:  2.304972/  2.308762, val:  69.91%, val_best:  88.72%, tr:  99.85%, tr_best:  99.98%, epoch time: 74.87 seconds, 1.25 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-144 lr=['0.0001221'], tr/val_loss:  2.304581/  2.305402, val:  79.42%, val_best:  88.72%, tr:  99.88%, tr_best:  99.98%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-145 lr=['0.0001221'], tr/val_loss:  2.304781/  2.307447, val:  71.90%, val_best:  88.72%, tr:  99.95%, tr_best:  99.98%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-146 lr=['0.0001221'], tr/val_loss:  2.305672/  2.306018, val:  80.97%, val_best:  88.72%, tr:  99.98%, tr_best:  99.98%, epoch time: 75.27 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-147 lr=['0.0001221'], tr/val_loss:  2.305804/  2.308133, val:  72.79%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.20 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-148 lr=['0.0001221'], tr/val_loss:  2.306040/  2.310847, val:  72.12%, val_best:  88.72%, tr:  99.98%, tr_best:  99.98%, epoch time: 75.16 seconds, 1.25 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-149 lr=['0.0001221'], tr/val_loss:  2.305787/  2.304559, val:  85.40%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.35 seconds, 1.26 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-150 lr=['0.0001221'], tr/val_loss:  2.305367/  2.306468, val:  80.53%, val_best:  88.72%, tr:  99.98%, tr_best:  99.98%, epoch time: 75.10 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-151 lr=['0.0001221'], tr/val_loss:  2.305412/  2.308941, val:  73.01%, val_best:  88.72%, tr:  99.85%, tr_best:  99.98%, epoch time: 74.83 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-152 lr=['0.0001221'], tr/val_loss:  2.305176/  2.308334, val:  78.10%, val_best:  88.72%, tr:  99.85%, tr_best:  99.98%, epoch time: 74.83 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-153 lr=['0.0001221'], tr/val_loss:  2.305224/  2.312170, val:  75.22%, val_best:  88.72%, tr:  99.88%, tr_best:  99.98%, epoch time: 75.19 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-154 lr=['0.0001221'], tr/val_loss:  2.305408/  2.309492, val:  72.12%, val_best:  88.72%, tr:  99.90%, tr_best:  99.98%, epoch time: 75.12 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-155 lr=['0.0001221'], tr/val_loss:  2.305794/  2.307381, val:  76.11%, val_best:  88.72%, tr:  99.83%, tr_best:  99.98%, epoch time: 75.16 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-156 lr=['0.0001221'], tr/val_loss:  2.304859/  2.307837, val:  71.90%, val_best:  88.72%, tr:  99.93%, tr_best:  99.98%, epoch time: 75.29 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-157 lr=['0.0001221'], tr/val_loss:  2.305066/  2.307696, val:  77.21%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.44 seconds, 1.26 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-158 lr=['0.0001221'], tr/val_loss:  2.305201/  2.306711, val:  79.87%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 75.45 seconds, 1.26 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-159 lr=['0.0001221'], tr/val_loss:  2.305094/  2.308169, val:  78.54%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-160 lr=['0.0001221'], tr/val_loss:  2.304850/  2.308034, val:  79.42%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 75.05 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-161 lr=['0.0001221'], tr/val_loss:  2.304989/  2.308859, val:  74.56%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.19 seconds, 1.25 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-162 lr=['0.0001221'], tr/val_loss:  2.305259/  2.309895, val:  77.43%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.58 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-163 lr=['0.0001221'], tr/val_loss:  2.305452/  2.308855, val:  73.01%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.31 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-164 lr=['0.0001221'], tr/val_loss:  2.305515/  2.308549, val:  78.32%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.22 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-165 lr=['0.0001221'], tr/val_loss:  2.304899/  2.305029, val:  82.96%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.96 seconds, 1.25 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-166 lr=['0.0001221'], tr/val_loss:  2.305230/  2.309156, val:  72.79%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 75.47 seconds, 1.26 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-167 lr=['0.0001221'], tr/val_loss:  2.305487/  2.309728, val:  82.08%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.32 seconds, 1.26 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-168 lr=['0.0001221'], tr/val_loss:  2.305770/  2.307686, val:  81.42%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.48 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-169 lr=['0.0001221'], tr/val_loss:  2.304926/  2.310395, val:  74.78%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 72.28 seconds, 1.20 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-170 lr=['0.0001221'], tr/val_loss:  2.305438/  2.307540, val:  82.74%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.57 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-171 lr=['0.0001221'], tr/val_loss:  2.305372/  2.310123, val:  82.30%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 76.98 seconds, 1.28 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-172 lr=['0.0001221'], tr/val_loss:  2.305958/  2.311113, val:  77.88%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 77.53 seconds, 1.29 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-173 lr=['0.0001221'], tr/val_loss:  2.305620/  2.308275, val:  81.86%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.27 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-174 lr=['0.0001221'], tr/val_loss:  2.305980/  2.309603, val:  78.54%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.13 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-175 lr=['0.0001221'], tr/val_loss:  2.305420/  2.306557, val:  84.51%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 73.07 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-176 lr=['0.0001221'], tr/val_loss:  2.305272/  2.309540, val:  72.12%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.13 seconds, 1.24 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-177 lr=['0.0001221'], tr/val_loss:  2.305969/  2.310948, val:  80.31%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-178 lr=['0.0001221'], tr/val_loss:  2.304952/  2.307801, val:  74.34%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.98 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-179 lr=['0.0001221'], tr/val_loss:  2.304693/  2.306038, val:  82.30%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 75.68 seconds, 1.26 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-180 lr=['0.0001221'], tr/val_loss:  2.305424/  2.307244, val:  77.21%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.49 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-181 lr=['0.0001221'], tr/val_loss:  2.305885/  2.310185, val:  77.21%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.62 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-182 lr=['0.0001221'], tr/val_loss:  2.304999/  2.309706, val:  72.12%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.58 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-183 lr=['0.0001221'], tr/val_loss:  2.305074/  2.309033, val:  70.35%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.01 seconds, 1.22 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-184 lr=['0.0001221'], tr/val_loss:  2.304993/  2.307618, val:  77.65%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 73.48 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-185 lr=['0.0001221'], tr/val_loss:  2.305320/  2.308815, val:  75.88%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-186 lr=['0.0001221'], tr/val_loss:  2.305477/  2.304700, val:  83.19%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.10 seconds, 1.22 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-187 lr=['0.0001221'], tr/val_loss:  2.305350/  2.307265, val:  78.54%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.40 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-188 lr=['0.0001221'], tr/val_loss:  2.304811/  2.304337, val:  78.76%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.02 seconds, 1.20 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-189 lr=['0.0001221'], tr/val_loss:  2.305103/  2.311502, val:  77.65%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 72.59 seconds, 1.21 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-190 lr=['0.0001221'], tr/val_loss:  2.305993/  2.308756, val:  72.57%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 74.10 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-191 lr=['0.0001221'], tr/val_loss:  2.305639/  2.309906, val:  75.22%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.10 seconds, 1.24 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-192 lr=['0.0001221'], tr/val_loss:  2.305650/  2.308813, val:  77.65%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.00 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-193 lr=['0.0001221'], tr/val_loss:  2.305543/  2.309377, val:  80.53%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.11 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-194 lr=['0.0001221'], tr/val_loss:  2.306073/  2.312562, val:  74.12%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 73.13 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-195 lr=['0.0001221'], tr/val_loss:  2.305802/  2.307788, val:  73.01%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.05 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-196 lr=['0.0001221'], tr/val_loss:  2.305634/  2.310865, val:  78.76%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 73.15 seconds, 1.22 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-197 lr=['0.0001221'], tr/val_loss:  2.305787/  2.310425, val:  78.10%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 72.60 seconds, 1.21 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-198 lr=['0.0001221'], tr/val_loss:  2.305124/  2.308936, val:  82.30%, val_best:  88.72%, tr:  99.85%, tr_best: 100.00%, epoch time: 74.00 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-199 lr=['0.0001221'], tr/val_loss:  2.305636/  2.307961, val:  75.44%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.65 seconds, 1.23 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-200 lr=['0.0001221'], tr/val_loss:  2.305249/  2.314119, val:  73.01%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 73.61 seconds, 1.23 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-201 lr=['0.0001221'], tr/val_loss:  2.306016/  2.310879, val:  83.41%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 73.90 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-202 lr=['0.0001221'], tr/val_loss:  2.305495/  2.307773, val:  81.42%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.72 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-203 lr=['0.0001221'], tr/val_loss:  2.305877/  2.306801, val:  81.64%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.36 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-204 lr=['0.0001221'], tr/val_loss:  2.306035/  2.305668, val:  81.64%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.74 seconds, 1.21 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-205 lr=['0.0001221'], tr/val_loss:  2.306693/  2.310829, val:  75.22%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 73.70 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-206 lr=['0.0001221'], tr/val_loss:  2.306478/  2.309407, val:  78.32%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-207 lr=['0.0001221'], tr/val_loss:  2.305395/  2.306114, val:  83.41%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.53 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-208 lr=['0.0001221'], tr/val_loss:  2.305688/  2.308526, val:  82.74%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.90 seconds, 1.23 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-209 lr=['0.0001221'], tr/val_loss:  2.305790/  2.309639, val:  80.97%, val_best:  88.72%, tr:  99.88%, tr_best: 100.00%, epoch time: 71.78 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-210 lr=['0.0001221'], tr/val_loss:  2.305610/  2.309268, val:  83.41%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 72.73 seconds, 1.21 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-211 lr=['0.0001221'], tr/val_loss:  2.305945/  2.308760, val:  80.53%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.93 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-212 lr=['0.0001221'], tr/val_loss:  2.305668/  2.311374, val:  77.21%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.24 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-213 lr=['0.0001221'], tr/val_loss:  2.305359/  2.309217, val:  71.68%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.15 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-214 lr=['0.0001221'], tr/val_loss:  2.305468/  2.307350, val:  77.43%, val_best:  88.72%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.75 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-215 lr=['0.0001221'], tr/val_loss:  2.306350/  2.308120, val:  79.65%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.35 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-216 lr=['0.0001221'], tr/val_loss:  2.306321/  2.310483, val:  71.24%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.21 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-217 lr=['0.0001221'], tr/val_loss:  2.305973/  2.306664, val:  81.42%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.61 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-218 lr=['0.0001221'], tr/val_loss:  2.305760/  2.307881, val:  78.98%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.82 seconds, 1.23 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-219 lr=['0.0001221'], tr/val_loss:  2.306334/  2.306411, val:  87.83%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.46 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-220 lr=['0.0001221'], tr/val_loss:  2.306208/  2.306809, val:  79.20%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.08 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-221 lr=['0.0001221'], tr/val_loss:  2.306472/  2.312901, val:  67.92%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.20 seconds, 1.24 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-222 lr=['0.0001221'], tr/val_loss:  2.306404/  2.309427, val:  79.65%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.29 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-223 lr=['0.0001221'], tr/val_loss:  2.306101/  2.308116, val:  76.77%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-224 lr=['0.0001221'], tr/val_loss:  2.306546/  2.307901, val:  76.33%, val_best:  88.72%, tr:  99.90%, tr_best: 100.00%, epoch time: 73.69 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-225 lr=['0.0001221'], tr/val_loss:  2.306408/  2.309674, val:  65.71%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.15 seconds, 1.20 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-226 lr=['0.0001221'], tr/val_loss:  2.305746/  2.307176, val:  81.42%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.42 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-227 lr=['0.0001221'], tr/val_loss:  2.306225/  2.310464, val:  80.53%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-228 lr=['0.0001221'], tr/val_loss:  2.305147/  2.305172, val:  79.20%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.81 seconds, 1.23 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-229 lr=['0.0001221'], tr/val_loss:  2.305837/  2.308653, val:  77.21%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-230 lr=['0.0001221'], tr/val_loss:  2.305478/  2.307442, val:  77.21%, val_best:  88.72%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-231 lr=['0.0001221'], tr/val_loss:  2.305447/  2.310632, val:  76.55%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.62 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-232 lr=['0.0001221'], tr/val_loss:  2.305918/  2.310467, val:  77.43%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.04 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-233 lr=['0.0001221'], tr/val_loss:  2.305710/  2.306526, val:  80.97%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.23 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-234 lr=['0.0001221'], tr/val_loss:  2.305126/  2.307895, val:  75.22%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.70 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-235 lr=['0.0001221'], tr/val_loss:  2.305869/  2.312688, val:  70.58%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.42 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-236 lr=['0.0001221'], tr/val_loss:  2.305652/  2.309663, val:  70.58%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.60 seconds, 1.23 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-237 lr=['0.0001221'], tr/val_loss:  2.305469/  2.312552, val:  82.08%, val_best:  88.72%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.82 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-238 lr=['0.0001221'], tr/val_loss:  2.306171/  2.309632, val:  76.33%, val_best:  88.72%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.10 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-239 lr=['0.0001221'], tr/val_loss:  2.305604/  2.303118, val:  89.16%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.10 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-240 lr=['0.0001221'], tr/val_loss:  2.306069/  2.313907, val:  68.14%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.57 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-241 lr=['0.0001221'], tr/val_loss:  2.305870/  2.305100, val:  79.42%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.75 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-242 lr=['0.0001221'], tr/val_loss:  2.305905/  2.309994, val:  69.91%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-243 lr=['0.0001221'], tr/val_loss:  2.306595/  2.310049, val:  73.23%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 72.78 seconds, 1.21 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-244 lr=['0.0001221'], tr/val_loss:  2.305691/  2.308485, val:  80.97%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.16 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-245 lr=['0.0001221'], tr/val_loss:  2.305612/  2.310796, val:  78.54%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.85 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-246 lr=['0.0001221'], tr/val_loss:  2.305733/  2.310080, val:  75.88%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.26 seconds, 1.24 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-247 lr=['0.0001221'], tr/val_loss:  2.305013/  2.308093, val:  75.00%, val_best:  89.16%, tr:  99.88%, tr_best: 100.00%, epoch time: 74.27 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-248 lr=['0.0001221'], tr/val_loss:  2.305330/  2.308677, val:  74.12%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.27 seconds, 1.24 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-249 lr=['0.0001221'], tr/val_loss:  2.305703/  2.308916, val:  75.22%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.65 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-250 lr=['0.0001221'], tr/val_loss:  2.305660/  2.307451, val:  83.85%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.93 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-251 lr=['0.0001221'], tr/val_loss:  2.305906/  2.309941, val:  79.20%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 75.48 seconds, 1.26 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-252 lr=['0.0001221'], tr/val_loss:  2.306383/  2.315090, val:  68.14%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.87 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-253 lr=['0.0001221'], tr/val_loss:  2.307001/  2.307835, val:  80.97%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.88 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-254 lr=['0.0001221'], tr/val_loss:  2.306336/  2.305470, val:  85.84%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.14 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-255 lr=['0.0001221'], tr/val_loss:  2.306169/  2.306383, val:  81.42%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.69 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-256 lr=['0.0001221'], tr/val_loss:  2.305746/  2.305177, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.80 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-257 lr=['0.0001221'], tr/val_loss:  2.305568/  2.304180, val:  84.96%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 75.04 seconds, 1.25 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-258 lr=['0.0001221'], tr/val_loss:  2.305534/  2.305928, val:  81.19%, val_best:  89.16%, tr:  99.80%, tr_best: 100.00%, epoch time: 74.57 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-259 lr=['0.0001221'], tr/val_loss:  2.305174/  2.307723, val:  80.97%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 74.67 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-260 lr=['0.0001221'], tr/val_loss:  2.305383/  2.309050, val:  79.42%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.74 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-261 lr=['0.0001221'], tr/val_loss:  2.305269/  2.306934, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.47 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-262 lr=['0.0001221'], tr/val_loss:  2.305514/  2.308310, val:  78.32%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-263 lr=['0.0001221'], tr/val_loss:  2.305504/  2.306957, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-264 lr=['0.0001221'], tr/val_loss:  2.305705/  2.309795, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-265 lr=['0.0001221'], tr/val_loss:  2.305532/  2.304193, val:  83.85%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.23 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-266 lr=['0.0001221'], tr/val_loss:  2.306069/  2.306979, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.58 seconds, 1.23 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-267 lr=['0.0001221'], tr/val_loss:  2.304995/  2.312845, val:  78.98%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.95 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-268 lr=['0.0001221'], tr/val_loss:  2.305972/  2.303851, val:  87.39%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.49 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-269 lr=['0.0001221'], tr/val_loss:  2.305983/  2.312153, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.30 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-270 lr=['0.0001221'], tr/val_loss:  2.305218/  2.310144, val:  74.56%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.29 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-271 lr=['0.0001221'], tr/val_loss:  2.305381/  2.309654, val:  75.22%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.91 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-272 lr=['0.0001221'], tr/val_loss:  2.305551/  2.309809, val:  68.58%, val_best:  89.16%, tr:  99.88%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-273 lr=['0.0001221'], tr/val_loss:  2.305903/  2.306679, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.91 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-274 lr=['0.0001221'], tr/val_loss:  2.305239/  2.306762, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.27 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-275 lr=['0.0001221'], tr/val_loss:  2.305277/  2.307512, val:  87.83%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.43 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-276 lr=['0.0001221'], tr/val_loss:  2.305487/  2.310567, val:  69.25%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-277 lr=['0.0001221'], tr/val_loss:  2.305096/  2.309527, val:  69.91%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.78 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-278 lr=['0.0001221'], tr/val_loss:  2.304908/  2.307810, val:  74.12%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.95 seconds, 1.23 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-279 lr=['0.0001221'], tr/val_loss:  2.305469/  2.308226, val:  83.41%, val_best:  89.16%, tr:  99.90%, tr_best: 100.00%, epoch time: 73.35 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-280 lr=['0.0001221'], tr/val_loss:  2.305358/  2.306480, val:  80.09%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 73.99 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-281 lr=['0.0001221'], tr/val_loss:  2.305781/  2.309206, val:  77.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.62 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-282 lr=['0.0001221'], tr/val_loss:  2.305747/  2.308753, val:  75.44%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.32 seconds, 1.22 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-283 lr=['0.0001221'], tr/val_loss:  2.306042/  2.310410, val:  83.63%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.36 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-284 lr=['0.0001221'], tr/val_loss:  2.306383/  2.310047, val:  77.21%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.85 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-285 lr=['0.0001221'], tr/val_loss:  2.305458/  2.308807, val:  78.32%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.35 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-286 lr=['0.0001221'], tr/val_loss:  2.306219/  2.313464, val:  69.03%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.59 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-287 lr=['0.0001221'], tr/val_loss:  2.306298/  2.312100, val:  67.92%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.23 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-288 lr=['0.0001221'], tr/val_loss:  2.305767/  2.312202, val:  75.00%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.93 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-289 lr=['0.0001221'], tr/val_loss:  2.304938/  2.309787, val:  77.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.30 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-290 lr=['0.0001221'], tr/val_loss:  2.304485/  2.305853, val:  81.64%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.35 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-291 lr=['0.0001221'], tr/val_loss:  2.305683/  2.309817, val:  78.76%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.57 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-292 lr=['0.0001221'], tr/val_loss:  2.305810/  2.309678, val:  69.25%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.55 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-293 lr=['0.0001221'], tr/val_loss:  2.305654/  2.307388, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.95 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-294 lr=['0.0001221'], tr/val_loss:  2.306072/  2.304090, val:  85.62%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.74 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-295 lr=['0.0001221'], tr/val_loss:  2.305919/  2.310423, val:  72.35%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-296 lr=['0.0001221'], tr/val_loss:  2.306958/  2.314688, val:  71.02%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.04 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-297 lr=['0.0001221'], tr/val_loss:  2.306583/  2.306806, val:  79.87%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.77 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-298 lr=['0.0001221'], tr/val_loss:  2.306168/  2.310759, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.18 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 85 occurrences\n",
      "test - Value 1: 367 occurrences\n",
      "epoch-299 lr=['0.0001221'], tr/val_loss:  2.306651/  2.311775, val:  68.81%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.03 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-300 lr=['0.0001221'], tr/val_loss:  2.306444/  2.308583, val:  82.30%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.44 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-301 lr=['0.0001221'], tr/val_loss:  2.306010/  2.308869, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.74 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-302 lr=['0.0001221'], tr/val_loss:  2.305408/  2.308024, val:  72.79%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.64 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-303 lr=['0.0001221'], tr/val_loss:  2.305734/  2.306438, val:  83.63%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.53 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-304 lr=['0.0001221'], tr/val_loss:  2.306237/  2.307112, val:  82.52%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.44 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-305 lr=['0.0001221'], tr/val_loss:  2.306106/  2.304958, val:  87.83%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.24 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-306 lr=['0.0001221'], tr/val_loss:  2.306573/  2.307604, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.42 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-307 lr=['0.0001221'], tr/val_loss:  2.305546/  2.310435, val:  76.99%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 72.57 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-308 lr=['0.0001221'], tr/val_loss:  2.305618/  2.306840, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.33 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-309 lr=['0.0001221'], tr/val_loss:  2.305988/  2.308825, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.81 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-310 lr=['0.0001221'], tr/val_loss:  2.305810/  2.308573, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.15 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-311 lr=['0.0001221'], tr/val_loss:  2.305910/  2.311244, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.47 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-312 lr=['0.0001221'], tr/val_loss:  2.306380/  2.306645, val:  84.73%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.49 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-313 lr=['0.0001221'], tr/val_loss:  2.306444/  2.303829, val:  87.17%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.54 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-314 lr=['0.0001221'], tr/val_loss:  2.306618/  2.310133, val:  84.96%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.83 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-315 lr=['0.0001221'], tr/val_loss:  2.306842/  2.310606, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-316 lr=['0.0001221'], tr/val_loss:  2.306850/  2.312551, val:  76.11%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.85 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-317 lr=['0.0001221'], tr/val_loss:  2.306610/  2.309702, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.58 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-318 lr=['0.0001221'], tr/val_loss:  2.306570/  2.309762, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-319 lr=['0.0001221'], tr/val_loss:  2.306739/  2.308194, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.89 seconds, 1.18 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-320 lr=['0.0001221'], tr/val_loss:  2.306879/  2.312897, val:  71.68%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.65 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-321 lr=['0.0001221'], tr/val_loss:  2.306797/  2.312125, val:  71.46%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-322 lr=['0.0001221'], tr/val_loss:  2.306882/  2.310419, val:  82.52%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.09 seconds, 1.18 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-323 lr=['0.0001221'], tr/val_loss:  2.306909/  2.311729, val:  79.20%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.24 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-324 lr=['0.0001221'], tr/val_loss:  2.306948/  2.310796, val:  79.42%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 72.84 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-325 lr=['0.0001221'], tr/val_loss:  2.306992/  2.310419, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.79 seconds, 1.20 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-326 lr=['0.0001221'], tr/val_loss:  2.306329/  2.309619, val:  71.90%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.09 seconds, 1.18 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-327 lr=['0.0001221'], tr/val_loss:  2.306571/  2.309948, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.17 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-328 lr=['0.0001221'], tr/val_loss:  2.306725/  2.309833, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.28 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-329 lr=['0.0001221'], tr/val_loss:  2.306620/  2.307912, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-330 lr=['0.0001221'], tr/val_loss:  2.307317/  2.310731, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.80 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-331 lr=['0.0001221'], tr/val_loss:  2.307094/  2.306189, val:  82.30%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.65 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-332 lr=['0.0001221'], tr/val_loss:  2.307418/  2.311016, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.90 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-333 lr=['0.0001221'], tr/val_loss:  2.307227/  2.308069, val:  83.41%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.47 seconds, 1.17 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-334 lr=['0.0001221'], tr/val_loss:  2.307334/  2.310674, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.21 seconds, 1.19 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-335 lr=['0.0001221'], tr/val_loss:  2.307033/  2.310670, val:  74.12%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-336 lr=['0.0001221'], tr/val_loss:  2.306942/  2.313975, val:  70.35%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 69.51 seconds, 1.16 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-337 lr=['0.0001221'], tr/val_loss:  2.307767/  2.311606, val:  77.21%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 70.87 seconds, 1.18 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-338 lr=['0.0001221'], tr/val_loss:  2.308457/  2.306397, val:  85.84%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.66 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-339 lr=['0.0001221'], tr/val_loss:  2.307390/  2.308638, val:  86.50%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.84 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-340 lr=['0.0001221'], tr/val_loss:  2.307471/  2.312522, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.53 seconds, 1.19 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-341 lr=['0.0001221'], tr/val_loss:  2.306633/  2.312055, val:  81.64%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.78 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-342 lr=['0.0001221'], tr/val_loss:  2.305958/  2.311279, val:  70.80%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.03 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-343 lr=['0.0001221'], tr/val_loss:  2.306676/  2.313572, val:  81.64%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.04 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-344 lr=['0.0001221'], tr/val_loss:  2.306420/  2.314606, val:  67.92%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.51 seconds, 1.21 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-345 lr=['0.0001221'], tr/val_loss:  2.306113/  2.309649, val:  76.55%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 71.79 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-346 lr=['0.0001221'], tr/val_loss:  2.306304/  2.307048, val:  84.29%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.40 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-347 lr=['0.0001221'], tr/val_loss:  2.306938/  2.308400, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.62 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-348 lr=['0.0001221'], tr/val_loss:  2.306376/  2.309623, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.12 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-349 lr=['0.0001221'], tr/val_loss:  2.306115/  2.310604, val:  78.76%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.66 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-350 lr=['0.0001221'], tr/val_loss:  2.306684/  2.313483, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.02 seconds, 1.20 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-351 lr=['0.0001221'], tr/val_loss:  2.306911/  2.310890, val:  74.12%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.04 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-352 lr=['0.0001221'], tr/val_loss:  2.307059/  2.311136, val:  77.88%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 72.38 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-353 lr=['0.0001221'], tr/val_loss:  2.306583/  2.311224, val:  81.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.22 seconds, 1.19 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-354 lr=['0.0001221'], tr/val_loss:  2.307463/  2.310146, val:  79.42%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.00 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-355 lr=['0.0001221'], tr/val_loss:  2.307673/  2.308019, val:  83.19%, val_best:  89.16%, tr:  99.93%, tr_best: 100.00%, epoch time: 71.62 seconds, 1.19 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-356 lr=['0.0001221'], tr/val_loss:  2.307312/  2.307650, val:  80.09%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.95 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-357 lr=['0.0001221'], tr/val_loss:  2.307271/  2.314623, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.20 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-358 lr=['0.0001221'], tr/val_loss:  2.307278/  2.313423, val:  69.25%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.58 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-359 lr=['0.0001221'], tr/val_loss:  2.307343/  2.311546, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.90 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-360 lr=['0.0001221'], tr/val_loss:  2.306196/  2.312831, val:  72.79%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.68 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-361 lr=['0.0001221'], tr/val_loss:  2.306611/  2.311775, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.55 seconds, 1.19 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-362 lr=['0.0001221'], tr/val_loss:  2.306671/  2.306334, val:  83.63%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.47 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-363 lr=['0.0001221'], tr/val_loss:  2.306825/  2.309924, val:  82.74%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.66 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-364 lr=['0.0001221'], tr/val_loss:  2.307515/  2.311315, val:  74.34%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.30 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-365 lr=['0.0001221'], tr/val_loss:  2.307395/  2.309521, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.79 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-366 lr=['0.0001221'], tr/val_loss:  2.307706/  2.312044, val:  76.77%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.17 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-367 lr=['0.0001221'], tr/val_loss:  2.308237/  2.311006, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.29 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-368 lr=['0.0001221'], tr/val_loss:  2.307668/  2.309706, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.37 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-369 lr=['0.0001221'], tr/val_loss:  2.307049/  2.310267, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.88 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-370 lr=['0.0001221'], tr/val_loss:  2.307019/  2.313799, val:  71.46%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.13 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-371 lr=['0.0001221'], tr/val_loss:  2.307372/  2.311031, val:  73.01%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.06 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-372 lr=['0.0001221'], tr/val_loss:  2.306476/  2.312469, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.21 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-373 lr=['0.0001221'], tr/val_loss:  2.307161/  2.311612, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.91 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-374 lr=['0.0001221'], tr/val_loss:  2.307410/  2.304630, val:  85.18%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.11 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-375 lr=['0.0001221'], tr/val_loss:  2.306460/  2.312480, val:  78.54%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-376 lr=['0.0001221'], tr/val_loss:  2.307564/  2.308374, val:  77.88%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.55 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-377 lr=['0.0001221'], tr/val_loss:  2.305780/  2.308747, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.94 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-378 lr=['0.0001221'], tr/val_loss:  2.306639/  2.308613, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.49 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-379 lr=['0.0001221'], tr/val_loss:  2.306541/  2.307958, val:  78.76%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.44 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-380 lr=['0.0001221'], tr/val_loss:  2.306550/  2.313093, val:  72.57%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.50 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-381 lr=['0.0001221'], tr/val_loss:  2.306643/  2.310322, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.73 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-382 lr=['0.0001221'], tr/val_loss:  2.306959/  2.311750, val:  66.81%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.35 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-383 lr=['0.0001221'], tr/val_loss:  2.306968/  2.312008, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.36 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-384 lr=['0.0001221'], tr/val_loss:  2.306729/  2.312942, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.73 seconds, 1.21 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-385 lr=['0.0001221'], tr/val_loss:  2.306703/  2.310275, val:  82.30%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.77 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-386 lr=['0.0001221'], tr/val_loss:  2.307336/  2.308888, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.65 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-387 lr=['0.0001221'], tr/val_loss:  2.306499/  2.308991, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.52 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-388 lr=['0.0001221'], tr/val_loss:  2.306776/  2.306259, val:  83.41%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.60 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-389 lr=['0.0001221'], tr/val_loss:  2.306075/  2.311255, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.92 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-390 lr=['0.0001221'], tr/val_loss:  2.306498/  2.308813, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.74 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-391 lr=['0.0001221'], tr/val_loss:  2.305479/  2.309505, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.18 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-392 lr=['0.0001221'], tr/val_loss:  2.305993/  2.308900, val:  79.42%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.71 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-393 lr=['0.0001221'], tr/val_loss:  2.306248/  2.308669, val:  83.63%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.79 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-394 lr=['0.0001221'], tr/val_loss:  2.305967/  2.308279, val:  74.78%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.33 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-395 lr=['0.0001221'], tr/val_loss:  2.305982/  2.309109, val:  82.30%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.52 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-396 lr=['0.0001221'], tr/val_loss:  2.306320/  2.310359, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.42 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-397 lr=['0.0001221'], tr/val_loss:  2.306396/  2.310401, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.34 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-398 lr=['0.0001221'], tr/val_loss:  2.306495/  2.308663, val:  79.87%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.67 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-399 lr=['0.0001221'], tr/val_loss:  2.306068/  2.308307, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-400 lr=['0.0001221'], tr/val_loss:  2.306705/  2.309338, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.22 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-401 lr=['0.0001221'], tr/val_loss:  2.307263/  2.310575, val:  68.14%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.76 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-402 lr=['0.0001221'], tr/val_loss:  2.306926/  2.310610, val:  65.49%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.69 seconds, 1.18 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-403 lr=['0.0001221'], tr/val_loss:  2.306742/  2.313302, val:  78.76%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.76 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-404 lr=['0.0001221'], tr/val_loss:  2.307243/  2.309133, val:  83.63%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.68 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-405 lr=['0.0001221'], tr/val_loss:  2.306411/  2.310017, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.66 seconds, 1.21 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-406 lr=['0.0001221'], tr/val_loss:  2.307014/  2.312801, val:  76.11%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.96 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-407 lr=['0.0001221'], tr/val_loss:  2.306784/  2.310705, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.11 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-408 lr=['0.0001221'], tr/val_loss:  2.307133/  2.312507, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.30 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-409 lr=['0.0001221'], tr/val_loss:  2.307323/  2.311093, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.38 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-410 lr=['0.0001221'], tr/val_loss:  2.307064/  2.312407, val:  70.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.82 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-411 lr=['0.0001221'], tr/val_loss:  2.307455/  2.313512, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.82 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-412 lr=['0.0001221'], tr/val_loss:  2.306491/  2.309833, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.44 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-413 lr=['0.0001221'], tr/val_loss:  2.306899/  2.307528, val:  79.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.59 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-414 lr=['0.0001221'], tr/val_loss:  2.306771/  2.309155, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.32 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-415 lr=['0.0001221'], tr/val_loss:  2.307168/  2.309597, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.12 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-416 lr=['0.0001221'], tr/val_loss:  2.307638/  2.312541, val:  76.33%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.48 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-417 lr=['0.0001221'], tr/val_loss:  2.306739/  2.309716, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.59 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-418 lr=['0.0001221'], tr/val_loss:  2.306971/  2.310047, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.25 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-419 lr=['0.0001221'], tr/val_loss:  2.307508/  2.313736, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.14 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-420 lr=['0.0001221'], tr/val_loss:  2.307231/  2.313931, val:  71.90%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.26 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-421 lr=['0.0001221'], tr/val_loss:  2.306909/  2.308793, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.43 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-422 lr=['0.0001221'], tr/val_loss:  2.306414/  2.313532, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.29 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-423 lr=['0.0001221'], tr/val_loss:  2.306096/  2.308601, val:  82.96%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.72 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-424 lr=['0.0001221'], tr/val_loss:  2.307027/  2.311749, val:  81.19%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.91 seconds, 1.25 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-425 lr=['0.0001221'], tr/val_loss:  2.306488/  2.306424, val:  81.19%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.90 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-426 lr=['0.0001221'], tr/val_loss:  2.306982/  2.309861, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-427 lr=['0.0001221'], tr/val_loss:  2.307014/  2.308930, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.27 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-428 lr=['0.0001221'], tr/val_loss:  2.305931/  2.312375, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.40 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-429 lr=['0.0001221'], tr/val_loss:  2.306698/  2.310535, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.13 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-430 lr=['0.0001221'], tr/val_loss:  2.307079/  2.310031, val:  77.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.79 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-431 lr=['0.0001221'], tr/val_loss:  2.307411/  2.309149, val:  77.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.77 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-432 lr=['0.0001221'], tr/val_loss:  2.306803/  2.308806, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-433 lr=['0.0001221'], tr/val_loss:  2.306144/  2.310987, val:  77.88%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.34 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-434 lr=['0.0001221'], tr/val_loss:  2.306398/  2.309897, val:  83.63%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.02 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-435 lr=['0.0001221'], tr/val_loss:  2.307065/  2.311601, val:  74.56%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.46 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-436 lr=['0.0001221'], tr/val_loss:  2.307208/  2.310717, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.12 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-437 lr=['0.0001221'], tr/val_loss:  2.306391/  2.309590, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.65 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-438 lr=['0.0001221'], tr/val_loss:  2.306509/  2.310686, val:  74.56%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.54 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-439 lr=['0.0001221'], tr/val_loss:  2.306577/  2.312334, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.39 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-440 lr=['0.0001221'], tr/val_loss:  2.306710/  2.314245, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-441 lr=['0.0001221'], tr/val_loss:  2.306435/  2.311004, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.82 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-442 lr=['0.0001221'], tr/val_loss:  2.306134/  2.309873, val:  82.30%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-443 lr=['0.0001221'], tr/val_loss:  2.307076/  2.315296, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.63 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-444 lr=['0.0001221'], tr/val_loss:  2.306613/  2.309430, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-445 lr=['0.0001221'], tr/val_loss:  2.306916/  2.311543, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.83 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-446 lr=['0.0001221'], tr/val_loss:  2.306631/  2.311590, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.96 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-447 lr=['0.0001221'], tr/val_loss:  2.306458/  2.311245, val:  79.87%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.04 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-448 lr=['0.0001221'], tr/val_loss:  2.306869/  2.307845, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.96 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-449 lr=['0.0001221'], tr/val_loss:  2.306703/  2.311211, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.62 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-450 lr=['0.0001221'], tr/val_loss:  2.307307/  2.313461, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.92 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-451 lr=['0.0001221'], tr/val_loss:  2.307104/  2.313307, val:  81.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.77 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-452 lr=['0.0001221'], tr/val_loss:  2.306323/  2.311630, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-453 lr=['0.0001221'], tr/val_loss:  2.307436/  2.308390, val:  79.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.98 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-454 lr=['0.0001221'], tr/val_loss:  2.306530/  2.309990, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.04 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-455 lr=['0.0001221'], tr/val_loss:  2.306599/  2.311501, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.94 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-456 lr=['0.0001221'], tr/val_loss:  2.305918/  2.310255, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.00 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-457 lr=['0.0001221'], tr/val_loss:  2.306807/  2.311797, val:  70.80%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.13 seconds, 1.24 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-458 lr=['0.0001221'], tr/val_loss:  2.306148/  2.308965, val:  77.88%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-459 lr=['0.0001221'], tr/val_loss:  2.306507/  2.310776, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.31 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-460 lr=['0.0001221'], tr/val_loss:  2.306993/  2.312524, val:  79.87%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.41 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-461 lr=['0.0001221'], tr/val_loss:  2.307281/  2.311221, val:  71.24%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-462 lr=['0.0001221'], tr/val_loss:  2.307345/  2.312201, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.75 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-463 lr=['0.0001221'], tr/val_loss:  2.306788/  2.309444, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-464 lr=['0.0001221'], tr/val_loss:  2.306223/  2.310089, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.09 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-465 lr=['0.0001221'], tr/val_loss:  2.306564/  2.309695, val:  76.77%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.29 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-466 lr=['0.0001221'], tr/val_loss:  2.306651/  2.313889, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-467 lr=['0.0001221'], tr/val_loss:  2.308600/  2.313974, val:  83.19%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.47 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-468 lr=['0.0001221'], tr/val_loss:  2.307132/  2.313104, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-469 lr=['0.0001221'], tr/val_loss:  2.306867/  2.309072, val:  75.44%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.26 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-470 lr=['0.0001221'], tr/val_loss:  2.306454/  2.313061, val:  76.55%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.80 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-471 lr=['0.0001221'], tr/val_loss:  2.306418/  2.307015, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.10 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-472 lr=['0.0001221'], tr/val_loss:  2.305971/  2.311520, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-473 lr=['0.0001221'], tr/val_loss:  2.306733/  2.311488, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.28 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-474 lr=['0.0001221'], tr/val_loss:  2.307092/  2.305182, val:  83.63%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.90 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-475 lr=['0.0001221'], tr/val_loss:  2.307149/  2.310103, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.78 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-476 lr=['0.0001221'], tr/val_loss:  2.306347/  2.310083, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.31 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-477 lr=['0.0001221'], tr/val_loss:  2.307234/  2.310840, val:  76.77%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.63 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-478 lr=['0.0001221'], tr/val_loss:  2.307477/  2.310951, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.96 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-479 lr=['0.0001221'], tr/val_loss:  2.307175/  2.310788, val:  76.77%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-480 lr=['0.0001221'], tr/val_loss:  2.306861/  2.310629, val:  81.86%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.69 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-481 lr=['0.0001221'], tr/val_loss:  2.306423/  2.310515, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.92 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-482 lr=['0.0001221'], tr/val_loss:  2.307266/  2.311311, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.06 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-483 lr=['0.0001221'], tr/val_loss:  2.307527/  2.312893, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.67 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-484 lr=['0.0001221'], tr/val_loss:  2.307290/  2.306974, val:  82.96%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.62 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-485 lr=['0.0001221'], tr/val_loss:  2.306386/  2.312768, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.73 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-486 lr=['0.0001221'], tr/val_loss:  2.306263/  2.312441, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.41 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-487 lr=['0.0001221'], tr/val_loss:  2.306707/  2.313024, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.30 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-488 lr=['0.0001221'], tr/val_loss:  2.307019/  2.309159, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.26 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-489 lr=['0.0001221'], tr/val_loss:  2.306792/  2.313227, val:  61.50%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.31 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-490 lr=['0.0001221'], tr/val_loss:  2.306920/  2.310395, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.81 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-491 lr=['0.0001221'], tr/val_loss:  2.307520/  2.311006, val:  79.87%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.11 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-492 lr=['0.0001221'], tr/val_loss:  2.306648/  2.311857, val:  71.46%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.06 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-493 lr=['0.0001221'], tr/val_loss:  2.306591/  2.312130, val:  70.58%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.59 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-494 lr=['0.0001221'], tr/val_loss:  2.307641/  2.312319, val:  66.59%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-495 lr=['0.0001221'], tr/val_loss:  2.307320/  2.310314, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.49 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-496 lr=['0.0001221'], tr/val_loss:  2.306839/  2.311054, val:  75.44%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.39 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-497 lr=['0.0001221'], tr/val_loss:  2.307410/  2.311529, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.71 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-498 lr=['0.0001221'], tr/val_loss:  2.307679/  2.308487, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-499 lr=['0.0001221'], tr/val_loss:  2.306560/  2.311149, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.29 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-500 lr=['0.0001221'], tr/val_loss:  2.306937/  2.312280, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.54 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-501 lr=['0.0001221'], tr/val_loss:  2.306946/  2.311348, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.47 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-502 lr=['0.0001221'], tr/val_loss:  2.306248/  2.313265, val:  68.58%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.66 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-503 lr=['0.0001221'], tr/val_loss:  2.306409/  2.311526, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.86 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-504 lr=['0.0001221'], tr/val_loss:  2.306322/  2.308836, val:  77.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.64 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-505 lr=['0.0001221'], tr/val_loss:  2.307256/  2.312235, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.78 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-506 lr=['0.0001221'], tr/val_loss:  2.306426/  2.312909, val:  72.79%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 73.80 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-507 lr=['0.0001221'], tr/val_loss:  2.306540/  2.307765, val:  84.96%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-508 lr=['0.0001221'], tr/val_loss:  2.306590/  2.312205, val:  76.77%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.53 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-509 lr=['0.0001221'], tr/val_loss:  2.306256/  2.313771, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-510 lr=['0.0001221'], tr/val_loss:  2.306787/  2.312324, val:  71.68%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.94 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-511 lr=['0.0001221'], tr/val_loss:  2.306977/  2.312227, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.94 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-512 lr=['0.0001221'], tr/val_loss:  2.307504/  2.314224, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.90 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-513 lr=['0.0001221'], tr/val_loss:  2.307657/  2.308674, val:  81.86%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.71 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-514 lr=['0.0001221'], tr/val_loss:  2.307825/  2.314772, val:  67.70%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.26 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-515 lr=['0.0001221'], tr/val_loss:  2.308480/  2.311790, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.21 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-516 lr=['0.0001221'], tr/val_loss:  2.308435/  2.314630, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.11 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-517 lr=['0.0001221'], tr/val_loss:  2.307315/  2.308372, val:  82.30%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.06 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-518 lr=['0.0001221'], tr/val_loss:  2.307910/  2.309433, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.87 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-519 lr=['0.0001221'], tr/val_loss:  2.307815/  2.312806, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.96 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-520 lr=['0.0001221'], tr/val_loss:  2.306418/  2.310995, val:  82.74%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.51 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-521 lr=['0.0001221'], tr/val_loss:  2.307224/  2.310947, val:  83.41%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.19 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-522 lr=['0.0001221'], tr/val_loss:  2.307850/  2.309118, val:  85.84%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.02 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-523 lr=['0.0001221'], tr/val_loss:  2.308535/  2.310500, val:  82.52%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.39 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-524 lr=['0.0001221'], tr/val_loss:  2.307873/  2.312561, val:  73.89%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.41 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-525 lr=['0.0001221'], tr/val_loss:  2.307834/  2.314203, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.55 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-526 lr=['0.0001221'], tr/val_loss:  2.308215/  2.311329, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.04 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-527 lr=['0.0001221'], tr/val_loss:  2.306995/  2.310863, val:  75.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.05 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-528 lr=['0.0001221'], tr/val_loss:  2.307098/  2.311612, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.53 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-529 lr=['0.0001221'], tr/val_loss:  2.307202/  2.314950, val:  72.57%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.31 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-530 lr=['0.0001221'], tr/val_loss:  2.307213/  2.312172, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.67 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-531 lr=['0.0001221'], tr/val_loss:  2.306818/  2.311725, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.19 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-532 lr=['0.0001221'], tr/val_loss:  2.307208/  2.312836, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.90 seconds, 1.21 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-533 lr=['0.0001221'], tr/val_loss:  2.306811/  2.311972, val:  76.33%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.11 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-534 lr=['0.0001221'], tr/val_loss:  2.307823/  2.312812, val:  82.96%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.82 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-535 lr=['0.0001221'], tr/val_loss:  2.307440/  2.312351, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.71 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-536 lr=['0.0001221'], tr/val_loss:  2.307546/  2.309391, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.41 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-537 lr=['0.0001221'], tr/val_loss:  2.307736/  2.312133, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.42 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-538 lr=['0.0001221'], tr/val_loss:  2.307172/  2.309276, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.52 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-539 lr=['0.0001221'], tr/val_loss:  2.307630/  2.312458, val:  67.26%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.90 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-540 lr=['0.0001221'], tr/val_loss:  2.307538/  2.314249, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.24 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-541 lr=['0.0001221'], tr/val_loss:  2.307519/  2.315413, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.56 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-542 lr=['0.0001221'], tr/val_loss:  2.307675/  2.312518, val:  76.55%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.58 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-543 lr=['0.0001221'], tr/val_loss:  2.307640/  2.310710, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.72 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-544 lr=['0.0001221'], tr/val_loss:  2.306852/  2.308814, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.69 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-545 lr=['0.0001221'], tr/val_loss:  2.307238/  2.314158, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.25 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-546 lr=['0.0001221'], tr/val_loss:  2.306556/  2.312428, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.92 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-547 lr=['0.0001221'], tr/val_loss:  2.306600/  2.308995, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.64 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-548 lr=['0.0001221'], tr/val_loss:  2.307501/  2.309452, val:  78.32%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.48 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-549 lr=['0.0001221'], tr/val_loss:  2.307845/  2.309173, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.63 seconds, 1.21 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-550 lr=['0.0001221'], tr/val_loss:  2.307352/  2.312798, val:  75.44%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.41 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-551 lr=['0.0001221'], tr/val_loss:  2.308200/  2.311499, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-552 lr=['0.0001221'], tr/val_loss:  2.307992/  2.310113, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.28 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-553 lr=['0.0001221'], tr/val_loss:  2.307443/  2.312110, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.45 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-554 lr=['0.0001221'], tr/val_loss:  2.307799/  2.310828, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.89 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-555 lr=['0.0001221'], tr/val_loss:  2.307732/  2.310964, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.75 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-556 lr=['0.0001221'], tr/val_loss:  2.308501/  2.311080, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.30 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-557 lr=['0.0001221'], tr/val_loss:  2.307218/  2.309814, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.12 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-558 lr=['0.0001221'], tr/val_loss:  2.306802/  2.311561, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.98 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-559 lr=['0.0001221'], tr/val_loss:  2.307106/  2.304818, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.62 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-560 lr=['0.0001221'], tr/val_loss:  2.307129/  2.314088, val:  69.91%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.92 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-561 lr=['0.0001221'], tr/val_loss:  2.307656/  2.311064, val:  71.68%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.27 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-562 lr=['0.0001221'], tr/val_loss:  2.307621/  2.313686, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.09 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-563 lr=['0.0001221'], tr/val_loss:  2.307723/  2.312234, val:  76.55%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.22 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-564 lr=['0.0001221'], tr/val_loss:  2.308016/  2.311685, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.79 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-565 lr=['0.0001221'], tr/val_loss:  2.308320/  2.313487, val:  68.58%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.25 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-566 lr=['0.0001221'], tr/val_loss:  2.308027/  2.311055, val:  83.41%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.95 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-567 lr=['0.0001221'], tr/val_loss:  2.307670/  2.315016, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.94 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-568 lr=['0.0001221'], tr/val_loss:  2.307180/  2.311311, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.25 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-569 lr=['0.0001221'], tr/val_loss:  2.307634/  2.313233, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-570 lr=['0.0001221'], tr/val_loss:  2.307231/  2.314592, val:  76.77%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.57 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-571 lr=['0.0001221'], tr/val_loss:  2.307469/  2.308230, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.30 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-572 lr=['0.0001221'], tr/val_loss:  2.307252/  2.312217, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-573 lr=['0.0001221'], tr/val_loss:  2.306384/  2.309640, val:  71.24%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.14 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-574 lr=['0.0001221'], tr/val_loss:  2.306247/  2.313047, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.45 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-575 lr=['0.0001221'], tr/val_loss:  2.307028/  2.312064, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.93 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-576 lr=['0.0001221'], tr/val_loss:  2.307142/  2.313184, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.69 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-577 lr=['0.0001221'], tr/val_loss:  2.307515/  2.311120, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.03 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-578 lr=['0.0001221'], tr/val_loss:  2.307549/  2.309173, val:  80.53%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.02 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-579 lr=['0.0001221'], tr/val_loss:  2.307380/  2.310881, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.37 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-580 lr=['0.0001221'], tr/val_loss:  2.307671/  2.311941, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.83 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-581 lr=['0.0001221'], tr/val_loss:  2.308208/  2.314138, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.40 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-582 lr=['0.0001221'], tr/val_loss:  2.307668/  2.310613, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.95 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-583 lr=['0.0001221'], tr/val_loss:  2.307436/  2.311487, val:  82.96%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.72 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-584 lr=['0.0001221'], tr/val_loss:  2.307205/  2.311763, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.52 seconds, 1.21 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-585 lr=['0.0001221'], tr/val_loss:  2.306974/  2.310724, val:  77.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.99 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-586 lr=['0.0001221'], tr/val_loss:  2.307224/  2.316757, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.03 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-587 lr=['0.0001221'], tr/val_loss:  2.307270/  2.312243, val:  75.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.00 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-588 lr=['0.0001221'], tr/val_loss:  2.306426/  2.308862, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.88 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-589 lr=['0.0001221'], tr/val_loss:  2.306775/  2.309813, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.17 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-590 lr=['0.0001221'], tr/val_loss:  2.306308/  2.315134, val:  71.46%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.71 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-591 lr=['0.0001221'], tr/val_loss:  2.307103/  2.312945, val:  75.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.63 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-592 lr=['0.0001221'], tr/val_loss:  2.307457/  2.313065, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.89 seconds, 1.18 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-593 lr=['0.0001221'], tr/val_loss:  2.307711/  2.312452, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.82 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-594 lr=['0.0001221'], tr/val_loss:  2.306928/  2.307604, val:  83.85%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.54 seconds, 1.19 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-595 lr=['0.0001221'], tr/val_loss:  2.306543/  2.311043, val:  75.66%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.10 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-596 lr=['0.0001221'], tr/val_loss:  2.306772/  2.309065, val:  85.40%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.79 seconds, 1.20 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-597 lr=['0.0001221'], tr/val_loss:  2.306334/  2.309987, val:  76.99%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.73 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-598 lr=['0.0001221'], tr/val_loss:  2.305887/  2.310690, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.10 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-599 lr=['0.0001221'], tr/val_loss:  2.306268/  2.311310, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.28 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-600 lr=['0.0001221'], tr/val_loss:  2.306731/  2.310833, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.43 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-601 lr=['0.0001221'], tr/val_loss:  2.306261/  2.310801, val:  77.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.71 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-602 lr=['0.0001221'], tr/val_loss:  2.306582/  2.308547, val:  79.87%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.96 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-603 lr=['0.0001221'], tr/val_loss:  2.305937/  2.309737, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-604 lr=['0.0001221'], tr/val_loss:  2.306784/  2.309132, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-605 lr=['0.0001221'], tr/val_loss:  2.306071/  2.313229, val:  75.88%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 71.59 seconds, 1.19 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-606 lr=['0.0001221'], tr/val_loss:  2.305779/  2.308472, val:  84.07%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 71.43 seconds, 1.19 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-607 lr=['0.0001221'], tr/val_loss:  2.305983/  2.312908, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.88 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-608 lr=['0.0001221'], tr/val_loss:  2.306789/  2.309451, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.18 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-609 lr=['0.0001221'], tr/val_loss:  2.306764/  2.309533, val:  78.98%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-610 lr=['0.0001221'], tr/val_loss:  2.306339/  2.307010, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.16 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-611 lr=['0.0001221'], tr/val_loss:  2.306321/  2.311418, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.28 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-612 lr=['0.0001221'], tr/val_loss:  2.305547/  2.313529, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.39 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-613 lr=['0.0001221'], tr/val_loss:  2.305258/  2.310765, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.67 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-614 lr=['0.0001221'], tr/val_loss:  2.306873/  2.312950, val:  72.57%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.68 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-615 lr=['0.0001221'], tr/val_loss:  2.306707/  2.307135, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-616 lr=['0.0001221'], tr/val_loss:  2.307061/  2.311734, val:  83.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.36 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-617 lr=['0.0001221'], tr/val_loss:  2.306331/  2.315183, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.17 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-618 lr=['0.0001221'], tr/val_loss:  2.306863/  2.307534, val:  82.74%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-619 lr=['0.0001221'], tr/val_loss:  2.306738/  2.313906, val:  76.55%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.25 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-620 lr=['0.0001221'], tr/val_loss:  2.306874/  2.311167, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.71 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-621 lr=['0.0001221'], tr/val_loss:  2.306159/  2.309413, val:  78.98%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.54 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-622 lr=['0.0001221'], tr/val_loss:  2.305816/  2.313593, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.61 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-623 lr=['0.0001221'], tr/val_loss:  2.306618/  2.310256, val:  79.42%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.01 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-624 lr=['0.0001221'], tr/val_loss:  2.306713/  2.313233, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.31 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-625 lr=['0.0001221'], tr/val_loss:  2.306586/  2.310284, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.54 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-626 lr=['0.0001221'], tr/val_loss:  2.306056/  2.310974, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.64 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-627 lr=['0.0001221'], tr/val_loss:  2.306525/  2.309798, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-628 lr=['0.0001221'], tr/val_loss:  2.306756/  2.313324, val:  74.34%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.12 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-629 lr=['0.0001221'], tr/val_loss:  2.305973/  2.310824, val:  80.31%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.04 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-630 lr=['0.0001221'], tr/val_loss:  2.306181/  2.307632, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.32 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-631 lr=['0.0001221'], tr/val_loss:  2.306870/  2.308059, val:  82.08%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.62 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-632 lr=['0.0001221'], tr/val_loss:  2.306936/  2.311095, val:  82.30%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.53 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-633 lr=['0.0001221'], tr/val_loss:  2.305938/  2.313924, val:  67.48%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.07 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-634 lr=['0.0001221'], tr/val_loss:  2.306607/  2.315265, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.65 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-635 lr=['0.0001221'], tr/val_loss:  2.306805/  2.309824, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.71 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-636 lr=['0.0001221'], tr/val_loss:  2.306593/  2.311630, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.71 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-637 lr=['0.0001221'], tr/val_loss:  2.306495/  2.308342, val:  79.87%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.83 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-638 lr=['0.0001221'], tr/val_loss:  2.306234/  2.313883, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.76 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-639 lr=['0.0001221'], tr/val_loss:  2.305893/  2.314268, val:  70.80%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.99 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-640 lr=['0.0001221'], tr/val_loss:  2.306477/  2.311268, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-641 lr=['0.0001221'], tr/val_loss:  2.306953/  2.311371, val:  78.76%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.13 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-642 lr=['0.0001221'], tr/val_loss:  2.306076/  2.307328, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.41 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-643 lr=['0.0001221'], tr/val_loss:  2.306861/  2.308913, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.98 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-644 lr=['0.0001221'], tr/val_loss:  2.306454/  2.311405, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.40 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-645 lr=['0.0001221'], tr/val_loss:  2.306854/  2.313972, val:  71.68%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.36 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-646 lr=['0.0001221'], tr/val_loss:  2.307491/  2.313103, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.39 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-647 lr=['0.0001221'], tr/val_loss:  2.306211/  2.312455, val:  74.34%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.44 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-648 lr=['0.0001221'], tr/val_loss:  2.307730/  2.313447, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.84 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-649 lr=['0.0001221'], tr/val_loss:  2.306430/  2.310086, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.62 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-650 lr=['0.0001221'], tr/val_loss:  2.306418/  2.313579, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.18 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-651 lr=['0.0001221'], tr/val_loss:  2.306723/  2.311879, val:  72.79%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.39 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-652 lr=['0.0001221'], tr/val_loss:  2.307009/  2.311878, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.73 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-653 lr=['0.0001221'], tr/val_loss:  2.306524/  2.310398, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.95 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-654 lr=['0.0001221'], tr/val_loss:  2.305994/  2.314186, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.49 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-655 lr=['0.0001221'], tr/val_loss:  2.305845/  2.312810, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.07 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-656 lr=['0.0001221'], tr/val_loss:  2.306172/  2.309558, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.52 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-657 lr=['0.0001221'], tr/val_loss:  2.306020/  2.307851, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.96 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-658 lr=['0.0001221'], tr/val_loss:  2.305888/  2.312580, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.25 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-659 lr=['0.0001221'], tr/val_loss:  2.305711/  2.309846, val:  74.78%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.54 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-660 lr=['0.0001221'], tr/val_loss:  2.306852/  2.313692, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.83 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-661 lr=['0.0001221'], tr/val_loss:  2.307005/  2.311259, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.23 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-662 lr=['0.0001221'], tr/val_loss:  2.306436/  2.308707, val:  79.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.01 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-663 lr=['0.0001221'], tr/val_loss:  2.306002/  2.312292, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.34 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-664 lr=['0.0001221'], tr/val_loss:  2.306108/  2.306504, val:  78.54%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.07 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-665 lr=['0.0001221'], tr/val_loss:  2.306235/  2.309169, val:  84.51%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.77 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-666 lr=['0.0001221'], tr/val_loss:  2.307002/  2.312302, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.24 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-667 lr=['0.0001221'], tr/val_loss:  2.306744/  2.313982, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.12 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-668 lr=['0.0001221'], tr/val_loss:  2.306721/  2.306774, val:  85.18%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.11 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-669 lr=['0.0001221'], tr/val_loss:  2.306246/  2.310569, val:  73.45%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.63 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-670 lr=['0.0001221'], tr/val_loss:  2.306622/  2.313081, val:  69.69%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.48 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-671 lr=['0.0001221'], tr/val_loss:  2.305939/  2.314195, val:  70.58%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.98 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-672 lr=['0.0001221'], tr/val_loss:  2.306413/  2.314202, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.00 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-673 lr=['0.0001221'], tr/val_loss:  2.306093/  2.315805, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.40 seconds, 1.22 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-674 lr=['0.0001221'], tr/val_loss:  2.306823/  2.308944, val:  75.22%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.59 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-675 lr=['0.0001221'], tr/val_loss:  2.307199/  2.311525, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.39 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-676 lr=['0.0001221'], tr/val_loss:  2.306507/  2.310347, val:  72.35%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.67 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-677 lr=['0.0001221'], tr/val_loss:  2.306160/  2.314001, val:  77.43%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 72.39 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-678 lr=['0.0001221'], tr/val_loss:  2.306933/  2.308666, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.93 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-679 lr=['0.0001221'], tr/val_loss:  2.306333/  2.310879, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.49 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-680 lr=['0.0001221'], tr/val_loss:  2.305869/  2.312753, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.02 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-681 lr=['0.0001221'], tr/val_loss:  2.305660/  2.309791, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.62 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-682 lr=['0.0001221'], tr/val_loss:  2.306749/  2.312257, val:  65.71%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.10 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-683 lr=['0.0001221'], tr/val_loss:  2.306231/  2.313767, val:  76.11%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.25 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-684 lr=['0.0001221'], tr/val_loss:  2.306603/  2.315453, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.72 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-685 lr=['0.0001221'], tr/val_loss:  2.305976/  2.307523, val:  80.31%, val_best:  89.16%, tr:  99.95%, tr_best: 100.00%, epoch time: 74.32 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-686 lr=['0.0001221'], tr/val_loss:  2.306637/  2.306131, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.58 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-687 lr=['0.0001221'], tr/val_loss:  2.306249/  2.311169, val:  75.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.61 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-688 lr=['0.0001221'], tr/val_loss:  2.306677/  2.310424, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.23 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-689 lr=['0.0001221'], tr/val_loss:  2.306377/  2.310641, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.39 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-690 lr=['0.0001221'], tr/val_loss:  2.306432/  2.311395, val:  69.03%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.72 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-691 lr=['0.0001221'], tr/val_loss:  2.306375/  2.306057, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.11 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-692 lr=['0.0001221'], tr/val_loss:  2.306261/  2.312127, val:  71.24%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.46 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-693 lr=['0.0001221'], tr/val_loss:  2.306590/  2.307605, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.29 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-694 lr=['0.0001221'], tr/val_loss:  2.306298/  2.312056, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.28 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-695 lr=['0.0001221'], tr/val_loss:  2.306194/  2.309571, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.30 seconds, 1.20 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-696 lr=['0.0001221'], tr/val_loss:  2.306648/  2.309186, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-697 lr=['0.0001221'], tr/val_loss:  2.306262/  2.309956, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.60 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-698 lr=['0.0001221'], tr/val_loss:  2.306525/  2.310615, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.17 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-699 lr=['0.0001221'], tr/val_loss:  2.306328/  2.307321, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.64 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-700 lr=['0.0001221'], tr/val_loss:  2.307106/  2.310585, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.68 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-701 lr=['0.0001221'], tr/val_loss:  2.306226/  2.311367, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.80 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-702 lr=['0.0001221'], tr/val_loss:  2.306928/  2.310689, val:  76.77%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.83 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-703 lr=['0.0001221'], tr/val_loss:  2.307072/  2.311576, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.76 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-704 lr=['0.0001221'], tr/val_loss:  2.307915/  2.308042, val:  82.74%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.16 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-705 lr=['0.0001221'], tr/val_loss:  2.306800/  2.314433, val:  75.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.32 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-706 lr=['0.0001221'], tr/val_loss:  2.307655/  2.313682, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.37 seconds, 1.22 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-707 lr=['0.0001221'], tr/val_loss:  2.307060/  2.312869, val:  79.65%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.29 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-708 lr=['0.0001221'], tr/val_loss:  2.307149/  2.310276, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-709 lr=['0.0001221'], tr/val_loss:  2.307737/  2.311695, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.75 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-710 lr=['0.0001221'], tr/val_loss:  2.307205/  2.312566, val:  66.59%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.38 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-711 lr=['0.0001221'], tr/val_loss:  2.307577/  2.311076, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.95 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-712 lr=['0.0001221'], tr/val_loss:  2.307817/  2.313040, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.11 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-713 lr=['0.0001221'], tr/val_loss:  2.307452/  2.314612, val:  63.05%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.59 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-714 lr=['0.0001221'], tr/val_loss:  2.307457/  2.315269, val:  77.43%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-715 lr=['0.0001221'], tr/val_loss:  2.307872/  2.312406, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.56 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-716 lr=['0.0001221'], tr/val_loss:  2.307122/  2.309236, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-717 lr=['0.0001221'], tr/val_loss:  2.307278/  2.308892, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.15 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-718 lr=['0.0001221'], tr/val_loss:  2.307060/  2.314836, val:  76.77%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.32 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-719 lr=['0.0001221'], tr/val_loss:  2.307310/  2.310426, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.36 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-720 lr=['0.0001221'], tr/val_loss:  2.306908/  2.309504, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.16 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-721 lr=['0.0001221'], tr/val_loss:  2.306524/  2.312870, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.31 seconds, 1.26 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-722 lr=['0.0001221'], tr/val_loss:  2.306940/  2.311058, val:  75.88%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.43 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-723 lr=['0.0001221'], tr/val_loss:  2.307291/  2.312521, val:  70.58%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.49 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-724 lr=['0.0001221'], tr/val_loss:  2.307582/  2.311088, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.26 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-725 lr=['0.0001221'], tr/val_loss:  2.307862/  2.310354, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.76 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-726 lr=['0.0001221'], tr/val_loss:  2.307531/  2.311362, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.73 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-727 lr=['0.0001221'], tr/val_loss:  2.308367/  2.313648, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 76.34 seconds, 1.27 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-728 lr=['0.0001221'], tr/val_loss:  2.308728/  2.311333, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.65 seconds, 1.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-729 lr=['0.0001221'], tr/val_loss:  2.307230/  2.311115, val:  72.35%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.77 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-730 lr=['0.0001221'], tr/val_loss:  2.307422/  2.311892, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.59 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-731 lr=['0.0001221'], tr/val_loss:  2.307496/  2.309003, val:  76.77%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.92 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-732 lr=['0.0001221'], tr/val_loss:  2.307493/  2.311599, val:  70.58%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 76.05 seconds, 1.27 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-733 lr=['0.0001221'], tr/val_loss:  2.307412/  2.309620, val:  78.76%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.87 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-734 lr=['0.0001221'], tr/val_loss:  2.307299/  2.309092, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.81 seconds, 1.25 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-735 lr=['0.0001221'], tr/val_loss:  2.308169/  2.309035, val:  80.53%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 73.67 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-736 lr=['0.0001221'], tr/val_loss:  2.307441/  2.307307, val:  83.41%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.85 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-737 lr=['0.0001221'], tr/val_loss:  2.306851/  2.311416, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.60 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-738 lr=['0.0001221'], tr/val_loss:  2.307108/  2.312862, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.29 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-739 lr=['0.0001221'], tr/val_loss:  2.306748/  2.316135, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.57 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-740 lr=['0.0001221'], tr/val_loss:  2.307243/  2.315468, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-741 lr=['0.0001221'], tr/val_loss:  2.307433/  2.313162, val:  72.79%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.82 seconds, 1.26 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-742 lr=['0.0001221'], tr/val_loss:  2.307063/  2.312392, val:  72.79%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.47 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-743 lr=['0.0001221'], tr/val_loss:  2.307101/  2.312594, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.64 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-744 lr=['0.0001221'], tr/val_loss:  2.307540/  2.309711, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.20 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-745 lr=['0.0001221'], tr/val_loss:  2.307469/  2.310558, val:  82.52%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.74 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-746 lr=['0.0001221'], tr/val_loss:  2.307384/  2.308482, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.47 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-747 lr=['0.0001221'], tr/val_loss:  2.306842/  2.309401, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.50 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-748 lr=['0.0001221'], tr/val_loss:  2.306955/  2.312944, val:  70.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.34 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-749 lr=['0.0001221'], tr/val_loss:  2.306635/  2.309741, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.05 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-750 lr=['0.0001221'], tr/val_loss:  2.306759/  2.313408, val:  69.03%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.00 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-751 lr=['0.0001221'], tr/val_loss:  2.307507/  2.312093, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.29 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-752 lr=['0.0001221'], tr/val_loss:  2.307673/  2.316768, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.32 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-753 lr=['0.0001221'], tr/val_loss:  2.308139/  2.314945, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.18 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-754 lr=['0.0001221'], tr/val_loss:  2.307762/  2.311931, val:  76.55%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.93 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-755 lr=['0.0001221'], tr/val_loss:  2.306372/  2.312987, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.77 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-756 lr=['0.0001221'], tr/val_loss:  2.307409/  2.312026, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.12 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-757 lr=['0.0001221'], tr/val_loss:  2.306920/  2.307002, val:  84.73%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.09 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-758 lr=['0.0001221'], tr/val_loss:  2.306665/  2.314983, val:  64.38%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.30 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-759 lr=['0.0001221'], tr/val_loss:  2.306134/  2.313221, val:  69.25%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.08 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-760 lr=['0.0001221'], tr/val_loss:  2.306497/  2.309741, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.47 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-761 lr=['0.0001221'], tr/val_loss:  2.307887/  2.311713, val:  76.77%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.58 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-762 lr=['0.0001221'], tr/val_loss:  2.307192/  2.312855, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.82 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-763 lr=['0.0001221'], tr/val_loss:  2.306871/  2.311179, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.39 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-764 lr=['0.0001221'], tr/val_loss:  2.306858/  2.311454, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.35 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-765 lr=['0.0001221'], tr/val_loss:  2.306289/  2.308021, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.07 seconds, 1.23 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-766 lr=['0.0001221'], tr/val_loss:  2.306804/  2.314724, val:  76.55%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 75.17 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-767 lr=['0.0001221'], tr/val_loss:  2.308020/  2.313210, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 76.61 seconds, 1.28 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-768 lr=['0.0001221'], tr/val_loss:  2.306572/  2.311152, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.86 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-769 lr=['0.0001221'], tr/val_loss:  2.307593/  2.311244, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.29 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-770 lr=['0.0001221'], tr/val_loss:  2.306417/  2.309825, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-771 lr=['0.0001221'], tr/val_loss:  2.307039/  2.312136, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.43 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-772 lr=['0.0001221'], tr/val_loss:  2.307841/  2.312207, val:  82.08%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-773 lr=['0.0001221'], tr/val_loss:  2.307323/  2.311017, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.45 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-774 lr=['0.0001221'], tr/val_loss:  2.307108/  2.310884, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.11 seconds, 1.24 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-775 lr=['0.0001221'], tr/val_loss:  2.307704/  2.312577, val:  80.31%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-776 lr=['0.0001221'], tr/val_loss:  2.306980/  2.310331, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-777 lr=['0.0001221'], tr/val_loss:  2.307875/  2.311777, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.93 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-778 lr=['0.0001221'], tr/val_loss:  2.307811/  2.310709, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.68 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-779 lr=['0.0001221'], tr/val_loss:  2.307606/  2.314182, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.53 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-780 lr=['0.0001221'], tr/val_loss:  2.307993/  2.313694, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.25 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-781 lr=['0.0001221'], tr/val_loss:  2.307864/  2.314090, val:  67.70%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 78.17 seconds, 1.30 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-782 lr=['0.0001221'], tr/val_loss:  2.307122/  2.310109, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.62 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-783 lr=['0.0001221'], tr/val_loss:  2.307558/  2.313992, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.70 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-784 lr=['0.0001221'], tr/val_loss:  2.308481/  2.310364, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.27 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-785 lr=['0.0001221'], tr/val_loss:  2.307973/  2.312792, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.14 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-786 lr=['0.0001221'], tr/val_loss:  2.308404/  2.309700, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.33 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-787 lr=['0.0001221'], tr/val_loss:  2.308975/  2.311111, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.83 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-788 lr=['0.0001221'], tr/val_loss:  2.308398/  2.312002, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.88 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-789 lr=['0.0001221'], tr/val_loss:  2.307803/  2.312508, val:  69.25%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.90 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-790 lr=['0.0001221'], tr/val_loss:  2.307914/  2.310772, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.78 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-791 lr=['0.0001221'], tr/val_loss:  2.308342/  2.313986, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.71 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-792 lr=['0.0001221'], tr/val_loss:  2.308153/  2.310377, val:  75.88%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.90 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-793 lr=['0.0001221'], tr/val_loss:  2.308506/  2.314610, val:  71.24%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.12 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-794 lr=['0.0001221'], tr/val_loss:  2.309343/  2.311708, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.03 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-795 lr=['0.0001221'], tr/val_loss:  2.308038/  2.314430, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.02 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-796 lr=['0.0001221'], tr/val_loss:  2.306639/  2.308769, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.75 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-797 lr=['0.0001221'], tr/val_loss:  2.307372/  2.312248, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.71 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-798 lr=['0.0001221'], tr/val_loss:  2.308345/  2.314324, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-799 lr=['0.0001221'], tr/val_loss:  2.307822/  2.311418, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.93 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-800 lr=['0.0001221'], tr/val_loss:  2.307412/  2.312600, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.43 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-801 lr=['0.0001221'], tr/val_loss:  2.308060/  2.312484, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.93 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-802 lr=['0.0001221'], tr/val_loss:  2.308132/  2.315373, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.70 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-803 lr=['0.0001221'], tr/val_loss:  2.307394/  2.311713, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.97 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-804 lr=['0.0001221'], tr/val_loss:  2.308897/  2.309308, val:  82.08%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.88 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-805 lr=['0.0001221'], tr/val_loss:  2.307263/  2.313321, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.68 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-806 lr=['0.0001221'], tr/val_loss:  2.307766/  2.309802, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.08 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-807 lr=['0.0001221'], tr/val_loss:  2.308005/  2.312028, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.54 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-808 lr=['0.0001221'], tr/val_loss:  2.307226/  2.312068, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.12 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-809 lr=['0.0001221'], tr/val_loss:  2.307760/  2.310015, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.49 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-810 lr=['0.0001221'], tr/val_loss:  2.308858/  2.311780, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.57 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-811 lr=['0.0001221'], tr/val_loss:  2.307611/  2.312535, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.11 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-812 lr=['0.0001221'], tr/val_loss:  2.307996/  2.314858, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.91 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-813 lr=['0.0001221'], tr/val_loss:  2.307458/  2.312538, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.88 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-814 lr=['0.0001221'], tr/val_loss:  2.306944/  2.311773, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.80 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-815 lr=['0.0001221'], tr/val_loss:  2.307823/  2.310501, val:  79.20%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.14 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-816 lr=['0.0001221'], tr/val_loss:  2.307360/  2.311488, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.06 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-817 lr=['0.0001221'], tr/val_loss:  2.307789/  2.312278, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.53 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-818 lr=['0.0001221'], tr/val_loss:  2.307435/  2.310431, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.36 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-819 lr=['0.0001221'], tr/val_loss:  2.306384/  2.310913, val:  81.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.27 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-820 lr=['0.0001221'], tr/val_loss:  2.306031/  2.309773, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.47 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-821 lr=['0.0001221'], tr/val_loss:  2.307124/  2.313297, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.83 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-822 lr=['0.0001221'], tr/val_loss:  2.306889/  2.313765, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.23 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-823 lr=['0.0001221'], tr/val_loss:  2.307433/  2.315408, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.53 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-824 lr=['0.0001221'], tr/val_loss:  2.308245/  2.311387, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.45 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-825 lr=['0.0001221'], tr/val_loss:  2.306770/  2.311870, val:  78.32%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.47 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-826 lr=['0.0001221'], tr/val_loss:  2.307386/  2.314283, val:  70.80%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.06 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-827 lr=['0.0001221'], tr/val_loss:  2.307293/  2.313554, val:  72.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-828 lr=['0.0001221'], tr/val_loss:  2.307169/  2.312807, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.51 seconds, 1.24 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-829 lr=['0.0001221'], tr/val_loss:  2.306339/  2.313759, val:  69.91%, val_best:  89.16%, tr:  99.98%, tr_best: 100.00%, epoch time: 74.92 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-830 lr=['0.0001221'], tr/val_loss:  2.307368/  2.312138, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.03 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-831 lr=['0.0001221'], tr/val_loss:  2.306367/  2.312561, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-832 lr=['0.0001221'], tr/val_loss:  2.305995/  2.309482, val:  81.64%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.57 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-833 lr=['0.0001221'], tr/val_loss:  2.305650/  2.313654, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.96 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-834 lr=['0.0001221'], tr/val_loss:  2.306241/  2.312472, val:  81.86%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.36 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-835 lr=['0.0001221'], tr/val_loss:  2.306248/  2.311038, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.54 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-836 lr=['0.0001221'], tr/val_loss:  2.305690/  2.311767, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.06 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-837 lr=['0.0001221'], tr/val_loss:  2.306758/  2.312923, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.55 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-838 lr=['0.0001221'], tr/val_loss:  2.306186/  2.312940, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.30 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-839 lr=['0.0001221'], tr/val_loss:  2.307065/  2.310992, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.63 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-840 lr=['0.0001221'], tr/val_loss:  2.307388/  2.311753, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.87 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-841 lr=['0.0001221'], tr/val_loss:  2.307348/  2.310170, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.01 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-842 lr=['0.0001221'], tr/val_loss:  2.307977/  2.315462, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.55 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-843 lr=['0.0001221'], tr/val_loss:  2.307141/  2.311377, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.92 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-844 lr=['0.0001221'], tr/val_loss:  2.306331/  2.311221, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.71 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-845 lr=['0.0001221'], tr/val_loss:  2.306037/  2.308781, val:  79.87%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.83 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-846 lr=['0.0001221'], tr/val_loss:  2.306276/  2.309668, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.83 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-847 lr=['0.0001221'], tr/val_loss:  2.306916/  2.311060, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.80 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-848 lr=['0.0001221'], tr/val_loss:  2.307183/  2.313861, val:  74.34%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.01 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-849 lr=['0.0001221'], tr/val_loss:  2.306909/  2.310390, val:  76.99%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 76.03 seconds, 1.27 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-850 lr=['0.0001221'], tr/val_loss:  2.306788/  2.312246, val:  78.10%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.63 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-851 lr=['0.0001221'], tr/val_loss:  2.306845/  2.309632, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.30 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-852 lr=['0.0001221'], tr/val_loss:  2.306982/  2.309795, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.22 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-853 lr=['0.0001221'], tr/val_loss:  2.307164/  2.312476, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.13 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-854 lr=['0.0001221'], tr/val_loss:  2.307916/  2.311626, val:  76.33%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.82 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-855 lr=['0.0001221'], tr/val_loss:  2.307416/  2.313219, val:  69.91%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.31 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-856 lr=['0.0001221'], tr/val_loss:  2.307534/  2.315747, val:  72.79%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.66 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-857 lr=['0.0001221'], tr/val_loss:  2.307166/  2.314301, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.22 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-858 lr=['0.0001221'], tr/val_loss:  2.307593/  2.312994, val:  71.68%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.76 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-859 lr=['0.0001221'], tr/val_loss:  2.307528/  2.311130, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.26 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-860 lr=['0.0001221'], tr/val_loss:  2.308408/  2.313727, val:  70.80%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.05 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-861 lr=['0.0001221'], tr/val_loss:  2.306856/  2.316357, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.05 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-862 lr=['0.0001221'], tr/val_loss:  2.307170/  2.311829, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.57 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-863 lr=['0.0001221'], tr/val_loss:  2.307207/  2.314638, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.44 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-864 lr=['0.0001221'], tr/val_loss:  2.307703/  2.311816, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.34 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-865 lr=['0.0001221'], tr/val_loss:  2.307476/  2.310357, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.11 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-866 lr=['0.0001221'], tr/val_loss:  2.306666/  2.316229, val:  80.09%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.48 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-867 lr=['0.0001221'], tr/val_loss:  2.307661/  2.311915, val:  71.68%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-868 lr=['0.0001221'], tr/val_loss:  2.307914/  2.313560, val:  80.75%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.94 seconds, 1.27 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-869 lr=['0.0001221'], tr/val_loss:  2.306581/  2.311605, val:  75.00%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.84 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-870 lr=['0.0001221'], tr/val_loss:  2.306299/  2.312886, val:  71.90%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.59 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-871 lr=['0.0001221'], tr/val_loss:  2.306760/  2.313221, val:  79.42%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.50 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-872 lr=['0.0001221'], tr/val_loss:  2.308210/  2.312867, val:  72.35%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.92 seconds, 1.27 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-873 lr=['0.0001221'], tr/val_loss:  2.307310/  2.313953, val:  68.14%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.86 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-874 lr=['0.0001221'], tr/val_loss:  2.307279/  2.312404, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.56 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-875 lr=['0.0001221'], tr/val_loss:  2.307739/  2.316298, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-876 lr=['0.0001221'], tr/val_loss:  2.308372/  2.315341, val:  73.23%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.55 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-877 lr=['0.0001221'], tr/val_loss:  2.306885/  2.313345, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.40 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-878 lr=['0.0001221'], tr/val_loss:  2.307016/  2.313661, val:  75.22%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.91 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-879 lr=['0.0001221'], tr/val_loss:  2.307797/  2.309898, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.17 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-880 lr=['0.0001221'], tr/val_loss:  2.307513/  2.312498, val:  74.12%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.06 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-881 lr=['0.0001221'], tr/val_loss:  2.308825/  2.314726, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.38 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-882 lr=['0.0001221'], tr/val_loss:  2.307026/  2.313099, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.14 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-883 lr=['0.0001221'], tr/val_loss:  2.307449/  2.310059, val:  80.97%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.16 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-884 lr=['0.0001221'], tr/val_loss:  2.307033/  2.308190, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.52 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-885 lr=['0.0001221'], tr/val_loss:  2.307901/  2.312396, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.19 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-886 lr=['0.0001221'], tr/val_loss:  2.308186/  2.317078, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.69 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-887 lr=['0.0001221'], tr/val_loss:  2.308380/  2.314605, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.03 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-888 lr=['0.0001221'], tr/val_loss:  2.307656/  2.310086, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.57 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-889 lr=['0.0001221'], tr/val_loss:  2.306819/  2.311568, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 72.32 seconds, 1.21 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-890 lr=['0.0001221'], tr/val_loss:  2.307176/  2.313184, val:  78.98%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.89 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-891 lr=['0.0001221'], tr/val_loss:  2.307750/  2.313850, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.38 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-892 lr=['0.0001221'], tr/val_loss:  2.307472/  2.313030, val:  73.67%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.70 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-893 lr=['0.0001221'], tr/val_loss:  2.307068/  2.311128, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.98 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-894 lr=['0.0001221'], tr/val_loss:  2.307089/  2.310612, val:  76.11%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.55 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-895 lr=['0.0001221'], tr/val_loss:  2.306705/  2.311400, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.06 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-896 lr=['0.0001221'], tr/val_loss:  2.306986/  2.313700, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.02 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-897 lr=['0.0001221'], tr/val_loss:  2.308064/  2.313778, val:  70.80%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.66 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-898 lr=['0.0001221'], tr/val_loss:  2.306544/  2.309654, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.14 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-899 lr=['0.0001221'], tr/val_loss:  2.306379/  2.315630, val:  75.44%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.85 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-900 lr=['0.0001221'], tr/val_loss:  2.307341/  2.310218, val:  81.86%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.95 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-901 lr=['0.0001221'], tr/val_loss:  2.306779/  2.311789, val:  69.47%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.09 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-902 lr=['0.0001221'], tr/val_loss:  2.306846/  2.312826, val:  74.34%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.60 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-903 lr=['0.0001221'], tr/val_loss:  2.307317/  2.309285, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.45 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-904 lr=['0.0001221'], tr/val_loss:  2.307474/  2.310136, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.62 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-905 lr=['0.0001221'], tr/val_loss:  2.307747/  2.312547, val:  78.54%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.37 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-906 lr=['0.0001221'], tr/val_loss:  2.308130/  2.313831, val:  71.68%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.86 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-907 lr=['0.0001221'], tr/val_loss:  2.308264/  2.313335, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.21 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-908 lr=['0.0001221'], tr/val_loss:  2.308178/  2.311902, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.59 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-909 lr=['0.0001221'], tr/val_loss:  2.307661/  2.313804, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.16 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-910 lr=['0.0001221'], tr/val_loss:  2.308630/  2.311707, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.39 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-911 lr=['0.0001221'], tr/val_loss:  2.307840/  2.310709, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.37 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-912 lr=['0.0001221'], tr/val_loss:  2.307586/  2.311486, val:  77.21%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.41 seconds, 1.22 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-913 lr=['0.0001221'], tr/val_loss:  2.308068/  2.310269, val:  77.65%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.56 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-914 lr=['0.0001221'], tr/val_loss:  2.308177/  2.313097, val:  77.43%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.81 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-915 lr=['0.0001221'], tr/val_loss:  2.307907/  2.313579, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.68 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-916 lr=['0.0001221'], tr/val_loss:  2.307327/  2.312789, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 76.15 seconds, 1.27 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-917 lr=['0.0001221'], tr/val_loss:  2.308203/  2.312145, val:  75.66%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.89 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-918 lr=['0.0001221'], tr/val_loss:  2.307804/  2.313411, val:  80.31%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.98 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-919 lr=['0.0001221'], tr/val_loss:  2.307290/  2.316738, val:  73.01%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.03 seconds, 1.25 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-920 lr=['0.0001221'], tr/val_loss:  2.307593/  2.311319, val:  74.34%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.02 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-921 lr=['0.0001221'], tr/val_loss:  2.307612/  2.311888, val:  73.89%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.83 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-922 lr=['0.0001221'], tr/val_loss:  2.307129/  2.313357, val:  74.56%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.83 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-923 lr=['0.0001221'], tr/val_loss:  2.307966/  2.315681, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 75.62 seconds, 1.26 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-924 lr=['0.0001221'], tr/val_loss:  2.307664/  2.310967, val:  78.76%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.60 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-925 lr=['0.0001221'], tr/val_loss:  2.306890/  2.312841, val:  80.53%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.46 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-926 lr=['0.0001221'], tr/val_loss:  2.307148/  2.314188, val:  73.45%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 74.45 seconds, 1.24 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-927 lr=['0.0001221'], tr/val_loss:  2.308607/  2.316667, val:  74.78%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.61 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-928 lr=['0.0001221'], tr/val_loss:  2.308009/  2.311062, val:  81.19%, val_best:  89.16%, tr: 100.00%, tr_best: 100.00%, epoch time: 73.91 seconds, 1.23 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "my_snn_system(  devices = \"1\",\n",
    "                single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "                unique_name = run_name,\n",
    "                my_seed = 1,\n",
    "                TIME = 4, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "                BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                # n_tidigits_tonic 8\n",
    "\n",
    "                # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "                which_data = 'n_tidigits_tonic',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.0625,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "                lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "                synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "                # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "                # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                learning_rate = 1/8192, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 1000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 25_000, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "                # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "                # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "                exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 9, \n",
    "\n",
    "                num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "                chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = False, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 8, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "                # quantize_bit_list=[8,8,8],\n",
    "                # scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "                quantize_bit_list=[],\n",
    "                scale_exp=[], \n",
    "                timestep_sums_threshold = 0,\n",
    "# 1w -11~-9\n",
    "# 1b -11~ -7\n",
    "# 2w -10~-8\n",
    "# 2b -10~-8\n",
    "# 3w -10\n",
    "# 3b -10\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# average pooling  \n",
    "# Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# # Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [8]},\n",
    "#         \"BATCH\": {\"values\": [1]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [4.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.01,0.001,0.0001,0.00001]}, \n",
    "#         \"epoch_num\": {\"values\": [1]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [14]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [25_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [True]},\n",
    "#         \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [5]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "#         \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "#         \"scale_exp_1w\": {\"values\": [-11,-10,-9]},\n",
    "#         # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "#         \"scale_exp_2w\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "#         \"scale_exp_3w\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"5\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#         quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "#         scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_2w,wandb.config.scale_exp_2w],[wandb.config.scale_exp_3w,wandb.config.scale_exp_3w]],\n",
    "#                         ) \n",
    "#     # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "#     # average pooling\n",
    "#     # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "#     # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = 'v89awhtt'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
