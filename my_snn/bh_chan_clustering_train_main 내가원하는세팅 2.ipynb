{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, lateral_feature_num], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            # net = SAE_fc_only(encoder_ch=[96, 64, 32, lateral_feature_num], \n",
    "            #                     decoder_ch=[32,64,96,n_sample], \n",
    "            #                     in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "            #                     synapse_fc_trace_const1=1,\n",
    "            #                     synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last)\n",
    "            net = SAE_fc_only(encoder_ch=[200, lateral_feature_num], \n",
    "                                decoder_ch=[200,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250106_173037_486.pth'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike_backup = data\n",
    "            spike = data\n",
    "            spike = spike.to(device) # batch, feature\n",
    "            if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                # spike: batch, time, level_num\n",
    "                # levels: time, level_num\n",
    "                if Conv_net == True:\n",
    "                    spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    if two_channel_input == True:\n",
    "                        spike_backup = spike_backup.to(device)\n",
    "                        spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                        spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                        spike_backup = spike_backup.unsqueeze(-2)\n",
    "                        spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "            elif 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                if Conv_net == True:\n",
    "                    spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "            else:\n",
    "                if Conv_net == True:\n",
    "                    spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "            # for i in range (10):\n",
    "            #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "            #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "            # assert False\n",
    "                    \n",
    "            spike_class = net(spike) # batch, time, feature\n",
    "\n",
    "            if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                loss = nn.MSELoss()(spike_class, spike)\n",
    "            elif 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "            else:\n",
    "                loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            sys.stdout.write(f'\\repoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "            sys.stdout.flush()\n",
    "            # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "            iter += 1\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template).float()\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                \n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250108_194846-wgvdebny</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/wgvdebny' target=\"_blank\">firm-monkey-320</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/wgvdebny' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/wgvdebny</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 1, 'Conv_net': False, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 7000, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 20, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 10000.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250108_194844_886', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': False, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'coarse_com_config': (2.0, -2.0)}\n",
      "DataParallel(\n",
      "  (module): SAE_fc_only(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=20, out_features=200, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Linear(in_features=200, out_features=4, bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=200, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Linear(in_features=200, out_features=20, bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250108_194844_886\n",
      "\n",
      "epoch-0, running_loss : 26.37149, iter percent 99.92%\n",
      "epoch-0 loss : 0.02198\n",
      "ae train 실행 시간: 132.413초\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97540208 0.9736098  0.86278286 0.77242044 0.79154229 0.92216981\n",
      " 0.86275485 0.54891816 0.78164397 0.66748047 0.59797297 0.46226415\n",
      " 0.57331976 0.43549952 0.625      0.22455805]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.14%, post_traincycle_acc : 69.23%, total_acc : 69.59%\n",
      "save model\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 69.23%\n",
      "accuracy_check 실행 시간: 21.061초\n",
      "\n",
      "epoch-1, running_loss : 13.18712, iter percent 99.92%\n",
      "epoch-1 loss : 0.01099\n",
      "ae train 실행 시간: 134.059초\n",
      "\n",
      "epoch-1 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97729423 0.97737983 0.91044776 0.78302797 0.96467662 0.7995283\n",
      " 0.78070612 0.50893697 0.95259708 0.65527344 0.62548263 0.71251241\n",
      " 0.93737271 0.87051406 0.53137255 0.40277114]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.10%, post_traincycle_acc : 77.44%, total_acc : 76.07%\n",
      "save model\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.44%\n",
      "accuracy_check 실행 시간: 21.035초\n",
      "\n",
      "epoch-2, running_loss : 10.11848, iter percent 99.92%\n",
      "epoch-2 loss : 0.00843\n",
      "ae train 실행 시간: 132.058초\n",
      "\n",
      "epoch-2 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97114475 0.97643732 0.84400578 0.78977821 0.96616915 0.92830189\n",
      " 0.86176032 0.31984948 0.80635401 0.88769531 0.61003861 0.60377358\n",
      " 0.9592668  0.92870999 0.78333333 0.67271859]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.00%, post_traincycle_acc : 80.68%, total_acc : 79.98%\n",
      "save model\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.68%\n",
      "accuracy_check 실행 시간: 20.692초\n",
      "\n",
      "epoch-3, running_loss : 9.64814, iter percent 99.92%\n",
      "epoch-3 loss : 0.00804\n",
      "ae train 실행 시간: 133.695초\n",
      "\n",
      "epoch-3 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97161779 0.9736098  0.97014925 0.83895853 0.96567164 0.94150943\n",
      " 0.84883143 0.31326435 0.94856278 0.89257812 0.6742278  0.55561072\n",
      " 0.68279022 0.6042677  0.58333333 0.53511706]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.31%, post_traincycle_acc : 76.88%, total_acc : 76.64%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.68%\n",
      "accuracy_check 실행 시간: 20.365초\n",
      "\n",
      "epoch-4, running_loss : 10.73898, iter percent 99.92%\n",
      "epoch-4 loss : 0.00895\n",
      "ae train 실행 시간: 130.247초\n",
      "\n",
      "epoch-4 accuracy check\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = 1\n",
    "Conv_net = False\n",
    "SAE_net = True\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 20 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (2.0, -2.0) # (max, min) (2.0, -2.0) (3.0 -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = False # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 60bl8wyr\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/60bl8wyr\n",
      "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16,32,48]}, \n",
    "        \"max_epoch\": {\"values\": [1]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [50,40,30,20]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75,0.875]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"coarse_com_mode\": {\"values\": [True]}, # ['Adam', 'SGD']\n",
    "        \"coarse_com_config\": {\"values\": [(2.0, -2.0), (3.0, -3.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"sae_l2_norm_bridge\": {\"values\": [False]}, # [True, False]\n",
    "        \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "        \"accuracy_check_epoch_term\": {\"values\": [5]}, \n",
    "\n",
    "        \"lif_add_at_last\": {\"values\": [True, False]},# [True, False]\n",
    "\n",
    "        \"two_channel_input\": {\"values\": [True, False]},# [True, False]\n",
    "\n",
    "        \"lateral_feature_num\": {\"values\": [4, 5, 6]},# [True, False]\n",
    "\n",
    "        \"lc_adc_on\": {\"values\": [True, False]},# [True, False]\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  3\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "    coarse_com_mode = wandb.config.coarse_com_mode\n",
    "    coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "    sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "    accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "    lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "    two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "    lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "    lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "        coarse_com_mode = coarse_com_mode,\n",
    "        coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "        sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "        sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "        accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "        lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "        two_channel_input = two_channel_input,\n",
    "        \n",
    "        lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "        lc_adc_on = lc_adc_on,\n",
    "        )\n",
    "    \n",
    "# sweep_id = 'ygoj9jt4'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263d97159a7a47c1b655e5284437393f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sky-311</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/091mub31' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/091mub31</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250108_191832-091mub31/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result_save/cluster_accuracy_history_20250108_191829_830.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# current_time = '20250102_225243_972'\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult_save/cluster_accuracy_history_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_time\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# JSON으로 저장\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result_save/cluster_accuracy_history_20250108_191829_830.pkl'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# current_time = '20250102_225243_972'\n",
    "\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "# JSON으로 저장\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "    loaded_hyperparameters = json.load(f)\n",
    "\n",
    "loss_history = data['loss_history']\n",
    "mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "print(data)\n",
    "max_acc = 0\n",
    "for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "    if i[1] > max_acc:\n",
    "        max_acc = i[1]\n",
    "\n",
    "# 설정 정보 제목 작성\n",
    "title = (\n",
    "    f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "    f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "    f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "    f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    ")\n",
    "\n",
    "# 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "data_list = [\n",
    "    (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "]\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 첫 번째 y축: Accuracy 관련 데이터\n",
    "for label, data in data_list:\n",
    "    epochs, values = zip(*data)  # epoch, value 분리\n",
    "    ax1.plot(epochs, values, label=label)\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.legend(loc=\"center right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# x축을 정수만 표시하도록 설정\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# 두 번째 y축: Loss History\n",
    "ax2 = ax1.twinx()\n",
    "epochs, values = zip(*loss_history)\n",
    "ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "ax2.legend(loc=\"center left\")\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
