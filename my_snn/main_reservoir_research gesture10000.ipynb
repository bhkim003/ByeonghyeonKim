{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH:256\n",
    "# batch_size:256\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.7834769413661389\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:32\n",
    "# learning_rate:0.007176761798504128\n",
    "# pre_spike_weight:5.165214142219577\n",
    "# rate_coding:true\n",
    "# TIME_STEP:9\n",
    "# time_step:9\n",
    "# v_decay:0.7834769413661389\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"CIFAR10\"\n",
    "\n",
    "\n",
    "# BATCH:256\n",
    "# batch_size:256\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.38993471232202725\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:28\n",
    "# learning_rate:0.06285718352377828\n",
    "# pre_spike_weight:6.21970124592063\n",
    "# rate_coding:true\n",
    "# TIME_STEP:16\n",
    "# time_step:16\n",
    "# v_decay:0.38993471232202725\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"MNIST\"\n",
    "\n",
    "# BATCH:64\n",
    "# batch_size:64\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.9266077968579136\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:28\n",
    "# learning_rate:0.07732456724854177\n",
    "# pre_spike_weight:1.5377416716615555\n",
    "# rate_coding:true\n",
    "# TIME_STEP:7\n",
    "# time_step:7\n",
    "# v_decay:0.9266077968579136\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"FASHION_MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from snntorch import spikegen\n",
    "\n",
    " \n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class RESERVOIR(nn.Module):\n",
    "    def __init__ (self, TIME_STEP=8, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1):\n",
    "        super(RESERVOIR, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.in_spike_size = in_spike_size\n",
    "        self.in_channel = in_channel\n",
    "        self.receptive_size = receptive_size #3\n",
    "        self.v_init = v_init\n",
    "        self.v_decay = v_decay\n",
    "        self.v_threshold = v_threshold\n",
    "        self.v_reset = v_reset\n",
    "        self.hard_reset = hard_reset\n",
    "        self.pre_spike_weight = pre_spike_weight\n",
    "\n",
    "        self.out_channel = 1\n",
    "\n",
    "        # 파라미터 \n",
    "        self.conv_depthwise = nn.Conv2d(in_channels=self.in_channel, out_channels=self.in_channel, \n",
    "                                        kernel_size=self.receptive_size, \n",
    "                                        stride=1, padding=1, groups=self.in_channel)\n",
    "\n",
    "        # kaiming 초기화\n",
    "        nn.init.kaiming_normal_(self.conv_depthwise.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.conv_depthwise.bias, 0)\n",
    "\n",
    "        # membrane potential 초기화\n",
    "        self.v = torch.full((self.in_channel, self.in_spike_size, self.in_spike_size), fill_value=self.v_init, requires_grad=False)\n",
    "\n",
    "        \n",
    "    def forward(self, pre_spike):    \n",
    "        # pre_spike [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        v = torch.full_like(pre_spike[0], fill_value=self.v_init, requires_grad=False)\n",
    "        post_spike = torch.zeros_like(pre_spike[0], requires_grad=False)\n",
    "        # v [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "        # recurrent [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        # timestep 안 맞으면 종료\n",
    "        assert pre_spike.size(0) == self.TIME_STEP, f\"Time step mismatch: {pre_spike.size(0)} vs {self.TIME_STEP}\"\n",
    "\n",
    "        output = []\n",
    "        for t in range (self.TIME_STEP):\n",
    "            # pre_spike[t] [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "            input_current = self.pre_spike_weight * pre_spike[t]\n",
    "            recurrent_current = self.conv_depthwise(post_spike)\n",
    "            current = input_current + recurrent_current\n",
    "            # current [batch_size, in_channel, in_spike_size, in_spike_size] # kernel size 3이니까 사이즈 유지\n",
    "            \n",
    "            # decay and itegrate\n",
    "            v = v*self.v_decay + current\n",
    "\n",
    "            # post spike\n",
    "            post_spike = (v >= self.v_threshold).float()\n",
    "\n",
    "            output.append(post_spike)\n",
    "            \n",
    "            #reset\n",
    "            if self.hard_reset: # hard reset\n",
    "                v = (1 - post_spike)*v + post_spike*self.v_reset \n",
    "            else: # soft reset\n",
    "                v = v - post_spike*self.v_threshold\n",
    "\n",
    "        output = torch.stack(output, dim=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NO_RESERVOIR_NET(nn.Module):\n",
    "    def __init__(self, TIME_STEP=8, CLASS_NUM=10, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1):\n",
    "        super(NO_RESERVOIR_NET, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.reservoir = RESERVOIR(TIME_STEP = self.TIME_STEP, in_spike_size=in_spike_size, in_channel=in_channel, receptive_size=receptive_size, v_init=v_init, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "        self.linear = nn.Linear(in_features=in_channel*in_spike_size*in_spike_size, out_features=CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x size [batch_size, TIME_STEP, in_channel, in_spike_size, in_spike_size]\n",
    "        x = x.permute(1,0,2,3,4)\n",
    "        # x size [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     x = self.reservoir(x) # reservoir weight는 학습 안함\n",
    "\n",
    "        T, B, *spatial_dims = x.shape\n",
    "        x = x.reshape(T * B, -1) # time,batch 축은 합쳐서 FC에 삽입\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        x = x.view(T , B, -1).contiguous() \n",
    "        \n",
    "        x = x.mean(dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESERVOIR_NET(nn.Module):\n",
    "    def __init__(self, TIME_STEP=8, CLASS_NUM=10, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1):\n",
    "        super(RESERVOIR_NET, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.reservoir = RESERVOIR(TIME_STEP = self.TIME_STEP, in_spike_size=in_spike_size, in_channel=in_channel, receptive_size=receptive_size, v_init=v_init, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "        self.linear = nn.Linear(in_features=in_channel*in_spike_size*in_spike_size, out_features=CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x size [batch_size, TIME_STEP, in_channel, in_spike_size, in_spike_size]\n",
    "        x = x.permute(1,0,2,3,4)\n",
    "        # x size [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.reservoir(x) # reservoir weight는 학습 안함\n",
    "\n",
    "        T, B, *spatial_dims = x.shape\n",
    "        x = x.reshape(T * B, -1) # time,batch 축은 합쳐서 FC에 삽입\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        x = x.view(T , B, -1).contiguous() \n",
    "        \n",
    "        x = x.mean(dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(which_data, data_path, rate_coding, BATCH, IMAGE_SIZE, TIME, dvs_duration, dvs_clipping):\n",
    "    if which_data == 'MNIST':\n",
    "        if rate_coding :\n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0,), (1,))])\n",
    "        else : \n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,),(0.5))])\n",
    "\n",
    "        trainset = torchvision.datasets.MNIST(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.MNIST(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        synapse_conv_in_channels = 1\n",
    "        CLASS_NUM = 10\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    elif (which_data == 'CIFAR10'):\n",
    "\n",
    "        if rate_coding :\n",
    "            # transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.RandomHorizontalFlip(),\n",
    "            #                                     transforms.ToTensor()])\n",
    "\n",
    "            # transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.ToTensor()])\n",
    "            \n",
    "            transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor()])\n",
    "                                            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                                transforms.ToTensor()])\n",
    "        \n",
    "        else :\n",
    "            # transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.RandomHorizontalFlip(),\n",
    "            #                                     transforms.ToTensor(),\n",
    "            #                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "            #                                 # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "            # transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.ToTensor(),\n",
    "            #                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),])\n",
    "            #                                 # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            \n",
    "            # assert IMAGE_SIZE == 32, 'OTTT랑 맞짱뜰 때는 32로 ㄱ'\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(IMAGE_SIZE, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform_test)\n",
    "        \n",
    "        \n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        \n",
    "        synapse_conv_in_channels = 3\n",
    "        CLASS_NUM = 10\n",
    "        '''\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "                'dog', 'frog', 'horse', 'ship', 'truck') \n",
    "        '''\n",
    "\n",
    "\n",
    "    elif (which_data == 'FASHION_MNIST'):\n",
    "\n",
    "        if rate_coding :\n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor()])\n",
    "        else : \n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,),(0.5))])\n",
    "\n",
    "        trainset = torchvision.datasets.FashionMNIST(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.FashionMNIST(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        synapse_conv_in_channels = 1\n",
    "        CLASS_NUM = 10\n",
    "    elif (which_data == 'DVS_GESTURE'):\n",
    "        data_dir = data_path + '/gesture'\n",
    "        transform = None\n",
    "\n",
    "        # # spikingjelly.datasets.dvs128_gesture.DVS128Gesture(root: str, train: bool, use_frame=True, frames_num=10, split_by='number', normalization='max')\n",
    "       \n",
    "        #https://spikingjelly.readthedocs.io/zh-cn/latest/activation_based_en/neuromorphic_datasets.html\n",
    "        # 10ms마다 1개의 timestep하고 싶으면 위의 주소 참고. 근데 timestep이 각각 좀 다를 거임.\n",
    "\n",
    "        \n",
    "        if dvs_duration > 0:\n",
    "            resize_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "            train_data = CustomDVS128Gesture(\n",
    "                data_dir, train=True, data_type='frame',  split_by='time',  duration=dvs_duration, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "            test_data = CustomDVS128Gesture(\n",
    "                data_dir, train=False, data_type='frame',  split_by='time',  duration=dvs_duration, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "\n",
    "        else:\n",
    "            train_data = CustomDVS128Gesture(\n",
    "                data_dir, train=True, data_type='frame', split_by='number', frames_number=TIME, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "            test_data = CustomDVS128Gesture(data_dir, train=False,\n",
    "                                            data_type='frame', split_by='number', frames_number=TIME, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "        ## 11번째 클래스 배제 ########################################################################\n",
    "        exclude_class = 10\n",
    "        if dvs_duration > 0:\n",
    "            train_file_name = f'modules/dvs_gesture_class_index/train_indices_dvsgesture_duration_{dvs_duration}'\n",
    "            test_file_name = f'modules/dvs_gesture_class_index/test_indices_dvsgesture_duration_{dvs_duration}'\n",
    "            if (os.path.isfile(train_file_name) and os.path.isfile(test_file_name)):\n",
    "                print('\\ndvsgestrue 10th exclude class indices exist\\n')\n",
    "                with open(train_file_name, 'rb') as f:\n",
    "                    train_indices = pickle.load(f)\n",
    "                with open(test_file_name, 'rb') as f:\n",
    "                    test_indices = pickle.load(f)\n",
    "            else:\n",
    "                print('\\ndvsgestrue 10th exclude class indices doesn\\'t exist\\n')\n",
    "                train_indices = [i for i, (_, target) in enumerate(train_data) if target != exclude_class]\n",
    "                test_indices = [i for i, (_, target) in enumerate(test_data) if target != exclude_class]\n",
    "                with open(train_file_name, 'wb') as f:\n",
    "                    pickle.dump(train_indices, f)\n",
    "                with open(test_file_name, 'wb') as f:\n",
    "                    pickle.dump(test_indices, f)\n",
    "        else:\n",
    "            train_indices = [i for i, (_, target) in enumerate(train_data) if target != exclude_class]\n",
    "            test_indices = [i for i, (_, target) in enumerate(test_data) if target != exclude_class]\n",
    "        ################################################################################################\n",
    "            \n",
    "        # SubsetRandomSampler 생성\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        test_sampler = SequentialSampler(test_indices)\n",
    "\n",
    "        # ([B, T, 2, 128, 128]) \n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH, num_workers=2, sampler=train_sampler, collate_fn=pad_sequence_collate)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH, num_workers=2, sampler=test_sampler, collate_fn=pad_sequence_collate)\n",
    "        synapse_conv_in_channels = 2\n",
    "        CLASS_NUM = 10\n",
    "        # mapping = { 0 :'Hand Clapping'  1 :'Right Hand Wave'2 :'Left Hand Wave' 3 :'Right Arm CW'   4 :'Right Arm CCW'  5 :'Left Arm CW'    6 :'Left Arm CCW'   7 :'Arm Roll'       8 :'Air Drums'      9 :'Air Guitar'     10:'Other'}\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert False, 'wrong dataset name'\n",
    "\n",
    "\n",
    "    \n",
    "    return train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, rate_coding, TIME_STEP, which_data):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterator = enumerate(train_loader, 0)\n",
    "    for i, data in iterator:\n",
    "    # for i, (inputs, labels) in enumerate(train_loader):\n",
    "        if len(data) == 2:\n",
    "            inputs, labels = data\n",
    "            # 처리 로직 작성\n",
    "        elif len(data) == 3:\n",
    "            inputs, labels, x_len = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # if rate_coding == True:\n",
    "        #     inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "        # else:\n",
    "        #     inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "        \n",
    "\n",
    "        ###########################################################################################################################        \n",
    "        if (which_data == 'n_tidigits'):\n",
    "            inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "            labels = labels[:, 0, :]\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "        elif (which_data == 'heidelberg'):\n",
    "            inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "            print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "        # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "        # print(labels)\n",
    "            \n",
    "        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        elif rate_coding == True :\n",
    "            inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "        else :\n",
    "            inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "        ####################################################################################################################### \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        iter_correct = (predicted == labels).sum().item()\n",
    "        correct += iter_correct\n",
    "        # if i % 100 == 99:\n",
    "        # print(f\"[{i+1}] loss: {running_loss / 100:.3f}\")\n",
    "        # running_loss = 0.0\n",
    "        iter_accuracy = 100 * iter_correct / labels.size(0)\n",
    "        wandb.log({\"iter_accuracy\": iter_accuracy})\n",
    "    tr_accuracy = 100 * correct / total         \n",
    "    wandb.log({\"tr_accuracy\": tr_accuracy})\n",
    "    print(f\"Train Accuracy: {tr_accuracy:.2f}%\")\n",
    "    \n",
    "def test(model, test_loader, criterion, device, rate_coding, TIME_STEP, which_data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    iterator = enumerate(test_loader, 0)\n",
    "    with torch.no_grad():\n",
    "        for i, data in iterator:\n",
    "        # for inputs, labels in test_loader:\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # if rate_coding == True:\n",
    "            #     inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "            # else:\n",
    "            #     inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "\n",
    "        \n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = 100 * correct / total\n",
    "    wandb.log({\"val_accuracy\": val_accuracy})\n",
    "    print(f\"Test loss: {test_loss / len(test_loader):.3f}, Val Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path='/data2', which_data='MNIST', gpu = '3',learning_rate = 0.0001, BATCH=5, IMAGE_SIZE=28, TIME_STEP=8, EPOCH=10, rate_coding=True, v_decay= 0.6,\n",
    "v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "    # run = wandb.init(project=f'reservoir')\n",
    "\n",
    "    hyperparameters = locals()\n",
    "\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{which_data}_sweeprun_epoch{EPOCH}'\n",
    "    wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "\n",
    "    train_loader, test_loader, in_channel, CLASS_NUM = data_loader(\n",
    "        which_data=which_data, data_path=data_path, rate_coding=rate_coding, BATCH=BATCH, IMAGE_SIZE=IMAGE_SIZE, TIME=TIME_STEP, dvs_duration=dvs_duration, dvs_clipping=dvs_clipping)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if no_reservoir == True:\n",
    "        net = NO_RESERVOIR_NET(TIME_STEP=TIME_STEP, CLASS_NUM=CLASS_NUM, in_spike_size=IMAGE_SIZE, in_channel=in_channel, receptive_size=3, v_init=0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "    else:\n",
    "        net = RESERVOIR_NET(TIME_STEP=TIME_STEP, CLASS_NUM=CLASS_NUM, in_spike_size=IMAGE_SIZE, in_channel=in_channel, receptive_size=3, v_init=0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "    net = net.to(device)\n",
    "    wandb.watch(net, log=\"all\", log_freq = 1) #gradient, parameter logging해줌\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        train(net, train_loader, criterion, optimizer, device, rate_coding, TIME_STEP, which_data)\n",
    "        test(net, test_loader, criterion, device, rate_coding, TIME_STEP, which_data)\n",
    "        # torch.save(net.state_dict(), 'net_save/reservoir_net.pth')\n",
    "        # artifact = wandb.Artifact('model', type='model')\n",
    "        # artifact.add_file('net_save/reservoir_net.pth')\n",
    "        # run.log_artifact(artifact)\n",
    "        wandb.log({\"epoch\": epoch})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하기 싫을 때\n",
    "# wandb.init(project=f'reservoir')\n",
    "# main(data_path='/data2', which_data='CIFAR10', gpu = '3', learning_rate = 0.0072, BATCH=256, IMAGE_SIZE=32, TIME_STEP=9, EPOCH=50, rate_coding=True, v_decay= 0.78,\n",
    "# v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=5.0, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: r2y8yym7\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9x0s3z8w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.8205614341403393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09376399117836123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 7.415579574193588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240726_123008-9x0s3z8w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/9x0s3z8w' target=\"_blank\">celestial-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/9x0s3z8w' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/9x0s3z8w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10th exclude class indices exist\n",
      "\n",
      "RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (conv_depthwise): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (linear): Linear(in_features=32768, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 25.97%\n",
      "Test loss: 73.816, Val Accuracy: 24.62%\n",
      "Epoch 2\n",
      "Train Accuracy: 36.83%\n",
      "Test loss: 59.757, Val Accuracy: 39.39%\n",
      "Epoch 3\n",
      "Train Accuracy: 49.54%\n",
      "Test loss: 47.115, Val Accuracy: 35.61%\n",
      "Epoch 4\n",
      "Train Accuracy: 55.94%\n",
      "Test loss: 27.708, Val Accuracy: 57.20%\n",
      "Epoch 5\n",
      "Train Accuracy: 65.96%\n",
      "Test loss: 22.554, Val Accuracy: 56.82%\n",
      "Epoch 6\n",
      "Train Accuracy: 71.80%\n",
      "Test loss: 14.103, Val Accuracy: 61.36%\n",
      "Epoch 7\n",
      "Train Accuracy: 74.03%\n",
      "Test loss: 14.898, Val Accuracy: 62.50%\n",
      "Epoch 8\n",
      "Train Accuracy: 82.10%\n",
      "Test loss: 11.627, Val Accuracy: 69.32%\n",
      "Epoch 9\n",
      "Train Accuracy: 84.60%\n",
      "Test loss: 12.692, Val Accuracy: 62.88%\n",
      "Epoch 10\n",
      "Train Accuracy: 86.46%\n",
      "Test loss: 18.542, Val Accuracy: 63.64%\n",
      "Epoch 11\n",
      "Train Accuracy: 90.54%\n",
      "Test loss: 9.269, Val Accuracy: 64.77%\n",
      "Epoch 12\n",
      "Train Accuracy: 93.14%\n",
      "Test loss: 8.773, Val Accuracy: 65.53%\n",
      "Epoch 13\n",
      "Train Accuracy: 92.02%\n",
      "Test loss: 6.786, Val Accuracy: 67.05%\n",
      "Epoch 14\n",
      "Train Accuracy: 93.23%\n",
      "Test loss: 11.177, Val Accuracy: 65.53%\n",
      "Epoch 15\n",
      "Train Accuracy: 96.20%\n",
      "Test loss: 11.120, Val Accuracy: 71.59%\n",
      "Epoch 16\n",
      "Train Accuracy: 95.64%\n",
      "Test loss: 9.404, Val Accuracy: 66.29%\n",
      "Epoch 17\n",
      "Train Accuracy: 96.20%\n",
      "Test loss: 9.782, Val Accuracy: 67.05%\n",
      "Epoch 18\n",
      "Train Accuracy: 95.08%\n",
      "Test loss: 12.081, Val Accuracy: 68.94%\n",
      "Epoch 19\n",
      "Train Accuracy: 97.03%\n",
      "Test loss: 7.844, Val Accuracy: 68.18%\n",
      "Epoch 20\n",
      "Train Accuracy: 98.52%\n",
      "Test loss: 9.132, Val Accuracy: 68.56%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500aa69709e44b4ebcad6bd7ea35b559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='20.666 MB of 20.666 MB uploaded (20.369 MB deduped)\\r'), FloatProgress(value=1.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 98.3%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>iter_accuracy</td><td>▁▂▂▃▃▃▃▅▅▅▅▆▅▆▆▇▇▆▆▇▇█▇█▇▇▇███▇████▇████</td></tr><tr><td>tr_accuracy</td><td>▁▂▃▄▅▅▆▆▇▇▇▇▇▇██████</td></tr><tr><td>val_accuracy</td><td>▁▃▃▆▆▆▇█▇▇▇▇▇▇█▇▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>iter_accuracy</td><td>100.0</td></tr><tr><td>tr_accuracy</td><td>98.51577</td></tr><tr><td>val_accuracy</td><td>68.56061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/9x0s3z8w' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/9x0s3z8w</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a><br/>Synced 7 W&B file(s), 0 media file(s), 31 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240726_123008-9x0s3z8w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: twqovuoz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.5999127218860145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06612271477604525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 1.0570593018270005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240726_124819-twqovuoz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/twqovuoz' target=\"_blank\">stoic-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/twqovuoz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/twqovuoz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10th exclude class indices exist\n",
      "\n",
      "NO_RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (conv_depthwise): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 33.30%\n",
      "Test loss: 1.562, Val Accuracy: 46.21%\n",
      "Epoch 2\n",
      "Train Accuracy: 54.36%\n",
      "Test loss: 1.444, Val Accuracy: 51.14%\n",
      "Epoch 3\n",
      "Train Accuracy: 66.05%\n",
      "Test loss: 1.280, Val Accuracy: 52.65%\n",
      "Epoch 4\n",
      "Train Accuracy: 71.34%\n",
      "Test loss: 1.230, Val Accuracy: 59.09%\n",
      "Epoch 5\n",
      "Train Accuracy: 73.75%\n",
      "Test loss: 1.144, Val Accuracy: 59.09%\n",
      "Epoch 6\n",
      "Train Accuracy: 74.40%\n",
      "Test loss: 1.208, Val Accuracy: 60.23%\n",
      "Epoch 7\n",
      "Train Accuracy: 79.41%\n",
      "Test loss: 1.258, Val Accuracy: 61.36%\n",
      "Epoch 8\n",
      "Train Accuracy: 79.87%\n",
      "Test loss: 1.145, Val Accuracy: 59.47%\n",
      "Epoch 9\n",
      "Train Accuracy: 83.30%\n",
      "Test loss: 1.050, Val Accuracy: 65.53%\n",
      "Epoch 10\n",
      "Train Accuracy: 82.65%\n",
      "Test loss: 1.079, Val Accuracy: 64.77%\n",
      "Epoch 11\n",
      "Train Accuracy: 82.37%\n",
      "Test loss: 1.128, Val Accuracy: 62.50%\n",
      "Epoch 12\n",
      "Train Accuracy: 84.60%\n",
      "Test loss: 1.119, Val Accuracy: 64.02%\n",
      "Epoch 13\n",
      "Train Accuracy: 85.99%\n",
      "Test loss: 1.068, Val Accuracy: 65.91%\n",
      "Epoch 14\n",
      "Train Accuracy: 87.01%\n",
      "Test loss: 1.020, Val Accuracy: 65.53%\n",
      "Epoch 15\n",
      "Train Accuracy: 87.85%\n",
      "Test loss: 1.089, Val Accuracy: 66.67%\n",
      "Epoch 16\n",
      "Train Accuracy: 87.85%\n",
      "Test loss: 1.130, Val Accuracy: 64.02%\n",
      "Epoch 17\n",
      "Train Accuracy: 86.46%\n",
      "Test loss: 1.173, Val Accuracy: 62.50%\n",
      "Epoch 18\n",
      "Train Accuracy: 86.92%\n",
      "Test loss: 1.086, Val Accuracy: 67.80%\n",
      "Epoch 19\n",
      "Train Accuracy: 89.15%\n",
      "Test loss: 1.062, Val Accuracy: 67.42%\n",
      "Epoch 20\n",
      "Train Accuracy: 90.07%\n",
      "Test loss: 1.054, Val Accuracy: 66.29%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9453f9c45864c058b50e7d683b81153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='20.672 MB of 20.672 MB uploaded (20.431 MB deduped)\\r'), FloatProgress(value=1.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 98.5%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>iter_accuracy</td><td>▁▅▃▃▅▅▅▆▇▆▆▆▇▇▇█▇▇▇▆▆▇▇▇█▇█▇█████▇▇▇████</td></tr><tr><td>tr_accuracy</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇███████</td></tr><tr><td>val_accuracy</td><td>▁▃▃▅▅▆▆▅▇▇▆▇▇▇█▇▆███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>iter_accuracy</td><td>90.74074</td></tr><tr><td>tr_accuracy</td><td>90.07421</td></tr><tr><td>val_accuracy</td><td>66.28788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-sweep-2</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/twqovuoz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/twqovuoz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a><br/>Synced 7 W&B file(s), 0 media file(s), 30 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240726_124819-twqovuoz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmciaub6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.6361841193374299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08643614927021905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 3.6816220502620847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240726_130042-lmciaub6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/lmciaub6' target=\"_blank\">fluent-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/lmciaub6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/lmciaub6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10th exclude class indices exist\n",
      "\n",
      "NO_RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (conv_depthwise): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 18.55%\n",
      "Test loss: 2.280, Val Accuracy: 24.62%\n",
      "Epoch 2\n",
      "Train Accuracy: 34.04%\n",
      "Test loss: 1.736, Val Accuracy: 38.26%\n",
      "Epoch 3\n",
      "Train Accuracy: 52.23%\n",
      "Test loss: 1.724, Val Accuracy: 41.67%\n",
      "Epoch 4\n",
      "Train Accuracy: 56.86%\n",
      "Test loss: 1.554, Val Accuracy: 45.08%\n",
      "Epoch 5\n",
      "Train Accuracy: 60.85%\n",
      "Test loss: 1.551, Val Accuracy: 44.32%\n",
      "Epoch 6\n",
      "Train Accuracy: 62.89%\n",
      "Test loss: 1.493, Val Accuracy: 47.35%\n",
      "Epoch 7\n",
      "Train Accuracy: 65.21%\n",
      "Test loss: 1.544, Val Accuracy: 45.83%\n",
      "Epoch 8\n",
      "Train Accuracy: 68.92%\n",
      "Test loss: 1.438, Val Accuracy: 47.73%\n",
      "Epoch 9\n",
      "Train Accuracy: 71.61%\n",
      "Test loss: 1.390, Val Accuracy: 51.52%\n",
      "Epoch 10\n",
      "Train Accuracy: 73.10%\n",
      "Test loss: 1.382, Val Accuracy: 49.24%\n",
      "Epoch 11\n",
      "Train Accuracy: 76.53%\n",
      "Test loss: 1.409, Val Accuracy: 50.38%\n",
      "Epoch 12\n",
      "Train Accuracy: 75.79%\n",
      "Test loss: 1.276, Val Accuracy: 50.00%\n",
      "Epoch 13\n",
      "Train Accuracy: 78.11%\n",
      "Test loss: 1.360, Val Accuracy: 51.14%\n",
      "Epoch 14\n",
      "Train Accuracy: 78.48%\n",
      "Test loss: 1.365, Val Accuracy: 51.89%\n",
      "Epoch 15\n",
      "Train Accuracy: 80.24%\n",
      "Test loss: 1.234, Val Accuracy: 53.41%\n",
      "Epoch 16\n",
      "Train Accuracy: 81.26%\n",
      "Test loss: 1.379, Val Accuracy: 53.03%\n",
      "Epoch 17\n",
      "Train Accuracy: 81.08%\n",
      "Test loss: 1.267, Val Accuracy: 53.41%\n",
      "Epoch 18\n",
      "Train Accuracy: 82.47%\n",
      "Test loss: 1.178, Val Accuracy: 53.03%\n",
      "Epoch 19\n",
      "Train Accuracy: 82.28%\n",
      "Test loss: 1.409, Val Accuracy: 51.52%\n",
      "Epoch 20\n",
      "Train Accuracy: 83.49%\n",
      "Test loss: 1.207, Val Accuracy: 52.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47896ea6e1c4ad9a114fcf581688026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.241 MB of 0.241 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>iter_accuracy</td><td>▁▂▂▃▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇██</td></tr><tr><td>tr_accuracy</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▇▆▇█▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>iter_accuracy</td><td>81.48148</td></tr><tr><td>tr_accuracy</td><td>83.48794</td></tr><tr><td>val_accuracy</td><td>52.65152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-sweep-3</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/lmciaub6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/lmciaub6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240726_130042-lmciaub6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1svdgaei with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.7377503436393351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03779158330035504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 3.6130240892481154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240726_131452-1svdgaei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/1svdgaei' target=\"_blank\">easy-sweep-4</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/1svdgaei' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/1svdgaei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10th exclude class indices exist\n",
      "\n",
      "RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (conv_depthwise): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (linear): Linear(in_features=32768, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 46.20%\n",
      "Test loss: 7.720, Val Accuracy: 44.70%\n",
      "Epoch 2\n",
      "Train Accuracy: 64.66%\n",
      "Test loss: 8.976, Val Accuracy: 55.30%\n",
      "Epoch 3\n",
      "Train Accuracy: 74.86%\n",
      "Test loss: 6.816, Val Accuracy: 59.47%\n",
      "Epoch 4\n",
      "Train Accuracy: 84.04%\n",
      "Test loss: 4.159, Val Accuracy: 57.20%\n",
      "Epoch 5\n",
      "Train Accuracy: 84.42%\n",
      "Test loss: 4.474, Val Accuracy: 64.77%\n",
      "Epoch 6\n",
      "Train Accuracy: 87.57%\n",
      "Test loss: 6.218, Val Accuracy: 59.09%\n",
      "Epoch 7\n",
      "Train Accuracy: 86.27%\n",
      "Test loss: 5.675, Val Accuracy: 64.39%\n",
      "Epoch 8\n",
      "Train Accuracy: 90.26%\n",
      "Test loss: 5.935, Val Accuracy: 65.15%\n",
      "Epoch 9\n",
      "Train Accuracy: 96.10%\n",
      "Test loss: 6.273, Val Accuracy: 64.39%\n",
      "Epoch 10\n",
      "Train Accuracy: 98.52%\n",
      "Test loss: 4.910, Val Accuracy: 64.77%\n",
      "Epoch 11\n",
      "Train Accuracy: 99.35%\n",
      "Test loss: 4.778, Val Accuracy: 64.39%\n",
      "Epoch 12\n",
      "Train Accuracy: 99.91%\n",
      "Test loss: 5.110, Val Accuracy: 65.15%\n",
      "Epoch 13\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.874, Val Accuracy: 67.05%\n",
      "Epoch 14\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.846, Val Accuracy: 67.05%\n",
      "Epoch 15\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.834, Val Accuracy: 66.67%\n",
      "Epoch 16\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.829, Val Accuracy: 66.67%\n",
      "Epoch 17\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.830, Val Accuracy: 66.67%\n",
      "Epoch 18\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.824, Val Accuracy: 67.05%\n",
      "Epoch 19\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.816, Val Accuracy: 67.05%\n",
      "Epoch 20\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 4.813, Val Accuracy: 67.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b6741aaa674be49a2ef08e37ef28e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.241 MB of 0.241 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>iter_accuracy</td><td>▁▁▃▂▅▅▆▆▆▅█▆▇▆▆▇████████████████████████</td></tr><tr><td>tr_accuracy</td><td>▁▃▅▆▆▆▆▇▇███████████</td></tr><tr><td>val_accuracy</td><td>▁▄▆▅▇▆▇▇▇▇▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>iter_accuracy</td><td>100.0</td></tr><tr><td>tr_accuracy</td><td>100.0</td></tr><tr><td>val_accuracy</td><td>67.04545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-sweep-4</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/1svdgaei' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/1svdgaei</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240726_131452-1svdgaei/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ctej3dvl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3441106270184617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09366666652419056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 1.7731555432278077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240726_133235-ctej3dvl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/ctej3dvl' target=\"_blank\">eager-sweep-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/ctej3dvl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/ctej3dvl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10th exclude class indices exist\n",
      "\n",
      "NO_RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (conv_depthwise): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (linear): Linear(in_features=4608, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 43.41%\n",
      "Test loss: 2.901, Val Accuracy: 49.62%\n",
      "Epoch 2\n",
      "Train Accuracy: 66.14%\n",
      "Test loss: 3.314, Val Accuracy: 56.82%\n",
      "Epoch 3\n",
      "Train Accuracy: 77.74%\n",
      "Test loss: 2.611, Val Accuracy: 53.03%\n",
      "Epoch 4\n",
      "Train Accuracy: 85.06%\n",
      "Test loss: 1.943, Val Accuracy: 64.39%\n",
      "Epoch 5\n",
      "Train Accuracy: 90.35%\n",
      "Test loss: 2.169, Val Accuracy: 62.88%\n",
      "Epoch 6\n",
      "Train Accuracy: 96.20%\n",
      "Test loss: 1.876, Val Accuracy: 62.50%\n",
      "Epoch 7\n",
      "Train Accuracy: 97.87%\n",
      "Test loss: 1.811, Val Accuracy: 63.26%\n",
      "Epoch 8\n",
      "Train Accuracy: 99.81%\n",
      "Test loss: 1.861, Val Accuracy: 62.88%\n",
      "Epoch 9\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.751, Val Accuracy: 68.94%\n",
      "Epoch 10\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.734, Val Accuracy: 68.18%\n",
      "Epoch 11\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.758, Val Accuracy: 68.18%\n",
      "Epoch 12\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.753, Val Accuracy: 68.18%\n",
      "Epoch 13\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.746, Val Accuracy: 68.56%\n",
      "Epoch 14\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.763, Val Accuracy: 67.80%\n",
      "Epoch 15\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.752, Val Accuracy: 68.56%\n",
      "Epoch 16\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.749, Val Accuracy: 68.18%\n",
      "Epoch 17\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.738, Val Accuracy: 68.18%\n",
      "Epoch 18\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.747, Val Accuracy: 68.18%\n",
      "Epoch 19\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.751, Val Accuracy: 68.18%\n",
      "Epoch 20\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.741, Val Accuracy: 67.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c44ea0d2bd4848bfd5f49fbf4682ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.241 MB of 0.241 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>iter_accuracy</td><td>▁▁▅▃▆▅▇▇▇██▇▇███████████████████████████</td></tr><tr><td>tr_accuracy</td><td>▁▄▅▆▇███████████████</td></tr><tr><td>val_accuracy</td><td>▁▄▂▆▆▆▆▆███████████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>iter_accuracy</td><td>100.0</td></tr><tr><td>tr_accuracy</td><td>100.0</td></tr><tr><td>val_accuracy</td><td>67.04545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-5</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/ctej3dvl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/ctej3dvl</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240726_133235-ctej3dvl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: it1b99mc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.8261405874155671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.021388557645593408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 7.846733988137918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240726_134514-it1b99mc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/it1b99mc' target=\"_blank\">neat-sweep-6</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/r2y8yym7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/it1b99mc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/it1b99mc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10th exclude class indices exist\n",
      "\n",
      "RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (conv_depthwise): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (linear): Linear(in_features=4608, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 36.46%\n",
      "Test loss: 1.567, Val Accuracy: 49.24%\n",
      "Epoch 2\n",
      "Train Accuracy: 61.04%\n",
      "Test loss: 1.335, Val Accuracy: 56.82%\n",
      "Epoch 3\n",
      "Train Accuracy: 67.35%\n",
      "Test loss: 1.426, Val Accuracy: 52.65%\n",
      "Epoch 4\n",
      "Train Accuracy: 72.73%\n",
      "Test loss: 1.133, Val Accuracy: 65.15%\n",
      "Epoch 5\n",
      "Train Accuracy: 83.95%\n",
      "Test loss: 1.127, Val Accuracy: 59.85%\n",
      "Epoch 6\n",
      "Train Accuracy: 89.33%\n",
      "Test loss: 1.163, Val Accuracy: 66.67%\n",
      "Epoch 7\n",
      "Train Accuracy: 91.47%\n",
      "Test loss: 0.953, Val Accuracy: 68.56%\n",
      "Epoch 8\n",
      "Train Accuracy: 96.20%\n",
      "Test loss: 1.024, Val Accuracy: 68.56%\n",
      "Epoch 9\n",
      "Train Accuracy: 98.05%\n",
      "Test loss: 1.049, Val Accuracy: 68.56%\n",
      "Epoch 10\n",
      "Train Accuracy: 98.61%\n",
      "Test loss: 0.969, Val Accuracy: 69.32%\n",
      "Epoch 11\n",
      "Train Accuracy: 98.98%\n",
      "Test loss: 1.042, Val Accuracy: 68.56%\n",
      "Epoch 12\n",
      "Train Accuracy: 99.17%\n",
      "Test loss: 1.063, Val Accuracy: 67.42%\n",
      "Epoch 13\n",
      "Train Accuracy: 98.70%\n",
      "Test loss: 1.151, Val Accuracy: 68.94%\n",
      "Epoch 14\n",
      "Train Accuracy: 99.44%\n",
      "Test loss: 1.091, Val Accuracy: 68.94%\n",
      "Epoch 15\n",
      "Train Accuracy: 99.72%\n",
      "Test loss: 1.028, Val Accuracy: 69.32%\n",
      "Epoch 16\n",
      "Train Accuracy: 100.00%\n",
      "Test loss: 1.095, Val Accuracy: 70.08%\n",
      "Epoch 17\n",
      "Train Accuracy: 99.91%\n"
     ]
    }
   ],
   "source": [
    "# sweep하고싶을 때\n",
    "def sweep_cover(data_path='/data2', which_data='CIFAR10', gpu = '3', learning_rate = 0.0001, BATCH=5, IMAGE_SIZE=28, TIME_STEP=8, EPOCH=3, rate_coding=True, v_decay= 0.6,\n",
    "v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False):\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.batch_size\n",
    "    TIME_STEP  =  wandb.config.time_step\n",
    "    v_decay  =  wandb.config.decay\n",
    "    pre_spike_weight  =  wandb.config.pre_spike_weight\n",
    "    which_data  =  wandb.config.which_data\n",
    "    data_path  =  wandb.config.data_path\n",
    "    rate_coding  =  wandb.config.rate_coding\n",
    "    EPOCH  =  wandb.config.EPOCH\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    no_reservoir  =  wandb.config.no_reservoir\n",
    "    main(data_path=data_path, which_data=which_data, gpu = gpu, learning_rate = learning_rate, BATCH=BATCH, IMAGE_SIZE=IMAGE_SIZE, TIME_STEP=TIME_STEP, EPOCH=EPOCH, rate_coding=rate_coding, v_decay= v_decay,\n",
    "v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight, dvs_duration=dvs_duration, dvs_clipping=dvs_clipping, no_reservoir = no_reservoir)\n",
    "\n",
    "\n",
    "\n",
    "which_data_hyper = 'DVS_GESTURE' # 'MNIST', 'CIFAR10' ', 'FASHION_MNIST', 'DVS_GESTURE'\n",
    "data_path_hyper = '/data2'\n",
    "\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': which_data_hyper,\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"min\": 0.00001, \"max\": 0.1},\n",
    "        \"batch_size\": {\"values\": [16, 32, 64, 128, 256]},\n",
    "        \"time_step\": {\"values\": [4,5,6,7,8,9,10,11,12]},\n",
    "        \"decay\": {\"min\": 0.25, \"max\": 1.0},\n",
    "        \"pre_spike_weight\": {\"min\": 0.5, \"max\": 10.0},\n",
    "        \"which_data\": {\"values\": [which_data_hyper]},\n",
    "        \"data_path\": {\"values\": [data_path_hyper]},\n",
    "        \"rate_coding\": {\"values\": [True, False]},\n",
    "        \"EPOCH\": {\"values\": [20]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [16,32,48,128]},\n",
    "        \"dvs_duration\": {\"values\": [10000]},\n",
    "        \"dvs_clipping\": {\"values\": [True]},\n",
    "        \"no_reservoir\": {\"values\": [True, False]},\n",
    "     }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'reservoir')\n",
    "wandb.agent(sweep_id, function=sweep_cover, count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE하기\n",
    "\n",
    "# # Import\n",
    "# import wandb\n",
    "# # Save your model.\n",
    "# torch.save(model.state_dict(), 'save/to/path/model.pth')\n",
    "# # Save as artifact for version control.\n",
    "# run = wandb.init(project='your-project-name')\n",
    "# artifact = wandb.Artifact('model', type='model')\n",
    "# artifact.add_file('save/to/path/model.pth')\n",
    "# run.log_artifact(artifact)\n",
    "# run.finish()\n",
    "\n",
    "\n",
    "# # LOAD 하기\n",
    "\n",
    "# import wandb\n",
    "# run = wandb.init()\n",
    "\n",
    "\n",
    "# artifact = run.use_artifact('entity/your-project-name/model:v0', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "\n",
    "# run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
