{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAIhCAYAAACfVbSSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8BElEQVR4nO3deXxU1f3/8fckkAlLEtaEICHErUYQg4kLmz9cSEsBsS5QVBYBC4ZFliqkWlGoRNAirQiKbCKLkQKCSpFUq6CCxMiiokUFSVBiBJGwJmTm/v6g5NshAZNh5lxm5vV8PO7jYW7unPuZKcqn73PuGYdlWZYAAADgd2F2FwAAABAqaLwAAAAMofECAAAwhMYLAADAEBovAAAAQ2i8AAAADKHxAgAAMITGCwAAwBAaLwAAAENovAAvzJ8/Xw6Ho/yoUaOG4uPj9fvf/15fffWVbXU99thjcjgctt3/dHl5eRo6dKiuuOIKRUVFKS4uTjfffLPeeeedCtf279/f4zOtU6eOWrRooVtuuUXz5s1TSUlJte8/evRoORwOdevWzRdvBwDOGY0XcA7mzZunDRs26F//+peGDRumVatWqUOHDjpw4IDdpZ0XlixZok2bNmnAgAFauXKlZs+eLafTqZtuukkLFiyocH2tWrW0YcMGbdiwQW+88YYmTJigOnXq6L777lNqaqr27NlT5XufOHFCCxculCStWbNG3333nc/eFwB4zQJQbfPmzbMkWbm5uR7nH3/8cUuSNXfuXFvqGj9+vHU+/Wv9ww8/VDhXVlZmtW7d2rrooos8zvfr18+qU6dOpeO89dZbVs2aNa1rr722yvdeunSpJcnq2rWrJcl64oknqvS60tJS68SJE5X+7siRI1W+PwBUhsQL8KG0tDRJ0g8//FB+7vjx4xozZoxSUlIUExOjBg0aqG3btlq5cmWF1zscDg0bNkwvv/yykpOTVbt2bV155ZV64403Klz75ptvKiUlRU6nU0lJSXr66acrren48ePKzMxUUlKSIiIidMEFF2jo0KH6+eefPa5r0aKFunXrpjfeeENt2rRRrVq1lJycXH7v+fPnKzk5WXXq1NE111yjjz/++Bc/j9jY2ArnwsPDlZqaqoKCgl98/Snp6em677779NFHH2ndunVVes2cOXMUERGhefPmKSEhQfPmzZNlWR7XvPvuu3I4HHr55Zc1ZswYXXDBBXI6nfr666/Vv39/1a1bV59++qnS09MVFRWlm266SZKUk5OjHj16qFmzZoqMjNTFF1+swYMHa9++feVjr1+/Xg6HQ0uWLKlQ24IFC+RwOJSbm1vlzwBAcKDxAnxo165dkqRLL720/FxJSYl++ukn/fGPf9Rrr72mJUuWqEOHDrrtttsqnW578803NX36dE2YMEHLli1TgwYN9Lvf/U47d+4sv+btt99Wjx49FBUVpVdeeUVPPfWUXn31Vc2bN89jLMuydOutt+rpp59Wnz599Oabb2r06NF66aWXdOONN1ZYN7V161ZlZmZq7NixWr58uWJiYnTbbbdp/Pjxmj17tiZNmqRFixbp4MGD6tatm44dO1btz6isrEzr169Xy5Ytq/W6W265RZKq1Hjt2bNHa9euVY8ePdS4cWP169dPX3/99Rlfm5mZqfz8fD3//PN6/fXXyxvG0tJS3XLLLbrxxhu1cuVKPf7445Kkb775Rm3bttXMmTO1du1aPfroo/roo4/UoUMHnThxQpLUsWNHtWnTRs8991yF+02fPl1XX321rr766mp9BgCCgN2RGxCITk01bty40Tpx4oR16NAha82aNVaTJk2s66+//oxTVZZ1cqrtxIkT1sCBA602bdp4/E6SFRcXZxUXF5efKywstMLCwqysrKzyc9dee63VtGlT69ixY+XniouLrQYNGnhMNa5Zs8aSZE2ZMsXjPtnZ2ZYka9asWeXnEhMTrVq1all79uwpP7dlyxZLkhUfH+8xzfbaa69ZkqxVq1ZV5ePy8PDDD1uSrNdee83j/NmmGi3Lsr744gtLknX//ff/4j0mTJhgSbLWrFljWZZl7dy503I4HFafPn08rvv3v/9tSbKuv/76CmP069evStPGbrfbOnHihLV7925LkrVy5cry3536c7J58+byc5s2bbIkWS+99NIvvg8AwYfECzgH1113nWrWrKmoqCj95je/Uf369bVy5UrVqFHD47qlS5eqffv2qlu3rmrUqKGaNWtqzpw5+uKLLyqMecMNNygqKqr857i4OMXGxmr37t2SpCNHjig3N1e33XabIiMjy6+LiopS9+7dPcY69fRg//79Pc7feeedqlOnjt5++22P8ykpKbrgggvKf05OTpYkderUSbVr165w/lRNVTV79mw98cQTGjNmjHr06FGt11qnTROe7bpT04udO3eWJCUlJalTp05atmyZiouLK7zm9ttvP+N4lf2uqKhIQ4YMUUJCQvn/nomJiZLk8b9p7969FRsb65F6Pfvss2rcuLF69epVpfcDILjQeAHnYMGCBcrNzdU777yjwYMH64svvlDv3r09rlm+fLl69uypCy64QAsXLtSGDRuUm5urAQMG6Pjx4xXGbNiwYYVzTqezfFrvwIEDcrvdatKkSYXrTj+3f/9+1ahRQ40bN/Y473A41KRJE+3fv9/jfIMGDTx+joiIOOv5yuo/k3nz5mnw4MH6wx/+oKeeeqrKrzvlVJPXtGnTs173zjvvaNeuXbrzzjtVXFysn3/+WT///LN69uypo0ePVrrmKj4+vtKxateurejoaI9zbrdb6enpWr58uR566CG9/fbb2rRpkzZu3ChJHtOvTqdTgwcP1uLFi/Xzzz/rxx9/1KuvvqpBgwbJ6XRW6/0DCA41fvkSAGeSnJxcvqD+hhtukMvl0uzZs/WPf/xDd9xxhyRp4cKFSkpKUnZ2tsceW97sSyVJ9evXl8PhUGFhYYXfnX6uYcOGKisr048//ujRfFmWpcLCQmNrjObNm6dBgwapX79+ev75573aa2zVqlWSTqZvZzNnzhxJ0tSpUzV16tRKfz948GCPc2eqp7Lzn332mbZu3ar58+erX79+5ee//vrrSse4//779eSTT2ru3Lk6fvy4ysrKNGTIkLO+BwDBi8QL8KEpU6aofv36evTRR+V2uyWd/Ms7IiLC4y/xwsLCSp9qrIpTTxUuX77cI3E6dOiQXn/9dY9rTz2Fd2o/q1OWLVumI0eOlP/en+bPn69Bgwbpnnvu0ezZs71qunJycjR79my1a9dOHTp0OON1Bw4c0IoVK9S+fXv9+9//rnDcfffdys3N1Weffeb1+zlV/+mJ1QsvvFDp9fHx8brzzjs1Y8YMPf/88+revbuaN2/u9f0BBDYSL8CH6tevr8zMTD300ENavHix7rnnHnXr1k3Lly9XRkaG7rjjDhUUFGjixImKj4/3epf7iRMn6je/+Y06d+6sMWPGyOVyafLkyapTp45++umn8us6d+6sX//61xo7dqyKi4vVvn17bdu2TePHj1ebNm3Up08fX731Si1dulQDBw5USkqKBg8erE2bNnn8vk2bNh4NjNvtLp+yKykpUX5+vv75z3/q1VdfVXJysl599dWz3m/RokU6fvy4RowYUWky1rBhQy1atEhz5szRM88849V7uuyyy3TRRRdp3LhxsixLDRo00Ouvv66cnJwzvuaBBx7QtddeK0kVnjwFEGLsXdsPBKYzbaBqWZZ17Ngxq3nz5tYll1xilZWVWZZlWU8++aTVokULy+l0WsnJydaLL75Y6WankqyhQ4dWGDMxMdHq16+fx7lVq1ZZrVu3tiIiIqzmzZtbTz75ZKVjHjt2zBo7dqyVmJho1axZ04qPj7fuv/9+68CBAxXu0bVr1wr3rqymXbt2WZKsp5566oyfkWX935OBZzp27dp1xmtr1aplNW/e3Orevbs1d+5cq6Sk5Kz3sizLSklJsWJjY8967XXXXWc1atTIKikpKX+qcenSpZXWfqanLLdv32517tzZioqKsurXr2/deeedVn5+viXJGj9+fKWvadGihZWcnPyL7wFAcHNYVhUfFQIAeGXbtm268sor9dxzzykjI8PucgDYiMYLAPzkm2++0e7du/WnP/1J+fn5+vrrrz225QAQelhcDwB+MnHiRHXu3FmHDx/W0qVLaboAkHgBAACYQuIFAABgCI0XAACAITReAAAAhgT0Bqput1vff/+9oqKivNoNGwCAUGJZlg4dOqSmTZsqLMx89nL8+HGVlpb6ZeyIiAhFRkb6ZWxfCujG6/vvv1dCQoLdZQAAEFAKCgrUrFkzo/c8fvy4khLrqrDI5ZfxmzRpol27dp33zVdAN15RUVGSpMvv/rPCI87vD/p0jXN/trsEr0x79SW7S/Dab/8dmBtX1toZYXcJXimtH7gPTEf+GJgJerO1P/3yReeh/IcD96+iRnWP2F1CtZQdLVXuXS+U//1pUmlpqQqLXNqd10LRUb5N24oPuZWY+q1KS0tpvPzp1PRieERkwDVeNcKdv3zReSjKx/+ymBRWK7D+jJwS7gzMxissMnAbr3BnYDZegfrflfDagftXUY06ZXaX4BU7l+fUjXKobpRv7+9W4Pw7G7h/2gEAQMBxWW65fPz/y1yW27cD+lHgxhcAAAABhsQLAAAY45Ylt3wbefl6PH8i8QIAADCExAsAABjjllu+XpHl+xH9h8QLAADAEBIvAABgjMuy5LJ8uybL1+P5E4kXAACAISReAADAmFB/qpHGCwAAGOOWJVcIN15MNQIAABhC4gUAAIwJ9alGEi8AAABDSLwAAIAxbCcBAAAAI0i8AACAMe7/Hr4eM1DYnnjNmDFDSUlJioyMVGpqqtavX293SQAAAH5ha+OVnZ2tkSNH6uGHH9bmzZvVsWNHdenSRfn5+XaWBQAA/MT13328fH0EClsbr6lTp2rgwIEaNGiQkpOTNW3aNCUkJGjmzJl2lgUAAPzEZfnnCBS2NV6lpaXKy8tTenq6x/n09HR9+OGHlb6mpKRExcXFHgcAAECgsK3x2rdvn1wul+Li4jzOx8XFqbCwsNLXZGVlKSYmpvxISEgwUSoAAPARt5+OQGH74nqHw+Hxs2VZFc6dkpmZqYMHD5YfBQUFJkoEAADwCdu2k2jUqJHCw8MrpFtFRUUVUrBTnE6nnE6nifIAAIAfuOWQS5UHLOcyZqCwLfGKiIhQamqqcnJyPM7n5OSoXbt2NlUFAADgP7ZuoDp69Gj16dNHaWlpatu2rWbNmqX8/HwNGTLEzrIAAICfuK2Th6/HDBS2Nl69evXS/v37NWHCBO3du1etWrXS6tWrlZiYaGdZAAAAfmH7VwZlZGQoIyPD7jIAAIABLj+s8fL1eP5ke+MFAABCR6g3XrZvJwEAABAqSLwAAIAxbssht+Xj7SR8PJ4/kXgBAAAYQuIFAACMYY0XAAAAjCDxAgAAxrgUJpePcx+XT0fzLxIvAAAAQ0i8AACAMZYfnmq0AuipRhovAABgDIvrAQAAYASJFwAAMMZlhcll+XhxveXT4fyKxAsAAMAQEi8AAGCMWw65fZz7uBU4kReJFwAAgCFBkXiV1XbIcgbOEw2S1H7hFrtL8MqQ1l3tLsFr0fOP2F2CVy659Fu7S/DKzkWX2F2C1w60LrO7BK+sXLvY7hK80u7Pw+wuwWtdRm2yu4RqOX74hDbYXANPNQIAAMCIoEi8AABAYPDPU42Bs8aLxgsAABhzcnG9b6cGfT2ePzHVCAAAYAiJFwAAMMatMLnYTgIAAAD+RuIFAACMCfXF9SReAAAAhpB4AQAAY9wK4yuDAAAA4H8kXgAAwBiX5ZDL8vFXBvl4PH+i8QIAAMa4/LCdhIupRgAAAJyOxAsAABjjtsLk9vF2Em62kwAAAMDpSLwAAIAxrPECAACAESReAADAGLd8v/2D26ej+ReJFwAAgCEkXgAAwBj/fGVQ4ORINF4AAMAYlxUml4+3k/D1eP4UOJUCAAAEOBIvAABgjFsOueXrxfWB812NJF4AAACGkHgBAABjWOMFAAAAI0i8AACAMf75yqDAyZECp1IAAIAAR+IFAACMcVsOuX39lUE+Hs+fSLwAAAAMIfECAADGuP2wxouvDAIAAKiE2wqT28fbP/h6PH8KnEoBAAACHIkXAAAwxiWHXD7+ih9fj+dPJF4AAACGkHgBAABjWOMFAAAAI0i8AACAMS75fk2Wy6ej+ReJFwAAgCEkXgAAwJhQX+NF4wUAAIxxWWFy+bhR8vV4/hQ4lQIAAAQ4Gi8AAGCMJYfcPj4sLxfrz5gxQ0lJSYqMjFRqaqrWr19/1usXLVqkK6+8UrVr11Z8fLzuvfde7d+/v1r3pPECAAAhJzs7WyNHjtTDDz+szZs3q2PHjurSpYvy8/Mrvf79999X3759NXDgQH3++edaunSpcnNzNWjQoGrdl8YLAAAYc2qNl6+P6po6daoGDhyoQYMGKTk5WdOmTVNCQoJmzpxZ6fUbN25UixYtNGLECCUlJalDhw4aPHiwPv7442rdl8YLAAAEheLiYo+jpKSk0utKS0uVl5en9PR0j/Pp6en68MMPK31Nu3bttGfPHq1evVqWZemHH37QP/7xD3Xt2rVaNQbFU41NNhSrRnip3WVUy7+6XGZ3CV654b0ddpfgtQ0DE+wuwSuf3XKJ3SV4paR1IG1p6OmRG1bZXYJX/vRDmt0leKXB3A12l+C1f+7tZHcJ1VJ24rikf9lag9tyyG35dgPVU+MlJHj+d378+PF67LHHKly/b98+uVwuxcXFeZyPi4tTYWFhpfdo166dFi1apF69eun48eMqKyvTLbfcomeffbZatZJ4AQCAoFBQUKCDBw+WH5mZmWe93uHwbAAty6pw7pTt27drxIgRevTRR5WXl6c1a9Zo165dGjJkSLVqDIrECwAABAaXwuTyce5zarzo6GhFR0f/4vWNGjVSeHh4hXSrqKioQgp2SlZWltq3b68HH3xQktS6dWvVqVNHHTt21F/+8hfFx8dXqVYSLwAAYMypqUZfH9URERGh1NRU5eTkeJzPyclRu3btKn3N0aNHFRbm2TaFh4dLOpmUVRWNFwAACDmjR4/W7NmzNXfuXH3xxRcaNWqU8vPzy6cOMzMz1bdv3/Lru3fvruXLl2vmzJnauXOnPvjgA40YMULXXHONmjZtWuX7MtUIAACMcStMbh/nPt6M16tXL+3fv18TJkzQ3r171apVK61evVqJiYmSpL1793rs6dW/f38dOnRI06dP15gxY1SvXj3deOONmjx5crXuS+MFAABCUkZGhjIyMir93fz58yucGz58uIYPH35O96TxAgAAxrgsh1w+3k7C1+P5E2u8AAAADCHxAgAAxvhzA9VAQOIFAABgCIkXAAAwxrLC5PbiS61/acxAQeMFAACMcckhl3y8uN7H4/lT4LSIAAAAAY7ECwAAGOO2fL8Y3l31b+yxHYkXAACAISReAADAGLcfFtf7ejx/CpxKAQAAAhyJFwAAMMYth9w+fgrR1+P5k62JV1ZWlq6++mpFRUUpNjZWt956q/7zn//YWRIAAIDf2Np4vffeexo6dKg2btyonJwclZWVKT09XUeOHLGzLAAA4CenviTb10egsHWqcc2aNR4/z5s3T7GxscrLy9P1119vU1UAAMBfQn1x/Xm1xuvgwYOSpAYNGlT6+5KSEpWUlJT/XFxcbKQuAAAAXzhvWkTLsjR69Gh16NBBrVq1qvSarKwsxcTElB8JCQmGqwQAAOfCLYfclo8PFtdX37Bhw7Rt2zYtWbLkjNdkZmbq4MGD5UdBQYHBCgEAAM7NeTHVOHz4cK1atUrr1q1Ts2bNznid0+mU0+k0WBkAAPAlyw/bSVgBlHjZ2nhZlqXhw4drxYoVevfdd5WUlGRnOQAAAH5la+M1dOhQLV68WCtXrlRUVJQKCwslSTExMapVq5adpQEAAD84tS7L12MGClvXeM2cOVMHDx5Up06dFB8fX35kZ2fbWRYAAIBf2D7VCAAAQgf7eAEAABjCVCMAAACMIPECAADGuP2wnQQbqAIAAKACEi8AAGAMa7wAAABgBIkXAAAwhsQLAAAARpB4AQAAY0I98aLxAgAAxoR648VUIwAAgCEkXgAAwBhLvt/wNJC++ZnECwAAwBASLwAAYAxrvAAAAGAEiRcAADAm1BOvoGi8wo6UKiw8cD50STrySrzdJXjlw8+i7C7Ba1/1r213CV658B8ldpfglaNxEXaX4LUnXD3sLsErl/1ll90leOXqLXvtLsFrv4t5zu4SquXwIbduvMLuKkJbUDReAAAgMJB4AQAAGBLqjReL6wEAAAwh8QIAAMZYlkOWjxMqX4/nTyReAAAAhpB4AQAAY9xy+Pwrg3w9nj+ReAEAABhC4gUAAIzhqUYAAAAYQeIFAACM4alGAAAAGEHiBQAAjAn1NV40XgAAwBimGgEAAGAEiRcAADDG8sNUI4kXAAAAKiDxAgAAxliSLMv3YwYKEi8AAABDSLwAAIAxbjnk4EuyAQAA4G8kXgAAwJhQ38eLxgsAABjjthxyhPDO9Uw1AgAAGELiBQAAjLEsP2wnEUD7SZB4AQAAGELiBQAAjAn1xfUkXgAAAIaQeAEAAGNIvAAAAGAEiRcAADAm1PfxovECAADGsJ0EAAAAjCDxAgAAxpxMvHy9uN6nw/kViRcAAIAhJF4AAMAYtpMAAACAESReAADAGOu/h6/HDBQkXgAAAIaQeAEAAGNCfY0XjRcAADAnxOcamWoEAAAwhMQLAACY44epRgXQVCOJFwAAgCE0XgAAwJhTX5Lt68MbM2bMUFJSkiIjI5Wamqr169ef9fqSkhI9/PDDSkxMlNPp1EUXXaS5c+dW655MNQIAgJCTnZ2tkSNHasaMGWrfvr1eeOEFdenSRdu3b1fz5s0rfU3Pnj31ww8/aM6cObr44otVVFSksrKyat03KBqvbx6qrbDakXaXUS1u13G7S/BKva8C94+Moyxw1gD8r5IGNe0uwSuOAHrK6HRJK6r3H9LzxerNa+0uwSvvHgvcyZc/9RpodwnVUlZ2XFKWrTX4czuJ4uJij/NOp1NOp7PS10ydOlUDBw7UoEGDJEnTpk3TW2+9pZkzZyorq+JntGbNGr333nvauXOnGjRoIElq0aJFtWsN3D/tAAAA/yMhIUExMTHlR2UNlCSVlpYqLy9P6enpHufT09P14YcfVvqaVatWKS0tTVOmTNEFF1ygSy+9VH/84x917NixatUYuPEFAAAIPJbD908h/ne8goICRUdHl58+U9q1b98+uVwuxcXFeZyPi4tTYWFhpa/ZuXOn3n//fUVGRmrFihXat2+fMjIy9NNPP1VrnReNFwAAMOZcFsOfbUxJio6O9mi8fonD4dkAWpZV4dwpbrdbDodDixYtUkxMjKST05V33HGHnnvuOdWqVatK92SqEQAAhJRGjRopPDy8QrpVVFRUIQU7JT4+XhdccEF50yVJycnJsixLe/bsqfK9abwAAIA5lp+OaoiIiFBqaqpycnI8zufk5Khdu3aVvqZ9+/b6/vvvdfjw4fJzO3bsUFhYmJo1a1ble9N4AQCAkDN69GjNnj1bc+fO1RdffKFRo0YpPz9fQ4YMkSRlZmaqb9++5dffddddatiwoe69915t375d69at04MPPqgBAwZUeZpRYo0XAAAwyJ/bSVRHr169tH//fk2YMEF79+5Vq1attHr1aiUmJkqS9u7dq/z8/PLr69atq5ycHA0fPlxpaWlq2LChevbsqb/85S/Vui+NFwAACEkZGRnKyMio9Hfz58+vcO6yyy6rMD1ZXTReAADArADeYPlcscYLAADAEBIvAABgzPmyxssuNF4AAMAcL7Z/qNKYAYKpRgAAAENIvAAAgEGO/x6+HjMwkHgBAAAYQuIFAADMYY0XAAAATCDxAgAA5pB4AQAAwITzpvHKysqSw+HQyJEj7S4FAAD4i+XwzxEgzoupxtzcXM2aNUutW7e2uxQAAOBHlnXy8PWYgcL2xOvw4cO6++679eKLL6p+/fp2lwMAAOA3tjdeQ4cOVdeuXXXzzTf/4rUlJSUqLi72OAAAQACx/HQECFunGl955RV98sknys3NrdL1WVlZevzxx/1cFQAAgH/YlngVFBTogQce0MKFCxUZGVml12RmZurgwYPlR0FBgZ+rBAAAPsXienvk5eWpqKhIqamp5edcLpfWrVun6dOnq6SkROHh4R6vcTqdcjqdpksFAADwCdsar5tuukmffvqpx7l7771Xl112mcaOHVuh6QIAAIHPYZ08fD1moLCt8YqKilKrVq08ztWpU0cNGzascB4AACAYVHuN10svvaQ333yz/OeHHnpI9erVU7t27bR7926fFgcAAIJMiD/VWO3Ga9KkSapVq5YkacOGDZo+fbqmTJmiRo0aadSoUedUzLvvvqtp06ad0xgAAOA8xuL66ikoKNDFF18sSXrttdd0xx136A9/+IPat2+vTp06+bo+AACAoFHtxKtu3brav3+/JGnt2rXlG59GRkbq2LFjvq0OAAAElxCfaqx24tW5c2cNGjRIbdq00Y4dO9S1a1dJ0ueff64WLVr4uj4AAICgUe3E67nnnlPbtm31448/atmyZWrYsKGkk/ty9e7d2+cFAgCAIELiVT316tXT9OnTK5znq3wAAADOrkqN17Zt29SqVSuFhYVp27ZtZ722devWPikMAAAEIX8kVMGWeKWkpKiwsFCxsbFKSUmRw+GQZf3fuzz1s8PhkMvl8luxAAAAgaxKjdeuXbvUuHHj8n8GAADwij/23Qq2fbwSExMr/efT/W8KBgAAAE/VfqqxT58+Onz4cIXz3377ra6//nqfFAUAAILTqS/J9vURKKrdeG3fvl1XXHGFPvjgg/JzL730kq688krFxcX5tDgAABBk2E6iej766CM98sgjuvHGGzVmzBh99dVXWrNmjf72t79pwIAB/qgRAAAgKFS78apRo4aefPJJOZ1OTZw4UTVq1NB7772ntm3b+qM+AACAoFHtqcYTJ05ozJgxmjx5sjIzM9W2bVv97ne/0+rVq/1RHwAAQNCoduKVlpamo0eP6t1339V1110ny7I0ZcoU3XbbbRowYIBmzJjhjzoBAEAQcMj3i+EDZzMJLxuvv//976pTp46kk5unjh07Vr/+9a91zz33+LzAqig7WlNhVk1b7u2tyf/vVbtL8ErkdSfsLsFrTz9oz5/PczVl6ky7S/DKvS8Nt7sErx2PD7e7BK+0eSLD7hK8UlLP7gq81/yTTXaXUC0OK3D/Gx4sqt14zZkzp9LzKSkpysvLO+eCAABAEGMDVe8dO3ZMJ054ds9Op/OcCgIAAAhW1V5cf+TIEQ0bNkyxsbGqW7eu6tev73EAAACcUYjv41Xtxuuhhx7SO++8oxkzZsjpdGr27Nl6/PHH1bRpUy1YsMAfNQIAgGAR4o1XtacaX3/9dS1YsECdOnXSgAED1LFjR1188cVKTEzUokWLdPfdd/ujTgAAgIBX7cTrp59+UlJSkiQpOjpaP/30kySpQ4cOWrdunW+rAwAAQYXvaqymCy+8UN9++60k6fLLL9err57cFuH1119XvXr1fFkbAABAUKl243Xvvfdq69atkqTMzMzytV6jRo3Sgw8+6PMCAQBAEGGNV/WMGjWq/J9vuOEGffnll/r444910UUX6corr/RpcQAAAMHknPbxkqTmzZurefPmvqgFAAAEO38kVAGUeFV7qhEAAADeOefECwAAoKr88RRiUD7VuGfPHn/WAQAAQsGp72r09REgqtx4tWrVSi+//LI/awEAAAhqVW68Jk2apKFDh+r222/X/v37/VkTAAAIViG+nUSVG6+MjAxt3bpVBw4cUMuWLbVq1Sp/1gUAABB0qrW4PikpSe+8846mT5+u22+/XcnJyapRw3OITz75xKcFAgCA4BHqi+ur/VTj7t27tWzZMjVo0EA9evSo0HgBAACgctXqml588UWNGTNGN998sz777DM1btzYX3UBAIBgFOIbqFa58frNb36jTZs2afr06erbt68/awIAAAhKVW68XC6Xtm3bpmbNmvmzHgAAEMz8sMYrKBOvnJwcf9YBAABCQYhPNfJdjQAAAIbwSCIAADCHxAsAAAAmkHgBAABjQn0DVRIvAAAAQ2i8AAAADKHxAgAAMIQ1XgAAwJwQf6qRxgsAABjD4noAAAAYQeIFAADMCqCEytdIvAAAAAwh8QIAAOaE+OJ6Ei8AAABDSLwAAIAxPNUIAAAAI0i8AACAOSG+xovGCwAAGMNUIwAAAIwg8QIAAOaE+FQjiRcAAIAhJF4AAMAcEi8AAIDQM2PGDCUlJSkyMlKpqalav359lV73wQcfqEaNGkpJSan2PWm8AACAMaeeavT1UV3Z2dkaOXKkHn74YW3evFkdO3ZUly5dlJ+ff9bXHTx4UH379tVNN93k1fsPiqnGhIR9qlHHaXcZ1TLnnlvsLsErhyccsbsEr1067gu7S/DKhPQ77C7BK8cfPGF3CV5r0vwnu0vwyg9ljewuwSv3d/qX3SV4bUaCd3/52sV97Lg0cpndZZwXpk6dqoEDB2rQoEGSpGnTpumtt97SzJkzlZWVdcbXDR48WHfddZfCw8P12muvVfu+JF4AAMAcy0+HpOLiYo+jpKSk0hJKS0uVl5en9PR0j/Pp6en68MMPz1j6vHnz9M0332j8+PHevHNJNF4AAMAkPzZeCQkJiomJKT/OlFzt27dPLpdLcXFxHufj4uJUWFhY6Wu++uorjRs3TosWLVKNGt5PGAbFVCMAAEBBQYGio6PLf3Y6z74MyeFwePxsWVaFc5Lkcrl011136fHHH9ell156TjXSeAEAAGP8+ZVB0dHRHo3XmTRq1Ejh4eEV0q2ioqIKKZgkHTp0SB9//LE2b96sYcOGSZLcbrcsy1KNGjW0du1a3XjjjVWqlalGAAAQUiIiIpSamqqcnByP8zk5OWrXrl2F66Ojo/Xpp59qy5Yt5ceQIUP0q1/9Slu2bNG1115b5XuTeAEAAHPOkw1UR48erT59+igtLU1t27bVrFmzlJ+fryFDhkiSMjMz9d1332nBggUKCwtTq1atPF4fGxuryMjICud/CY0XAAAIOb169dL+/fs1YcIE7d27V61atdLq1auVmJgoSdq7d+8v7unlDRovAABgjD/XeFVXRkaGMjIyKv3d/Pnzz/raxx57TI899li178kaLwAAAENIvAAAgDnnyRovu9B4AQAAc0K88WKqEQAAwBASLwAAYIzjv4evxwwUJF4AAACGkHgBAABzWOMFAAAAE0i8AACAMefTBqp2IPECAAAwxPbG67vvvtM999yjhg0bqnbt2kpJSVFeXp7dZQEAAH+w/HQECFunGg8cOKD27dvrhhtu0D//+U/Fxsbqm2++Ub169ewsCwAA+FMANUq+ZmvjNXnyZCUkJGjevHnl51q0aGFfQQAAAH5k61TjqlWrlJaWpjvvvFOxsbFq06aNXnzxxTNeX1JSouLiYo8DAAAEjlOL6319BApbG6+dO3dq5syZuuSSS/TWW29pyJAhGjFihBYsWFDp9VlZWYqJiSk/EhISDFcMAADgPVsbL7fbrauuukqTJk1SmzZtNHjwYN13332aOXNmpddnZmbq4MGD5UdBQYHhigEAwDkJ8cX1tjZe8fHxuvzyyz3OJScnKz8/v9LrnU6noqOjPQ4AAIBAYevi+vbt2+s///mPx7kdO3YoMTHRpooAAIA/sYGqjUaNGqWNGzdq0qRJ+vrrr7V48WLNmjVLQ4cOtbMsAAAAv7C18br66qu1YsUKLVmyRK1atdLEiRM1bdo03X333XaWBQAA/CXE13jZ/l2N3bp1U7du3ewuAwAAwO9sb7wAAEDoCPU1XjReAADAHH9MDQZQ42X7l2QDAACEChIvAABgDokXAAAATCDxAgAAxoT64noSLwAAAENIvAAAgDms8QIAAIAJJF4AAMAYh2XJYfk2ovL1eP5E4wUAAMxhqhEAAAAmkHgBAABj2E4CAAAARpB4AQAAc1jjBQAAABOCIvGqPbamaoTXtLuMavnmMYfdJXil1uomdpfgtfxbyuwuwSs1C763uwSvfPTbhXaX4LV+v+psdwlembv9ZbtL8MrvNg22uwSvRRYG1l+jruP218saLwAAABhhf+sLAABCR4iv8aLxAgAAxjDVCAAAACNIvAAAgDkhPtVI4gUAAGAIiRcAADAqkNZk+RqJFwAAgCEkXgAAwBzLOnn4eswAQeIFAABgCIkXAAAwJtT38aLxAgAA5rCdBAAAAEwg8QIAAMY43CcPX48ZKEi8AAAADCHxAgAA5rDGCwAAACaQeAEAAGNCfTsJEi8AAABDSLwAAIA5If6VQTReAADAGKYaAQAAYASJFwAAMIftJAAAAGACiRcAADCGNV4AAAAwgsQLAACYE+LbSZB4AQAAGELiBQAAjAn1NV40XgAAwBy2kwAAAIAJJF4AAMCYUJ9qJPECAAAwhMQLAACY47ZOHr4eM0CQeAEAABhC4gUAAMzhqUYAAACYQOIFAACMccgPTzX6dji/ovECAADm8F2NAAAAMIHECwAAGMMGqgAAADCCxAsAAJjDdhIAAAAwgcYLAAAY47AsvxzemDFjhpKSkhQZGanU1FStX7/+jNcuX75cnTt3VuPGjRUdHa22bdvqrbfeqvY9g2Kq8fCTZapRJ9zuMqolJ3mG3SV45fUrku0uwWuru6TYXYJX+mzbYXcJXul7yx/sLsFrx26qY3cJXll16Ee7S/CK47Mou0vwWuNtZXaXUC1lJ8r0jd1FnCeys7M1cuRIzZgxQ+3bt9cLL7ygLl26aPv27WrevHmF69etW6fOnTtr0qRJqlevnubNm6fu3bvro48+Ups2bap836BovAAAQIBw//fw9ZjVNHXqVA0cOFCDBg2SJE2bNk1vvfWWZs6cqaysrArXT5s2zePnSZMmaeXKlXr99ddpvAAAwPnpXKYGzzamJBUXF3ucdzqdcjqdFa4vLS1VXl6exo0b53E+PT1dH374YZXu6Xa7dejQITVo0KBatbLGCwAABIWEhATFxMSUH5UlV5K0b98+uVwuxcXFeZyPi4tTYWFhle7117/+VUeOHFHPnj2rVSOJFwAAMMeP20kUFBQoOjq6/HRladf/cjg8v+XRsqwK5yqzZMkSPfbYY1q5cqViY2OrVSqNFwAACArR0dEejdeZNGrUSOHh4RXSraKiogop2Omys7M1cOBALV26VDfffHO1a2SqEQAAmHPqS7J9fVRDRESEUlNTlZOT43E+JydH7dq1O+PrlixZov79+2vx4sXq2rWrV2+fxAsAAISc0aNHq0+fPkpLS1Pbtm01a9Ys5efna8iQIZKkzMxMfffdd1qwYIGkk01X37599be//U3XXXddeVpWq1YtxcTEVPm+NF4AAMCY8+VLsnv16qX9+/drwoQJ2rt3r1q1aqXVq1crMTFRkrR3717l5+eXX//CCy+orKxMQ4cO1dChQ8vP9+vXT/Pnz6/yfWm8AABASMrIyFBGRkalvzu9mXr33Xd9ck8aLwAAYI4Xa7KqNGaAYHE9AACAISReAADAGIf75OHrMQMFjRcAADCHqUYAAACYQOIFAADM8eNXBgUCEi8AAABDSLwAAIAxDsuSw8drsnw9nj+ReAEAABhC4gUAAMzhqUb7lJWV6ZFHHlFSUpJq1aqlCy+8UBMmTJDbHUAbcgAAAFSRrYnX5MmT9fzzz+ull15Sy5Yt9fHHH+vee+9VTEyMHnjgATtLAwAA/mBJ8nW+EjiBl72N14YNG9SjRw917dpVktSiRQstWbJEH3/8caXXl5SUqKSkpPzn4uJiI3UCAADfYHG9jTp06KC3335bO3bskCRt3bpV77//vn77299Wen1WVpZiYmLKj4SEBJPlAgAAnBNbE6+xY8fq4MGDuuyyyxQeHi6Xy6UnnnhCvXv3rvT6zMxMjR49uvzn4uJimi8AAAKJJT8srvftcP5ka+OVnZ2thQsXavHixWrZsqW2bNmikSNHqmnTpurXr1+F651Op5xOpw2VAgAAnDtbG68HH3xQ48aN0+9//3tJ0hVXXKHdu3crKyur0sYLAAAEOLaTsM/Ro0cVFuZZQnh4ONtJAACAoGRr4tW9e3c98cQTat68uVq2bKnNmzdr6tSpGjBggJ1lAQAAf3FLcvhhzABha+P17LPP6s9//rMyMjJUVFSkpk2bavDgwXr00UftLAsAAMAvbG28oqKiNG3aNE2bNs3OMgAAgCGhvo8X39UIAADMYXE9AAAATCDxAgAA5pB4AQAAwAQSLwAAYA6JFwAAAEwg8QIAAOaE+AaqJF4AAACGkHgBAABj2EAVAADAFBbXAwAAwAQSLwAAYI7bkhw+TqjcJF4AAAA4DYkXAAAwhzVeAAAAMIHECwAAGOSHxEuBk3gFReP187tNFO6MtLuMarlx24N2l+CVWkW+3m7YnITDX9pdgleyvviN3SV4JWnaPrtL8NpzLV6wuwSv/P7TAXaX4JUG7QrtLsFrf+yzxu4SquXoIZfufsPuKkJbUDReAAAgQIT4Gi8aLwAAYI7bks+nBtlOAgAAAKcj8QIAAOZY7pOHr8cMECReAAAAhpB4AQAAc0J8cT2JFwAAgCEkXgAAwByeagQAAIAJJF4AAMCcEF/jReMFAADMseSHxsu3w/kTU40AAACGkHgBAABzQnyqkcQLAADAEBIvAABgjtstycdf8ePmK4MAAABwGhIvAABgDmu8AAAAYAKJFwAAMCfEEy8aLwAAYA7f1QgAAAATSLwAAIAxluWWZfl2+wdfj+dPJF4AAACGkHgBAABzLMv3a7ICaHE9iRcAAIAhJF4AAMAcyw9PNZJ4AQAA4HQkXgAAwBy3W3L4+CnEAHqqkcYLAACYw1QjAAAATCDxAgAAxlhutywfTzWygSoAAAAqIPECAADmsMYLAAAAJpB4AQAAc9yW5CDxAgAAgJ+ReAEAAHMsS5KvN1Al8QIAAMBpSLwAAIAxltuS5eM1XlYAJV40XgAAwBzLLd9PNbKBKgAAAE5D4gUAAIwJ9alGEi8AAABDSLwAAIA5Ib7GK6Abr1PRoqvkuM2VVJ/7eODEov/LVeKwuwSvlblL7S7BK66jJXaX4JUTEYH5eUvS4UOB8x/x/xWof1bKwsvsLsFrRw+57C6hWo4ePlmvnVNzZTrh869qLNMJ3w7oRw4rkCZGT7Nnzx4lJCTYXQYAAAGloKBAzZo1M3rP48ePKykpSYWFhX4Zv0mTJtq1a5ciIyP9Mr6vBHTj5Xa79f333ysqKkoOh2+TmOLiYiUkJKigoEDR0dE+HRuV4zM3i8/bLD5v8/jMK7IsS4cOHVLTpk0VFmZ+mffx48dVWuqfNDwiIuK8b7qkAJ9qDAsL83vHHh0dzb+whvGZm8XnbRaft3l85p5iYmJsu3dkZGRANEf+xFONAAAAhtB4AQAAGELjdQZOp1Pjx4+X0+m0u5SQwWduFp+3WXze5vGZ43wU0IvrAQAAAgmJFwAAgCE0XgAAAIbQeAEAABhC4wUAAGAIjdcZzJgxQ0lJSYqMjFRqaqrWr19vd0lBKSsrS1dffbWioqIUGxurW2+9Vf/5z3/sLitkZGVlyeFwaOTIkXaXEtS+++473XPPPWrYsKFq166tlJQU5eXl2V1WUCorK9MjjzyipKQk1apVSxdeeKEmTJggtzswv38TwYfGqxLZ2dkaOXKkHn74YW3evFkdO3ZUly5dlJ+fb3dpQee9997T0KFDtXHjRuXk5KisrEzp6ek6cuSI3aUFvdzcXM2aNUutW7e2u5SgduDAAbVv3141a9bUP//5T23fvl1//etfVa9ePbtLC0qTJ0/W888/r+nTp+uLL77QlClT9NRTT+nZZ5+1uzRAEttJVOraa6/VVVddpZkzZ5afS05O1q233qqsrCwbKwt+P/74o2JjY/Xee+/p+uuvt7ucoHX48GFdddVVmjFjhv7yl78oJSVF06ZNs7usoDRu3Dh98MEHpOaGdOvWTXFxcZozZ075udtvv121a9fWyy+/bGNlwEkkXqcpLS1VXl6e0tPTPc6np6frww8/tKmq0HHw4EFJUoMGDWyuJLgNHTpUXbt21c0332x3KUFv1apVSktL05133qnY2Fi1adNGL774ot1lBa0OHTro7bff1o4dOyRJW7du1fvvv6/f/va3NlcGnBTQX5LtD/v27ZPL5VJcXJzH+bi4OBUWFtpUVWiwLEujR49Whw4d1KpVK7vLCVqvvPKKPvnkE+Xm5tpdSkjYuXOnZs6cqdGjR+tPf/qTNm3apBEjRsjpdKpv3752lxd0xo4dq4MHD+qyyy5TeHi4XC6XnnjiCfXu3dvu0gBJNF5n5HA4PH62LKvCOfjWsGHDtG3bNr3//vt2lxK0CgoK9MADD2jt2rWKjIy0u5yQ4Ha7lZaWpkmTJkmS2rRpo88//1wzZ86k8fKD7OxsLVy4UIsXL1bLli21ZcsWjRw5Uk2bNlW/fv3sLg+g8Tpdo0aNFB4eXiHdKioqqpCCwXeGDx+uVatWad26dWrWrJnd5QStvLw8FRUVKTU1tfycy+XSunXrNH36dJWUlCg8PNzGCoNPfHy8Lr/8co9zycnJWrZsmU0VBbcHH3xQ48aN0+9//3tJ0hVXXKHdu3crKyuLxgvnBdZ4nSYiIkKpqanKycnxOJ+Tk6N27drZVFXwsixLw4YN0/Lly/XOO+8oKSnJ7pKC2k033aRPP/1UW7ZsKT/S0tJ09913a8uWLTRdftC+ffsKW6Ts2LFDiYmJNlUU3I4ePaqwMM+/2sLDw9lOAucNEq9KjB49Wn369FFaWpratm2rWbNmKT8/X0OGDLG7tKAzdOhQLV68WCtXrlRUVFR50hgTE6NatWrZXF3wiYqKqrB+rk6dOmrYsCHr6vxk1KhRateunSZNmqSePXtq06ZNmjVrlmbNmmV3aUGpe/fueuKJJ9S8eXO1bNlSmzdv1tSpUzVgwAC7SwMksZ3EGc2YMUNTpkzR3r171apVKz3zzDNsb+AHZ1o3N2/ePPXv399sMSGqU6dObCfhZ2+88YYyMzP11VdfKSkpSaNHj9Z9991nd1lB6dChQ/rzn/+sFStWqKioSE2bNlXv3r316KOPKiIiwu7yABovAAAAU1jjBQAAYAiNFwAAgCE0XgAAAIbQeAEAABhC4wUAAGAIjRcAAIAhNF4AAACG0HgBAAAYQuMFwHYOh0Ovvfaa3WUAgN/ReAGQy+VSu3btdPvtt3ucP3jwoBISEvTII4/49f579+5Vly5d/HoPADgf8JVBACRJX331lVJSUjRr1izdfffdkqS+fftq69atys3N5XvuAMAHSLwASJIuueQSZWVlafjw4fr++++1cuVKvfLKK3rppZfO2nQtXLhQaWlpioqKUpMmTXTXXXepqKio/PcTJkxQ06ZNtX///vJzt9xyi66//nq53W5JnlONpaWlGjZsmOLj4xUZGakWLVooKyvLP28aAAwj8QJQzrIs3XjjjQoPD9enn36q4cOH/+I049y5cxUfH69f/epXKioq0qhRo1S/fn2tXr1a0slpzI4dOyouLk4rVqzQ888/r3Hjxmnr1q1KTEyUdLLxWrFihW699VY9/fTT+vvf/65FixapefPmKigoUEFBgXr37u339w8A/kbjBcDDl19+qeTkZF1xxRX65JNPVKNGjWq9Pjc3V9dcc40OHTqkunXrSpJ27typlJQUZWRk6Nlnn/WYzpQ8G68RI0bo888/17/+9S85HA6fvjcAsBtTjQA8zJ07V7Vr19auXbu0Z8+eX7x+8+bN6tGjhxITExUVFaVOnTpJkvLz88uvufDCC/X0009r8uTJ6t69u0fTdbr+/ftry5Yt+tWvfqURI0Zo7dq15/yeAOB8QeMFoNyGDRv0zDPPaOXKlWrbtq0GDhyos4XiR44cUXp6uurWrauFCxcqNzdXK1askHRyrdb/WrduncLDw/Xtt9+qrKzsjGNeddVV2rVrlyZOnKhjx46pZ8+euuOOO3zzBgHAZjReACRJx44dU79+/TR48GDdfPPNmj17tnJzc/XCCy+c8TVffvml9u3bpyeffFIdO3bUZZdd5rGw/pTs7GwtX75c7777rgoKCjRx4sSz1hIdHa1evXrpxRdfVHZ2tpYtW6affvrpnN8jANiNxguAJGncuHFyu92aPHmyJKl58+b661//qgcffFDffvttpa9p3ry5IiIi9Oyzz2rnzp1atWpVhaZqz549uv/++zV58mR16NBB8+fPV1ZWljZu3FjpmM8884xeeeUVffnll9qxY4eWLl2qJk2aqF69er58uwBgCxovAHrvvff03HPPaf78+apTp075+fvuu0/t2rU745Rj48aNNX/+fC1dulSXX365nnzyST399NPlv7csS/3799c111yjYcOGSZI6d+6sYcOG6Z577tHhw4crjFm3bl1NnjxZaWlpuvrqq/Xtt99q9erVCgvjP1cAAh9PNQIAABjC/4UEAAAwhMYLAADAEBovAAAAQ2i8AAAADKHxAgAAMITGCwAAwBAaLwAAAENovAAAAAyh8QIAADCExgsAAMAQGi8AAABD/j8DDCBazr6CVAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch} running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch %5 ==0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 5\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 16\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 8 # SAE일 때만 유효\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: r4vb7qc8\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/r4vb7qc8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3una0f07 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.25\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250103_002028-3una0f07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/3una0f07' target=\"_blank\">young-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/r4vb7qc8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/r4vb7qc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/r4vb7qc8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/r4vb7qc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/3una0f07' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/3una0f07</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 0, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 2, 'v_decay': 0.75, 'v_threshold': 0.25, 'v_reset': 10000, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250103_002034_883', 'optimizer': 'Adam'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250103_002034_883\n",
      "\n",
      "epoch-0 loss : 0.27992\n",
      "ae train 실행 시간: 21.682초\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96641438 0.96277097 0.9523351  0.93105111 0.92288557 0.84009434\n",
      " 0.75932372 0.61100659 0.54563792 0.56347656 0.61486486 0.56454816\n",
      " 0.92718941 0.8457808  0.69803922 0.52365026]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.83%, post_traincycle_acc : 76.43%, total_acc : 76.19%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.43%\n",
      "accuracy_check 실행 시간: 12.861초\n",
      "\n",
      "epoch-1 loss : 0.08997\n",
      "ae train 실행 시간: 22.583초\n",
      "\n",
      "epoch-1 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96310312 0.96418473 0.947039   0.91272903 0.93333333 0.85566038\n",
      " 0.75584286 0.61382879 0.65758951 0.57861328 0.63754826 0.46772592\n",
      " 0.92617108 0.82250242 0.69901961 0.57238414]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.47%, post_traincycle_acc : 76.92%, total_acc : 76.74%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.92%\n",
      "accuracy_check 실행 시간: 12.548초\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2,4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  0\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_174013_409'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
