{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH:256\n",
    "# batch_size:256\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.7834769413661389\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:32\n",
    "# learning_rate:0.007176761798504128\n",
    "# pre_spike_weight:5.165214142219577\n",
    "# rate_coding:true\n",
    "# TIME_STEP:9\n",
    "# time_step:9\n",
    "# v_decay:0.7834769413661389\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"CIFAR10\"\n",
    "\n",
    "\n",
    "# BATCH:256\n",
    "# batch_size:256\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.38993471232202725\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:28\n",
    "# learning_rate:0.06285718352377828\n",
    "# pre_spike_weight:6.21970124592063\n",
    "# rate_coding:true\n",
    "# TIME_STEP:16\n",
    "# time_step:16\n",
    "# v_decay:0.38993471232202725\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"MNIST\"\n",
    "\n",
    "# BATCH:64\n",
    "# batch_size:64\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.9266077968579136\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:28\n",
    "# learning_rate:0.07732456724854177\n",
    "# pre_spike_weight:1.5377416716615555\n",
    "# rate_coding:true\n",
    "# TIME_STEP:7\n",
    "# time_step:7\n",
    "# v_decay:0.9266077968579136\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"FASHION_MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from snntorch import spikegen\n",
    "\n",
    " \n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class RESERVOIR(nn.Module):\n",
    "    def __init__ (self, TIME_STEP=8, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1,\n",
    "                  FC_RESERVOIR=False):\n",
    "        super(RESERVOIR, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.in_spike_size = in_spike_size\n",
    "        self.in_channel = in_channel\n",
    "        self.receptive_size = receptive_size #3\n",
    "        self.v_init = v_init\n",
    "        self.v_decay = v_decay\n",
    "        self.v_threshold = v_threshold\n",
    "        self.v_reset = v_reset\n",
    "        self.hard_reset = hard_reset\n",
    "        self.pre_spike_weight = pre_spike_weight\n",
    "        self.FC_RESERVOIR = FC_RESERVOIR\n",
    "\n",
    "        self.out_channel = 1\n",
    "\n",
    "        # 파라미터 \n",
    "        if self.FC_RESERVOIR == True:\n",
    "            self.reservoir = nn.Linear(in_features=self.in_channel*self.in_spike_size*self.in_spike_size, out_features=self.in_channel*self.in_spike_size*self.in_spike_size, bias=True)\n",
    "        else:\n",
    "            self.reservoir = nn.Conv2d(in_channels=self.in_channel, out_channels=self.in_channel, \n",
    "                                            kernel_size=self.receptive_size, \n",
    "                                            stride=1, padding=1, groups=self.in_channel)\n",
    "\n",
    "        # kaiming 초기화\n",
    "        nn.init.kaiming_normal_(self.reservoir.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.reservoir.bias, 0)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, pre_spike):    \n",
    "        # pre_spike [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        v = torch.full_like(pre_spike[0], fill_value=self.v_init, requires_grad=False)\n",
    "        post_spike = torch.zeros_like(pre_spike[0], requires_grad=False)\n",
    "        # v [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "        # recurrent [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        # timestep 안 맞으면 종료\n",
    "        assert pre_spike.size(0) == self.TIME_STEP, f\"Time step mismatch: {pre_spike.size(0)} vs {self.TIME_STEP}\"\n",
    "\n",
    "        output = []\n",
    "        for t in range (self.TIME_STEP):\n",
    "            # depthwise conv reservoir: pre_spike[t] [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "            # fc conv reservoir: pre_spike[t] [batch_size, in_channel*in_spike_size*in_spike_size]\n",
    "            input_current = self.pre_spike_weight * pre_spike[t]\n",
    "                \n",
    "            recurrent_current = self.reservoir(post_spike)\n",
    "            current = input_current + recurrent_current\n",
    "            # current [batch_size, in_channel, in_spike_size, in_spike_size] # kernel size 3이니까 사이즈 유지\n",
    "            \n",
    "            # decay and itegrate\n",
    "            v = v*self.v_decay + current\n",
    "\n",
    "            # post spike\n",
    "            post_spike = (v >= self.v_threshold).float()\n",
    "\n",
    "            output.append(post_spike)\n",
    "            \n",
    "            #reset\n",
    "            if self.hard_reset: # hard reset\n",
    "                v = (1 - post_spike)*v + post_spike*self.v_reset \n",
    "            else: # soft reset\n",
    "                v = v - post_spike*self.v_threshold\n",
    "\n",
    "        output = torch.stack(output, dim=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESERVOIR_NET(nn.Module):\n",
    "    def __init__(self, TIME_STEP=8, CLASS_NUM=10, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1,\n",
    "                 no_reservoir = False, FC_RESERVOIR=False):\n",
    "        super(RESERVOIR_NET, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.no_reservoir = no_reservoir\n",
    "        self.FC_RESERVOIR = FC_RESERVOIR\n",
    "\n",
    "        if self.no_reservoir == False:\n",
    "            self.reservoir = RESERVOIR(TIME_STEP = self.TIME_STEP, in_spike_size=in_spike_size, in_channel=in_channel, receptive_size=receptive_size, v_init=v_init, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight,\n",
    "                                       FC_RESERVOIR=FC_RESERVOIR)\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=in_channel*in_spike_size*in_spike_size, out_features=CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert self.TIME_STEP == x.size(1), f\"Time step mismatch: {x.size(1)} vs {self.TIME_STEP}\"\n",
    "\n",
    "        # x size [batch_size, TIME_STEP, in_channel, in_spike_size, in_spike_size]\n",
    "        x = x.permute(1,0,2,3,4)\n",
    "        # x size [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        if (self.FC_RESERVOIR == True):\n",
    "            x = x.reshape(x.size(0), x.size(1), -1)\n",
    "\n",
    "        if self.no_reservoir == False:\n",
    "            with torch.no_grad():\n",
    "                x = self.reservoir(x) # reservoir weight는 학습 안함\n",
    "\n",
    "        T, B, *spatial_dims = x.shape\n",
    "\n",
    "        x = x.reshape(T * B, -1) # time,batch 축은 합쳐서 FC에 삽입\n",
    "\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        x = x.view(T , B, -1).contiguous() \n",
    "        \n",
    "        x = x.mean(dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(which_data, data_path, rate_coding, BATCH, IMAGE_SIZE, TIME, dvs_duration, dvs_clipping):\n",
    "    if which_data == 'MNIST':\n",
    "        if rate_coding :\n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0,), (1,))])\n",
    "        else : \n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,),(0.5))])\n",
    "\n",
    "        trainset = torchvision.datasets.MNIST(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.MNIST(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        synapse_conv_in_channels = 1\n",
    "        CLASS_NUM = 10\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    elif (which_data == 'CIFAR10'):\n",
    "\n",
    "        if rate_coding :\n",
    "            # transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.RandomHorizontalFlip(),\n",
    "            #                                     transforms.ToTensor()])\n",
    "\n",
    "            # transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.ToTensor()])\n",
    "            \n",
    "            transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor()])\n",
    "                                            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                                transforms.ToTensor()])\n",
    "        \n",
    "        else :\n",
    "            # transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.RandomHorizontalFlip(),\n",
    "            #                                     transforms.ToTensor(),\n",
    "            #                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "            #                                 # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "            # transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.ToTensor(),\n",
    "            #                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),])\n",
    "            #                                 # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            \n",
    "            # assert IMAGE_SIZE == 32, 'OTTT랑 맞짱뜰 때는 32로 ㄱ'\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(IMAGE_SIZE, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform_test)\n",
    "        \n",
    "        \n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        \n",
    "        synapse_conv_in_channels = 3\n",
    "        CLASS_NUM = 10\n",
    "        '''\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "                'dog', 'frog', 'horse', 'ship', 'truck') \n",
    "        '''\n",
    "\n",
    "\n",
    "    elif (which_data == 'FASHION_MNIST'):\n",
    "\n",
    "        if rate_coding :\n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor()])\n",
    "        else : \n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,),(0.5))])\n",
    "\n",
    "        trainset = torchvision.datasets.FashionMNIST(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.FashionMNIST(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        synapse_conv_in_channels = 1\n",
    "        CLASS_NUM = 10\n",
    "    elif (which_data == 'DVS_GESTURE'):\n",
    "        # class mapping = { 0 :'Hand Clapping'  1 :'Right Hand Wave'2 :'Left Hand Wave' 3 :'Right Arm CW'   4 :'Right Arm CCW'  5 :'Left Arm CW'    6 :'Left Arm CCW'   7 :'Arm Roll'       8 :'Air Drums'      9 :'Air Guitar'     10:'Other'}\n",
    "\n",
    "        data_dir = data_path + '/gesture'\n",
    "        transform = None\n",
    "\n",
    "        # # spikingjelly.datasets.dvs128_gesture.DVS128Gesture(root: str, train: bool, use_frame=True, frames_num=10, split_by='number', normalization='max')\n",
    "       \n",
    "        #https://spikingjelly.readthedocs.io/zh-cn/latest/activation_based_en/neuromorphic_datasets.html\n",
    "        # 10ms마다 1개의 timestep하고 싶으면 위의 주소 참고. 근데 timestep이 각각 좀 다를 거임.\n",
    "\n",
    "        if dvs_duration > 0:\n",
    "            resize_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "            train_data = CustomDVS128Gesture(\n",
    "                data_dir, train=True, data_type='frame',  split_by='time',  duration=dvs_duration, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "            test_data = CustomDVS128Gesture(\n",
    "                data_dir, train=False, data_type='frame',  split_by='time',  duration=dvs_duration, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "        else:\n",
    "            train_data = CustomDVS128Gesture(\n",
    "                data_dir, train=True, data_type='frame', split_by='number', frames_number=TIME, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "            test_data = CustomDVS128Gesture(\n",
    "                data_dir, train=False, data_type='frame', split_by='number', frames_number=TIME, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "        \n",
    "        print(f'train samples = {train_data.__len__()}, test samples = {test_data.__len__()}')\n",
    "        print(f'total samples = {train_data.__len__() + test_data.__len__()}')\n",
    "\n",
    "        ## 'Other' 클래스 배제 ########################################################################\n",
    "        # gesture_mapping = { 0 :'Hand Clapping' , 1 :'Right Hand Wave', 2:'Other',  3 :'Left Hand Wave' ,4 :'Right Arm CW'  , 5 :'Right Arm CCW' , 6 :'Left Arm CW' ,   7 :'Left Arm CCW' ,  8 :'Arm Roll'   ,    9 :'Air Drums'  ,    10 :'Air Guitar'}\n",
    "        \n",
    "        exclude_class = 2\n",
    "        if dvs_duration > 0:\n",
    "            train_file_name = f'{data_dir}/dvs_gesture_class_index/train_indices_dvsgesture_duration_{dvs_duration}'\n",
    "            test_file_name = f'{data_dir}/dvs_gesture_class_index/test_indices_dvsgesture_duration_{dvs_duration}'\n",
    "            if (os.path.isfile(train_file_name) and os.path.isfile(test_file_name)):\n",
    "                print('\\ndvsgestrue 10 classes\\' indices exist. we exclude the \\'other\\' class\\n')\n",
    "                with open(train_file_name, 'rb') as f:\n",
    "                    train_indices = pickle.load(f)\n",
    "                with open(test_file_name, 'rb') as f:\n",
    "                    test_indices = pickle.load(f)\n",
    "            else:\n",
    "                print('\\ndvsgestrue 10 classes\\' indices doesn\\'t exist. we exclude the \\'other\\' class\\n')\n",
    "                train_indices = [i for i, (_, target) in enumerate(train_data) if target != exclude_class]\n",
    "                test_indices = [i for i, (_, target) in enumerate(test_data) if target != exclude_class]\n",
    "                with open(train_file_name, 'wb') as f:\n",
    "                    pickle.dump(train_indices, f)\n",
    "                with open(test_file_name, 'wb') as f:\n",
    "                    pickle.dump(test_indices, f)\n",
    "        else:\n",
    "            train_indices = [i for i, (_, target) in enumerate(train_data) if target != exclude_class]\n",
    "            test_indices = [i for i, (_, target) in enumerate(test_data) if target != exclude_class]\n",
    "        ################################################################################################\n",
    "\n",
    "        # train_indices = [i for i, (_, target) in enumerate(train_data) if target != exclude_class]\n",
    "        # test_indices = [i for i, (_, target) in enumerate(test_data) if target != exclude_class]\n",
    "\n",
    "        \n",
    "\n",
    "        # # # SubsetRandomSampler 생성\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH, num_workers=2, sampler=train_sampler, collate_fn=pad_sequence_collate)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH, num_workers=2, sampler=test_sampler, collate_fn=pad_sequence_collate)\n",
    "        \n",
    "        # original\n",
    "        # train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH, num_workers=2, collate_fn=pad_sequence_collate, shuffle = True)\n",
    "        # test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH, num_workers=2, collate_fn=pad_sequence_collate, shuffle = False)\n",
    "        \n",
    "\n",
    "\n",
    "        # ([B, T, 2, 128, 128]) \n",
    "        \n",
    "        synapse_conv_in_channels = 2\n",
    "        CLASS_NUM = 10\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert False, 'wrong dataset name'\n",
    "\n",
    "\n",
    "    \n",
    "    return train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, rate_coding, TIME_STEP, which_data):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterator = enumerate(train_loader, 0)\n",
    "    for i, data in iterator:\n",
    "    # for i, (inputs, labels) in enumerate(train_loader):\n",
    "        if len(data) == 2:\n",
    "            inputs, labels = data\n",
    "            # 처리 로직 작성\n",
    "        elif len(data) == 3:\n",
    "            inputs, labels, x_len = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "        \n",
    "        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "        if (which_data == 'DVS_GESTURE'):\n",
    "            labels[labels>2] -= 1\n",
    "        #######################################################\n",
    "\n",
    "        ###########################################################################################################################        \n",
    "        if (which_data == 'n_tidigits'):\n",
    "            inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "            labels = labels[:, 0, :]\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "        elif (which_data == 'heidelberg'):\n",
    "            inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "            print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "        # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "        # print(labels)\n",
    "            \n",
    "        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        elif rate_coding == True :\n",
    "            inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "        else :\n",
    "            inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "        ####################################################################################################################### \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        iter_correct = (predicted == labels).sum().item()\n",
    "        correct += iter_correct\n",
    "        # if i % 100 == 99:\n",
    "        # print(f\"[{i+1}] loss: {running_loss / 100:.3f}\")\n",
    "        # running_loss = 0.0\n",
    "        iter_accuracy = 100 * iter_correct / labels.size(0)\n",
    "        wandb.log({\"iter_accuracy\": iter_accuracy})\n",
    "    tr_accuracy = 100 * correct / total         \n",
    "    wandb.log({\"tr_accuracy\": tr_accuracy})\n",
    "    print(f\"Train Accuracy: {tr_accuracy:.2f}%\")\n",
    "    \n",
    "def test(model, test_loader, criterion, device, rate_coding, TIME_STEP, which_data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    iterator = enumerate(test_loader, 0)\n",
    "    with torch.no_grad():\n",
    "        for i, data in iterator:\n",
    "        # for inputs, labels in test_loader:\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "        \n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = 100 * correct / total\n",
    "    wandb.log({\"val_accuracy\": val_accuracy})\n",
    "    print(f\"Test loss: {test_loss / len(test_loader):.3f}, Val Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path='/data2', which_data='MNIST', gpu = '3',learning_rate = 0.0001, BATCH=5, IMAGE_SIZE=28, TIME_STEP=8, EPOCH=10, rate_coding=True, v_decay= 0.6,\n",
    "v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False, FC_RESERVOIR=False):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "    # run = wandb.init(project=f'reservoir')\n",
    "\n",
    "    hyperparameters = locals()\n",
    "\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{which_data}_sweeprun_epoch{EPOCH}'\n",
    "    wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "\n",
    "    train_loader, test_loader, in_channel, CLASS_NUM = data_loader(\n",
    "        which_data=which_data, data_path=data_path, rate_coding=rate_coding, BATCH=BATCH, IMAGE_SIZE=IMAGE_SIZE, TIME=TIME_STEP, dvs_duration=dvs_duration, dvs_clipping=dvs_clipping)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = RESERVOIR_NET(TIME_STEP=TIME_STEP, CLASS_NUM=CLASS_NUM, in_spike_size=IMAGE_SIZE, in_channel=in_channel, receptive_size=3, v_init=0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight, \n",
    "                            no_reservoir = no_reservoir, FC_RESERVOIR=FC_RESERVOIR)\n",
    "    net = net.to(device)\n",
    "    wandb.watch(net, log=\"all\", log_freq = 1) #gradient, parameter logging해줌\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        train(net, train_loader, criterion, optimizer, device, rate_coding, TIME_STEP, which_data)\n",
    "        test(net, test_loader, criterion, device, rate_coding, TIME_STEP, which_data)\n",
    "        wandb.log({\"epoch\": epoch})\n",
    "        # torch.save(net.state_dict(), 'net_save/reservoir_net.pth')\n",
    "        # artifact = wandb.Artifact('model', type='model')\n",
    "        # artifact.add_file('net_save/reservoir_net.pth')\n",
    "        # run.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하기 싫을 때\n",
    "# wandb.init(project=f'reservoir')\n",
    "# main(data_path='/data2', which_data='CIFAR10', gpu = '3', learning_rate = 0.0072, BATCH=256, IMAGE_SIZE=32, TIME_STEP=9, EPOCH=50, rate_coding=True, v_decay= 0.78,\n",
    "# v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=5.0, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False, FC_RESERVOIR=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: j9wx53cx\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/j9wx53cx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rtdeqizu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEPOCH: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tFC_RESERVOIR: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.8797392304568484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0175887669432025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_reservoir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_spike_weight: 5.342434491423778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240731_111710-rtdeqizu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/rtdeqizu' target=\"_blank\">frosty-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/j9wx53cx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/j9wx53cx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/j9wx53cx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/sweeps/j9wx53cx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/rtdeqizu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/reservoir/runs/rtdeqizu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'EPOCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_spike_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'no_reservoir' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'FC_RESERVOIR' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "train samples = 1176, test samples = 288\n",
      "total samples = 1464\n",
      "\n",
      "dvsgestrue 10 classes' indices exist. we exclude the 'other' class\n",
      "\n",
      "RESERVOIR_NET(\n",
      "  (reservoir): RESERVOIR(\n",
      "    (reservoir): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  )\n",
      "  (classifier): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1\n",
      "Train Accuracy: 41.19%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 2.846, Val Accuracy: 29.55%\n",
      "Epoch 2\n",
      "Train Accuracy: 64.66%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 2.373, Val Accuracy: 40.53%\n",
      "Epoch 3\n",
      "Train Accuracy: 73.28%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.775, Val Accuracy: 57.95%\n",
      "Epoch 4\n",
      "Train Accuracy: 85.53%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.732, Val Accuracy: 52.65%\n",
      "Epoch 5\n",
      "Train Accuracy: 90.63%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.578, Val Accuracy: 52.65%\n",
      "Epoch 6\n",
      "Train Accuracy: 94.25%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.624, Val Accuracy: 55.30%\n",
      "Epoch 7\n",
      "Train Accuracy: 97.12%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.815, Val Accuracy: 54.92%\n",
      "Epoch 8\n",
      "Train Accuracy: 98.61%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.812, Val Accuracy: 53.79%\n",
      "Epoch 9\n",
      "Train Accuracy: 98.52%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.644, Val Accuracy: 56.06%\n",
      "Epoch 10\n",
      "Train Accuracy: 99.72%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.647, Val Accuracy: 57.58%\n",
      "Epoch 11\n",
      "Train Accuracy: 99.91%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.664, Val Accuracy: 56.82%\n",
      "Epoch 12\n",
      "Train Accuracy: 99.91%\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "pre label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "post label tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "post label tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "pre label tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "post label tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
      "pre label tensor([6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "post label tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "post label tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "pre label tensor([9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
      "post label tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
      "Test loss: 1.731, Val Accuracy: 57.95%\n",
      "Epoch 13\n"
     ]
    }
   ],
   "source": [
    "# sweep하고싶을 때\n",
    "def sweep_cover(data_path='/data2', which_data='CIFAR10', gpu = '4', learning_rate = 0.0001, BATCH=5, IMAGE_SIZE=28, TIME_STEP=8, EPOCH=3, rate_coding=True, v_decay= 0.6,\n",
    "v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False, FC_RESERVOIR=False):\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    TIME_STEP  =  wandb.config.time_step\n",
    "    v_decay  =  wandb.config.decay\n",
    "    pre_spike_weight  =  wandb.config.pre_spike_weight\n",
    "    which_data  =  wandb.config.which_data\n",
    "    data_path  =  wandb.config.data_path\n",
    "    rate_coding  =  wandb.config.rate_coding\n",
    "    EPOCH  =  wandb.config.EPOCH\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    no_reservoir  =  wandb.config.no_reservoir\n",
    "    FC_RESERVOIR  =  wandb.config.FC_RESERVOIR\n",
    "    main(data_path=data_path, which_data=which_data, gpu = gpu, learning_rate = learning_rate, BATCH=BATCH, IMAGE_SIZE=IMAGE_SIZE, TIME_STEP=TIME_STEP, EPOCH=EPOCH, rate_coding=rate_coding, v_decay= v_decay,\n",
    "v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight, dvs_duration=dvs_duration, dvs_clipping=dvs_clipping, no_reservoir = no_reservoir, FC_RESERVOIR=FC_RESERVOIR)\n",
    "\n",
    "\n",
    "\n",
    "which_data_hyper = 'DVS_GESTURE' # 'MNIST', 'CIFAR10' ', 'FASHION_MNIST', 'DVS_GESTURE'\n",
    "data_path_hyper = '/data2'\n",
    "\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': f'{which_data_hyper}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"min\": 0.0001, \"max\": 0.05},\n",
    "        \"BATCH\": {\"values\": [16, 32, 64, 128, 256]},\n",
    "        \"time_step\": {\"values\": [4,5,6,7,8]},\n",
    "        \"decay\": {\"min\": 0.25, \"max\": 1.0},\n",
    "        \"pre_spike_weight\": {\"min\": 0.5, \"max\": 10.0},\n",
    "        \"which_data\": {\"values\": [which_data_hyper]},\n",
    "        \"data_path\": {\"values\": [data_path_hyper]},\n",
    "        \"rate_coding\": {\"values\": [True, False]},\n",
    "        \"EPOCH\": {\"values\": [20]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [16,32,48,128]},\n",
    "        \"dvs_duration\": {\"values\": [100_000]}, #100_000, 1_000_000, 10_000 , 1_000\n",
    "        \"dvs_clipping\": {\"values\": [True]},\n",
    "        \"no_reservoir\": {\"values\": [True, False]},\n",
    "        \"FC_RESERVOIR\": {\"values\": [True, False]},\n",
    "     }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'reservoir')\n",
    "wandb.agent(sweep_id, function=sweep_cover, count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE하기\n",
    "\n",
    "# # Import\n",
    "# import wandb\n",
    "# # Save your model.\n",
    "# torch.save(model.state_dict(), 'save/to/path/model.pth')\n",
    "# # Save as artifact for version control.\n",
    "# run = wandb.init(project='your-project-name')\n",
    "# artifact = wandb.Artifact('model', type='model')\n",
    "# artifact.add_file('save/to/path/model.pth')\n",
    "# run.log_artifact(artifact)\n",
    "# run.finish()\n",
    "\n",
    "\n",
    "# # LOAD 하기\n",
    "\n",
    "# import wandb\n",
    "# run = wandb.init()\n",
    "\n",
    "\n",
    "# artifact = run.use_artifact('entity/your-project-name/model:v0', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "\n",
    "# run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
