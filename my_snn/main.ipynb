{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35158/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == False\n",
    "    if BPTT_on == True:\n",
    "        assert tdBN_on == False\n",
    "    if convTrue_fcFalse == False:\n",
    "        assert OTTT_sWS_on == False\n",
    "    if pre_trained == True:\n",
    "        print(\"\\nCaution! pre_trained is True\\n\")    \n",
    "    \n",
    "    print('\\nyour OTTT_sWS_on', OTTT_sWS_on,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(f\"net_save/save_now_net_weights_{unique_name}.pth\"))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "        \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter:{100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            val_loss=0\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += loss.data\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss}, tr:{100 * tr_acc:.2f}%, val:{100 * val_acc_now:.2f}%, val_best:{100 * val_acc:.2f}%\")  \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board ########################\n",
    "# decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"4\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 8 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 32, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1,\n",
    "#                 synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1,\n",
    "#                 synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = [64,128,'P',128,'P'], \n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.001, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling\n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dfa code from ASAP\n",
    "# class feedback_receiver(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, input, weight_fb):\n",
    "#         output = input.clone()\n",
    "#         dummy = torch.Tensor(input.size()[0],weight_fb.size()[0]).zero_().to(input.device)\n",
    "#         ctx.save_for_backward(weight_fb,)\n",
    "#         ctx.shape = input.shape\n",
    "#         return output, dummy\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output, grad_dummy):\n",
    "#         weight_fb, = ctx.saved_tensors\n",
    "#         input_size = ctx.shape\n",
    "#         grad_weight_fb = None\n",
    "        \n",
    "#         grad_input = torch.mm(grad_dummy.view(grad_dummy.size()[0],-1), weight_fb).view(input_size) # Batch_size, input\n",
    "#         return grad_input, grad_weight_fb\n",
    "\n",
    "\n",
    "# class Feedback_Receiver(nn.Module):\n",
    "#     def __init__(self, connect_features):\n",
    "#         super(Feedback_Receiver, self).__init__()\n",
    "#         self.connect_features = connect_features\n",
    "#         self.weight_fb = None\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         if self.weight_fb is None:\n",
    "#             self.weight_fb = nn.Parameter(torch.Tensor(self.connect_features, *input.size()[1:]).view(self.connect_features, -1)).to(input.device)\n",
    "#             nn.init.normal_(self.weight_fb, std = math.sqrt(1./self.connect_features))\n",
    "#         return feedback_receiver.apply(input, self.weight_fb)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 7zc66a77\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/7zc66a77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 53lgkrl0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06969491484315936\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240803_024644-53lgkrl0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53lgkrl0' target=\"_blank\">eager-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/7zc66a77' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/7zc66a77</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/7zc66a77' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/7zc66a77</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53lgkrl0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53lgkrl0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "your OTTT_sWS_on False \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 1,054,731, system's param_num : 1,054,731\n",
      "Memory: 4.02MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-4/17 iter:7.81%, lr=['0.06969491484315936'], iter_loss:21.587343215942383, tr:0.00%, val:0.00%, val_best:0.00%:  29%|██▉       | 5/17 [00:43<01:29,  7.48s/it]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'my_snn_sweep',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"min\": 0.0001, \"max\": 0.1},\n",
    "        \"BATCH\": {\"values\": [8,16, 32,64]},\n",
    "        \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [5,6,7,8,9,10]},\n",
    "        \"epoch_num\": {\"values\": [25]},\n",
    "        \"dvs_duration\": {\"values\": [100_000,10_000,1_000]},\n",
    "        \"dvs_clipping\": {\"values\": [0,1,2,4]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "\n",
    "    my_snn_system(  devices = \"4\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = [64,128,'P',128,'P'], \n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
