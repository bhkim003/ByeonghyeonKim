{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26738/2361114005.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "                  ):\n",
    "    # 함수 내 모든 로컬 변수 저장\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "\n",
    "    \n",
    "    torch.manual_seed(my_seed)\n",
    "\n",
    "\n",
    "    \n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ##########################################\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ## criterion ##########################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "\n",
    "            ### input --> net --> output #####################################################\n",
    "            outputs = net(inputs)\n",
    "            ##################################################################################\n",
    "\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            batch = BATCH \n",
    "            if labels.size(0) != BATCH: \n",
    "                batch = labels.size(0)\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = (predicted[0:batch] == labels).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## loss, backward ##########################################\n",
    "            loss = criterion(outputs[0:batch,:], labels)\n",
    "            loss.backward()\n",
    "            ############################################################\n",
    "\n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## weight 업데이트!! ##################################\n",
    "            optimizer.step()\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = net(inputs.permute(1, 0, 2, 3, 4))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        batch = BATCH \n",
    "                        if labels.size(0) != BATCH: \n",
    "                            batch = labels.size(0)\n",
    "                        correct += (predicted[0:batch] == labels).sum().item()\n",
    "                        val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name = f'result_save/{base_name}_hyperparameters.json_{unique_name}'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기)\n",
    "            # np.save(iter_acc_file_name, iter_acc_array)\n",
    "            # np.save(val_acc_file_name, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "            np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            with open(f'result_save/hyperparameters.json_{unique_name}', 'w') as f:\n",
    "                json.dump(hyperparameters, f, indent=4)\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==================================================\n",
      "My Num of PARAMS: 9,302,410, system's param_num : 9,335,434\n",
      "Memory: 35.49MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 33.75%, lr=['0.001'], iter_loss: 1.8894157409667969, val_acc: 42.95%: 100%|██████████| 391/391 [09:30<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 570.3197457790375 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-390/391 iter_acc: 37.50%, lr=['0.000999972584682756'], iter_loss: 1.6526193618774414, val_acc: 46.59%: 100%|██████████| 391/391 [09:35<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 575.3453857898712 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-390/391 iter_acc: 42.50%, lr=['0.0009998903417374227'], iter_loss: 1.6429126262664795, val_acc: 52.83%: 100%|██████████| 391/391 [09:40<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 580.5547461509705 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-390/391 iter_acc: 43.75%, lr=['0.0009997532801828658'], iter_loss: 1.7672717571258545, val_acc: 54.15%: 100%|██████████| 391/391 [09:39<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 580.0208950042725 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-390/391 iter_acc: 53.75%, lr=['0.0009995614150494292'], iter_loss: 1.3127998113632202, val_acc: 56.31%: 100%|██████████| 391/391 [09:38<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 578.8369352817535 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 5-390/391 iter_acc: 51.25%, lr=['0.000999314767377287'], iter_loss: 1.1579172611236572, val_acc: 60.62%: 100%|██████████| 391/391 [09:29<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 569.5838310718536 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 6-390/391 iter_acc: 50.00%, lr=['0.0009990133642141358'], iter_loss: 1.3663475513458252, val_acc: 60.41%: 100%|██████████| 391/391 [09:33<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 573.7659142017365 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 7-390/391 iter_acc: 52.50%, lr=['0.000998657238612229'], iter_loss: 1.2678017616271973, val_acc: 64.58%: 100%|██████████| 391/391 [09:23<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 563.53990650177 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 8-390/391 iter_acc: 53.75%, lr=['0.0009982464296247522'], iter_loss: 1.3011029958724976, val_acc: 64.68%: 100%|██████████| 391/391 [09:19<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 559.9676954746246 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 9-390/391 iter_acc: 65.00%, lr=['0.00099778098230154'], iter_loss: 0.9687444567680359, val_acc: 66.23%: 100%|██████████| 391/391 [09:30<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 570.2674295902252 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 10-390/391 iter_acc: 58.75%, lr=['0.0009972609476841367'], iter_loss: 1.3816888332366943, val_acc: 67.00%: 100%|██████████| 391/391 [09:19<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 559.1854462623596 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 11-390/391 iter_acc: 63.75%, lr=['0.0009966863828001983'], iter_loss: 1.0160226821899414, val_acc: 65.03%: 100%|██████████| 391/391 [09:16<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 556.3299133777618 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 12-390/391 iter_acc: 63.75%, lr=['0.0009960573506572392'], iter_loss: 0.9814094305038452, val_acc: 70.52%: 100%|██████████| 391/391 [09:18<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 558.7227039337158 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 13-390/391 iter_acc: 76.25%, lr=['0.000995373920235722'], iter_loss: 0.7243193984031677, val_acc: 70.03%: 100%|██████████| 391/391 [09:42<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 583.1231212615967 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 14-390/391 iter_acc: 70.00%, lr=['0.0009946361664814943'], iter_loss: 0.7066953182220459, val_acc: 71.66%: 100%|██████████| 391/391 [09:56<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 596.7725920677185 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 15-390/391 iter_acc: 67.50%, lr=['0.000993844170297569'], iter_loss: 1.0161395072937012, val_acc: 72.71%: 100%|██████████| 391/391 [09:40<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 581.0821347236633 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 16-390/391 iter_acc: 73.75%, lr=['0.0009929980185352527'], iter_loss: 0.7975320219993591, val_acc: 74.07%: 100%|██████████| 391/391 [10:33<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 633.3708777427673 seconds\n",
      "\n",
      "EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 17-390/391 iter_acc: 71.25%, lr=['0.000992097803984621'], iter_loss: 0.8156541585922241, val_acc: 74.08%: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 562.8316767215729 seconds\n",
      "\n",
      "EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 18-390/391 iter_acc: 73.75%, lr=['0.0009911436253643446'], iter_loss: 0.7119726538658142, val_acc: 72.91%: 100%|██████████| 391/391 [09:18<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 558.8810698986053 seconds\n",
      "\n",
      "EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 19-390/391 iter_acc: 70.00%, lr=['0.0009901355873108612'], iter_loss: 0.7845871448516846, val_acc: 75.78%: 100%|██████████| 391/391 [09:46<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 586.754068851471 seconds\n",
      "\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 20-390/391 iter_acc: 67.50%, lr=['0.000989073800366903'], iter_loss: 0.9963811635971069, val_acc: 76.52%: 100%|██████████| 391/391 [10:36<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 636.3027873039246 seconds\n",
      "\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 21-390/391 iter_acc: 80.00%, lr=['0.0009879583809693738'], iter_loss: 0.6188622713088989, val_acc: 76.59%: 100%|██████████| 391/391 [10:16<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 616.8310503959656 seconds\n",
      "\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 22-390/391 iter_acc: 81.25%, lr=['0.0009867894514365802'], iter_loss: 0.6597434282302856, val_acc: 77.69%: 100%|██████████| 391/391 [10:03<00:00,  1.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 603.8688600063324 seconds\n",
      "\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 23-390/391 iter_acc: 82.50%, lr=['0.0009855671399548183'], iter_loss: 0.6398830413818359, val_acc: 76.71%: 100%|██████████| 391/391 [09:27<00:00,  1.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 567.7483077049255 seconds\n",
      "\n",
      "EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 24-390/391 iter_acc: 77.50%, lr=['0.0009842915805643158'], iter_loss: 0.5513478517532349, val_acc: 78.51%: 100%|██████████| 391/391 [09:25<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 565.9671938419342 seconds\n",
      "\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 25-390/391 iter_acc: 72.50%, lr=['0.0009829629131445344'], iter_loss: 0.7371513843536377, val_acc: 78.17%: 100%|██████████| 391/391 [10:04<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 604.394237279892 seconds\n",
      "\n",
      "EPOCH 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 26-381/391 iter_acc: 79.69%, lr=['0.0009815812833988294'], iter_loss: 0.6246928572654724, val_acc: 78.17%:  98%|█████████▊| 382/391 [09:40<00:12,  1.40s/it] "
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main'\n",
    "\n",
    "my_snn_system(  devices = \"2,3\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = False, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                learning_rate = 0.001, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = True,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename='hyperparameters.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch.spikevision import spikedata\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# root, train=True, transform=None, target_transform=None, download_and_create=True, num_steps=1000, ds=1, dt=1000)\n",
    "train_ds = spikedata.SHD(\"/data2/Heidelberg\", train=True)\n",
    "test_ds = spikedata.SHD(\"/data2/Heidelberg\", train=False)\n",
    "\n",
    "# create dataloaders\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=64) # 8156x2x1000x700\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size=64) # 2264x2x1000x700\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "\n",
    "# choose a random sample\n",
    "n = 6295\n",
    "\n",
    "# initialize figure and axes\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# use spikeplot to generate a raster\n",
    "splt.raster(train_dl.dataset[n][0], ax, s=1.5, c=\"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
