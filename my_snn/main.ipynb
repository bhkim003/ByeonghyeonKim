{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40855/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == False\n",
    "    if BPTT_on == True:\n",
    "        assert tdBN_on == False\n",
    "    if convTrue_fcFalse == False:\n",
    "        assert OTTT_sWS_on == False\n",
    "    if pre_trained == True:\n",
    "        print(\"\\nCaution! pre_trained is True\\n\")    \n",
    "    \n",
    "    print('\\nyour OTTT_sWS_on', OTTT_sWS_on,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(f\"net_save/save_now_net_weights_{unique_name}.pth\"))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter:{100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "\n",
    "                        \n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            val_loss=0\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += loss.data\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss}, val:{100 * val_acc_now:.2f}%, val_best:{100 * val_acc:.2f}%\")  \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240731_121434-pwidd7bp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pwidd7bp' target=\"_blank\">solar-voice-394</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pwidd7bp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pwidd7bp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "your OTTT_sWS_on True \n",
      "\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "The directory [/data2/gesture/duration_100000] already exists.\n",
      "\n",
      "dvsgestrue 10 classes' indices exist. we want to exclude the 'other' class\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): SYNAPSE_CONV_trace_sstep()\n",
      "      (1): LIF_layer_trace_sstep()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): Scale()\n",
      "      (6): DimChanger_for_FC_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 10,523,914, system's param_num : 10,524,042\n",
      "Memory: 40.15MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-33/34 iter:22.73%, lr=['0.001'], iter_loss:0.4112085998058319, val:18.56%, val_best:18.56%: 100%|██████████| 34/34 [01:25<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 85.21141409873962 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1-33/34 iter:50.00%, lr=['0.000999972584682756'], iter_loss:0.2734265923500061, val:43.56%, val_best:43.56%: 100%|██████████| 34/34 [01:24<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 84.2299165725708 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2-33/34 iter:77.27%, lr=['0.0009998903417374227'], iter_loss:0.39646491408348083, val:55.30%, val_best:55.30%: 100%|██████████| 34/34 [01:26<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 87.21598625183105 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3-33/34 iter:90.91%, lr=['0.0009997532801828658'], iter_loss:0.20709101855754852, val:59.85%, val_best:59.85%: 100%|██████████| 34/34 [01:26<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 86.75007557868958 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4-33/34 iter:95.45%, lr=['0.0009995614150494292'], iter_loss:0.3690926432609558, val:60.98%, val_best:60.98%: 100%|██████████| 34/34 [01:24<00:00,  2.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 84.63361239433289 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5-33/34 iter:100.00%, lr=['0.000999314767377287'], iter_loss:0.3369884192943573, val:65.15%, val_best:65.15%: 100%|██████████| 34/34 [01:24<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 84.83253741264343 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6-33/34 iter:100.00%, lr=['0.0009990133642141358'], iter_loss:0.37829428911209106, val:64.77%, val_best:65.15%: 100%|██████████| 34/34 [01:21<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 82.0518569946289 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7-33/34 iter:100.00%, lr=['0.000998657238612229'], iter_loss:0.12463052570819855, val:68.18%, val_best:68.18%: 100%|██████████| 34/34 [01:28<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 89.07205605506897 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8-33/34 iter:100.00%, lr=['0.0009982464296247522'], iter_loss:0.34352052211761475, val:65.15%, val_best:68.18%: 100%|██████████| 34/34 [01:28<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 88.3412413597107 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9-33/34 iter:100.00%, lr=['0.00099778098230154'], iter_loss:0.10413242876529694, val:67.80%, val_best:68.18%: 100%|██████████| 34/34 [01:22<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 82.87710332870483 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10-33/34 iter:100.00%, lr=['0.0009972609476841367'], iter_loss:0.25316065549850464, val:66.67%, val_best:68.18%: 100%|██████████| 34/34 [01:22<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 83.00841116905212 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11-33/34 iter:100.00%, lr=['0.0009966863828001983'], iter_loss:0.20832844078540802, val:68.94%, val_best:68.94%: 100%|██████████| 34/34 [01:22<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 82.99496626853943 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12-33/34 iter:100.00%, lr=['0.0009960573506572392'], iter_loss:0.31999775767326355, val:67.42%, val_best:68.94%: 100%|██████████| 34/34 [01:26<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 86.98007297515869 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13-33/34 iter:100.00%, lr=['0.000995373920235722'], iter_loss:0.38170570135116577, val:68.94%, val_best:68.94%: 100%|██████████| 34/34 [01:25<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 86.21402931213379 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14-33/34 iter:100.00%, lr=['0.0009946361664814943'], iter_loss:0.332112580537796, val:66.67%, val_best:68.94%: 100%|██████████| 34/34 [01:23<00:00,  2.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 84.2371518611908 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15-33/34 iter:100.00%, lr=['0.000993844170297569'], iter_loss:0.4177340269088745, val:68.18%, val_best:68.94%: 100%|██████████| 34/34 [01:24<00:00,  2.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 85.18191933631897 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "16-32/34 iter:100.00%, lr=['0.0009929980185352527'], iter_loss:0.36773306131362915, val:68.18%, val_best:68.94%:  97%|█████████▋| 33/34 [01:03<00:01,  1.45s/it]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "my_snn_system(  devices = \"4\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 8 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 32, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                cfg = [64, 64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.001, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs 0 아니면 1만 갖게 하기\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = 100000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 10_000 1_000 1_000_000 #nmnist 10000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# DDP 실행 코드\n",
    "'''\n",
    "ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dfa code from ASAP\n",
    "# class feedback_receiver(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, input, weight_fb):\n",
    "#         output = input.clone()\n",
    "#         dummy = torch.Tensor(input.size()[0],weight_fb.size()[0]).zero_().to(input.device)\n",
    "#         ctx.save_for_backward(weight_fb,)\n",
    "#         ctx.shape = input.shape\n",
    "#         return output, dummy\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output, grad_dummy):\n",
    "#         weight_fb, = ctx.saved_tensors\n",
    "#         input_size = ctx.shape\n",
    "#         grad_weight_fb = None\n",
    "        \n",
    "#         grad_input = torch.mm(grad_dummy.view(grad_dummy.size()[0],-1), weight_fb).view(input_size) # Batch_size, input\n",
    "#         return grad_input, grad_weight_fb\n",
    "\n",
    "\n",
    "# class Feedback_Receiver(nn.Module):\n",
    "#     def __init__(self, connect_features):\n",
    "#         super(Feedback_Receiver, self).__init__()\n",
    "#         self.connect_features = connect_features\n",
    "#         self.weight_fb = None\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         if self.weight_fb is None:\n",
    "#             self.weight_fb = nn.Parameter(torch.Tensor(self.connect_features, *input.size()[1:]).view(self.connect_features, -1)).to(input.device)\n",
    "#             nn.init.normal_(self.weight_fb, std = math.sqrt(1./self.connect_features))\n",
    "#         return feedback_receiver.apply(input, self.weight_fb)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# run_name = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"min\": 0.0001, \"max\": 0.1},\n",
    "#         \"BATCH\": {\"values\": [ 96]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [32,64,128]},\n",
    "#         \"TIME\": {\"values\": [5,6,7,8,9,10]},\n",
    "#         \"epoch_num\": {\"values\": [10]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init(save_code = True)\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     BATCH  =  wandb.config.BATCH\n",
    "#     decay  =  wandb.config.decay\n",
    "#     IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     epoch_num  =  wandb.config.epoch_num\n",
    "\n",
    "#     my_snn_system(   devices = \"3,5\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1,\n",
    "#                 synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1,\n",
    "#                 synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = True, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                 epoch_num = epoch_num,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = True, # dvs 0 아니면 1만 갖게 하기\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 10_000 1_000 1_000_000 #nmnist 10000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "run_name = 'main_FINAL_TEST'\n",
    "\n",
    "unique_name = run_name\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
