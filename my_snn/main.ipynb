{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7863/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "                    dvs_relative_timestep = True, \n",
    "                    \n",
    "                    I_wanna_sweep_at_this_epoch = -1,\n",
    "                    dvs_duration_domain = [],\n",
    "\n",
    "                    extra_train_dataset = 0,\n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = False,\n",
    "                    pin_memory = True, # True # False\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    test_loader_domain_set = []\n",
    "    test_loader_domain_set.append(test_loader)\n",
    "    ###########################################################################################################################################\n",
    "    \n",
    "    ## 다른 dvs duration domain을 validation set으로 불러오기 ##############################################################\n",
    "    if len(dvs_duration_domain) > 0:\n",
    "        for domain in dvs_duration_domain:\n",
    "            target_domain_timestep = (dvs_duration*TIME)//domain[0] if dvs_relative_timestep == True else TIME\n",
    "            train_loader_domain, test_loader_domain, synapse_conv_in_channels_domain, CLASS_NUM_domain = data_loader(\n",
    "                    which_data,\n",
    "                    data_path, \n",
    "                    rate_coding, \n",
    "                    BATCH, \n",
    "                    IMAGE_SIZE,\n",
    "                    ddp_on,\n",
    "                    target_domain_timestep,\n",
    "                    domain[1], # dvs_clipping\n",
    "                    domain[0], # dvs_duration\n",
    "                    exclude_class,\n",
    "                    merge_polarities,\n",
    "                    denoise_on,\n",
    "                    my_seed,\n",
    "                    extra_train_dataset,\n",
    "                    num_workers,\n",
    "                    chaching_on,\n",
    "                    pin_memory)\n",
    "            test_loader_domain_set.append(test_loader_domain)\n",
    "    ######################################################################################################################\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (I_wanna_sweep_at_this_epoch == epoch):\n",
    "            net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "            no_val_best_growth_count = 0\n",
    "            DFA_current = not DFA_current\n",
    "            DFA_toggle = True\n",
    "            DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "        else:\n",
    "            if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "                assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "                if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap :\n",
    "                    if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                        net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                        no_val_best_growth_count = 0\n",
    "                        DFA_current = not DFA_current\n",
    "                        DFA_toggle = True\n",
    "                        DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "                if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                    if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                        net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                        no_tr_best_growth_count = 0\n",
    "                        DFA_current = not DFA_current\n",
    "                        DFA_toggle = True\n",
    "                        DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################         \n",
    "                               \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "                \n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                domain_index = 0\n",
    "                val_loss_set = []\n",
    "                val_acc_now_set = []\n",
    "                while True:\n",
    "                    val_loss = 0\n",
    "                    correct_val = 0\n",
    "                    total_val = 0\n",
    "                    test_loader = test_loader_domain_set[domain_index]\n",
    "                    domain_index = domain_index + 1\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        net.eval() # eval 모드로 바꿔줘야함 \n",
    "                        for data_val in test_loader:\n",
    "                            ## data_val loading & semi-pre-processing ##########################################################\n",
    "                            if len(data_val) == 2:\n",
    "                                inputs_val, labels_val = data_val\n",
    "                                # 처리 로직 작성\n",
    "                            elif len(data_val) == 3:\n",
    "                                inputs_val, labels_val, x_len = data_val\n",
    "                                # print('x_len',x_len)\n",
    "                                # mask = padded_sequence_mask(x_len)\n",
    "                                # max_time_step = x_len.max()\n",
    "                                # min_time_step = x_len.min()\n",
    "                                # B, T, *spatial_dims = inputs_val.shape\n",
    "                            else:\n",
    "                                assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                                inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            elif rate_coding == True :\n",
    "                                inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                            else :\n",
    "                                inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                            # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                            ###################################################################################################\n",
    "\n",
    "                            inputs_val = inputs_val.to(device)\n",
    "                            labels_val = labels_val.to(device)\n",
    "                            real_batch = labels_val.size(0)\n",
    "                            \n",
    "                            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                            if (which_data == 'DVS_GESTURE'):\n",
    "                                labels_val[labels_val>2] -= 1\n",
    "                            #######################################################\n",
    "                            \n",
    "                            if merge_polarities == True:\n",
    "                                inputs_val = inputs_val[:,:,0,:,:]\n",
    "\n",
    "                            ## network 연산 시작 ############################################################################################################\n",
    "                            if single_step == False:\n",
    "                                outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                                val_loss_val += criterion(outputs, labels_val)/len(test_loader)\n",
    "                            else:\n",
    "                                outputs_all = []\n",
    "                                for t in range(TIME):\n",
    "                                    outputs = net(inputs_val[t])\n",
    "                                    val_loss_temp = criterion(outputs, labels_val)\n",
    "                                    outputs_all.append(outputs.detach())\n",
    "                                    val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                                outputs = outputs_all.mean(1)\n",
    "                            val_loss_set.append(val_loss)\n",
    "                            #################################################################################################################################\n",
    "\n",
    "                            _, predicted = torch.max(outputs.data, 1)\n",
    "                            total_val += real_batch\n",
    "                            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                            correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                        val_acc_now = correct_val / total_val\n",
    "                        # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "                        val_acc_now_set.append(val_acc_now)\n",
    "\n",
    "                    if domain_index == len(dvs_duration_domain) + 1:\n",
    "                        break\n",
    "\n",
    "                val_loss = val_loss_set[0]\n",
    "                val_acc_now = val_acc_now_set[0]\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    if len(dvs_duration_domain) > 0:\n",
    "                        dvs_duration_full = [(dvs_duration, dvs_clipping)] + dvs_duration_domain\n",
    "                        print(\" | \".join(f\"{dvs_duration_full[i][0]:,}c{dvs_duration_full[i][1]}t{dvs_duration_full[i][2]}:{val_acc_now_set[i]*100:.2f}%\" for i in range(len(val_acc_now_set))))\n",
    "                    iter_of_val = False\n",
    "            \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "\n",
    "\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240926_004032-1ksau66x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1ksau66x' target=\"_blank\">worldly-aardvark-5806</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1ksau66x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1ksau66x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 85d996fe519730ffa72cbb391ca98b37\n",
      "cache path exists\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,211, system's param_num : 452,211\n",
      "Memory: 1.73MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.365774/  2.268681, tr:  10.31%, val:  14.77%, val_best:  14.77%: 100%|██████████| 68/68 [00:29<00:00,  2.34it/s]\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.058992/  1.877776, tr:  32.31%, val:  42.05%, val_best:  42.05%: 100%|██████████| 68/68 [00:25<00:00,  2.63it/s]\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  1.651561/  1.634302, tr:  52.37%, val:  46.97%, val_best:  46.97%: 100%|██████████| 68/68 [00:24<00:00,  2.73it/s]\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  1.445503/  1.500141, tr:  59.61%, val:  60.23%, val_best:  60.23%: 100%|██████████| 68/68 [00:26<00:00,  2.60it/s]\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  1.343616/  1.454369, tr:  64.44%, val:  60.23%, val_best:  60.23%: 100%|██████████| 68/68 [00:25<00:00,  2.63it/s]\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.284766/  1.395600, tr:  63.60%, val:  62.50%, val_best:  62.50%: 100%|██████████| 68/68 [00:25<00:00,  2.65it/s]\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.218728/  1.407536, tr:  66.76%, val:  62.50%, val_best:  62.50%: 100%|██████████| 68/68 [00:25<00:00,  2.68it/s]\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.176355/  1.381853, tr:  69.36%, val:  62.50%, val_best:  62.50%: 100%|██████████| 68/68 [00:26<00:00,  2.58it/s]\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.138209/  1.388146, tr:  69.17%, val:  64.39%, val_best:  64.39%: 100%|██████████| 68/68 [00:26<00:00,  2.59it/s]\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.104978/  1.367553, tr:  72.52%, val:  64.77%, val_best:  64.77%: 100%|██████████| 68/68 [00:25<00:00,  2.62it/s]\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.093648/  1.361967, tr:  71.87%, val:  66.29%, val_best:  66.29%: 100%|██████████| 68/68 [00:26<00:00,  2.57it/s]\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.045431/  1.385125, tr:  74.19%, val:  62.88%, val_best:  66.29%: 100%|██████████| 68/68 [00:25<00:00,  2.65it/s]\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.027156/  1.343639, tr:  74.47%, val:  67.80%, val_best:  67.80%: 100%|██████████| 68/68 [00:26<00:00,  2.60it/s]\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  0.988691/  1.371706, tr:  76.51%, val:  67.05%, val_best:  67.80%: 100%|██████████| 68/68 [00:26<00:00,  2.54it/s]\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  0.982632/  1.347816, tr:  77.34%, val:  67.42%, val_best:  67.80%: 100%|██████████| 68/68 [00:26<00:00,  2.61it/s]\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  0.952077/  1.349691, tr:  77.62%, val:  70.45%, val_best:  70.45%: 100%|██████████| 68/68 [00:26<00:00,  2.60it/s]\n",
      "epoch-16  iter_acc:  87.50%, lr=['0.0001000'], iter_loss:  0.995025, val_best:  70.45%:  12%|█▏        | 8/68 [00:03<00:20,  2.91it/s]"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "if const2 == True:\n",
    "    const2 = decay\n",
    "else:\n",
    "    const2 = 0.0\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 60, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.720291189014991, # 1.3102821334243646,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 3.555718888923306, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = ['M','M',200,200],\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.0001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = 2, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "\n",
    "                drop_rate = 0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "                exclude_class = False, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False\n",
    "\n",
    "                I_wanna_sweep_at_this_epoch = -1, # 지정 에포크에서 BP와 DFA를 바꿔줌. -1이면 실행 안함.\n",
    "                # dvs_duration_domain=[(100_000,5),(125_000,5),(150_000,5),],\n",
    "                # dvs_duration_domain=[(40_000,4),(50_000,4),(60_000,4),],\n",
    "                dvs_duration_domain=[],\n",
    "                dvs_relative_timestep = False, # True # False \n",
    "                \n",
    "                extra_train_dataset = 0,\n",
    "\n",
    "                num_workers = 4,\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# DDP 실행 코드0\n",
    "'''\n",
    "ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# run_name = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.001]}, #0.00936191669529645\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"decay\": {\"values\": [0.25,0.5,0.75]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"epoch_num\": {\"values\": [200]},\n",
    "#         \"dvs_duration\": {\"values\": [100_000]},\n",
    "#         \"dvs_clipping\": {\"values\": [1,2,3,4,5]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "#         \"const2\": {\"values\": [False]},\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "#         \"DFA_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "#         \"e_transport_swap\": {\"values\": [0]},\n",
    "#         \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "#         \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [0,10000]},\n",
    "#         \"lif_layer_sg_width\": {\"min\": 1.0, \"max\": 8.0},\n",
    "#         \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "#         \"lif_layer_v_threshold\": {\"min\": 0.0, \"max\": 3.0},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "#         \"denoise_on\": {\"values\": ['True']}, \n",
    "#         \"I_wanna_sweep_at_this_epoch\": {\"values\": [-1]}, \n",
    "#         \"dvs_duration_domain\": {\"values\": [[]]}, \n",
    "#         \"dvs_relative_timestep\": {\"values\": [[True]]}, \n",
    "#         \"extra_train_dataset\": {\"values\": [0,1,2,3]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init(save_code = True)\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     BATCH  =  wandb.config.BATCH\n",
    "#     decay  =  wandb.config.decay\n",
    "#     IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     epoch_num  =  wandb.config.epoch_num \n",
    "#     dvs_duration  =  wandb.config.dvs_duration\n",
    "#     dvs_clipping  =  wandb.config.dvs_clipping\n",
    "#     which_data  =  wandb.config.which_data\n",
    "#     OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "#     const2  =  wandb.config.const2\n",
    "#     surrogate  =  wandb.config.surrogate\n",
    "#     DFA_on  =  wandb.config.DFA_on\n",
    "#     OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "#     cfg  =  wandb.config.cfg\n",
    "#     e_transport_swap  =  wandb.config.e_transport_swap\n",
    "#     e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "#     drop_rate  =  wandb.config.drop_rate\n",
    "#     exclude_class  =  wandb.config.exclude_class\n",
    "#     merge_polarities  =  wandb.config.merge_polarities\n",
    "#     lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "#     lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "#     e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "#     lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "#     scheduler_name  =  wandb.config.scheduler_name\n",
    "#     denoise_on  =  wandb.config.denoise_on\n",
    "#     I_wanna_sweep_at_this_epoch  =  wandb.config.I_wanna_sweep_at_this_epoch\n",
    "#     dvs_duration_domain  =  wandb.config.dvs_duration_domain\n",
    "#     dvs_relative_timestep  =  wandb.config.dvs_relative_timestep\n",
    "#     extra_train_dataset  =  wandb.config.extra_train_dataset\n",
    "#     if const2 == True:\n",
    "#         const2 = decay\n",
    "#     else:\n",
    "#         const2 = 0.0\n",
    "\n",
    "#     my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = which_data,\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 cfg = cfg,\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = epoch_num,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "#                 drop_rate = drop_rate,\n",
    "\n",
    "#                 exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = denoise_on,\n",
    "\n",
    "#                 I_wanna_sweep_at_this_epoch = I_wanna_sweep_at_this_epoch,\n",
    "#                 dvs_duration_domain = dvs_duration_domain,\n",
    "#                 dvs_relative_timestep = dvs_relative_timestep, # True # False \n",
    "\n",
    "#                 extra_train_dataset = extra_train_dataset,\n",
    "\n",
    "#                 num_workers = 4,\n",
    "#                 chaching_on = True,\n",
    "#                 pin_memory = True, # True # False\n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06972516770468ebe0ceaab6aad584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.084 MB of 1.084 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▄▇▆▆▇█▇█████████▇██████████████▇████▇█</td></tr><tr><td>tr_acc</td><td>▁▃▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▄▇▆▆▇█▇█████████▇██████████████▇████▇█</td></tr><tr><td>val_loss</td><td>▃▁▁▁▂▃▂▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>299</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00141</td></tr><tr><td>val_acc_best</td><td>0.87917</td></tr><tr><td>val_acc_now</td><td>0.87083</td></tr><tr><td>val_loss</td><td>1.95997</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sponge-5788</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/628zjf20' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/628zjf20</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_213946-628zjf20/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
