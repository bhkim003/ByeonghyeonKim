{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35557/1994964446.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "    # 함수 내 모든 로컬 변수 저장\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    \n",
    "    wandb.init(project= f'my_snn {unique_name}', config=hyperparameters)\n",
    "    wandb.run.name = unique_name\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "\n",
    "            ### input --> net --> output #####################################################\n",
    "            outputs = net(inputs)\n",
    "            ##################################################################################\n",
    "\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            batch = BATCH \n",
    "            if labels.size(0) != BATCH: \n",
    "                batch = labels.size(0)\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = (predicted[0:batch] == labels).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## loss, backward ##########################################\n",
    "            loss = criterion(outputs[0:batch,:], labels)\n",
    "            loss.backward()\n",
    "            ############################################################\n",
    "\n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## weight 업데이트!! ##################################\n",
    "            optimizer.step()\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = net(inputs.permute(1, 0, 2, 3, 4))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        batch = BATCH \n",
    "                        if labels.size(0) != BATCH: \n",
    "                            batch = labels.size(0)\n",
    "                        correct += (predicted[0:batch] == labels).sum().item()\n",
    "                        val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "            wandb.log({\"iter_acc\": iter_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"tr_acc\": tr_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"val_acc_now\": val_acc_now}, step=i+epoch*len(train_loader))\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            # # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기)\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "            np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                json.dump(hyperparameters, f, indent=4)\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    wandb.finish()\n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240722_224239-75arip9x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75arip9x' target=\"_blank\">peachy-energy-107</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75arip9x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75arip9x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace()\n",
      "      (1): LIF_layer_trace()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace()\n",
      "      (4): LIF_layer_trace()\n",
      "      (5): Scale()\n",
      "      (6): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (7): SYNAPSE_CONV_trace()\n",
      "      (8): LIF_layer_trace()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace()\n",
      "      (11): LIF_layer_trace()\n",
      "      (12): Scale()\n",
      "      (13): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (14): SYNAPSE_CONV_trace()\n",
      "      (15): LIF_layer_trace()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace()\n",
      "      (18): LIF_layer_trace()\n",
      "      (19): Scale()\n",
      "      (20): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (21): SYNAPSE_CONV_trace()\n",
      "      (22): LIF_layer_trace()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace()\n",
      "      (25): LIF_layer_trace()\n",
      "      (26): Scale()\n",
      "      (27): DimChanger_for_pooling(\n",
      "        (ann_module): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      )\n",
      "      (28): DimChanger_for_FC()\n",
      "      (29): SYNAPSE_FC_trace()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-178/391 iter_acc: 10.94%, lr=['0.1'], iter_loss: 0.36541295051574707, val_acc: 0.00%:  46%|████▌     | 179/391 [00:47<00:52,  4.04it/s]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "my_snn_system(  devices = \"4,5\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.1, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-4])\n",
    "x = torch.sigmoid(x)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
