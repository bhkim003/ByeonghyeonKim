{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40007/2809884579.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net) #나중에풀어줘\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "\n",
    "            ### input --> net --> output #####################################################\n",
    "            outputs = net(inputs)\n",
    "            ##################################################################################\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            batch = BATCH \n",
    "            if labels.size(0) != BATCH: \n",
    "                batch = labels.size(0)\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = (predicted[0:batch] == labels).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## loss, backward ##########################################\n",
    "            loss = criterion(outputs[0:batch,:], labels)\n",
    "            loss.backward()\n",
    "            ############################################################\n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## weight 업데이트!! ##################################\n",
    "            optimizer.step()\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = net(inputs.permute(1, 0, 2, 3, 4))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        batch = BATCH \n",
    "                        if labels.size(0) != BATCH: \n",
    "                            batch = labels.size(0)\n",
    "                        correct += (predicted[0:batch] == labels).sum().item()\n",
    "                        val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "            wandb.log({\"iter_acc\": iter_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"tr_acc\": tr_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"val_acc_now\": val_acc_now}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            #######################################################################################\n",
    "\n",
    "            # np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            # np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            # np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            # with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_113144-ruwc2slr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ruwc2slr' target=\"_blank\">cool-wind-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ruwc2slr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ruwc2slr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace()\n",
      "      (1): LIF_layer_trace()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace()\n",
      "      (4): LIF_layer_trace()\n",
      "      (5): Scale()\n",
      "      (6): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (7): SYNAPSE_CONV_trace()\n",
      "      (8): LIF_layer_trace()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace()\n",
      "      (11): LIF_layer_trace()\n",
      "      (12): Scale()\n",
      "      (13): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (14): SYNAPSE_CONV_trace()\n",
      "      (15): LIF_layer_trace()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace()\n",
      "      (18): LIF_layer_trace()\n",
      "      (19): Scale()\n",
      "      (20): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (21): SYNAPSE_CONV_trace()\n",
      "      (22): LIF_layer_trace()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace()\n",
      "      (25): LIF_layer_trace()\n",
      "      (26): Scale()\n",
      "      (27): DimChanger_for_pooling(\n",
      "        (ann_module): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      )\n",
      "      (28): DimChanger_for_FC()\n",
      "      (29): SYNAPSE_FC_trace()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 18.75%, lr=['0.6'], iter_loss: 0.3295895457267761, val_acc: 21.86%: 100%|██████████| 391/391 [03:11<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 191.95171689987183 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-49/391 iter_acc: 10.94%, lr=['0.5999835508096536'], iter_loss: 0.33470937609672546, val_acc: 21.86%:  13%|█▎        | 50/391 [00:22<02:39,  2.14it/s]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "wandb.init(project= f'my_snn {unique_name}')\n",
    "my_snn_system(  devices = \"2\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.6, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 02uhuz1p\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hghhiqdy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.1911562407482998\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_111153-hghhiqdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hghhiqdy' target=\"_blank\">lyric-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hghhiqdy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hghhiqdy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace()\n",
      "      (1): LIF_layer_trace()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace()\n",
      "      (4): LIF_layer_trace()\n",
      "      (5): Scale()\n",
      "      (6): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (7): SYNAPSE_CONV_trace()\n",
      "      (8): LIF_layer_trace()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace()\n",
      "      (11): LIF_layer_trace()\n",
      "      (12): Scale()\n",
      "      (13): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (14): SYNAPSE_CONV_trace()\n",
      "      (15): LIF_layer_trace()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace()\n",
      "      (18): LIF_layer_trace()\n",
      "      (19): Scale()\n",
      "      (20): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (21): SYNAPSE_CONV_trace()\n",
      "      (22): LIF_layer_trace()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace()\n",
      "      (25): LIF_layer_trace()\n",
      "      (26): Scale()\n",
      "      (27): DimChanger_for_pooling(\n",
      "        (ann_module): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      )\n",
      "      (28): DimChanger_for_FC()\n",
      "      (29): SYNAPSE_FC_trace()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-258/391 iter_acc: 10.94%, lr=['1.1911562407482998'], iter_loss: 0.3571101129055023, val_acc: 0.00%:  66%|██████▌   | 258/391 [01:56<00:59,  2.23it/s] "
     ]
    }
   ],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"min\": 0.1, \"max\": 2.0},\n",
    "#         \"batch_size\": {\"values\": [64, 96, 128]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init()\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     decay  =  wandb.config.decay\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                     unique_name = unique_name,\n",
    "#                     my_seed = 42,\n",
    "#                     TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                     BATCH = batch_size, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                     IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "#                     # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                     #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                     # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                     which_data = 'CIFAR10',\n",
    "#     # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "#     # 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                     # CLASS_NUM = 10,\n",
    "#                     data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                     rate_coding = False, # True # False\n",
    "\n",
    "#                     lif_layer_v_init = 0.0,\n",
    "#                     lif_layer_v_decay = decay,\n",
    "#                     lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                     lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                     lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                     # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                     synapse_conv_kernel_size = 3,\n",
    "#                     synapse_conv_stride = 1,\n",
    "#                     synapse_conv_padding = 1,\n",
    "#                     synapse_conv_trace_const1 = 1,\n",
    "#                     synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     # synapse_fc_out_features = CLASS_NUM,\n",
    "#                     synapse_fc_trace_const1 = 1,\n",
    "#                     synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     pre_trained = False, # True # False\n",
    "#                     convTrue_fcFalse = True, # True # False\n",
    "\n",
    "#                     # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                     # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                     # cfg = [64],\n",
    "#                     # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                     cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "#                     # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                     # cfg = [20001,10001], # depthwise, separable\n",
    "#                     # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                     # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                     # cfg = [], \n",
    "                    \n",
    "#                     net_print = True, # True # False\n",
    "#                     weight_count_print = False, # True # False\n",
    "                    \n",
    "#                     pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "#                     learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                     epoch_num = 4,\n",
    "#                     verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                     validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                     tdBN_on = False,  # True # False\n",
    "#                     BN_on = False,  # True # False\n",
    "                    \n",
    "#                     surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                    \n",
    "#                     gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                     BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                     optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                     scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "#                     ddp_on = False,   # True # False\n",
    "\n",
    "#                     nda_net = False,   # True # False\n",
    "\n",
    "#                     domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                    \n",
    "#                     dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "#                     OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                    \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
