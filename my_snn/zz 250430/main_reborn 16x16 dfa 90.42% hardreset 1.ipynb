{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23984/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #     criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    slice_bucket.append(slice_concat)\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],)\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372a2dc01fb14b8dbe9218256285b84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111302855424583, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_143232-eem9vvhz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/eem9vvhz' target=\"_blank\">sage-dragon-7351</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/eem9vvhz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/eem9vvhz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8} \n",
      "\n",
      "dataset_hash = ddd2d600e882f330b6acfa4755a9bed1\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=2560, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.25, v_threshold=0.75, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.0, TIME=10, sstep=True, trace_on=True)\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.25, v_threshold=0.75, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.0, TIME=10, sstep=True, trace_on=True)\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 554,410\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.306249/  2.303913, val:   5.00%, val_best:   5.00%, tr:   9.91%, tr_best:   9.91%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.099936/  1.803051, val:  42.50%, val_best:  42.50%, tr:  21.04%, tr_best:  21.04%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.522314/  1.455614, val:  57.08%, val_best:  57.08%, tr:  52.71%, tr_best:  52.71%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.246627/  1.355900, val:  60.00%, val_best:  60.00%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.131813/  1.290559, val:  62.50%, val_best:  62.50%, tr:  64.04%, tr_best:  65.47%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.065134/  1.222224, val:  68.33%, val_best:  68.33%, tr:  66.19%, tr_best:  66.19%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.995995/  1.184150, val:  70.00%, val_best:  70.00%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.954030/  1.143521, val:  69.17%, val_best:  70.00%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.891481/  1.113130, val:  76.67%, val_best:  76.67%, tr:  76.10%, tr_best:  76.10%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.824823/  1.102169, val:  79.17%, val_best:  79.17%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.785414/  1.082400, val:  79.58%, val_best:  79.58%, tr:  86.21%, tr_best:  86.21%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.713243/  1.033911, val:  81.25%, val_best:  81.25%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.670452/  1.020092, val:  83.33%, val_best:  83.33%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.630711/  1.010568, val:  82.92%, val_best:  83.33%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.577342/  1.084626, val:  77.08%, val_best:  83.33%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.548430/  0.997540, val:  87.08%, val_best:  87.08%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.536778/  0.955393, val:  88.75%, val_best:  88.75%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.487796/  0.979209, val:  85.83%, val_best:  88.75%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.464987/  1.043903, val:  81.67%, val_best:  88.75%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.443124/  1.001723, val:  87.92%, val_best:  88.75%, tr:  94.99%, tr_best:  95.51%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.417210/  0.991029, val:  85.83%, val_best:  88.75%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.390267/  0.978684, val:  88.75%, val_best:  88.75%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.392720/  0.967035, val:  89.58%, val_best:  89.58%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.362742/  0.999862, val:  87.08%, val_best:  89.58%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.339820/  1.034458, val:  85.00%, val_best:  89.58%, tr:  97.04%, tr_best:  97.14%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.327125/  1.001009, val:  87.92%, val_best:  89.58%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.309970/  1.028434, val:  86.25%, val_best:  89.58%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.295266/  1.067777, val:  86.25%, val_best:  89.58%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.284726/  1.024532, val:  90.42%, val_best:  90.42%, tr:  98.37%, tr_best:  98.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.269360/  1.051146, val:  88.33%, val_best:  90.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.254567/  1.064453, val:  87.92%, val_best:  90.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.247180/  1.067205, val:  88.75%, val_best:  90.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.231761/  1.074104, val:  88.33%, val_best:  90.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.227691/  1.102362, val:  87.50%, val_best:  90.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.215995/  1.100278, val:  88.33%, val_best:  90.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.206685/  1.145299, val:  87.08%, val_best:  90.42%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.191260/  1.141655, val:  87.92%, val_best:  90.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.186214/  1.158925, val:  87.08%, val_best:  90.42%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.178515/  1.126845, val:  89.17%, val_best:  90.42%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.174142/  1.148576, val:  87.92%, val_best:  90.42%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.160336/  1.164028, val:  88.75%, val_best:  90.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.156391/  1.169091, val:  90.00%, val_best:  90.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.153557/  1.168571, val:  89.17%, val_best:  90.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.139168/  1.198706, val:  88.75%, val_best:  90.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.134654/  1.178263, val:  89.17%, val_best:  90.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.125566/  1.214313, val:  88.75%, val_best:  90.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.123832/  1.198680, val:  87.50%, val_best:  90.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.117714/  1.215762, val:  87.92%, val_best:  90.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.110703/  1.237486, val:  88.33%, val_best:  90.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.108420/  1.238361, val:  88.75%, val_best:  90.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.103710/  1.250366, val:  88.33%, val_best:  90.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.098916/  1.284004, val:  88.75%, val_best:  90.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.093953/  1.273924, val:  89.17%, val_best:  90.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.093666/  1.286389, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.088858/  1.306802, val:  88.33%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.079433/  1.330473, val:  88.33%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.080071/  1.335551, val:  88.75%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.076586/  1.335349, val:  87.92%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.070985/  1.356760, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.070947/  1.348994, val:  90.00%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.068645/  1.370589, val:  89.17%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.065904/  1.383160, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.063607/  1.385474, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.060685/  1.378858, val:  90.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.057048/  1.426211, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.056880/  1.423210, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.055728/  1.404926, val:  88.75%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.053972/  1.418443, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.052933/  1.427669, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.049500/  1.436254, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.048530/  1.438950, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.049326/  1.468757, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.046077/  1.469808, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.043621/  1.448105, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.041112/  1.472222, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.038594/  1.484622, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.040272/  1.492558, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.037002/  1.508067, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.038498/  1.525818, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.037717/  1.539813, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.036049/  1.540515, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.033703/  1.553601, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.031707/  1.563743, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.032582/  1.568501, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.033017/  1.563548, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.031922/  1.567863, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.029973/  1.585151, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.030611/  1.587120, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.029863/  1.582508, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.028725/  1.595372, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.027940/  1.592623, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.026628/  1.599196, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.025823/  1.627812, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.026890/  1.618504, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.025691/  1.640228, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.025483/  1.636276, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.023421/  1.634750, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.024099/  1.652173, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.022937/  1.647117, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.023436/  1.652887, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.021615/  1.659095, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.022418/  1.673998, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.022292/  1.665077, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.022295/  1.686252, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.020898/  1.675523, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.022112/  1.686411, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.019994/  1.691750, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.020094/  1.693844, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.019986/  1.706805, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.019396/  1.710194, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.019826/  1.707929, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.017803/  1.709029, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.018042/  1.705468, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.017208/  1.714766, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.016937/  1.705010, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.016782/  1.708905, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.016467/  1.731498, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.016994/  1.742099, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.016042/  1.737813, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.016344/  1.752483, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.015704/  1.737454, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.015680/  1.738661, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.015350/  1.743154, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.014293/  1.740395, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.014513/  1.764158, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.015770/  1.766069, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.014814/  1.760918, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.015236/  1.779255, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.015531/  1.764794, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.014199/  1.765816, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.014668/  1.775417, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.015348/  1.777160, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.014521/  1.778774, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.013356/  1.790699, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.013860/  1.783922, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.014244/  1.797234, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.013907/  1.803582, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.015848/  1.810895, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.013323/  1.808067, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.013054/  1.809219, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.012652/  1.807714, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.012543/  1.803645, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.012756/  1.814378, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.012613/  1.807928, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.012538/  1.824119, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.012458/  1.831165, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.012309/  1.838514, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.012611/  1.826138, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.012514/  1.844223, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.011252/  1.844140, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.012064/  1.845973, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.011359/  1.850177, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.011317/  1.856777, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.012066/  1.847285, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.011318/  1.854259, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.011213/  1.853575, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.010781/  1.864617, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.010768/  1.867413, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.010466/  1.872108, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.009997/  1.868301, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.010316/  1.878428, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.010110/  1.870993, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.010156/  1.884508, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.009805/  1.882794, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.010418/  1.894532, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.010163/  1.895701, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.010061/  1.912005, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.009621/  1.903100, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.009618/  1.897402, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.009824/  1.905300, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.009328/  1.899683, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.009495/  1.902313, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.009896/  1.900885, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.009503/  1.910500, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.008990/  1.908877, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.009039/  1.900225, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.008828/  1.889026, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.009239/  1.900436, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.008605/  1.907027, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.008467/  1.900715, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.008609/  1.896728, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.008566/  1.898194, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.008132/  1.912355, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.008217/  1.917891, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.008366/  1.915457, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.008390/  1.918819, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.008527/  1.932128, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.008931/  1.921043, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.008553/  1.913397, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.008618/  1.918414, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.008734/  1.923997, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.008209/  1.922272, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.008169/  1.927961, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.008364/  1.918650, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.007645/  1.919514, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.007650/  1.934187, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.007979/  1.936078, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.008181/  1.950094, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.007925/  1.944981, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.007791/  1.963404, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-200 lr=['0.0010000'], tr/val_loss:  0.008445/  1.965648, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-201 lr=['0.0010000'], tr/val_loss:  0.008045/  1.959585, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-202 lr=['0.0010000'], tr/val_loss:  0.007818/  1.971978, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-203 lr=['0.0010000'], tr/val_loss:  0.008456/  1.981873, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-204 lr=['0.0010000'], tr/val_loss:  0.008861/  1.979552, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-205 lr=['0.0010000'], tr/val_loss:  0.007739/  1.972469, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-206 lr=['0.0010000'], tr/val_loss:  0.007765/  1.974244, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-207 lr=['0.0010000'], tr/val_loss:  0.007705/  1.977851, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-208 lr=['0.0010000'], tr/val_loss:  0.007428/  1.984714, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-209 lr=['0.0010000'], tr/val_loss:  0.008003/  1.996860, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-210 lr=['0.0010000'], tr/val_loss:  0.007666/  1.988314, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-211 lr=['0.0010000'], tr/val_loss:  0.007480/  1.987880, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-212 lr=['0.0010000'], tr/val_loss:  0.007721/  1.992105, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-213 lr=['0.0010000'], tr/val_loss:  0.007222/  1.992256, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-214 lr=['0.0010000'], tr/val_loss:  0.007436/  2.002443, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-215 lr=['0.0010000'], tr/val_loss:  0.007433/  1.981045, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-216 lr=['0.0010000'], tr/val_loss:  0.007116/  1.980382, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-217 lr=['0.0010000'], tr/val_loss:  0.007154/  1.995190, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-218 lr=['0.0010000'], tr/val_loss:  0.006879/  1.992733, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-219 lr=['0.0010000'], tr/val_loss:  0.007313/  1.987399, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-220 lr=['0.0010000'], tr/val_loss:  0.006747/  1.996676, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-221 lr=['0.0010000'], tr/val_loss:  0.007368/  1.991126, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-222 lr=['0.0010000'], tr/val_loss:  0.007177/  1.994277, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-223 lr=['0.0010000'], tr/val_loss:  0.007128/  1.997437, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-224 lr=['0.0010000'], tr/val_loss:  0.006542/  1.995493, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-225 lr=['0.0010000'], tr/val_loss:  0.006612/  1.996351, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-226 lr=['0.0010000'], tr/val_loss:  0.006998/  2.008600, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-227 lr=['0.0010000'], tr/val_loss:  0.006226/  2.010379, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-228 lr=['0.0010000'], tr/val_loss:  0.006421/  2.016829, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-229 lr=['0.0010000'], tr/val_loss:  0.006731/  2.008720, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-230 lr=['0.0010000'], tr/val_loss:  0.006586/  2.024535, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-231 lr=['0.0010000'], tr/val_loss:  0.006770/  2.010164, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-232 lr=['0.0010000'], tr/val_loss:  0.006594/  2.021754, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-233 lr=['0.0010000'], tr/val_loss:  0.006927/  2.021122, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-234 lr=['0.0010000'], tr/val_loss:  0.006637/  2.017687, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-235 lr=['0.0010000'], tr/val_loss:  0.006436/  2.015496, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-236 lr=['0.0010000'], tr/val_loss:  0.007390/  2.006217, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-237 lr=['0.0010000'], tr/val_loss:  0.006568/  2.018008, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-238 lr=['0.0010000'], tr/val_loss:  0.006457/  2.002465, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-239 lr=['0.0010000'], tr/val_loss:  0.006043/  2.004215, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-240 lr=['0.0010000'], tr/val_loss:  0.005931/  2.000397, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-241 lr=['0.0010000'], tr/val_loss:  0.005784/  1.999062, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-242 lr=['0.0010000'], tr/val_loss:  0.006014/  1.998496, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-243 lr=['0.0010000'], tr/val_loss:  0.006008/  2.000139, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-244 lr=['0.0010000'], tr/val_loss:  0.005484/  2.007275, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-245 lr=['0.0010000'], tr/val_loss:  0.005364/  2.008821, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-246 lr=['0.0010000'], tr/val_loss:  0.005262/  2.012157, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-247 lr=['0.0010000'], tr/val_loss:  0.005171/  2.010945, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-248 lr=['0.0010000'], tr/val_loss:  0.005322/  2.012948, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-249 lr=['0.0010000'], tr/val_loss:  0.006271/  2.008045, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-250 lr=['0.0010000'], tr/val_loss:  0.005505/  2.003362, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-251 lr=['0.0010000'], tr/val_loss:  0.005495/  2.003027, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-252 lr=['0.0010000'], tr/val_loss:  0.005220/  2.009797, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-253 lr=['0.0010000'], tr/val_loss:  0.005327/  2.022161, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-254 lr=['0.0010000'], tr/val_loss:  0.005324/  2.025568, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-255 lr=['0.0010000'], tr/val_loss:  0.005009/  2.029357, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-256 lr=['0.0010000'], tr/val_loss:  0.004812/  2.033413, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-257 lr=['0.0010000'], tr/val_loss:  0.004721/  2.028965, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-258 lr=['0.0010000'], tr/val_loss:  0.005390/  2.038890, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-259 lr=['0.0010000'], tr/val_loss:  0.005685/  2.034949, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-260 lr=['0.0010000'], tr/val_loss:  0.005448/  2.033769, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-261 lr=['0.0010000'], tr/val_loss:  0.005138/  2.031000, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-262 lr=['0.0010000'], tr/val_loss:  0.004800/  2.035241, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-263 lr=['0.0010000'], tr/val_loss:  0.005017/  2.036350, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-264 lr=['0.0010000'], tr/val_loss:  0.004561/  2.036843, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-265 lr=['0.0010000'], tr/val_loss:  0.004650/  2.042462, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-266 lr=['0.0010000'], tr/val_loss:  0.004747/  2.046869, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-267 lr=['0.0010000'], tr/val_loss:  0.004820/  2.050364, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-268 lr=['0.0010000'], tr/val_loss:  0.004577/  2.055862, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-269 lr=['0.0010000'], tr/val_loss:  0.004717/  2.052594, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-270 lr=['0.0010000'], tr/val_loss:  0.004684/  2.054017, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-271 lr=['0.0010000'], tr/val_loss:  0.004754/  2.055861, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-272 lr=['0.0010000'], tr/val_loss:  0.004397/  2.054923, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-273 lr=['0.0010000'], tr/val_loss:  0.004476/  2.057695, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-274 lr=['0.0010000'], tr/val_loss:  0.004659/  2.058421, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-275 lr=['0.0010000'], tr/val_loss:  0.004395/  2.058467, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-276 lr=['0.0010000'], tr/val_loss:  0.004403/  2.065014, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-277 lr=['0.0010000'], tr/val_loss:  0.004253/  2.074232, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-278 lr=['0.0010000'], tr/val_loss:  0.004465/  2.066337, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-279 lr=['0.0010000'], tr/val_loss:  0.004352/  2.076151, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "const2 = False # True # False\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "if const2 == True:\n",
    "    const2 = decay\n",
    "else:\n",
    "    const2 = 0.0\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"1\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.75,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 2, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = True,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = True, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "\n",
    "                last_lif = False,\n",
    "\n",
    "                temporal_filter = 5, \n",
    "                initial_pooling = 8,\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "#         \"epoch_num\": {\"values\": [100]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [True]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [1]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"0\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  unique_name_hyper,\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#                         ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = '6pj3lh8j'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
