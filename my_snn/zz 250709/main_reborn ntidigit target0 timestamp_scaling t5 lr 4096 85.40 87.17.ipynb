{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26792/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. 전체 state_dict 로드\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. 현재 모델의 state_dict 가져오기\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'가 포함된 key만 필터링 (현재 모델에도 존재하는 key만)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. 업데이트된 키 출력\n",
    "        print(\"🔄 업데이트된 SYNAPSE 관련 레이어들:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. 모델 dict 업데이트 및 로딩\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> 클래스 인덱스\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE 스타일의 gradient를 흉내냄\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # 이거 걍 1.0임\n",
    "    #         return input_one_hot - target_one_hot, None  # target에는 gradient 없음\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    input_argmin = input_slice.argmin(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient 방향을 argmin 쪽으로\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"모든 파라미터에 대해 gradient descent 수행\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradient를 이용해 파라미터 업데이트\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer 초기화\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    ooo_fifo = 0\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO 처리 ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw 위 연산이랑 다름. inmemory연산이라 좀 다른 듯\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight 프린트 ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # 통계량 계산\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # 절대값 기반 max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # 그래프 그리기\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # 제목에 통계값 포함\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight 프린트 ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "            ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpe별로 sum값이 10미만일 시 제외\n",
    "            #     # time step별 합 계산: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 이상인 타임스텝만 선택\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # 해당 타임스텝만 추출\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # valid한 time step의 개수\n",
    "            #     net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 중 하나 선택\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                    optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch 크기 ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "                        ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpe별로 sum값이 10미만일 시 제외\n",
    "                        #     # time step별 합 계산: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 이상인 타임스텝만 선택\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # 해당 타임스텝만 추출\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # valid한 time step의 개수\n",
    "                        #     net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250708_163748-jkbq0o1d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkbq0o1d' target=\"_blank\">cerulean-butterfly-12405</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkbq0o1d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkbq0o1d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20250708_163746_217', 'my_seed': 1, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 6.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_20250704_185524_987.pth', 'learning_rate': 0.000244140625, 'epoch_num': 1000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [], 'timestep_sums_threshold': 0} \n",
      "\n",
      "train_dataset length = 446, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 446 BATCH: 1 train_data_count: 446\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[])\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[])\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.000244140625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 178 occurrences\n",
      "train - Value 1: 268 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 302 occurrences\n",
      "test - Value 1: 150 occurrences\n",
      "epoch-0   lr=['0.0002441'], tr/val_loss:  2.300091/  2.298484, val:  50.88%, val_best:  50.88%, tr:  51.35%, tr_best:  51.35%, epoch time: 15.57 seconds, 0.26 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 313 occurrences\n",
      "train - Value 1: 133 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-1   lr=['0.0002441'], tr/val_loss:  2.296253/  2.288123, val:  54.20%, val_best:  54.20%, tr:  55.61%, tr_best:  55.61%, epoch time: 13.50 seconds, 0.23 minutes\n",
      "train - Value 0: 286 occurrences\n",
      "train - Value 1: 160 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-2   lr=['0.0002441'], tr/val_loss:  2.306886/  2.320696, val:  55.53%, val_best:  55.53%, tr:  52.69%, tr_best:  55.61%, epoch time: 13.09 seconds, 0.22 minutes\n",
      "train - Value 0: 243 occurrences\n",
      "train - Value 1: 203 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-3   lr=['0.0002441'], tr/val_loss:  2.310859/  2.308101, val:  53.76%, val_best:  55.53%, tr:  56.05%, tr_best:  56.05%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 194 occurrences\n",
      "train - Value 1: 252 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-4   lr=['0.0002441'], tr/val_loss:  2.308980/  2.303352, val:  50.44%, val_best:  55.53%, tr:  54.48%, tr_best:  56.05%, epoch time: 13.84 seconds, 0.23 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-5   lr=['0.0002441'], tr/val_loss:  2.304492/  2.298633, val:  54.20%, val_best:  55.53%, tr:  54.93%, tr_best:  56.05%, epoch time: 13.46 seconds, 0.22 minutes\n",
      "train - Value 0: 215 occurrences\n",
      "train - Value 1: 231 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-6   lr=['0.0002441'], tr/val_loss:  2.300045/  2.282001, val:  55.53%, val_best:  55.53%, tr:  54.26%, tr_best:  56.05%, epoch time: 13.47 seconds, 0.22 minutes\n",
      "train - Value 0: 246 occurrences\n",
      "train - Value 1: 200 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-7   lr=['0.0002441'], tr/val_loss:  2.299402/  2.306095, val:  55.53%, val_best:  55.53%, tr:  55.83%, tr_best:  56.05%, epoch time: 13.58 seconds, 0.23 minutes\n",
      "train - Value 0: 273 occurrences\n",
      "train - Value 1: 173 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-8   lr=['0.0002441'], tr/val_loss:  2.296800/  2.291470, val:  61.50%, val_best:  61.50%, tr:  62.78%, tr_best:  62.78%, epoch time: 13.81 seconds, 0.23 minutes\n",
      "train - Value 0: 287 occurrences\n",
      "train - Value 1: 159 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-9   lr=['0.0002441'], tr/val_loss:  2.298662/  2.293299, val:  63.05%, val_best:  63.05%, tr:  62.33%, tr_best:  62.78%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 260 occurrences\n",
      "train - Value 1: 186 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-10  lr=['0.0002441'], tr/val_loss:  2.298858/  2.309882, val:  67.48%, val_best:  67.48%, tr:  66.14%, tr_best:  66.14%, epoch time: 13.25 seconds, 0.22 minutes\n",
      "train - Value 0: 260 occurrences\n",
      "train - Value 1: 186 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-11  lr=['0.0002441'], tr/val_loss:  2.298594/  2.293573, val:  65.71%, val_best:  67.48%, tr:  65.70%, tr_best:  66.14%, epoch time: 14.06 seconds, 0.23 minutes\n",
      "train - Value 0: 261 occurrences\n",
      "train - Value 1: 185 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-12  lr=['0.0002441'], tr/val_loss:  2.301168/  2.301413, val:  65.93%, val_best:  67.48%, tr:  66.82%, tr_best:  66.82%, epoch time: 13.43 seconds, 0.22 minutes\n",
      "train - Value 0: 244 occurrences\n",
      "train - Value 1: 202 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-13  lr=['0.0002441'], tr/val_loss:  2.302055/  2.290736, val:  61.73%, val_best:  67.48%, tr:  69.73%, tr_best:  69.73%, epoch time: 13.53 seconds, 0.23 minutes\n",
      "train - Value 0: 242 occurrences\n",
      "train - Value 1: 204 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 398 occurrences\n",
      "test - Value 1: 54 occurrences\n",
      "epoch-14  lr=['0.0002441'], tr/val_loss:  2.301965/  2.291121, val:  57.08%, val_best:  67.48%, tr:  62.56%, tr_best:  69.73%, epoch time: 13.74 seconds, 0.23 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-15  lr=['0.0002441'], tr/val_loss:  2.302086/  2.296949, val:  65.71%, val_best:  67.48%, tr:  64.57%, tr_best:  69.73%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 253 occurrences\n",
      "train - Value 1: 193 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-16  lr=['0.0002441'], tr/val_loss:  2.302942/  2.293208, val:  62.61%, val_best:  67.48%, tr:  68.16%, tr_best:  69.73%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 248 occurrences\n",
      "train - Value 1: 198 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-17  lr=['0.0002441'], tr/val_loss:  2.305930/  2.313309, val:  60.40%, val_best:  67.48%, tr:  71.52%, tr_best:  71.52%, epoch time: 13.67 seconds, 0.23 minutes\n",
      "train - Value 0: 260 occurrences\n",
      "train - Value 1: 186 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 231 occurrences\n",
      "test - Value 1: 221 occurrences\n",
      "epoch-18  lr=['0.0002441'], tr/val_loss:  2.304123/  2.307745, val:  65.71%, val_best:  67.48%, tr:  71.52%, tr_best:  71.52%, epoch time: 13.72 seconds, 0.23 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-19  lr=['0.0002441'], tr/val_loss:  2.302829/  2.294927, val:  71.46%, val_best:  71.46%, tr:  72.42%, tr_best:  72.42%, epoch time: 13.50 seconds, 0.22 minutes\n",
      "train - Value 0: 242 occurrences\n",
      "train - Value 1: 204 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-20  lr=['0.0002441'], tr/val_loss:  2.305609/  2.298024, val:  69.47%, val_best:  71.46%, tr:  76.46%, tr_best:  76.46%, epoch time: 13.66 seconds, 0.23 minutes\n",
      "train - Value 0: 236 occurrences\n",
      "train - Value 1: 210 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-21  lr=['0.0002441'], tr/val_loss:  2.303742/  2.303557, val:  68.36%, val_best:  71.46%, tr:  76.91%, tr_best:  76.91%, epoch time: 13.42 seconds, 0.22 minutes\n",
      "train - Value 0: 236 occurrences\n",
      "train - Value 1: 210 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-22  lr=['0.0002441'], tr/val_loss:  2.306266/  2.297964, val:  66.59%, val_best:  71.46%, tr:  74.22%, tr_best:  76.91%, epoch time: 13.62 seconds, 0.23 minutes\n",
      "train - Value 0: 213 occurrences\n",
      "train - Value 1: 233 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-23  lr=['0.0002441'], tr/val_loss:  2.304481/  2.302134, val:  68.36%, val_best:  71.46%, tr:  76.23%, tr_best:  76.91%, epoch time: 13.65 seconds, 0.23 minutes\n",
      "train - Value 0: 219 occurrences\n",
      "train - Value 1: 227 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-24  lr=['0.0002441'], tr/val_loss:  2.306623/  2.292941, val:  65.71%, val_best:  71.46%, tr:  73.09%, tr_best:  76.91%, epoch time: 13.69 seconds, 0.23 minutes\n",
      "train - Value 0: 212 occurrences\n",
      "train - Value 1: 234 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-25  lr=['0.0002441'], tr/val_loss:  2.304822/  2.300863, val:  73.45%, val_best:  73.45%, tr:  76.91%, tr_best:  76.91%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-26  lr=['0.0002441'], tr/val_loss:  2.305046/  2.299905, val:  69.69%, val_best:  73.45%, tr:  77.35%, tr_best:  77.35%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 348 occurrences\n",
      "test - Value 1: 104 occurrences\n",
      "epoch-27  lr=['0.0002441'], tr/val_loss:  2.306554/  2.300694, val:  63.27%, val_best:  73.45%, tr:  73.77%, tr_best:  77.35%, epoch time: 13.71 seconds, 0.23 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 304 occurrences\n",
      "test - Value 1: 148 occurrences\n",
      "epoch-28  lr=['0.0002441'], tr/val_loss:  2.306907/  2.301736, val:  74.78%, val_best:  74.78%, tr:  80.04%, tr_best:  80.04%, epoch time: 13.39 seconds, 0.22 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-29  lr=['0.0002441'], tr/val_loss:  2.305453/  2.300422, val:  68.36%, val_best:  74.78%, tr:  79.37%, tr_best:  80.04%, epoch time: 13.62 seconds, 0.23 minutes\n",
      "train - Value 0: 213 occurrences\n",
      "train - Value 1: 233 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-30  lr=['0.0002441'], tr/val_loss:  2.304122/  2.309557, val:  67.26%, val_best:  74.78%, tr:  78.92%, tr_best:  80.04%, epoch time: 13.39 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-31  lr=['0.0002441'], tr/val_loss:  2.305743/  2.302013, val:  73.67%, val_best:  74.78%, tr:  78.70%, tr_best:  80.04%, epoch time: 13.42 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-32  lr=['0.0002441'], tr/val_loss:  2.304952/  2.303829, val:  70.80%, val_best:  74.78%, tr:  79.82%, tr_best:  80.04%, epoch time: 13.86 seconds, 0.23 minutes\n",
      "train - Value 0: 212 occurrences\n",
      "train - Value 1: 234 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-33  lr=['0.0002441'], tr/val_loss:  2.304853/  2.305257, val:  66.37%, val_best:  74.78%, tr:  80.04%, tr_best:  80.04%, epoch time: 13.66 seconds, 0.23 minutes\n",
      "train - Value 0: 213 occurrences\n",
      "train - Value 1: 233 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 381 occurrences\n",
      "test - Value 1: 71 occurrences\n",
      "epoch-34  lr=['0.0002441'], tr/val_loss:  2.304171/  2.297122, val:  63.05%, val_best:  74.78%, tr:  80.27%, tr_best:  80.27%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-35  lr=['0.0002441'], tr/val_loss:  2.306173/  2.305683, val:  65.04%, val_best:  74.78%, tr:  79.82%, tr_best:  80.27%, epoch time: 13.65 seconds, 0.23 minutes\n",
      "train - Value 0: 207 occurrences\n",
      "train - Value 1: 239 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 232 occurrences\n",
      "test - Value 1: 220 occurrences\n",
      "epoch-36  lr=['0.0002441'], tr/val_loss:  2.304582/  2.305900, val:  72.57%, val_best:  74.78%, tr:  80.27%, tr_best:  80.27%, epoch time: 13.49 seconds, 0.22 minutes\n",
      "train - Value 0: 213 occurrences\n",
      "train - Value 1: 233 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-37  lr=['0.0002441'], tr/val_loss:  2.304972/  2.309185, val:  68.36%, val_best:  74.78%, tr:  78.48%, tr_best:  80.27%, epoch time: 13.52 seconds, 0.23 minutes\n",
      "train - Value 0: 216 occurrences\n",
      "train - Value 1: 230 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-38  lr=['0.0002441'], tr/val_loss:  2.305602/  2.308355, val:  55.75%, val_best:  74.78%, tr:  81.39%, tr_best:  81.39%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 200 occurrences\n",
      "train - Value 1: 246 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-39  lr=['0.0002441'], tr/val_loss:  2.307173/  2.303457, val:  65.04%, val_best:  74.78%, tr:  81.39%, tr_best:  81.39%, epoch time: 13.69 seconds, 0.23 minutes\n",
      "train - Value 0: 198 occurrences\n",
      "train - Value 1: 248 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 361 occurrences\n",
      "test - Value 1: 91 occurrences\n",
      "epoch-40  lr=['0.0002441'], tr/val_loss:  2.305549/  2.301204, val:  65.71%, val_best:  74.78%, tr:  80.49%, tr_best:  81.39%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 203 occurrences\n",
      "train - Value 1: 243 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-41  lr=['0.0002441'], tr/val_loss:  2.305595/  2.301682, val:  65.04%, val_best:  74.78%, tr:  81.61%, tr_best:  81.61%, epoch time: 13.25 seconds, 0.22 minutes\n",
      "train - Value 0: 174 occurrences\n",
      "train - Value 1: 272 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-42  lr=['0.0002441'], tr/val_loss:  2.305037/  2.307911, val:  71.46%, val_best:  74.78%, tr:  77.80%, tr_best:  81.61%, epoch time: 13.40 seconds, 0.22 minutes\n",
      "train - Value 0: 188 occurrences\n",
      "train - Value 1: 258 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 269 occurrences\n",
      "test - Value 1: 183 occurrences\n",
      "epoch-43  lr=['0.0002441'], tr/val_loss:  2.304830/  2.303942, val:  71.90%, val_best:  74.78%, tr:  80.94%, tr_best:  81.61%, epoch time: 13.22 seconds, 0.22 minutes\n",
      "train - Value 0: 197 occurrences\n",
      "train - Value 1: 249 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-44  lr=['0.0002441'], tr/val_loss:  2.304370/  2.310006, val:  58.41%, val_best:  74.78%, tr:  82.06%, tr_best:  82.06%, epoch time: 13.44 seconds, 0.22 minutes\n",
      "train - Value 0: 193 occurrences\n",
      "train - Value 1: 253 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-45  lr=['0.0002441'], tr/val_loss:  2.305011/  2.303834, val:  61.95%, val_best:  74.78%, tr:  82.06%, tr_best:  82.06%, epoch time: 13.48 seconds, 0.22 minutes\n",
      "train - Value 0: 194 occurrences\n",
      "train - Value 1: 252 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-46  lr=['0.0002441'], tr/val_loss:  2.303992/  2.303174, val:  68.81%, val_best:  74.78%, tr:  82.29%, tr_best:  82.29%, epoch time: 13.51 seconds, 0.23 minutes\n",
      "train - Value 0: 204 occurrences\n",
      "train - Value 1: 242 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-47  lr=['0.0002441'], tr/val_loss:  2.303634/  2.305516, val:  67.70%, val_best:  74.78%, tr:  83.18%, tr_best:  83.18%, epoch time: 13.48 seconds, 0.22 minutes\n",
      "train - Value 0: 198 occurrences\n",
      "train - Value 1: 248 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-48  lr=['0.0002441'], tr/val_loss:  2.303315/  2.301327, val:  70.13%, val_best:  74.78%, tr:  80.49%, tr_best:  83.18%, epoch time: 13.10 seconds, 0.22 minutes\n",
      "train - Value 0: 205 occurrences\n",
      "train - Value 1: 241 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-49  lr=['0.0002441'], tr/val_loss:  2.302818/  2.305623, val:  73.67%, val_best:  74.78%, tr:  80.72%, tr_best:  83.18%, epoch time: 12.83 seconds, 0.21 minutes\n",
      "train - Value 0: 217 occurrences\n",
      "train - Value 1: 229 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-50  lr=['0.0002441'], tr/val_loss:  2.303483/  2.301031, val:  72.35%, val_best:  74.78%, tr:  80.27%, tr_best:  83.18%, epoch time: 13.46 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-51  lr=['0.0002441'], tr/val_loss:  2.302836/  2.299149, val:  71.46%, val_best:  74.78%, tr:  84.75%, tr_best:  84.75%, epoch time: 11.79 seconds, 0.20 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-52  lr=['0.0002441'], tr/val_loss:  2.302472/  2.303282, val:  64.82%, val_best:  74.78%, tr:  83.63%, tr_best:  84.75%, epoch time: 11.76 seconds, 0.20 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-53  lr=['0.0002441'], tr/val_loss:  2.302241/  2.304139, val:  65.93%, val_best:  74.78%, tr:  85.43%, tr_best:  85.43%, epoch time: 12.16 seconds, 0.20 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-54  lr=['0.0002441'], tr/val_loss:  2.301720/  2.300957, val:  75.66%, val_best:  75.66%, tr:  85.65%, tr_best:  85.65%, epoch time: 11.82 seconds, 0.20 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 355 occurrences\n",
      "test - Value 1: 97 occurrences\n",
      "epoch-55  lr=['0.0002441'], tr/val_loss:  2.301794/  2.296907, val:  65.27%, val_best:  75.66%, tr:  84.53%, tr_best:  85.65%, epoch time: 12.01 seconds, 0.20 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-56  lr=['0.0002441'], tr/val_loss:  2.301680/  2.306338, val:  57.30%, val_best:  75.66%, tr:  87.67%, tr_best:  87.67%, epoch time: 12.01 seconds, 0.20 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-57  lr=['0.0002441'], tr/val_loss:  2.301200/  2.299603, val:  78.32%, val_best:  78.32%, tr:  88.12%, tr_best:  88.12%, epoch time: 12.07 seconds, 0.20 minutes\n",
      "train - Value 0: 248 occurrences\n",
      "train - Value 1: 198 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-58  lr=['0.0002441'], tr/val_loss:  2.301735/  2.301129, val:  72.35%, val_best:  78.32%, tr:  84.53%, tr_best:  88.12%, epoch time: 12.11 seconds, 0.20 minutes\n",
      "train - Value 0: 248 occurrences\n",
      "train - Value 1: 198 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-59  lr=['0.0002441'], tr/val_loss:  2.301506/  2.304553, val:  63.05%, val_best:  78.32%, tr:  85.87%, tr_best:  88.12%, epoch time: 11.76 seconds, 0.20 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-60  lr=['0.0002441'], tr/val_loss:  2.301772/  2.301708, val:  71.90%, val_best:  78.32%, tr:  86.55%, tr_best:  88.12%, epoch time: 11.91 seconds, 0.20 minutes\n",
      "train - Value 0: 239 occurrences\n",
      "train - Value 1: 207 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-61  lr=['0.0002441'], tr/val_loss:  2.301731/  2.302243, val:  73.45%, val_best:  78.32%, tr:  85.20%, tr_best:  88.12%, epoch time: 12.00 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-62  lr=['0.0002441'], tr/val_loss:  2.301845/  2.306698, val:  61.73%, val_best:  78.32%, tr:  88.12%, tr_best:  88.12%, epoch time: 11.46 seconds, 0.19 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 346 occurrences\n",
      "test - Value 1: 106 occurrences\n",
      "epoch-63  lr=['0.0002441'], tr/val_loss:  2.302099/  2.298393, val:  67.26%, val_best:  78.32%, tr:  88.34%, tr_best:  88.34%, epoch time: 12.23 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-64  lr=['0.0002441'], tr/val_loss:  2.302029/  2.302671, val:  76.77%, val_best:  78.32%, tr:  89.24%, tr_best:  89.24%, epoch time: 11.47 seconds, 0.19 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-65  lr=['0.0002441'], tr/val_loss:  2.302518/  2.302897, val:  70.13%, val_best:  78.32%, tr:  88.12%, tr_best:  89.24%, epoch time: 11.56 seconds, 0.19 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-66  lr=['0.0002441'], tr/val_loss:  2.301769/  2.300525, val:  79.20%, val_best:  79.20%, tr:  84.53%, tr_best:  89.24%, epoch time: 11.75 seconds, 0.20 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 427 occurrences\n",
      "test - Value 1: 25 occurrences\n",
      "epoch-67  lr=['0.0002441'], tr/val_loss:  2.301528/  2.301837, val:  54.65%, val_best:  79.20%, tr:  86.77%, tr_best:  89.24%, epoch time: 11.54 seconds, 0.19 minutes\n",
      "train - Value 0: 238 occurrences\n",
      "train - Value 1: 208 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-68  lr=['0.0002441'], tr/val_loss:  2.301913/  2.301875, val:  67.04%, val_best:  79.20%, tr:  86.77%, tr_best:  89.24%, epoch time: 11.78 seconds, 0.20 minutes\n",
      "train - Value 0: 246 occurrences\n",
      "train - Value 1: 200 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-69  lr=['0.0002441'], tr/val_loss:  2.302019/  2.301933, val:  77.88%, val_best:  79.20%, tr:  88.12%, tr_best:  89.24%, epoch time: 11.60 seconds, 0.19 minutes\n",
      "train - Value 0: 240 occurrences\n",
      "train - Value 1: 206 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 367 occurrences\n",
      "test - Value 1: 85 occurrences\n",
      "epoch-70  lr=['0.0002441'], tr/val_loss:  2.302008/  2.298525, val:  65.71%, val_best:  79.20%, tr:  88.12%, tr_best:  89.24%, epoch time: 11.45 seconds, 0.19 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-71  lr=['0.0002441'], tr/val_loss:  2.301669/  2.301640, val:  64.38%, val_best:  79.20%, tr:  88.79%, tr_best:  89.24%, epoch time: 11.92 seconds, 0.20 minutes\n",
      "train - Value 0: 247 occurrences\n",
      "train - Value 1: 199 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-72  lr=['0.0002441'], tr/val_loss:  2.301372/  2.300136, val:  74.78%, val_best:  79.20%, tr:  86.10%, tr_best:  89.24%, epoch time: 11.49 seconds, 0.19 minutes\n",
      "train - Value 0: 244 occurrences\n",
      "train - Value 1: 202 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 366 occurrences\n",
      "test - Value 1: 86 occurrences\n",
      "epoch-73  lr=['0.0002441'], tr/val_loss:  2.301732/  2.300620, val:  66.81%, val_best:  79.20%, tr:  90.36%, tr_best:  90.36%, epoch time: 11.77 seconds, 0.20 minutes\n",
      "train - Value 0: 250 occurrences\n",
      "train - Value 1: 196 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-74  lr=['0.0002441'], tr/val_loss:  2.301462/  2.303395, val:  76.77%, val_best:  79.20%, tr:  87.22%, tr_best:  90.36%, epoch time: 11.89 seconds, 0.20 minutes\n",
      "train - Value 0: 248 occurrences\n",
      "train - Value 1: 198 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-75  lr=['0.0002441'], tr/val_loss:  2.301735/  2.300241, val:  75.00%, val_best:  79.20%, tr:  88.12%, tr_best:  90.36%, epoch time: 11.70 seconds, 0.19 minutes\n",
      "train - Value 0: 245 occurrences\n",
      "train - Value 1: 201 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-76  lr=['0.0002441'], tr/val_loss:  2.301683/  2.299013, val:  69.25%, val_best:  79.20%, tr:  87.89%, tr_best:  90.36%, epoch time: 11.97 seconds, 0.20 minutes\n",
      "train - Value 0: 240 occurrences\n",
      "train - Value 1: 206 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-77  lr=['0.0002441'], tr/val_loss:  2.302356/  2.300133, val:  72.57%, val_best:  79.20%, tr:  90.36%, tr_best:  90.36%, epoch time: 12.18 seconds, 0.20 minutes\n",
      "train - Value 0: 249 occurrences\n",
      "train - Value 1: 197 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 278 occurrences\n",
      "test - Value 1: 174 occurrences\n",
      "epoch-78  lr=['0.0002441'], tr/val_loss:  2.301891/  2.303643, val:  78.32%, val_best:  79.20%, tr:  86.55%, tr_best:  90.36%, epoch time: 12.17 seconds, 0.20 minutes\n",
      "train - Value 0: 239 occurrences\n",
      "train - Value 1: 207 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-79  lr=['0.0002441'], tr/val_loss:  2.301537/  2.302771, val:  72.12%, val_best:  79.20%, tr:  91.03%, tr_best:  91.03%, epoch time: 12.11 seconds, 0.20 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-80  lr=['0.0002441'], tr/val_loss:  2.302218/  2.298627, val:  71.24%, val_best:  79.20%, tr:  88.34%, tr_best:  91.03%, epoch time: 12.07 seconds, 0.20 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-81  lr=['0.0002441'], tr/val_loss:  2.302788/  2.299098, val:  77.43%, val_best:  79.20%, tr:  90.58%, tr_best:  91.03%, epoch time: 11.99 seconds, 0.20 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-82  lr=['0.0002441'], tr/val_loss:  2.301260/  2.302704, val:  73.67%, val_best:  79.20%, tr:  90.13%, tr_best:  91.03%, epoch time: 11.93 seconds, 0.20 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-83  lr=['0.0002441'], tr/val_loss:  2.302365/  2.301951, val:  75.00%, val_best:  79.20%, tr:  92.15%, tr_best:  92.15%, epoch time: 11.76 seconds, 0.20 minutes\n",
      "train - Value 0: 235 occurrences\n",
      "train - Value 1: 211 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-84  lr=['0.0002441'], tr/val_loss:  2.302952/  2.303677, val:  63.50%, val_best:  79.20%, tr:  90.13%, tr_best:  92.15%, epoch time: 11.51 seconds, 0.19 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-85  lr=['0.0002441'], tr/val_loss:  2.303284/  2.300955, val:  77.43%, val_best:  79.20%, tr:  90.36%, tr_best:  92.15%, epoch time: 11.89 seconds, 0.20 minutes\n",
      "train - Value 0: 236 occurrences\n",
      "train - Value 1: 210 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-86  lr=['0.0002441'], tr/val_loss:  2.302672/  2.299560, val:  61.06%, val_best:  79.20%, tr:  90.81%, tr_best:  92.15%, epoch time: 11.88 seconds, 0.20 minutes\n",
      "train - Value 0: 244 occurrences\n",
      "train - Value 1: 202 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 289 occurrences\n",
      "test - Value 1: 163 occurrences\n",
      "epoch-87  lr=['0.0002441'], tr/val_loss:  2.303405/  2.298392, val:  78.10%, val_best:  79.20%, tr:  91.26%, tr_best:  92.15%, epoch time: 11.80 seconds, 0.20 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-88  lr=['0.0002441'], tr/val_loss:  2.303029/  2.300373, val:  79.20%, val_best:  79.20%, tr:  92.38%, tr_best:  92.38%, epoch time: 12.10 seconds, 0.20 minutes\n",
      "train - Value 0: 238 occurrences\n",
      "train - Value 1: 208 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-89  lr=['0.0002441'], tr/val_loss:  2.302721/  2.301857, val:  80.09%, val_best:  80.09%, tr:  92.15%, tr_best:  92.38%, epoch time: 11.67 seconds, 0.19 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 314 occurrences\n",
      "test - Value 1: 138 occurrences\n",
      "epoch-90  lr=['0.0002441'], tr/val_loss:  2.303516/  2.299956, val:  75.22%, val_best:  80.09%, tr:  92.60%, tr_best:  92.60%, epoch time: 12.06 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-91  lr=['0.0002441'], tr/val_loss:  2.303407/  2.304552, val:  73.45%, val_best:  80.09%, tr:  92.60%, tr_best:  92.60%, epoch time: 11.78 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-92  lr=['0.0002441'], tr/val_loss:  2.304017/  2.301252, val:  80.53%, val_best:  80.53%, tr:  90.36%, tr_best:  92.60%, epoch time: 11.47 seconds, 0.19 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 313 occurrences\n",
      "test - Value 1: 139 occurrences\n",
      "epoch-93  lr=['0.0002441'], tr/val_loss:  2.304316/  2.301627, val:  74.12%, val_best:  80.53%, tr:  93.05%, tr_best:  93.05%, epoch time: 12.00 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 366 occurrences\n",
      "test - Value 1: 86 occurrences\n",
      "epoch-94  lr=['0.0002441'], tr/val_loss:  2.303758/  2.301303, val:  68.58%, val_best:  80.53%, tr:  91.26%, tr_best:  93.05%, epoch time: 11.68 seconds, 0.19 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-95  lr=['0.0002441'], tr/val_loss:  2.304125/  2.300805, val:  73.89%, val_best:  80.53%, tr:  92.83%, tr_best:  93.05%, epoch time: 11.92 seconds, 0.20 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-96  lr=['0.0002441'], tr/val_loss:  2.304344/  2.302746, val:  80.97%, val_best:  80.97%, tr:  93.50%, tr_best:  93.50%, epoch time: 11.67 seconds, 0.19 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-97  lr=['0.0002441'], tr/val_loss:  2.304486/  2.304145, val:  82.74%, val_best:  82.74%, tr:  92.83%, tr_best:  93.50%, epoch time: 11.47 seconds, 0.19 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-98  lr=['0.0002441'], tr/val_loss:  2.303639/  2.303679, val:  78.98%, val_best:  82.74%, tr:  93.95%, tr_best:  93.95%, epoch time: 11.93 seconds, 0.20 minutes\n",
      "train - Value 0: 233 occurrences\n",
      "train - Value 1: 213 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-99  lr=['0.0002441'], tr/val_loss:  2.303095/  2.306102, val:  72.35%, val_best:  82.74%, tr:  91.93%, tr_best:  93.95%, epoch time: 12.47 seconds, 0.21 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-100 lr=['0.0002441'], tr/val_loss:  2.302704/  2.302372, val:  71.68%, val_best:  82.74%, tr:  95.96%, tr_best:  95.96%, epoch time: 12.16 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 296 occurrences\n",
      "test - Value 1: 156 occurrences\n",
      "epoch-101 lr=['0.0002441'], tr/val_loss:  2.302973/  2.298746, val:  78.32%, val_best:  82.74%, tr:  95.74%, tr_best:  95.96%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-102 lr=['0.0002441'], tr/val_loss:  2.302708/  2.302389, val:  80.09%, val_best:  82.74%, tr:  95.29%, tr_best:  95.96%, epoch time: 12.41 seconds, 0.21 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-103 lr=['0.0002441'], tr/val_loss:  2.304303/  2.306247, val:  61.06%, val_best:  82.74%, tr:  93.95%, tr_best:  95.96%, epoch time: 12.40 seconds, 0.21 minutes\n",
      "train - Value 0: 219 occurrences\n",
      "train - Value 1: 227 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-104 lr=['0.0002441'], tr/val_loss:  2.303483/  2.300990, val:  83.41%, val_best:  83.41%, tr:  94.17%, tr_best:  95.96%, epoch time: 12.26 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-105 lr=['0.0002441'], tr/val_loss:  2.303025/  2.301230, val:  82.08%, val_best:  83.41%, tr:  94.84%, tr_best:  95.96%, epoch time: 12.53 seconds, 0.21 minutes\n",
      "train - Value 0: 219 occurrences\n",
      "train - Value 1: 227 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-106 lr=['0.0002441'], tr/val_loss:  2.303412/  2.300622, val:  82.74%, val_best:  83.41%, tr:  94.17%, tr_best:  95.96%, epoch time: 11.85 seconds, 0.20 minutes\n",
      "train - Value 0: 217 occurrences\n",
      "train - Value 1: 229 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-107 lr=['0.0002441'], tr/val_loss:  2.304113/  2.304927, val:  67.92%, val_best:  83.41%, tr:  94.17%, tr_best:  95.96%, epoch time: 11.99 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-108 lr=['0.0002441'], tr/val_loss:  2.304045/  2.307003, val:  70.80%, val_best:  83.41%, tr:  95.52%, tr_best:  95.96%, epoch time: 12.36 seconds, 0.21 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-109 lr=['0.0002441'], tr/val_loss:  2.304014/  2.302280, val:  73.67%, val_best:  83.41%, tr:  95.52%, tr_best:  95.96%, epoch time: 12.39 seconds, 0.21 minutes\n",
      "train - Value 0: 233 occurrences\n",
      "train - Value 1: 213 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-110 lr=['0.0002441'], tr/val_loss:  2.304663/  2.305621, val:  84.73%, val_best:  84.73%, tr:  94.62%, tr_best:  95.96%, epoch time: 12.40 seconds, 0.21 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-111 lr=['0.0002441'], tr/val_loss:  2.304433/  2.304279, val:  73.67%, val_best:  84.73%, tr:  95.52%, tr_best:  95.96%, epoch time: 12.30 seconds, 0.21 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-112 lr=['0.0002441'], tr/val_loss:  2.303535/  2.304481, val:  83.19%, val_best:  84.73%, tr:  94.84%, tr_best:  95.96%, epoch time: 12.24 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-113 lr=['0.0002441'], tr/val_loss:  2.303974/  2.305570, val:  67.26%, val_best:  84.73%, tr:  95.74%, tr_best:  95.96%, epoch time: 11.96 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-114 lr=['0.0002441'], tr/val_loss:  2.303593/  2.303210, val:  81.19%, val_best:  84.73%, tr:  97.53%, tr_best:  97.53%, epoch time: 12.09 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-115 lr=['0.0002441'], tr/val_loss:  2.302907/  2.305443, val:  80.97%, val_best:  84.73%, tr:  97.09%, tr_best:  97.53%, epoch time: 12.35 seconds, 0.21 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-116 lr=['0.0002441'], tr/val_loss:  2.303440/  2.304296, val:  79.20%, val_best:  84.73%, tr:  97.53%, tr_best:  97.53%, epoch time: 12.02 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-117 lr=['0.0002441'], tr/val_loss:  2.303267/  2.304680, val:  81.64%, val_best:  84.73%, tr:  95.96%, tr_best:  97.53%, epoch time: 12.36 seconds, 0.21 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-118 lr=['0.0002441'], tr/val_loss:  2.303614/  2.304328, val:  65.93%, val_best:  84.73%, tr:  94.84%, tr_best:  97.53%, epoch time: 11.93 seconds, 0.20 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-119 lr=['0.0002441'], tr/val_loss:  2.303255/  2.304919, val:  67.92%, val_best:  84.73%, tr:  96.64%, tr_best:  97.53%, epoch time: 12.28 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 313 occurrences\n",
      "test - Value 1: 139 occurrences\n",
      "epoch-120 lr=['0.0002441'], tr/val_loss:  2.303175/  2.300503, val:  76.77%, val_best:  84.73%, tr:  96.41%, tr_best:  97.53%, epoch time: 12.30 seconds, 0.20 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 269 occurrences\n",
      "test - Value 1: 183 occurrences\n",
      "epoch-121 lr=['0.0002441'], tr/val_loss:  2.303181/  2.301452, val:  82.08%, val_best:  84.73%, tr:  96.19%, tr_best:  97.53%, epoch time: 12.61 seconds, 0.21 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 325 occurrences\n",
      "test - Value 1: 127 occurrences\n",
      "epoch-122 lr=['0.0002441'], tr/val_loss:  2.304144/  2.300915, val:  69.69%, val_best:  84.73%, tr:  96.64%, tr_best:  97.53%, epoch time: 12.17 seconds, 0.20 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-123 lr=['0.0002441'], tr/val_loss:  2.303143/  2.303147, val:  80.53%, val_best:  84.73%, tr:  94.84%, tr_best:  97.53%, epoch time: 12.24 seconds, 0.20 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-124 lr=['0.0002441'], tr/val_loss:  2.304014/  2.304084, val:  82.30%, val_best:  84.73%, tr:  94.62%, tr_best:  97.53%, epoch time: 12.34 seconds, 0.21 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-125 lr=['0.0002441'], tr/val_loss:  2.304598/  2.304563, val:  71.90%, val_best:  84.73%, tr:  94.17%, tr_best:  97.53%, epoch time: 12.28 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-126 lr=['0.0002441'], tr/val_loss:  2.303679/  2.304229, val:  80.53%, val_best:  84.73%, tr:  97.09%, tr_best:  97.53%, epoch time: 12.19 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-127 lr=['0.0002441'], tr/val_loss:  2.303822/  2.306741, val:  82.74%, val_best:  84.73%, tr:  95.74%, tr_best:  97.53%, epoch time: 12.28 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-128 lr=['0.0002441'], tr/val_loss:  2.304029/  2.303646, val:  76.99%, val_best:  84.73%, tr:  94.62%, tr_best:  97.53%, epoch time: 12.09 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-129 lr=['0.0002441'], tr/val_loss:  2.302449/  2.300851, val:  78.76%, val_best:  84.73%, tr:  94.39%, tr_best:  97.53%, epoch time: 12.05 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-130 lr=['0.0002441'], tr/val_loss:  2.302742/  2.300388, val:  73.23%, val_best:  84.73%, tr:  96.86%, tr_best:  97.53%, epoch time: 12.16 seconds, 0.20 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 308 occurrences\n",
      "test - Value 1: 144 occurrences\n",
      "epoch-131 lr=['0.0002441'], tr/val_loss:  2.302351/  2.299179, val:  78.76%, val_best:  84.73%, tr:  95.74%, tr_best:  97.53%, epoch time: 12.38 seconds, 0.21 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-132 lr=['0.0002441'], tr/val_loss:  2.302427/  2.302990, val:  82.74%, val_best:  84.73%, tr:  96.64%, tr_best:  97.53%, epoch time: 12.43 seconds, 0.21 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-133 lr=['0.0002441'], tr/val_loss:  2.302449/  2.303051, val:  80.75%, val_best:  84.73%, tr:  95.96%, tr_best:  97.53%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 233 occurrences\n",
      "train - Value 1: 213 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-134 lr=['0.0002441'], tr/val_loss:  2.302535/  2.302403, val:  72.35%, val_best:  84.73%, tr:  95.96%, tr_best:  97.53%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 287 occurrences\n",
      "test - Value 1: 165 occurrences\n",
      "epoch-135 lr=['0.0002441'], tr/val_loss:  2.301997/  2.299763, val:  80.31%, val_best:  84.73%, tr:  97.09%, tr_best:  97.53%, epoch time: 12.12 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-136 lr=['0.0002441'], tr/val_loss:  2.302276/  2.303833, val:  81.86%, val_best:  84.73%, tr:  96.64%, tr_best:  97.53%, epoch time: 12.62 seconds, 0.21 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-137 lr=['0.0002441'], tr/val_loss:  2.301569/  2.304647, val:  72.79%, val_best:  84.73%, tr:  97.09%, tr_best:  97.53%, epoch time: 12.25 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-138 lr=['0.0002441'], tr/val_loss:  2.302013/  2.301684, val:  79.42%, val_best:  84.73%, tr:  96.86%, tr_best:  97.53%, epoch time: 12.39 seconds, 0.21 minutes\n",
      "train - Value 0: 234 occurrences\n",
      "train - Value 1: 212 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-139 lr=['0.0002441'], tr/val_loss:  2.301365/  2.305577, val:  74.12%, val_best:  84.73%, tr:  96.64%, tr_best:  97.53%, epoch time: 12.28 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-140 lr=['0.0002441'], tr/val_loss:  2.302165/  2.302707, val:  84.07%, val_best:  84.73%, tr:  97.98%, tr_best:  97.98%, epoch time: 12.21 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-141 lr=['0.0002441'], tr/val_loss:  2.302363/  2.302798, val:  82.30%, val_best:  84.73%, tr:  97.53%, tr_best:  97.98%, epoch time: 12.43 seconds, 0.21 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-142 lr=['0.0002441'], tr/val_loss:  2.301242/  2.303117, val:  75.66%, val_best:  84.73%, tr:  98.21%, tr_best:  98.21%, epoch time: 12.39 seconds, 0.21 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-143 lr=['0.0002441'], tr/val_loss:  2.300971/  2.302262, val:  80.75%, val_best:  84.73%, tr:  97.76%, tr_best:  98.21%, epoch time: 12.16 seconds, 0.20 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-144 lr=['0.0002441'], tr/val_loss:  2.301914/  2.302983, val:  74.34%, val_best:  84.73%, tr:  97.31%, tr_best:  98.21%, epoch time: 12.11 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-145 lr=['0.0002441'], tr/val_loss:  2.302156/  2.300065, val:  77.21%, val_best:  84.73%, tr:  96.86%, tr_best:  98.21%, epoch time: 12.05 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-146 lr=['0.0002441'], tr/val_loss:  2.301269/  2.298881, val:  80.31%, val_best:  84.73%, tr:  95.96%, tr_best:  98.21%, epoch time: 12.27 seconds, 0.20 minutes\n",
      "train - Value 0: 233 occurrences\n",
      "train - Value 1: 213 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-147 lr=['0.0002441'], tr/val_loss:  2.300582/  2.299216, val:  78.76%, val_best:  84.73%, tr:  94.62%, tr_best:  98.21%, epoch time: 11.69 seconds, 0.19 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-148 lr=['0.0002441'], tr/val_loss:  2.300615/  2.299710, val:  83.63%, val_best:  84.73%, tr:  96.41%, tr_best:  98.21%, epoch time: 12.07 seconds, 0.20 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-149 lr=['0.0002441'], tr/val_loss:  2.300863/  2.302168, val:  78.54%, val_best:  84.73%, tr:  95.96%, tr_best:  98.21%, epoch time: 11.92 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 300 occurrences\n",
      "test - Value 1: 152 occurrences\n",
      "epoch-150 lr=['0.0002441'], tr/val_loss:  2.301115/  2.303332, val:  80.09%, val_best:  84.73%, tr:  95.52%, tr_best:  98.21%, epoch time: 11.94 seconds, 0.20 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-151 lr=['0.0002441'], tr/val_loss:  2.300808/  2.301831, val:  83.85%, val_best:  84.73%, tr:  98.21%, tr_best:  98.21%, epoch time: 11.75 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 330 occurrences\n",
      "test - Value 1: 122 occurrences\n",
      "epoch-152 lr=['0.0002441'], tr/val_loss:  2.301020/  2.300114, val:  73.45%, val_best:  84.73%, tr:  96.86%, tr_best:  98.21%, epoch time: 11.77 seconds, 0.20 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-153 lr=['0.0002441'], tr/val_loss:  2.300786/  2.299389, val:  80.09%, val_best:  84.73%, tr:  95.74%, tr_best:  98.21%, epoch time: 12.03 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-154 lr=['0.0002441'], tr/val_loss:  2.300558/  2.302593, val:  74.12%, val_best:  84.73%, tr:  97.31%, tr_best:  98.21%, epoch time: 11.99 seconds, 0.20 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-155 lr=['0.0002441'], tr/val_loss:  2.301194/  2.300568, val:  82.96%, val_best:  84.73%, tr:  96.41%, tr_best:  98.21%, epoch time: 11.76 seconds, 0.20 minutes\n",
      "train - Value 0: 233 occurrences\n",
      "train - Value 1: 213 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-156 lr=['0.0002441'], tr/val_loss:  2.300578/  2.303925, val:  65.71%, val_best:  84.73%, tr:  96.41%, tr_best:  98.21%, epoch time: 11.67 seconds, 0.19 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-157 lr=['0.0002441'], tr/val_loss:  2.300744/  2.305878, val:  58.41%, val_best:  84.73%, tr:  97.76%, tr_best:  98.21%, epoch time: 11.65 seconds, 0.19 minutes\n",
      "train - Value 0: 236 occurrences\n",
      "train - Value 1: 210 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-158 lr=['0.0002441'], tr/val_loss:  2.300432/  2.300925, val:  65.04%, val_best:  84.73%, tr:  96.19%, tr_best:  98.21%, epoch time: 11.93 seconds, 0.20 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-159 lr=['0.0002441'], tr/val_loss:  2.301254/  2.299868, val:  75.44%, val_best:  84.73%, tr:  97.31%, tr_best:  98.21%, epoch time: 12.03 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-160 lr=['0.0002441'], tr/val_loss:  2.300298/  2.301383, val:  80.31%, val_best:  84.73%, tr:  97.31%, tr_best:  98.21%, epoch time: 11.72 seconds, 0.20 minutes\n",
      "train - Value 0: 233 occurrences\n",
      "train - Value 1: 213 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-161 lr=['0.0002441'], tr/val_loss:  2.299760/  2.301940, val:  83.63%, val_best:  84.73%, tr:  97.31%, tr_best:  98.21%, epoch time: 11.78 seconds, 0.20 minutes\n",
      "train - Value 0: 235 occurrences\n",
      "train - Value 1: 211 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-162 lr=['0.0002441'], tr/val_loss:  2.299811/  2.300076, val:  80.31%, val_best:  84.73%, tr:  96.41%, tr_best:  98.21%, epoch time: 11.77 seconds, 0.20 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-163 lr=['0.0002441'], tr/val_loss:  2.300828/  2.300574, val:  80.53%, val_best:  84.73%, tr:  95.74%, tr_best:  98.21%, epoch time: 11.98 seconds, 0.20 minutes\n",
      "train - Value 0: 237 occurrences\n",
      "train - Value 1: 209 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-164 lr=['0.0002441'], tr/val_loss:  2.300190/  2.303069, val:  66.15%, val_best:  84.73%, tr:  96.41%, tr_best:  98.21%, epoch time: 11.97 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 294 occurrences\n",
      "test - Value 1: 158 occurrences\n",
      "epoch-165 lr=['0.0002441'], tr/val_loss:  2.300350/  2.301655, val:  79.20%, val_best:  84.73%, tr:  97.76%, tr_best:  98.21%, epoch time: 11.80 seconds, 0.20 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-166 lr=['0.0002441'], tr/val_loss:  2.299816/  2.298806, val:  80.97%, val_best:  84.73%, tr:  97.53%, tr_best:  98.21%, epoch time: 11.93 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-167 lr=['0.0002441'], tr/val_loss:  2.300771/  2.300697, val:  78.54%, val_best:  84.73%, tr:  98.43%, tr_best:  98.43%, epoch time: 11.89 seconds, 0.20 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-168 lr=['0.0002441'], tr/val_loss:  2.299990/  2.298356, val:  77.65%, val_best:  84.73%, tr:  97.09%, tr_best:  98.43%, epoch time: 11.79 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-169 lr=['0.0002441'], tr/val_loss:  2.299893/  2.296759, val:  81.19%, val_best:  84.73%, tr:  95.96%, tr_best:  98.43%, epoch time: 12.06 seconds, 0.20 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 296 occurrences\n",
      "test - Value 1: 156 occurrences\n",
      "epoch-170 lr=['0.0002441'], tr/val_loss:  2.300677/  2.298681, val:  80.53%, val_best:  84.73%, tr:  98.43%, tr_best:  98.43%, epoch time: 12.05 seconds, 0.20 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-171 lr=['0.0002441'], tr/val_loss:  2.300441/  2.300908, val:  85.40%, val_best:  85.40%, tr:  95.29%, tr_best:  98.43%, epoch time: 11.87 seconds, 0.20 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-172 lr=['0.0002441'], tr/val_loss:  2.299977/  2.303084, val:  66.15%, val_best:  85.40%, tr:  97.53%, tr_best:  98.43%, epoch time: 11.90 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-173 lr=['0.0002441'], tr/val_loss:  2.300959/  2.301190, val:  76.11%, val_best:  85.40%, tr:  97.31%, tr_best:  98.43%, epoch time: 11.62 seconds, 0.19 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-174 lr=['0.0002441'], tr/val_loss:  2.300918/  2.304653, val:  75.00%, val_best:  85.40%, tr:  97.53%, tr_best:  98.43%, epoch time: 11.98 seconds, 0.20 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-175 lr=['0.0002441'], tr/val_loss:  2.300475/  2.304386, val:  81.64%, val_best:  85.40%, tr:  98.21%, tr_best:  98.43%, epoch time: 11.90 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-176 lr=['0.0002441'], tr/val_loss:  2.300480/  2.298559, val:  82.96%, val_best:  85.40%, tr:  96.19%, tr_best:  98.43%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 300 occurrences\n",
      "test - Value 1: 152 occurrences\n",
      "epoch-177 lr=['0.0002441'], tr/val_loss:  2.300646/  2.298019, val:  73.89%, val_best:  85.40%, tr:  94.62%, tr_best:  98.43%, epoch time: 11.94 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-178 lr=['0.0002441'], tr/val_loss:  2.299864/  2.301956, val:  79.87%, val_best:  85.40%, tr:  95.74%, tr_best:  98.43%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-179 lr=['0.0002441'], tr/val_loss:  2.299665/  2.304437, val:  65.49%, val_best:  85.40%, tr:  96.64%, tr_best:  98.43%, epoch time: 11.63 seconds, 0.19 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-180 lr=['0.0002441'], tr/val_loss:  2.299007/  2.297766, val:  76.99%, val_best:  85.40%, tr:  96.86%, tr_best:  98.43%, epoch time: 12.01 seconds, 0.20 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-181 lr=['0.0002441'], tr/val_loss:  2.299603/  2.303778, val:  79.87%, val_best:  85.40%, tr:  97.09%, tr_best:  98.43%, epoch time: 12.17 seconds, 0.20 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-182 lr=['0.0002441'], tr/val_loss:  2.298748/  2.300904, val:  79.87%, val_best:  85.40%, tr:  96.19%, tr_best:  98.43%, epoch time: 12.14 seconds, 0.20 minutes\n",
      "train - Value 0: 217 occurrences\n",
      "train - Value 1: 229 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-183 lr=['0.0002441'], tr/val_loss:  2.298849/  2.303206, val:  75.22%, val_best:  85.40%, tr:  97.76%, tr_best:  98.43%, epoch time: 11.95 seconds, 0.20 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-184 lr=['0.0002441'], tr/val_loss:  2.298488/  2.303221, val:  70.80%, val_best:  85.40%, tr:  96.86%, tr_best:  98.43%, epoch time: 11.97 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-185 lr=['0.0002441'], tr/val_loss:  2.299478/  2.303026, val:  84.73%, val_best:  85.40%, tr:  96.64%, tr_best:  98.43%, epoch time: 12.03 seconds, 0.20 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-186 lr=['0.0002441'], tr/val_loss:  2.299122/  2.295049, val:  71.90%, val_best:  85.40%, tr:  98.21%, tr_best:  98.43%, epoch time: 11.77 seconds, 0.20 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-187 lr=['0.0002441'], tr/val_loss:  2.298857/  2.304561, val:  73.67%, val_best:  85.40%, tr:  97.76%, tr_best:  98.43%, epoch time: 12.05 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-188 lr=['0.0002441'], tr/val_loss:  2.299437/  2.302455, val:  81.86%, val_best:  85.40%, tr:  99.10%, tr_best:  99.10%, epoch time: 12.18 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-189 lr=['0.0002441'], tr/val_loss:  2.299812/  2.299205, val:  81.64%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 12.12 seconds, 0.20 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-190 lr=['0.0002441'], tr/val_loss:  2.299387/  2.300735, val:  78.54%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 11.87 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-191 lr=['0.0002441'], tr/val_loss:  2.299262/  2.302616, val:  84.51%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 11.89 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 308 occurrences\n",
      "test - Value 1: 144 occurrences\n",
      "epoch-192 lr=['0.0002441'], tr/val_loss:  2.299911/  2.302603, val:  77.43%, val_best:  85.40%, tr:  99.10%, tr_best:  99.10%, epoch time: 11.91 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-193 lr=['0.0002441'], tr/val_loss:  2.300048/  2.299578, val:  76.11%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 12.01 seconds, 0.20 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-194 lr=['0.0002441'], tr/val_loss:  2.300883/  2.301075, val:  81.19%, val_best:  85.40%, tr:  97.09%, tr_best:  99.10%, epoch time: 12.10 seconds, 0.20 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-195 lr=['0.0002441'], tr/val_loss:  2.301116/  2.303568, val:  76.11%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 12.03 seconds, 0.20 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-196 lr=['0.0002441'], tr/val_loss:  2.299716/  2.300306, val:  80.53%, val_best:  85.40%, tr:  98.21%, tr_best:  99.10%, epoch time: 12.03 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-197 lr=['0.0002441'], tr/val_loss:  2.300182/  2.304215, val:  69.25%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 11.95 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-198 lr=['0.0002441'], tr/val_loss:  2.300898/  2.303927, val:  84.96%, val_best:  85.40%, tr:  97.53%, tr_best:  99.10%, epoch time: 11.75 seconds, 0.20 minutes\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-199 lr=['0.0002441'], tr/val_loss:  2.300351/  2.304821, val:  79.65%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 12.80 seconds, 0.21 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-200 lr=['0.0002441'], tr/val_loss:  2.300815/  2.298063, val:  66.59%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 12.88 seconds, 0.21 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-201 lr=['0.0002441'], tr/val_loss:  2.299855/  2.298211, val:  83.85%, val_best:  85.40%, tr:  97.53%, tr_best:  99.10%, epoch time: 12.92 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-202 lr=['0.0002441'], tr/val_loss:  2.300991/  2.303262, val:  75.00%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 13.04 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-203 lr=['0.0002441'], tr/val_loss:  2.300954/  2.300490, val:  79.20%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 13.16 seconds, 0.22 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-204 lr=['0.0002441'], tr/val_loss:  2.301173/  2.302720, val:  82.96%, val_best:  85.40%, tr:  97.31%, tr_best:  99.10%, epoch time: 13.14 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-205 lr=['0.0002441'], tr/val_loss:  2.302026/  2.300765, val:  81.19%, val_best:  85.40%, tr:  98.21%, tr_best:  99.10%, epoch time: 13.03 seconds, 0.22 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 302 occurrences\n",
      "test - Value 1: 150 occurrences\n",
      "epoch-206 lr=['0.0002441'], tr/val_loss:  2.301185/  2.296904, val:  78.76%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 13.02 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-207 lr=['0.0002441'], tr/val_loss:  2.301494/  2.296368, val:  81.42%, val_best:  85.40%, tr:  98.21%, tr_best:  99.10%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-208 lr=['0.0002441'], tr/val_loss:  2.301352/  2.305701, val:  78.98%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 13.17 seconds, 0.22 minutes\n",
      "train - Value 0: 229 occurrences\n",
      "train - Value 1: 217 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-209 lr=['0.0002441'], tr/val_loss:  2.301757/  2.306016, val:  73.67%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 13.05 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-210 lr=['0.0002441'], tr/val_loss:  2.301828/  2.299889, val:  83.63%, val_best:  85.40%, tr:  97.98%, tr_best:  99.10%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-211 lr=['0.0002441'], tr/val_loss:  2.302727/  2.305384, val:  77.65%, val_best:  85.40%, tr:  97.76%, tr_best:  99.10%, epoch time: 13.01 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-212 lr=['0.0002441'], tr/val_loss:  2.301328/  2.301584, val:  85.18%, val_best:  85.40%, tr:  97.98%, tr_best:  99.10%, epoch time: 13.08 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-213 lr=['0.0002441'], tr/val_loss:  2.301191/  2.299623, val:  82.74%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 13.09 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-214 lr=['0.0002441'], tr/val_loss:  2.301133/  2.305733, val:  77.43%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 13.16 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-215 lr=['0.0002441'], tr/val_loss:  2.301825/  2.305180, val:  78.10%, val_best:  85.40%, tr:  97.76%, tr_best:  99.10%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-216 lr=['0.0002441'], tr/val_loss:  2.303039/  2.305204, val:  82.96%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 13.03 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-217 lr=['0.0002441'], tr/val_loss:  2.302820/  2.301630, val:  82.30%, val_best:  85.40%, tr:  97.98%, tr_best:  99.10%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-218 lr=['0.0002441'], tr/val_loss:  2.301929/  2.301574, val:  81.19%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 13.00 seconds, 0.22 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-219 lr=['0.0002441'], tr/val_loss:  2.302269/  2.305583, val:  75.66%, val_best:  85.40%, tr:  98.43%, tr_best:  99.10%, epoch time: 13.01 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-220 lr=['0.0002441'], tr/val_loss:  2.301700/  2.306928, val:  78.10%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 12.97 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 258 occurrences\n",
      "test - Value 1: 194 occurrences\n",
      "epoch-221 lr=['0.0002441'], tr/val_loss:  2.302060/  2.297557, val:  81.42%, val_best:  85.40%, tr:  98.21%, tr_best:  99.10%, epoch time: 13.07 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-222 lr=['0.0002441'], tr/val_loss:  2.301719/  2.306168, val:  78.54%, val_best:  85.40%, tr:  97.98%, tr_best:  99.10%, epoch time: 13.42 seconds, 0.22 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 332 occurrences\n",
      "test - Value 1: 120 occurrences\n",
      "epoch-223 lr=['0.0002441'], tr/val_loss:  2.301247/  2.300390, val:  73.45%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 13.13 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-224 lr=['0.0002441'], tr/val_loss:  2.301117/  2.303561, val:  71.90%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 13.20 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 306 occurrences\n",
      "test - Value 1: 146 occurrences\n",
      "epoch-225 lr=['0.0002441'], tr/val_loss:  2.301785/  2.301645, val:  76.99%, val_best:  85.40%, tr:  98.65%, tr_best:  99.10%, epoch time: 13.25 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-226 lr=['0.0002441'], tr/val_loss:  2.302185/  2.301603, val:  82.30%, val_best:  85.40%, tr:  99.10%, tr_best:  99.10%, epoch time: 13.11 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-227 lr=['0.0002441'], tr/val_loss:  2.301643/  2.308170, val:  71.90%, val_best:  85.40%, tr:  97.53%, tr_best:  99.10%, epoch time: 13.17 seconds, 0.22 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 28 occurrences\n",
      "test - Value 1: 424 occurrences\n",
      "epoch-228 lr=['0.0002441'], tr/val_loss:  2.301724/  2.305921, val:  55.31%, val_best:  85.40%, tr:  98.88%, tr_best:  99.10%, epoch time: 12.82 seconds, 0.21 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-229 lr=['0.0002441'], tr/val_loss:  2.302214/  2.303527, val:  75.22%, val_best:  85.40%, tr:  99.10%, tr_best:  99.10%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-230 lr=['0.0002441'], tr/val_loss:  2.301378/  2.300490, val:  85.62%, val_best:  85.62%, tr:  98.65%, tr_best:  99.10%, epoch time: 12.87 seconds, 0.21 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-231 lr=['0.0002441'], tr/val_loss:  2.301373/  2.303977, val:  83.85%, val_best:  85.62%, tr:  99.10%, tr_best:  99.10%, epoch time: 13.28 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-232 lr=['0.0002441'], tr/val_loss:  2.301216/  2.296294, val:  77.88%, val_best:  85.62%, tr:  98.88%, tr_best:  99.10%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-233 lr=['0.0002441'], tr/val_loss:  2.301533/  2.300462, val:  82.52%, val_best:  85.62%, tr:  98.65%, tr_best:  99.10%, epoch time: 13.16 seconds, 0.22 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-234 lr=['0.0002441'], tr/val_loss:  2.302639/  2.311454, val:  63.27%, val_best:  85.62%, tr:  99.10%, tr_best:  99.10%, epoch time: 12.85 seconds, 0.21 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-235 lr=['0.0002441'], tr/val_loss:  2.301911/  2.304379, val:  84.29%, val_best:  85.62%, tr:  99.55%, tr_best:  99.55%, epoch time: 13.40 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-236 lr=['0.0002441'], tr/val_loss:  2.302505/  2.304037, val:  79.42%, val_best:  85.62%, tr:  99.10%, tr_best:  99.55%, epoch time: 13.11 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-237 lr=['0.0002441'], tr/val_loss:  2.302346/  2.308113, val:  67.04%, val_best:  85.62%, tr:  99.33%, tr_best:  99.55%, epoch time: 13.22 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-238 lr=['0.0002441'], tr/val_loss:  2.302227/  2.303824, val:  83.41%, val_best:  85.62%, tr:  99.10%, tr_best:  99.55%, epoch time: 13.37 seconds, 0.22 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-239 lr=['0.0002441'], tr/val_loss:  2.303046/  2.301034, val:  83.41%, val_best:  85.62%, tr:  98.88%, tr_best:  99.55%, epoch time: 13.17 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-240 lr=['0.0002441'], tr/val_loss:  2.301883/  2.302933, val:  68.14%, val_best:  85.62%, tr:  98.21%, tr_best:  99.55%, epoch time: 13.47 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-241 lr=['0.0002441'], tr/val_loss:  2.301453/  2.304542, val:  84.07%, val_best:  85.62%, tr:  98.65%, tr_best:  99.55%, epoch time: 13.27 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-242 lr=['0.0002441'], tr/val_loss:  2.302045/  2.303216, val:  83.63%, val_best:  85.62%, tr:  98.88%, tr_best:  99.55%, epoch time: 13.29 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-243 lr=['0.0002441'], tr/val_loss:  2.301811/  2.302591, val:  82.08%, val_best:  85.62%, tr:  99.33%, tr_best:  99.55%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-244 lr=['0.0002441'], tr/val_loss:  2.301979/  2.303003, val:  83.85%, val_best:  85.62%, tr:  99.55%, tr_best:  99.55%, epoch time: 13.08 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-245 lr=['0.0002441'], tr/val_loss:  2.301582/  2.303858, val:  85.40%, val_best:  85.62%, tr:  99.33%, tr_best:  99.55%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-246 lr=['0.0002441'], tr/val_loss:  2.301830/  2.306052, val:  71.02%, val_best:  85.62%, tr:  98.88%, tr_best:  99.55%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 258 occurrences\n",
      "test - Value 1: 194 occurrences\n",
      "epoch-247 lr=['0.0002441'], tr/val_loss:  2.302670/  2.300268, val:  82.30%, val_best:  85.62%, tr:  98.43%, tr_best:  99.55%, epoch time: 13.42 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-248 lr=['0.0002441'], tr/val_loss:  2.302412/  2.304597, val:  77.21%, val_best:  85.62%, tr:  98.88%, tr_best:  99.55%, epoch time: 13.22 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-249 lr=['0.0002441'], tr/val_loss:  2.302280/  2.304301, val:  80.53%, val_best:  85.62%, tr:  99.33%, tr_best:  99.55%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-250 lr=['0.0002441'], tr/val_loss:  2.302437/  2.297336, val:  79.87%, val_best:  85.62%, tr:  99.33%, tr_best:  99.55%, epoch time: 13.64 seconds, 0.23 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-251 lr=['0.0002441'], tr/val_loss:  2.302709/  2.301165, val:  80.53%, val_best:  85.62%, tr:  99.10%, tr_best:  99.55%, epoch time: 13.45 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-252 lr=['0.0002441'], tr/val_loss:  2.302444/  2.299690, val:  81.42%, val_best:  85.62%, tr:  99.78%, tr_best:  99.78%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-253 lr=['0.0002441'], tr/val_loss:  2.302802/  2.303149, val:  83.19%, val_best:  85.62%, tr:  99.55%, tr_best:  99.78%, epoch time: 13.18 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-254 lr=['0.0002441'], tr/val_loss:  2.302091/  2.299723, val:  84.73%, val_best:  85.62%, tr:  99.55%, tr_best:  99.78%, epoch time: 13.08 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-255 lr=['0.0002441'], tr/val_loss:  2.303319/  2.304801, val:  83.85%, val_best:  85.62%, tr:  99.33%, tr_best:  99.78%, epoch time: 13.17 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-256 lr=['0.0002441'], tr/val_loss:  2.303203/  2.300131, val:  85.40%, val_best:  85.62%, tr:  99.33%, tr_best:  99.78%, epoch time: 13.05 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-257 lr=['0.0002441'], tr/val_loss:  2.302764/  2.302523, val:  79.42%, val_best:  85.62%, tr:  99.33%, tr_best:  99.78%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-258 lr=['0.0002441'], tr/val_loss:  2.302397/  2.300117, val:  84.96%, val_best:  85.62%, tr:  99.33%, tr_best:  99.78%, epoch time: 13.33 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-259 lr=['0.0002441'], tr/val_loss:  2.302827/  2.302508, val:  84.96%, val_best:  85.62%, tr:  98.43%, tr_best:  99.78%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-260 lr=['0.0002441'], tr/val_loss:  2.302773/  2.304931, val:  67.04%, val_best:  85.62%, tr:  99.10%, tr_best:  99.78%, epoch time: 13.47 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-261 lr=['0.0002441'], tr/val_loss:  2.302258/  2.301753, val:  84.96%, val_best:  85.62%, tr:  98.88%, tr_best:  99.78%, epoch time: 13.21 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-262 lr=['0.0002441'], tr/val_loss:  2.301604/  2.304297, val:  70.58%, val_best:  85.62%, tr:  98.43%, tr_best:  99.78%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-263 lr=['0.0002441'], tr/val_loss:  2.302643/  2.303419, val:  78.76%, val_best:  85.62%, tr:  98.43%, tr_best:  99.78%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-264 lr=['0.0002441'], tr/val_loss:  2.302296/  2.299884, val:  81.86%, val_best:  85.62%, tr:  98.65%, tr_best:  99.78%, epoch time: 13.50 seconds, 0.23 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-265 lr=['0.0002441'], tr/val_loss:  2.301817/  2.303007, val:  84.96%, val_best:  85.62%, tr:  99.33%, tr_best:  99.78%, epoch time: 13.18 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-266 lr=['0.0002441'], tr/val_loss:  2.302568/  2.301463, val:  84.29%, val_best:  85.62%, tr:  98.65%, tr_best:  99.78%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-267 lr=['0.0002441'], tr/val_loss:  2.302133/  2.302507, val:  81.64%, val_best:  85.62%, tr:  98.65%, tr_best:  99.78%, epoch time: 13.16 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-268 lr=['0.0002441'], tr/val_loss:  2.302644/  2.301900, val:  83.19%, val_best:  85.62%, tr:  99.78%, tr_best:  99.78%, epoch time: 13.35 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 271 occurrences\n",
      "test - Value 1: 181 occurrences\n",
      "epoch-269 lr=['0.0002441'], tr/val_loss:  2.302330/  2.300857, val:  81.64%, val_best:  85.62%, tr:  99.55%, tr_best:  99.78%, epoch time: 13.53 seconds, 0.23 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-270 lr=['0.0002441'], tr/val_loss:  2.302786/  2.301348, val:  84.07%, val_best:  85.62%, tr:  99.10%, tr_best:  99.78%, epoch time: 13.15 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-271 lr=['0.0002441'], tr/val_loss:  2.303188/  2.306079, val:  74.78%, val_best:  85.62%, tr:  99.10%, tr_best:  99.78%, epoch time: 13.16 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-272 lr=['0.0002441'], tr/val_loss:  2.302266/  2.303607, val:  83.19%, val_best:  85.62%, tr:  99.78%, tr_best:  99.78%, epoch time: 13.06 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-273 lr=['0.0002441'], tr/val_loss:  2.302777/  2.306660, val:  83.63%, val_best:  85.62%, tr:  99.78%, tr_best:  99.78%, epoch time: 13.47 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-274 lr=['0.0002441'], tr/val_loss:  2.303251/  2.301999, val:  83.19%, val_best:  85.62%, tr:  99.10%, tr_best:  99.78%, epoch time: 13.17 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-275 lr=['0.0002441'], tr/val_loss:  2.301576/  2.299630, val:  85.40%, val_best:  85.62%, tr:  99.10%, tr_best:  99.78%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-276 lr=['0.0002441'], tr/val_loss:  2.302310/  2.304540, val:  81.86%, val_best:  85.62%, tr:  99.33%, tr_best:  99.78%, epoch time: 13.17 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-277 lr=['0.0002441'], tr/val_loss:  2.302771/  2.301832, val:  85.18%, val_best:  85.62%, tr:  98.65%, tr_best:  99.78%, epoch time: 13.13 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-278 lr=['0.0002441'], tr/val_loss:  2.301517/  2.301579, val:  82.96%, val_best:  85.62%, tr:  99.55%, tr_best:  99.78%, epoch time: 13.08 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-279 lr=['0.0002441'], tr/val_loss:  2.302894/  2.300329, val:  84.73%, val_best:  85.62%, tr:  99.10%, tr_best:  99.78%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 292 occurrences\n",
      "test - Value 1: 160 occurrences\n",
      "epoch-280 lr=['0.0002441'], tr/val_loss:  2.302068/  2.296588, val:  80.97%, val_best:  85.62%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.44 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-281 lr=['0.0002441'], tr/val_loss:  2.302402/  2.304687, val:  73.67%, val_best:  85.62%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 281 occurrences\n",
      "test - Value 1: 171 occurrences\n",
      "epoch-282 lr=['0.0002441'], tr/val_loss:  2.302719/  2.301334, val:  81.19%, val_best:  85.62%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.25 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-283 lr=['0.0002441'], tr/val_loss:  2.303252/  2.302491, val:  85.84%, val_best:  85.84%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.22 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-284 lr=['0.0002441'], tr/val_loss:  2.302146/  2.300515, val:  83.85%, val_best:  85.84%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-285 lr=['0.0002441'], tr/val_loss:  2.302730/  2.303262, val:  70.80%, val_best:  85.84%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 311 occurrences\n",
      "test - Value 1: 141 occurrences\n",
      "epoch-286 lr=['0.0002441'], tr/val_loss:  2.302998/  2.302499, val:  78.54%, val_best:  85.84%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-287 lr=['0.0002441'], tr/val_loss:  2.302955/  2.302808, val:  82.74%, val_best:  85.84%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.28 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-288 lr=['0.0002441'], tr/val_loss:  2.302701/  2.302927, val:  80.31%, val_best:  85.84%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.15 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-289 lr=['0.0002441'], tr/val_loss:  2.302856/  2.301564, val:  84.07%, val_best:  85.84%, tr:  98.65%, tr_best: 100.00%, epoch time: 13.39 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-290 lr=['0.0002441'], tr/val_loss:  2.302546/  2.301425, val:  81.86%, val_best:  85.84%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.40 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-291 lr=['0.0002441'], tr/val_loss:  2.302472/  2.301096, val:  82.96%, val_best:  85.84%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.35 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-292 lr=['0.0002441'], tr/val_loss:  2.303366/  2.304420, val:  85.18%, val_best:  85.84%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.38 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 307 occurrences\n",
      "test - Value 1: 145 occurrences\n",
      "epoch-293 lr=['0.0002441'], tr/val_loss:  2.302784/  2.298524, val:  77.65%, val_best:  85.84%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-294 lr=['0.0002441'], tr/val_loss:  2.302474/  2.303281, val:  86.06%, val_best:  86.06%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.27 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-295 lr=['0.0002441'], tr/val_loss:  2.303784/  2.304146, val:  86.95%, val_best:  86.95%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-296 lr=['0.0002441'], tr/val_loss:  2.302676/  2.304118, val:  72.79%, val_best:  86.95%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.11 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-297 lr=['0.0002441'], tr/val_loss:  2.303658/  2.301340, val:  85.18%, val_best:  86.95%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.38 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-298 lr=['0.0002441'], tr/val_loss:  2.303422/  2.304067, val:  82.96%, val_best:  86.95%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.28 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-299 lr=['0.0002441'], tr/val_loss:  2.303074/  2.301901, val:  81.19%, val_best:  86.95%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.21 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-300 lr=['0.0002441'], tr/val_loss:  2.302044/  2.305180, val:  75.22%, val_best:  86.95%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-301 lr=['0.0002441'], tr/val_loss:  2.302482/  2.301858, val:  74.34%, val_best:  86.95%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-302 lr=['0.0002441'], tr/val_loss:  2.301469/  2.304014, val:  82.74%, val_best:  86.95%, tr:  98.43%, tr_best: 100.00%, epoch time: 13.48 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-303 lr=['0.0002441'], tr/val_loss:  2.302715/  2.304541, val:  83.63%, val_best:  86.95%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.42 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 335 occurrences\n",
      "test - Value 1: 117 occurrences\n",
      "epoch-304 lr=['0.0002441'], tr/val_loss:  2.303387/  2.297959, val:  73.67%, val_best:  86.95%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-305 lr=['0.0002441'], tr/val_loss:  2.302964/  2.302757, val:  87.17%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.33 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-306 lr=['0.0002441'], tr/val_loss:  2.302449/  2.302100, val:  83.63%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.28 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-307 lr=['0.0002441'], tr/val_loss:  2.302836/  2.301226, val:  82.52%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 292 occurrences\n",
      "test - Value 1: 160 occurrences\n",
      "epoch-308 lr=['0.0002441'], tr/val_loss:  2.303351/  2.303105, val:  80.53%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-309 lr=['0.0002441'], tr/val_loss:  2.302375/  2.306613, val:  82.52%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-310 lr=['0.0002441'], tr/val_loss:  2.302280/  2.306159, val:  83.19%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.50 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-311 lr=['0.0002441'], tr/val_loss:  2.302315/  2.301235, val:  85.40%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-312 lr=['0.0002441'], tr/val_loss:  2.302156/  2.302468, val:  82.08%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-313 lr=['0.0002441'], tr/val_loss:  2.302670/  2.305808, val:  76.33%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.06 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-314 lr=['0.0002441'], tr/val_loss:  2.302829/  2.301244, val:  83.41%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.15 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-315 lr=['0.0002441'], tr/val_loss:  2.303053/  2.303152, val:  76.33%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-316 lr=['0.0002441'], tr/val_loss:  2.302502/  2.306643, val:  83.41%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-317 lr=['0.0002441'], tr/val_loss:  2.302402/  2.303850, val:  79.65%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.18 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-318 lr=['0.0002441'], tr/val_loss:  2.302334/  2.305018, val:  76.33%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.27 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-319 lr=['0.0002441'], tr/val_loss:  2.303259/  2.306245, val:  71.02%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.04 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-320 lr=['0.0002441'], tr/val_loss:  2.302692/  2.305661, val:  77.88%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.27 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-321 lr=['0.0002441'], tr/val_loss:  2.301089/  2.302499, val:  81.19%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.29 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-322 lr=['0.0002441'], tr/val_loss:  2.301332/  2.304649, val:  82.52%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.36 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-323 lr=['0.0002441'], tr/val_loss:  2.301965/  2.304235, val:  78.98%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-324 lr=['0.0002441'], tr/val_loss:  2.301859/  2.305941, val:  75.22%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 308 occurrences\n",
      "test - Value 1: 144 occurrences\n",
      "epoch-325 lr=['0.0002441'], tr/val_loss:  2.303288/  2.301414, val:  78.32%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.53 seconds, 0.23 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 258 occurrences\n",
      "test - Value 1: 194 occurrences\n",
      "epoch-326 lr=['0.0002441'], tr/val_loss:  2.301813/  2.302684, val:  84.51%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-327 lr=['0.0002441'], tr/val_loss:  2.301155/  2.301084, val:  84.73%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-328 lr=['0.0002441'], tr/val_loss:  2.302123/  2.301633, val:  82.30%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.40 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-329 lr=['0.0002441'], tr/val_loss:  2.302321/  2.300400, val:  83.63%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-330 lr=['0.0002441'], tr/val_loss:  2.301912/  2.306583, val:  82.52%, val_best:  87.17%, tr:  98.88%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-331 lr=['0.0002441'], tr/val_loss:  2.301615/  2.298122, val:  82.30%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.35 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-332 lr=['0.0002441'], tr/val_loss:  2.302361/  2.303179, val:  78.98%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-333 lr=['0.0002441'], tr/val_loss:  2.302264/  2.303433, val:  77.43%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 219 occurrences\n",
      "train - Value 1: 227 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-334 lr=['0.0002441'], tr/val_loss:  2.301723/  2.300827, val:  82.08%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.28 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-335 lr=['0.0002441'], tr/val_loss:  2.302575/  2.302075, val:  78.76%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-336 lr=['0.0002441'], tr/val_loss:  2.303195/  2.303214, val:  81.64%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.20 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 232 occurrences\n",
      "test - Value 1: 220 occurrences\n",
      "epoch-337 lr=['0.0002441'], tr/val_loss:  2.302984/  2.303299, val:  83.19%, val_best:  87.17%, tr:  98.88%, tr_best: 100.00%, epoch time: 13.33 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-338 lr=['0.0002441'], tr/val_loss:  2.302941/  2.301667, val:  81.19%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.39 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-339 lr=['0.0002441'], tr/val_loss:  2.302741/  2.302304, val:  83.63%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-340 lr=['0.0002441'], tr/val_loss:  2.302393/  2.305378, val:  78.10%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.46 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-341 lr=['0.0002441'], tr/val_loss:  2.302109/  2.302520, val:  76.99%, val_best:  87.17%, tr:  98.88%, tr_best: 100.00%, epoch time: 13.47 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-342 lr=['0.0002441'], tr/val_loss:  2.302483/  2.305031, val:  80.31%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.73 seconds, 0.23 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-343 lr=['0.0002441'], tr/val_loss:  2.302436/  2.299967, val:  82.52%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.15 seconds, 0.22 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-344 lr=['0.0002441'], tr/val_loss:  2.301771/  2.302604, val:  81.64%, val_best:  87.17%, tr:  98.88%, tr_best: 100.00%, epoch time: 13.46 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-345 lr=['0.0002441'], tr/val_loss:  2.302621/  2.305638, val:  81.86%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.56 seconds, 0.23 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-346 lr=['0.0002441'], tr/val_loss:  2.302270/  2.306529, val:  81.42%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.43 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-347 lr=['0.0002441'], tr/val_loss:  2.302346/  2.301347, val:  83.19%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.39 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-348 lr=['0.0002441'], tr/val_loss:  2.302850/  2.299889, val:  83.63%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-349 lr=['0.0002441'], tr/val_loss:  2.303154/  2.302997, val:  82.30%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-350 lr=['0.0002441'], tr/val_loss:  2.303199/  2.297878, val:  84.07%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.45 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 249 occurrences\n",
      "test - Value 1: 203 occurrences\n",
      "epoch-351 lr=['0.0002441'], tr/val_loss:  2.302673/  2.302588, val:  83.85%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.27 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-352 lr=['0.0002441'], tr/val_loss:  2.302019/  2.304451, val:  81.19%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.35 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-353 lr=['0.0002441'], tr/val_loss:  2.301640/  2.303268, val:  84.73%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-354 lr=['0.0002441'], tr/val_loss:  2.303161/  2.303208, val:  82.96%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.37 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-355 lr=['0.0002441'], tr/val_loss:  2.302818/  2.303676, val:  80.97%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-356 lr=['0.0002441'], tr/val_loss:  2.303071/  2.301692, val:  86.06%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-357 lr=['0.0002441'], tr/val_loss:  2.302321/  2.305937, val:  84.73%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.43 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 262 occurrences\n",
      "test - Value 1: 190 occurrences\n",
      "epoch-358 lr=['0.0002441'], tr/val_loss:  2.302413/  2.303563, val:  83.19%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-359 lr=['0.0002441'], tr/val_loss:  2.302939/  2.304548, val:  82.52%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.21 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-360 lr=['0.0002441'], tr/val_loss:  2.303722/  2.308024, val:  84.07%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-361 lr=['0.0002441'], tr/val_loss:  2.303853/  2.302829, val:  82.30%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.14 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-362 lr=['0.0002441'], tr/val_loss:  2.304960/  2.304323, val:  82.96%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-363 lr=['0.0002441'], tr/val_loss:  2.303107/  2.298887, val:  81.86%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-364 lr=['0.0002441'], tr/val_loss:  2.302251/  2.303255, val:  84.07%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-365 lr=['0.0002441'], tr/val_loss:  2.303266/  2.305588, val:  81.19%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.24 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-366 lr=['0.0002441'], tr/val_loss:  2.302447/  2.301793, val:  82.30%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.28 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-367 lr=['0.0002441'], tr/val_loss:  2.302314/  2.303453, val:  76.55%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.18 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-368 lr=['0.0002441'], tr/val_loss:  2.302385/  2.300131, val:  83.63%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.21 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-369 lr=['0.0002441'], tr/val_loss:  2.301528/  2.300756, val:  85.18%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 249 occurrences\n",
      "test - Value 1: 203 occurrences\n",
      "epoch-370 lr=['0.0002441'], tr/val_loss:  2.300592/  2.302816, val:  82.96%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-371 lr=['0.0002441'], tr/val_loss:  2.301146/  2.302144, val:  82.52%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.66 seconds, 0.23 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-372 lr=['0.0002441'], tr/val_loss:  2.303205/  2.295500, val:  79.20%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.35 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-373 lr=['0.0002441'], tr/val_loss:  2.302331/  2.303441, val:  77.43%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.14 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-374 lr=['0.0002441'], tr/val_loss:  2.302505/  2.300402, val:  83.19%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.07 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-375 lr=['0.0002441'], tr/val_loss:  2.302053/  2.308282, val:  78.10%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.36 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-376 lr=['0.0002441'], tr/val_loss:  2.303963/  2.300757, val:  84.51%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.25 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-377 lr=['0.0002441'], tr/val_loss:  2.303950/  2.302809, val:  84.07%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-378 lr=['0.0002441'], tr/val_loss:  2.302970/  2.308097, val:  82.30%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 12.99 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-379 lr=['0.0002441'], tr/val_loss:  2.303560/  2.308191, val:  85.18%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.37 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-380 lr=['0.0002441'], tr/val_loss:  2.303991/  2.302725, val:  86.73%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.06 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-381 lr=['0.0002441'], tr/val_loss:  2.303262/  2.305395, val:  83.85%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.29 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-382 lr=['0.0002441'], tr/val_loss:  2.301748/  2.303150, val:  82.30%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.40 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 275 occurrences\n",
      "test - Value 1: 177 occurrences\n",
      "epoch-383 lr=['0.0002441'], tr/val_loss:  2.302277/  2.300163, val:  81.64%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.29 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-384 lr=['0.0002441'], tr/val_loss:  2.303222/  2.304165, val:  84.29%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 329 occurrences\n",
      "test - Value 1: 123 occurrences\n",
      "epoch-385 lr=['0.0002441'], tr/val_loss:  2.302222/  2.298670, val:  75.00%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.20 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-386 lr=['0.0002441'], tr/val_loss:  2.303382/  2.302905, val:  75.00%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.23 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-387 lr=['0.0002441'], tr/val_loss:  2.303416/  2.304424, val:  83.41%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-388 lr=['0.0002441'], tr/val_loss:  2.301761/  2.300911, val:  85.62%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.29 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 231 occurrences\n",
      "test - Value 1: 221 occurrences\n",
      "epoch-389 lr=['0.0002441'], tr/val_loss:  2.302680/  2.302398, val:  83.85%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.55 seconds, 0.23 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-390 lr=['0.0002441'], tr/val_loss:  2.301465/  2.300107, val:  82.30%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.27 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-391 lr=['0.0002441'], tr/val_loss:  2.303295/  2.300346, val:  84.73%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.42 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-392 lr=['0.0002441'], tr/val_loss:  2.301864/  2.303436, val:  83.19%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 13.35 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-393 lr=['0.0002441'], tr/val_loss:  2.303325/  2.301796, val:  85.62%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.19 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-394 lr=['0.0002441'], tr/val_loss:  2.301988/  2.301234, val:  86.95%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.16 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-395 lr=['0.0002441'], tr/val_loss:  2.301656/  2.305110, val:  84.73%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-396 lr=['0.0002441'], tr/val_loss:  2.303170/  2.297785, val:  81.19%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.26 seconds, 0.22 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-397 lr=['0.0002441'], tr/val_loss:  2.301436/  2.300505, val:  84.96%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.34 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-398 lr=['0.0002441'], tr/val_loss:  2.303336/  2.302606, val:  81.64%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.11 seconds, 0.22 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-399 lr=['0.0002441'], tr/val_loss:  2.304130/  2.302338, val:  84.07%, val_best:  87.17%, tr:  98.43%, tr_best: 100.00%, epoch time: 13.18 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-400 lr=['0.0002441'], tr/val_loss:  2.302635/  2.302914, val:  83.63%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.38 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-401 lr=['0.0002441'], tr/val_loss:  2.303033/  2.304551, val:  83.63%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 13.31 seconds, 0.22 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-402 lr=['0.0002441'], tr/val_loss:  2.302543/  2.305550, val:  78.10%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 13.22 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-403 lr=['0.0002441'], tr/val_loss:  2.303441/  2.304516, val:  78.76%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.21 seconds, 0.22 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-404 lr=['0.0002441'], tr/val_loss:  2.302196/  2.302814, val:  84.07%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 13.32 seconds, 0.22 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 271 occurrences\n",
      "test - Value 1: 181 occurrences\n",
      "epoch-405 lr=['0.0002441'], tr/val_loss:  2.302756/  2.301595, val:  82.96%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.11 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-406 lr=['0.0002441'], tr/val_loss:  2.301941/  2.303489, val:  80.97%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.30 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-407 lr=['0.0002441'], tr/val_loss:  2.302497/  2.300463, val:  83.19%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.57 seconds, 0.23 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-408 lr=['0.0002441'], tr/val_loss:  2.301624/  2.302731, val:  84.73%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 13.41 seconds, 0.22 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-409 lr=['0.0002441'], tr/val_loss:  2.300273/  2.301473, val:  81.64%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 12.37 seconds, 0.21 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-410 lr=['0.0002441'], tr/val_loss:  2.301368/  2.303509, val:  74.34%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 12.44 seconds, 0.21 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-411 lr=['0.0002441'], tr/val_loss:  2.301419/  2.297157, val:  82.08%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 12.54 seconds, 0.21 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-412 lr=['0.0002441'], tr/val_loss:  2.301600/  2.301721, val:  83.63%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 12.57 seconds, 0.21 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-413 lr=['0.0002441'], tr/val_loss:  2.302508/  2.299324, val:  81.42%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 12.21 seconds, 0.20 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-414 lr=['0.0002441'], tr/val_loss:  2.302283/  2.304210, val:  81.42%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 12.53 seconds, 0.21 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-415 lr=['0.0002441'], tr/val_loss:  2.301474/  2.303156, val:  80.09%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-416 lr=['0.0002441'], tr/val_loss:  2.301760/  2.300892, val:  81.64%, val_best:  87.17%, tr:  99.55%, tr_best: 100.00%, epoch time: 12.14 seconds, 0.20 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-417 lr=['0.0002441'], tr/val_loss:  2.300617/  2.304106, val:  84.29%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 12.04 seconds, 0.20 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-418 lr=['0.0002441'], tr/val_loss:  2.300906/  2.307273, val:  67.70%, val_best:  87.17%, tr:  99.10%, tr_best: 100.00%, epoch time: 12.01 seconds, 0.20 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-419 lr=['0.0002441'], tr/val_loss:  2.302966/  2.302998, val:  81.64%, val_best:  87.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 12.10 seconds, 0.20 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-420 lr=['0.0002441'], tr/val_loss:  2.302299/  2.303826, val:  83.41%, val_best:  87.17%, tr:  99.33%, tr_best: 100.00%, epoch time: 12.27 seconds, 0.20 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test_spike_distribution.mean 5.000000, min 5, max 5\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-421 lr=['0.0002441'], tr/val_loss:  2.303508/  2.303286, val:  81.42%, val_best:  87.17%, tr:  99.78%, tr_best: 100.00%, epoch time: 11.92 seconds, 0.20 minutes\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "my_snn_system(  devices = \"3\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 1,\n",
    "                TIME = 8, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 1, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                # n_tidigits_tonic 8\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'n_tidigits_tonic',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "                # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                learning_rate = 1/4096, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 1000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용 # trace_on False면 의미없음.\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 9, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = False, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 8, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "                # quantize_bit_list=[8,8,8],\n",
    "                # scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "                quantize_bit_list=[],\n",
    "                scale_exp=[], \n",
    "                timestep_sums_threshold = 0,\n",
    "# 1w -11~-9\n",
    "# 1b -11~ -7\n",
    "# 2w -10~-8\n",
    "# 2b -10~-8\n",
    "# 3w -10\n",
    "# 3b -10\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [8]},\n",
    "#         \"BATCH\": {\"values\": [1]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [4.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.01,0.001,0.0001,0.00001]}, \n",
    "#         \"epoch_num\": {\"values\": [1]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [14]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [25_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [True]},\n",
    "#         \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [5]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "#         \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "#         \"scale_exp_1w\": {\"values\": [-11,-10,-9]},\n",
    "#         # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "#         \"scale_exp_2w\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "#         \"scale_exp_3w\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"5\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#         quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "#         scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_2w,wandb.config.scale_exp_2w],[wandb.config.scale_exp_3w,wandb.config.scale_exp_3w]],\n",
    "#                         ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = 'v89awhtt'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
