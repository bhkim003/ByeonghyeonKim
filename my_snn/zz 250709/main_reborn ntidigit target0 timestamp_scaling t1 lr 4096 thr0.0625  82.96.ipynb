{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30902/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "    #         return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    input_argmin = input_slice.argmin(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient Î∞©Ìñ•ÏùÑ argmin Ï™ΩÏúºÎ°ú\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    ooo_fifo = 0\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "            #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "            #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 Ï§ë ÌïòÎÇò ÏÑ†ÌÉù\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                    optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch ÌÅ¨Í∏∞ ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "                        #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "                        #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250708_182802-ivn6wup8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ivn6wup8' target=\"_blank\">morning-thunder-12421</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ivn6wup8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ivn6wup8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250708_182800_054', 'my_seed': 1, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.0625, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 6.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_20250704_185524_987.pth', 'learning_rate': 0.000244140625, 'epoch_num': 1000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [], 'timestep_sums_threshold': 0} \n",
      "\n",
      "train_dataset length = 446, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 446 BATCH: 1 train_data_count: 446\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[])\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.0625, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[])\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.0625, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.000244140625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 154 occurrences\n",
      "train - Value 1: 292 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-0   lr=['0.0002441'], tr/val_loss:  2.389068/  2.303659, val:  54.65%, val_best:  54.65%, tr:  53.14%, tr_best:  53.14%, epoch time: 6.38 seconds, 0.11 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 230 occurrences\n",
      "train - Value 1: 216 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-1   lr=['0.0002441'], tr/val_loss:  2.303346/  2.270851, val:  50.88%, val_best:  54.65%, tr:  50.00%, tr_best:  53.14%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 232 occurrences\n",
      "train - Value 1: 214 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-2   lr=['0.0002441'], tr/val_loss:  2.307957/  2.334407, val:  53.76%, val_best:  54.65%, tr:  55.38%, tr_best:  55.38%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-3   lr=['0.0002441'], tr/val_loss:  2.324924/  2.358822, val:  55.31%, val_best:  55.31%, tr:  55.16%, tr_best:  55.38%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-4   lr=['0.0002441'], tr/val_loss:  2.322757/  2.324123, val:  55.09%, val_best:  55.31%, tr:  63.45%, tr_best:  63.45%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 217 occurrences\n",
      "train - Value 1: 229 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-5   lr=['0.0002441'], tr/val_loss:  2.309833/  2.315918, val:  57.08%, val_best:  57.08%, tr:  57.85%, tr_best:  63.45%, epoch time: 4.96 seconds, 0.08 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-6   lr=['0.0002441'], tr/val_loss:  2.320594/  2.337778, val:  57.52%, val_best:  57.52%, tr:  59.42%, tr_best:  63.45%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-7   lr=['0.0002441'], tr/val_loss:  2.334181/  2.350608, val:  57.30%, val_best:  57.52%, tr:  64.57%, tr_best:  64.57%, epoch time: 4.94 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-8   lr=['0.0002441'], tr/val_loss:  2.336694/  2.349955, val:  61.95%, val_best:  61.95%, tr:  68.61%, tr_best:  68.61%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-9   lr=['0.0002441'], tr/val_loss:  2.348523/  2.361766, val:  65.04%, val_best:  65.04%, tr:  68.61%, tr_best:  68.61%, epoch time: 4.50 seconds, 0.07 minutes\n",
      "train - Value 0: 231 occurrences\n",
      "train - Value 1: 215 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-10  lr=['0.0002441'], tr/val_loss:  2.345890/  2.352105, val:  61.73%, val_best:  65.04%, tr:  67.71%, tr_best:  68.61%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-11  lr=['0.0002441'], tr/val_loss:  2.342248/  2.375859, val:  66.15%, val_best:  66.15%, tr:  68.16%, tr_best:  68.61%, epoch time: 4.87 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-12  lr=['0.0002441'], tr/val_loss:  2.330428/  2.343423, val:  70.13%, val_best:  70.13%, tr:  71.08%, tr_best:  71.08%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 218 occurrences\n",
      "train - Value 1: 228 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-13  lr=['0.0002441'], tr/val_loss:  2.324960/  2.323092, val:  71.02%, val_best:  71.02%, tr:  74.66%, tr_best:  74.66%, epoch time: 4.87 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-14  lr=['0.0002441'], tr/val_loss:  2.312278/  2.355623, val:  72.35%, val_best:  72.35%, tr:  75.78%, tr_best:  75.78%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 217 occurrences\n",
      "train - Value 1: 229 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 258 occurrences\n",
      "test - Value 1: 194 occurrences\n",
      "epoch-15  lr=['0.0002441'], tr/val_loss:  2.335692/  2.314103, val:  75.66%, val_best:  75.66%, tr:  76.68%, tr_best:  76.68%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-16  lr=['0.0002441'], tr/val_loss:  2.332477/  2.332193, val:  75.00%, val_best:  75.66%, tr:  77.80%, tr_best:  77.80%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-17  lr=['0.0002441'], tr/val_loss:  2.332791/  2.356478, val:  74.34%, val_best:  75.66%, tr:  78.70%, tr_best:  78.70%, epoch time: 4.59 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-18  lr=['0.0002441'], tr/val_loss:  2.346014/  2.346888, val:  72.57%, val_best:  75.66%, tr:  81.39%, tr_best:  81.39%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-19  lr=['0.0002441'], tr/val_loss:  2.353826/  2.313286, val:  75.44%, val_best:  75.66%, tr:  79.60%, tr_best:  81.39%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-20  lr=['0.0002441'], tr/val_loss:  2.342666/  2.317766, val:  76.77%, val_best:  76.77%, tr:  81.61%, tr_best:  81.61%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-21  lr=['0.0002441'], tr/val_loss:  2.330279/  2.341803, val:  75.00%, val_best:  76.77%, tr:  84.08%, tr_best:  84.08%, epoch time: 4.56 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-22  lr=['0.0002441'], tr/val_loss:  2.343109/  2.339757, val:  74.56%, val_best:  76.77%, tr:  80.72%, tr_best:  84.08%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-23  lr=['0.0002441'], tr/val_loss:  2.337228/  2.346277, val:  72.35%, val_best:  76.77%, tr:  80.72%, tr_best:  84.08%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 219 occurrences\n",
      "train - Value 1: 227 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-24  lr=['0.0002441'], tr/val_loss:  2.335600/  2.312999, val:  76.55%, val_best:  76.77%, tr:  81.17%, tr_best:  84.08%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-25  lr=['0.0002441'], tr/val_loss:  2.330429/  2.297775, val:  77.43%, val_best:  77.43%, tr:  83.86%, tr_best:  84.08%, epoch time: 4.92 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-26  lr=['0.0002441'], tr/val_loss:  2.320494/  2.321247, val:  75.22%, val_best:  77.43%, tr:  85.65%, tr_best:  85.65%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-27  lr=['0.0002441'], tr/val_loss:  2.347720/  2.396072, val:  74.56%, val_best:  77.43%, tr:  86.32%, tr_best:  86.32%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 215 occurrences\n",
      "train - Value 1: 231 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-28  lr=['0.0002441'], tr/val_loss:  2.340816/  2.326628, val:  78.10%, val_best:  78.10%, tr:  82.96%, tr_best:  86.32%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-29  lr=['0.0002441'], tr/val_loss:  2.336991/  2.328716, val:  75.00%, val_best:  78.10%, tr:  83.63%, tr_best:  86.32%, epoch time: 4.56 seconds, 0.08 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-30  lr=['0.0002441'], tr/val_loss:  2.327064/  2.386493, val:  76.99%, val_best:  78.10%, tr:  84.98%, tr_best:  86.32%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 217 occurrences\n",
      "train - Value 1: 229 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-31  lr=['0.0002441'], tr/val_loss:  2.337559/  2.306100, val:  78.54%, val_best:  78.54%, tr:  87.44%, tr_best:  87.44%, epoch time: 4.52 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-32  lr=['0.0002441'], tr/val_loss:  2.327699/  2.298535, val:  77.43%, val_best:  78.54%, tr:  86.77%, tr_best:  87.44%, epoch time: 4.42 seconds, 0.07 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-33  lr=['0.0002441'], tr/val_loss:  2.321387/  2.356318, val:  76.33%, val_best:  78.54%, tr:  84.98%, tr_best:  87.44%, epoch time: 4.42 seconds, 0.07 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-34  lr=['0.0002441'], tr/val_loss:  2.335493/  2.380778, val:  77.65%, val_best:  78.54%, tr:  88.12%, tr_best:  88.12%, epoch time: 4.51 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-35  lr=['0.0002441'], tr/val_loss:  2.342238/  2.348340, val:  75.22%, val_best:  78.54%, tr:  89.69%, tr_best:  89.69%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-36  lr=['0.0002441'], tr/val_loss:  2.350781/  2.326600, val:  78.10%, val_best:  78.54%, tr:  87.67%, tr_best:  89.69%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 228 occurrences\n",
      "train - Value 1: 218 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-37  lr=['0.0002441'], tr/val_loss:  2.323191/  2.384103, val:  79.20%, val_best:  79.20%, tr:  88.57%, tr_best:  89.69%, epoch time: 4.54 seconds, 0.08 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-38  lr=['0.0002441'], tr/val_loss:  2.362366/  2.364067, val:  76.77%, val_best:  79.20%, tr:  87.67%, tr_best:  89.69%, epoch time: 4.56 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-39  lr=['0.0002441'], tr/val_loss:  2.341320/  2.355386, val:  79.65%, val_best:  79.65%, tr:  86.32%, tr_best:  89.69%, epoch time: 4.38 seconds, 0.07 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-40  lr=['0.0002441'], tr/val_loss:  2.344878/  2.409056, val:  75.44%, val_best:  79.65%, tr:  89.01%, tr_best:  89.69%, epoch time: 4.52 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-41  lr=['0.0002441'], tr/val_loss:  2.345616/  2.378534, val:  81.19%, val_best:  81.19%, tr:  90.13%, tr_best:  90.13%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-42  lr=['0.0002441'], tr/val_loss:  2.351052/  2.368799, val:  80.75%, val_best:  81.19%, tr:  90.81%, tr_best:  90.81%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-43  lr=['0.0002441'], tr/val_loss:  2.353770/  2.371801, val:  80.31%, val_best:  81.19%, tr:  89.46%, tr_best:  90.81%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-44  lr=['0.0002441'], tr/val_loss:  2.347389/  2.361618, val:  77.43%, val_best:  81.19%, tr:  90.13%, tr_best:  90.81%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-45  lr=['0.0002441'], tr/val_loss:  2.347939/  2.360716, val:  76.55%, val_best:  81.19%, tr:  89.01%, tr_best:  90.81%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-46  lr=['0.0002441'], tr/val_loss:  2.333828/  2.338646, val:  77.65%, val_best:  81.19%, tr:  90.81%, tr_best:  90.81%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-47  lr=['0.0002441'], tr/val_loss:  2.355410/  2.387531, val:  79.42%, val_best:  81.19%, tr:  90.13%, tr_best:  90.81%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-48  lr=['0.0002441'], tr/val_loss:  2.354488/  2.347563, val:  80.31%, val_best:  81.19%, tr:  90.81%, tr_best:  90.81%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-49  lr=['0.0002441'], tr/val_loss:  2.364693/  2.339167, val:  81.42%, val_best:  81.42%, tr:  90.58%, tr_best:  90.81%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-50  lr=['0.0002441'], tr/val_loss:  2.359551/  2.339023, val:  77.88%, val_best:  81.42%, tr:  91.48%, tr_best:  91.48%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-51  lr=['0.0002441'], tr/val_loss:  2.343715/  2.359308, val:  78.32%, val_best:  81.42%, tr:  91.93%, tr_best:  91.93%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-52  lr=['0.0002441'], tr/val_loss:  2.332586/  2.365798, val:  77.43%, val_best:  81.42%, tr:  91.70%, tr_best:  91.93%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-53  lr=['0.0002441'], tr/val_loss:  2.334780/  2.345960, val:  79.87%, val_best:  81.42%, tr:  91.03%, tr_best:  91.93%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-54  lr=['0.0002441'], tr/val_loss:  2.332492/  2.329010, val:  82.08%, val_best:  82.08%, tr:  92.83%, tr_best:  92.83%, epoch time: 4.59 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-55  lr=['0.0002441'], tr/val_loss:  2.324605/  2.317438, val:  81.42%, val_best:  82.08%, tr:  90.58%, tr_best:  92.83%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-56  lr=['0.0002441'], tr/val_loss:  2.324277/  2.313328, val:  81.42%, val_best:  82.08%, tr:  93.72%, tr_best:  93.72%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-57  lr=['0.0002441'], tr/val_loss:  2.326986/  2.350685, val:  80.31%, val_best:  82.08%, tr:  91.26%, tr_best:  93.72%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-58  lr=['0.0002441'], tr/val_loss:  2.313198/  2.369801, val:  78.54%, val_best:  82.08%, tr:  91.26%, tr_best:  93.72%, epoch time: 4.92 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-59  lr=['0.0002441'], tr/val_loss:  2.295765/  2.360299, val:  80.75%, val_best:  82.08%, tr:  92.38%, tr_best:  93.72%, epoch time: 4.93 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-60  lr=['0.0002441'], tr/val_loss:  2.341694/  2.368329, val:  79.42%, val_best:  82.08%, tr:  94.17%, tr_best:  94.17%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-61  lr=['0.0002441'], tr/val_loss:  2.323267/  2.327906, val:  80.53%, val_best:  82.08%, tr:  92.60%, tr_best:  94.17%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-62  lr=['0.0002441'], tr/val_loss:  2.332962/  2.364038, val:  82.30%, val_best:  82.30%, tr:  94.17%, tr_best:  94.17%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-63  lr=['0.0002441'], tr/val_loss:  2.311373/  2.342824, val:  79.20%, val_best:  82.30%, tr:  92.38%, tr_best:  94.17%, epoch time: 4.89 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-64  lr=['0.0002441'], tr/val_loss:  2.330882/  2.356731, val:  78.76%, val_best:  82.30%, tr:  93.27%, tr_best:  94.17%, epoch time: 5.04 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-65  lr=['0.0002441'], tr/val_loss:  2.342055/  2.390134, val:  79.20%, val_best:  82.30%, tr:  92.83%, tr_best:  94.17%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-66  lr=['0.0002441'], tr/val_loss:  2.341229/  2.339177, val:  78.98%, val_best:  82.30%, tr:  94.17%, tr_best:  94.17%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-67  lr=['0.0002441'], tr/val_loss:  2.332167/  2.300004, val:  79.87%, val_best:  82.30%, tr:  94.62%, tr_best:  94.62%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-68  lr=['0.0002441'], tr/val_loss:  2.323095/  2.385574, val:  78.32%, val_best:  82.30%, tr:  94.17%, tr_best:  94.62%, epoch time: 5.05 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-69  lr=['0.0002441'], tr/val_loss:  2.326960/  2.386915, val:  77.65%, val_best:  82.30%, tr:  95.07%, tr_best:  95.07%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-70  lr=['0.0002441'], tr/val_loss:  2.352419/  2.341198, val:  79.87%, val_best:  82.30%, tr:  92.83%, tr_best:  95.07%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-71  lr=['0.0002441'], tr/val_loss:  2.331725/  2.356127, val:  78.54%, val_best:  82.30%, tr:  96.86%, tr_best:  96.86%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-72  lr=['0.0002441'], tr/val_loss:  2.325698/  2.357285, val:  79.20%, val_best:  82.30%, tr:  93.95%, tr_best:  96.86%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-73  lr=['0.0002441'], tr/val_loss:  2.307522/  2.333784, val:  78.54%, val_best:  82.30%, tr:  94.17%, tr_best:  96.86%, epoch time: 4.93 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-74  lr=['0.0002441'], tr/val_loss:  2.325548/  2.363904, val:  78.54%, val_best:  82.30%, tr:  92.83%, tr_best:  96.86%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-75  lr=['0.0002441'], tr/val_loss:  2.351798/  2.372643, val:  80.97%, val_best:  82.30%, tr:  95.29%, tr_best:  96.86%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-76  lr=['0.0002441'], tr/val_loss:  2.316015/  2.351926, val:  78.98%, val_best:  82.30%, tr:  95.07%, tr_best:  96.86%, epoch time: 4.92 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-77  lr=['0.0002441'], tr/val_loss:  2.341430/  2.375976, val:  79.20%, val_best:  82.30%, tr:  94.17%, tr_best:  96.86%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-78  lr=['0.0002441'], tr/val_loss:  2.324867/  2.354246, val:  79.65%, val_best:  82.30%, tr:  94.84%, tr_best:  96.86%, epoch time: 4.97 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-79  lr=['0.0002441'], tr/val_loss:  2.336764/  2.392015, val:  78.76%, val_best:  82.30%, tr:  97.31%, tr_best:  97.31%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-80  lr=['0.0002441'], tr/val_loss:  2.360742/  2.417153, val:  78.54%, val_best:  82.30%, tr:  95.29%, tr_best:  97.31%, epoch time: 5.15 seconds, 0.09 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-81  lr=['0.0002441'], tr/val_loss:  2.346288/  2.387578, val:  81.42%, val_best:  82.30%, tr:  94.39%, tr_best:  97.31%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-82  lr=['0.0002441'], tr/val_loss:  2.355536/  2.375595, val:  80.75%, val_best:  82.30%, tr:  95.52%, tr_best:  97.31%, epoch time: 4.89 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-83  lr=['0.0002441'], tr/val_loss:  2.359249/  2.396960, val:  79.20%, val_best:  82.30%, tr:  95.74%, tr_best:  97.31%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-84  lr=['0.0002441'], tr/val_loss:  2.336591/  2.375192, val:  77.43%, val_best:  82.30%, tr:  93.50%, tr_best:  97.31%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-85  lr=['0.0002441'], tr/val_loss:  2.329587/  2.362571, val:  77.43%, val_best:  82.30%, tr:  94.17%, tr_best:  97.31%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-86  lr=['0.0002441'], tr/val_loss:  2.335774/  2.408439, val:  78.54%, val_best:  82.30%, tr:  94.39%, tr_best:  97.31%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-87  lr=['0.0002441'], tr/val_loss:  2.373965/  2.441614, val:  77.43%, val_best:  82.30%, tr:  95.52%, tr_best:  97.31%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-88  lr=['0.0002441'], tr/val_loss:  2.377869/  2.389654, val:  79.87%, val_best:  82.30%, tr:  94.62%, tr_best:  97.31%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-89  lr=['0.0002441'], tr/val_loss:  2.352087/  2.431001, val:  77.21%, val_best:  82.30%, tr:  94.84%, tr_best:  97.31%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-90  lr=['0.0002441'], tr/val_loss:  2.361377/  2.383489, val:  78.76%, val_best:  82.30%, tr:  93.50%, tr_best:  97.31%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-91  lr=['0.0002441'], tr/val_loss:  2.371548/  2.428715, val:  77.43%, val_best:  82.30%, tr:  94.62%, tr_best:  97.31%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-92  lr=['0.0002441'], tr/val_loss:  2.357098/  2.373493, val:  80.09%, val_best:  82.30%, tr:  95.29%, tr_best:  97.31%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-93  lr=['0.0002441'], tr/val_loss:  2.329889/  2.394427, val:  78.98%, val_best:  82.30%, tr:  95.74%, tr_best:  97.31%, epoch time: 4.99 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-94  lr=['0.0002441'], tr/val_loss:  2.360498/  2.397152, val:  79.42%, val_best:  82.30%, tr:  95.74%, tr_best:  97.31%, epoch time: 5.07 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-95  lr=['0.0002441'], tr/val_loss:  2.355613/  2.408409, val:  78.10%, val_best:  82.30%, tr:  96.64%, tr_best:  97.31%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-96  lr=['0.0002441'], tr/val_loss:  2.357778/  2.388802, val:  79.65%, val_best:  82.30%, tr:  97.09%, tr_best:  97.31%, epoch time: 4.93 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-97  lr=['0.0002441'], tr/val_loss:  2.365760/  2.418994, val:  80.09%, val_best:  82.30%, tr:  97.31%, tr_best:  97.31%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-98  lr=['0.0002441'], tr/val_loss:  2.370420/  2.403735, val:  80.09%, val_best:  82.30%, tr:  96.41%, tr_best:  97.31%, epoch time: 4.90 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-99  lr=['0.0002441'], tr/val_loss:  2.369037/  2.405651, val:  81.42%, val_best:  82.30%, tr:  97.76%, tr_best:  97.76%, epoch time: 4.90 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-100 lr=['0.0002441'], tr/val_loss:  2.386762/  2.434804, val:  78.98%, val_best:  82.30%, tr:  96.86%, tr_best:  97.76%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-101 lr=['0.0002441'], tr/val_loss:  2.388433/  2.414990, val:  80.53%, val_best:  82.30%, tr:  97.31%, tr_best:  97.76%, epoch time: 5.15 seconds, 0.09 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-102 lr=['0.0002441'], tr/val_loss:  2.369630/  2.398498, val:  80.75%, val_best:  82.30%, tr:  97.09%, tr_best:  97.76%, epoch time: 5.07 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-103 lr=['0.0002441'], tr/val_loss:  2.364294/  2.391144, val:  79.20%, val_best:  82.30%, tr:  97.53%, tr_best:  97.76%, epoch time: 4.94 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-104 lr=['0.0002441'], tr/val_loss:  2.354771/  2.417550, val:  78.54%, val_best:  82.30%, tr:  97.31%, tr_best:  97.76%, epoch time: 4.98 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-105 lr=['0.0002441'], tr/val_loss:  2.382617/  2.425209, val:  77.43%, val_best:  82.30%, tr:  97.31%, tr_best:  97.76%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-106 lr=['0.0002441'], tr/val_loss:  2.383006/  2.418766, val:  80.31%, val_best:  82.30%, tr:  96.19%, tr_best:  97.76%, epoch time: 4.95 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-107 lr=['0.0002441'], tr/val_loss:  2.379645/  2.423331, val:  78.32%, val_best:  82.30%, tr:  98.21%, tr_best:  98.21%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-108 lr=['0.0002441'], tr/val_loss:  2.351299/  2.403970, val:  78.54%, val_best:  82.30%, tr:  98.65%, tr_best:  98.65%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-109 lr=['0.0002441'], tr/val_loss:  2.357715/  2.398397, val:  79.65%, val_best:  82.30%, tr:  97.53%, tr_best:  98.65%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-110 lr=['0.0002441'], tr/val_loss:  2.365356/  2.420799, val:  78.32%, val_best:  82.30%, tr:  95.52%, tr_best:  98.65%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-111 lr=['0.0002441'], tr/val_loss:  2.341939/  2.380356, val:  79.65%, val_best:  82.30%, tr:  97.76%, tr_best:  98.65%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-112 lr=['0.0002441'], tr/val_loss:  2.324780/  2.386289, val:  78.54%, val_best:  82.30%, tr:  97.53%, tr_best:  98.65%, epoch time: 4.99 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-113 lr=['0.0002441'], tr/val_loss:  2.320048/  2.406366, val:  78.10%, val_best:  82.30%, tr:  96.41%, tr_best:  98.65%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-114 lr=['0.0002441'], tr/val_loss:  2.364905/  2.414598, val:  78.32%, val_best:  82.30%, tr:  96.86%, tr_best:  98.65%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-115 lr=['0.0002441'], tr/val_loss:  2.368418/  2.424319, val:  78.98%, val_best:  82.30%, tr:  97.09%, tr_best:  98.65%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-116 lr=['0.0002441'], tr/val_loss:  2.354204/  2.411187, val:  79.87%, val_best:  82.30%, tr:  97.09%, tr_best:  98.65%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-117 lr=['0.0002441'], tr/val_loss:  2.339311/  2.391946, val:  76.99%, val_best:  82.30%, tr:  95.29%, tr_best:  98.65%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-118 lr=['0.0002441'], tr/val_loss:  2.337250/  2.368319, val:  79.42%, val_best:  82.30%, tr:  95.96%, tr_best:  98.65%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-119 lr=['0.0002441'], tr/val_loss:  2.330306/  2.426000, val:  78.76%, val_best:  82.30%, tr:  96.64%, tr_best:  98.65%, epoch time: 4.93 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-120 lr=['0.0002441'], tr/val_loss:  2.354261/  2.393874, val:  79.20%, val_best:  82.30%, tr:  96.86%, tr_best:  98.65%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-121 lr=['0.0002441'], tr/val_loss:  2.353408/  2.393698, val:  76.99%, val_best:  82.30%, tr:  97.98%, tr_best:  98.65%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-122 lr=['0.0002441'], tr/val_loss:  2.357706/  2.385483, val:  82.08%, val_best:  82.30%, tr:  97.09%, tr_best:  98.65%, epoch time: 4.98 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-123 lr=['0.0002441'], tr/val_loss:  2.336185/  2.367203, val:  79.87%, val_best:  82.30%, tr:  97.53%, tr_best:  98.65%, epoch time: 4.56 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-124 lr=['0.0002441'], tr/val_loss:  2.353348/  2.412856, val:  79.87%, val_best:  82.30%, tr:  96.86%, tr_best:  98.65%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-125 lr=['0.0002441'], tr/val_loss:  2.370117/  2.442364, val:  80.53%, val_best:  82.30%, tr:  97.76%, tr_best:  98.65%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-126 lr=['0.0002441'], tr/val_loss:  2.368668/  2.420326, val:  80.75%, val_best:  82.30%, tr:  97.31%, tr_best:  98.65%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-127 lr=['0.0002441'], tr/val_loss:  2.381372/  2.413990, val:  79.42%, val_best:  82.30%, tr:  97.98%, tr_best:  98.65%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-128 lr=['0.0002441'], tr/val_loss:  2.380175/  2.443064, val:  81.42%, val_best:  82.30%, tr:  98.88%, tr_best:  98.88%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-129 lr=['0.0002441'], tr/val_loss:  2.395543/  2.447464, val:  80.31%, val_best:  82.30%, tr:  98.65%, tr_best:  98.88%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-130 lr=['0.0002441'], tr/val_loss:  2.383396/  2.423330, val:  80.97%, val_best:  82.30%, tr:  99.33%, tr_best:  99.33%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-131 lr=['0.0002441'], tr/val_loss:  2.374829/  2.393549, val:  80.31%, val_best:  82.30%, tr:  97.31%, tr_best:  99.33%, epoch time: 4.54 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-132 lr=['0.0002441'], tr/val_loss:  2.355367/  2.414440, val:  80.75%, val_best:  82.30%, tr:  98.88%, tr_best:  99.33%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-133 lr=['0.0002441'], tr/val_loss:  2.347470/  2.394056, val:  82.96%, val_best:  82.96%, tr:  97.76%, tr_best:  99.33%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-134 lr=['0.0002441'], tr/val_loss:  2.350641/  2.387765, val:  80.75%, val_best:  82.96%, tr:  98.21%, tr_best:  99.33%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-135 lr=['0.0002441'], tr/val_loss:  2.362451/  2.428801, val:  80.09%, val_best:  82.96%, tr:  96.86%, tr_best:  99.33%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-136 lr=['0.0002441'], tr/val_loss:  2.357237/  2.370801, val:  82.08%, val_best:  82.96%, tr:  98.21%, tr_best:  99.33%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-137 lr=['0.0002441'], tr/val_loss:  2.327446/  2.420478, val:  79.65%, val_best:  82.96%, tr:  97.98%, tr_best:  99.33%, epoch time: 4.92 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-138 lr=['0.0002441'], tr/val_loss:  2.363259/  2.417433, val:  79.42%, val_best:  82.96%, tr:  98.43%, tr_best:  99.33%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-139 lr=['0.0002441'], tr/val_loss:  2.370954/  2.432728, val:  79.42%, val_best:  82.96%, tr:  97.76%, tr_best:  99.33%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-140 lr=['0.0002441'], tr/val_loss:  2.347271/  2.423791, val:  80.09%, val_best:  82.96%, tr:  97.31%, tr_best:  99.33%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-141 lr=['0.0002441'], tr/val_loss:  2.348000/  2.439240, val:  78.32%, val_best:  82.96%, tr:  97.76%, tr_best:  99.33%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-142 lr=['0.0002441'], tr/val_loss:  2.361330/  2.400615, val:  79.65%, val_best:  82.96%, tr:  98.65%, tr_best:  99.33%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 224 occurrences\n",
      "train - Value 1: 222 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-143 lr=['0.0002441'], tr/val_loss:  2.344172/  2.425108, val:  78.98%, val_best:  82.96%, tr:  98.43%, tr_best:  99.33%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-144 lr=['0.0002441'], tr/val_loss:  2.341296/  2.424987, val:  79.42%, val_best:  82.96%, tr:  98.88%, tr_best:  99.33%, epoch time: 4.59 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-145 lr=['0.0002441'], tr/val_loss:  2.349073/  2.406018, val:  80.09%, val_best:  82.96%, tr:  98.43%, tr_best:  99.33%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 226 occurrences\n",
      "train - Value 1: 220 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-146 lr=['0.0002441'], tr/val_loss:  2.366871/  2.455235, val:  79.20%, val_best:  82.96%, tr:  97.98%, tr_best:  99.33%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 221 occurrences\n",
      "train - Value 1: 225 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-147 lr=['0.0002441'], tr/val_loss:  2.374922/  2.382478, val:  81.19%, val_best:  82.96%, tr:  97.76%, tr_best:  99.33%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 227 occurrences\n",
      "train - Value 1: 219 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-148 lr=['0.0002441'], tr/val_loss:  2.344034/  2.453539, val:  77.65%, val_best:  82.96%, tr:  98.21%, tr_best:  99.33%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 220 occurrences\n",
      "train - Value 1: 226 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-149 lr=['0.0002441'], tr/val_loss:  2.346064/  2.385953, val:  78.98%, val_best:  82.96%, tr:  97.98%, tr_best:  99.33%, epoch time: 4.64 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-150 lr=['0.0002441'], tr/val_loss:  2.339955/  2.421379, val:  79.87%, val_best:  82.96%, tr:  98.21%, tr_best:  99.33%, epoch time: 4.64 seconds, 0.08 minutes\n",
      "train - Value 0: 222 occurrences\n",
      "train - Value 1: 224 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-151 lr=['0.0002441'], tr/val_loss:  2.363662/  2.397885, val:  80.31%, val_best:  82.96%, tr:  97.53%, tr_best:  99.33%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 225 occurrences\n",
      "train - Value 1: 221 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-152 lr=['0.0002441'], tr/val_loss:  2.351891/  2.442948, val:  77.43%, val_best:  82.96%, tr:  97.31%, tr_best:  99.33%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-153 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-154 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-155 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-156 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-157 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-158 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-159 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-160 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-161 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-162 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-163 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-164 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-165 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.57 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-166 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-167 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.55 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-168 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-169 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.40 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-170 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.56 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-171 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-172 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-173 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.48 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-174 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-175 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.55 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-176 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-177 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.64 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-178 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-179 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-180 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-181 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-182 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-183 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-184 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-185 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-186 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-187 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-188 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-189 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-190 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-191 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-192 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-193 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.50 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-194 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-195 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-196 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-197 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-198 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-199 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.54 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-200 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.60 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-201 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.59 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-202 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.87 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-203 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-204 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-205 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-206 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-207 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-208 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-209 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-210 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-211 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-212 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.51 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-213 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-214 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-215 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-216 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.51 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-217 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-218 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-219 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-220 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-221 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-222 lr=['0.0002441'], tr/val_loss:  2.382146/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-223 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-224 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-225 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-226 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-227 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.62 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-228 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-229 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.45 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-230 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-231 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.64 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-232 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-233 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-234 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-235 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-236 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-237 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-238 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-239 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-240 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.60 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-241 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-242 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.52 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-243 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-244 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.99 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-245 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-246 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.52 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-247 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-248 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.56 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-249 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-250 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.62 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-251 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-252 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 5.02 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-253 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.50 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-254 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-255 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.48 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-256 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.46 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-257 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-258 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.49 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-259 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-260 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.59 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-261 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-262 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-263 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-264 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-265 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-266 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-267 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-268 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.62 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-269 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-270 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-271 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.60 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-272 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.50 seconds, 0.07 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-273 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.63 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-274 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.62 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-275 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-276 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 5.04 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-277 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-278 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-279 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-280 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-281 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-282 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-283 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-284 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-285 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.66 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-286 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-287 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-288 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-289 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.90 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-290 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-291 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-292 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-293 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-294 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-295 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.87 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-296 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-297 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-298 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-299 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-300 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-301 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.79 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-302 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-303 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.61 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-304 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-305 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-306 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.77 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-307 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.74 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-308 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.83 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-309 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-310 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-311 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-312 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-313 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.89 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-314 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.99 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-315 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-316 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-317 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.91 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-318 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.73 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-319 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.58 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-320 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.95 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-321 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-322 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.57 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-323 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-324 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.54 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-325 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-326 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-327 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-328 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.90 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-329 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-330 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-331 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-332 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.76 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-333 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-334 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-335 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-336 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-337 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.82 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-338 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.65 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-339 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-340 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.62 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-341 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-342 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.78 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-343 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-344 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.93 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-345 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-346 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.71 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-347 lr=['0.0002441'], tr/val_loss:  2.382142/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.85 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-348 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.69 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-349 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-350 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.72 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-351 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-352 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.86 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-353 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.81 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-354 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.75 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-355 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-356 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 5.02 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-357 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 5.04 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-358 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.93 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-359 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.92 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-360 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.80 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-361 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.70 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-362 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.67 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-363 lr=['0.0002441'], tr/val_loss:  2.382145/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-364 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.68 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-365 lr=['0.0002441'], tr/val_loss:  2.382143/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.88 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-366 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.84 seconds, 0.08 minutes\n",
      "train - Value 0: 223 occurrences\n",
      "train - Value 1: 223 occurrences\n",
      "train_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test_spike_distribution.mean 1.000000, min 1, max 1\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-367 lr=['0.0002441'], tr/val_loss:  2.382144/  2.442948, val:  77.43%, val_best:  82.96%, tr: 100.00%, tr_best: 100.00%, epoch time: 4.64 seconds, 0.08 minutes\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "                unique_name = run_name,\n",
    "                my_seed = 1,\n",
    "                TIME = 8, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "                BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                # n_tidigits_tonic 8\n",
    "\n",
    "                # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "                which_data = 'n_tidigits_tonic',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.0625,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "                lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "                synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "                # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "                # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                learning_rate = 1/4096, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 1000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 25_000, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "                # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "                # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "                exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 9, \n",
    "\n",
    "                num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "                chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = False, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 8, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "                # quantize_bit_list=[8,8,8],\n",
    "                # scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "                quantize_bit_list=[],\n",
    "                scale_exp=[], \n",
    "                timestep_sums_threshold = 0,\n",
    "# 1w -11~-9\n",
    "# 1b -11~ -7\n",
    "# 2w -10~-8\n",
    "# 2b -10~-8\n",
    "# 3w -10\n",
    "# 3b -10\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# average pooling  \n",
    "# Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# # Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [8]},\n",
    "#         \"BATCH\": {\"values\": [1]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [4.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.01,0.001,0.0001,0.00001]}, \n",
    "#         \"epoch_num\": {\"values\": [1]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [14]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [25_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [True]},\n",
    "#         \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [5]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "#         \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "#         \"scale_exp_1w\": {\"values\": [-11,-10,-9]},\n",
    "#         # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "#         \"scale_exp_2w\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "#         \"scale_exp_3w\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"5\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#         quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "#         scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_2w,wandb.config.scale_exp_2w],[wandb.config.scale_exp_3w,wandb.config.scale_exp_3w]],\n",
    "#                         ) \n",
    "#     # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "#     # average pooling\n",
    "#     # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "#     # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = 'v89awhtt'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
