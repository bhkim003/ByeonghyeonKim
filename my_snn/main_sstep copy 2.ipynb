{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30197/2809884579.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'sstep_lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            if (single_step == False):\n",
    "                net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                            synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on).to(device)\n",
    "        else:\n",
    "            if (single_step == False):\n",
    "                net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                            synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                            synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                            synapse_conv_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on,\n",
    "                            OTTT_sWS_on).to(device)\n",
    "            else:\n",
    "                net = MY_SNN_CONV_ottt_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                            synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                            synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                            synapse_conv_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on,\n",
    "                            OTTT_sWS_on).to(device)\n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net) #나중에풀어줘\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            if i % 10 == 0:\n",
    "                print(iter_acc)\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            iter_loss = loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                val_loss = 0.\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        inputs, labels = data\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        # inputs, labels = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "                        outputs_all=[]\n",
    "                        for tt in range(TIME):\n",
    "                            # compute output\n",
    "                            outputs = net(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            outputs_all.append(outputs.detach())\n",
    "                            val_loss += loss.data\n",
    "                        outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                        mean_out = outputs_all.mean(1)\n",
    "                        assert mean_out.size(0) == labels.size(0), 'batch값 안맞노'\n",
    "                        _, predicted = torch.max(mean_out.data, 1)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                        total += labels.size(0)\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {iter_loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "            wandb.log({\"iter_acc\": iter_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"tr_acc\": tr_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"val_acc_now\": val_acc_now}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### 모듈 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## 모듈 세이브 ###########################################################################################\n",
    "            # np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            # np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            # np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            # with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_192253-3ynjejpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3ynjejpg' target=\"_blank\">lemon-breeze-63</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3ynjejpg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3ynjejpg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV_ottt_sstep(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace_sstep()\n",
      "      (1): LIF_layer_trace_sstep()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): Scale()\n",
      "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (7): SYNAPSE_CONV_trace_sstep()\n",
      "      (8): LIF_layer_trace_sstep()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace_sstep()\n",
      "      (11): LIF_layer_trace_sstep()\n",
      "      (12): Scale()\n",
      "      (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (14): SYNAPSE_CONV_trace_sstep()\n",
      "      (15): LIF_layer_trace_sstep()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace_sstep()\n",
      "      (18): LIF_layer_trace_sstep()\n",
      "      (19): Scale()\n",
      "      (20): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (21): SYNAPSE_CONV_trace_sstep()\n",
      "      (22): LIF_layer_trace_sstep()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace_sstep()\n",
      "      (25): LIF_layer_trace_sstep()\n",
      "      (26): Scale()\n",
      "      (27): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (28): DimChanger_for_FC_sstep()\n",
      "      (29): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-0/391 iter_acc: 11.72%, lr=['0.1'], iter_loss: 2.1897177696228027, val_acc: 0.00%:   0%|          | 1/391 [00:01<07:45,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-10/391 iter_acc: 11.72%, lr=['0.1'], iter_loss: 2.1957736015319824, val_acc: 0.00%:   3%|▎         | 11/391 [00:05<02:27,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-20/391 iter_acc: 9.38%, lr=['0.1'], iter_loss: 2.1826581954956055, val_acc: 0.00%:   5%|▌         | 21/391 [00:09<02:20,  2.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-30/391 iter_acc: 12.50%, lr=['0.1'], iter_loss: 2.1689953804016113, val_acc: 0.00%:   8%|▊         | 31/391 [00:13<02:43,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-40/391 iter_acc: 18.75%, lr=['0.1'], iter_loss: 2.0796070098876953, val_acc: 0.00%:  10%|█         | 41/391 [00:17<02:11,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-50/391 iter_acc: 23.44%, lr=['0.1'], iter_loss: 2.0177197456359863, val_acc: 0.00%:  13%|█▎        | 51/391 [00:22<02:17,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-60/391 iter_acc: 27.34%, lr=['0.1'], iter_loss: 1.8996000289916992, val_acc: 0.00%:  16%|█▌        | 61/391 [00:26<02:07,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-70/391 iter_acc: 21.88%, lr=['0.1'], iter_loss: 1.9857969284057617, val_acc: 0.00%:  18%|█▊        | 71/391 [00:30<02:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-80/391 iter_acc: 23.44%, lr=['0.1'], iter_loss: 1.9232622385025024, val_acc: 0.00%:  21%|██        | 81/391 [00:34<02:05,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-90/391 iter_acc: 32.81%, lr=['0.1'], iter_loss: 1.8516842126846313, val_acc: 0.00%:  23%|██▎       | 91/391 [00:42<03:35,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-95/391 iter_acc: 23.44%, lr=['0.1'], iter_loss: 1.8966046571731567, val_acc: 0.00%:  25%|██▍       | 96/391 [00:47<04:17,  1.15it/s]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "wandb.init(project= f'my_snn {unique_name}')\n",
    "my_snn_system(  devices = \"2\",\n",
    "                single_step= True,\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.1, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0]},\n",
    "#         \"batch_size\": {\"values\": [64, 96, 128]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init()\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     decay  =  wandb.config.decay\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                     unique_name = unique_name,\n",
    "#                     my_seed = 42,\n",
    "#                     TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                     BATCH = batch_size, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                     IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "#                     # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                     #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                     # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                     which_data = 'CIFAR10',\n",
    "#     # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "#     # 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                     # CLASS_NUM = 10,\n",
    "#                     data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                     rate_coding = False, # True # False\n",
    "\n",
    "#                     lif_layer_v_init = 0.0,\n",
    "#                     lif_layer_v_decay = decay,\n",
    "#                     lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                     lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                     lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                     # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                     synapse_conv_kernel_size = 3,\n",
    "#                     synapse_conv_stride = 1,\n",
    "#                     synapse_conv_padding = 1,\n",
    "#                     synapse_conv_trace_const1 = 1,\n",
    "#                     synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     # synapse_fc_out_features = CLASS_NUM,\n",
    "#                     synapse_fc_trace_const1 = 1,\n",
    "#                     synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     pre_trained = False, # True # False\n",
    "#                     convTrue_fcFalse = True, # True # False\n",
    "\n",
    "#                     # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                     # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                     # cfg = [64],\n",
    "#                     # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                     cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "#                     # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                     # cfg = [20001,10001], # depthwise, separable\n",
    "#                     # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                     # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                     # cfg = [], \n",
    "                    \n",
    "#                     net_print = True, # True # False\n",
    "#                     weight_count_print = False, # True # False\n",
    "                    \n",
    "#                     pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "#                     learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                     epoch_num = 4,\n",
    "#                     verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                     validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                     tdBN_on = False,  # True # False\n",
    "#                     BN_on = False,  # True # False\n",
    "                    \n",
    "#                     surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                    \n",
    "#                     gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                     BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                     optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                     scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "#                     ddp_on = False,   # True # False\n",
    "\n",
    "#                     nda_net = False,   # True # False\n",
    "\n",
    "#                     domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                    \n",
    "#                     dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "#                     OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                    \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
