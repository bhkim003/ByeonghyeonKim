{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch} running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch %5 ==0 or epoch == 1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 5\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 16\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 8 # SAE일 때만 유효\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uf7hob40 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.5\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_235227-uf7hob40</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/uf7hob40' target=\"_blank\">summer-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/uf7hob40' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/uf7hob40</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 3, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 8, 'v_decay': 0.75, 'v_threshold': 0.5, 'v_reset': 0, 'BPTT_on': True, 'SAE_hidden_nomean': False, 'current_time': '20250102_235234_051', 'optimizer': 'Adam'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_235234_051\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2,4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  3\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "sweep_id = '6xax2jii'\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_174013_409'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
