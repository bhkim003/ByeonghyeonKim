{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192060/2361114005.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    \n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "    # 함수 내 모든 로컬 변수 저장\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "\n",
    "            ### input --> net --> output #####################################################\n",
    "            outputs = net(inputs)\n",
    "            ##################################################################################\n",
    "\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            batch = BATCH \n",
    "            if labels.size(0) != BATCH: \n",
    "                batch = labels.size(0)\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = (predicted[0:batch] == labels).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## loss, backward ##########################################\n",
    "            loss = criterion(outputs[0:batch,:], labels)\n",
    "            loss.backward()\n",
    "            ############################################################\n",
    "\n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## weight 업데이트!! ##################################\n",
    "            optimizer.step()\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = net(inputs.permute(1, 0, 2, 3, 4))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        batch = BATCH \n",
    "                        if labels.size(0) != BATCH: \n",
    "                            batch = labels.size(0)\n",
    "                        correct += (predicted[0:batch] == labels).sum().item()\n",
    "                        val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name = f'result_save/{base_name}_hyperparameters.json_{unique_name}'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기)\n",
    "            # np.save(iter_acc_file_name, iter_acc_array)\n",
    "            # np.save(val_acc_file_name, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "            np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            with open(f'result_save/hyperparameters.json_{unique_name}', 'w') as f:\n",
    "                json.dump(hyperparameters, f, indent=4)\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==================================================\n",
      "My Num of PARAMS: 9,302,410, system's param_num : 9,305,162\n",
      "Memory: 35.49MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 36.25%, lr=['0.0001'], iter_loss: 0.2915748953819275, val_acc: 38.74%: 100%|██████████| 391/391 [06:15<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 375.4701316356659 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-390/391 iter_acc: 40.00%, lr=['9.999725846827562e-05'], iter_loss: 0.28189387917518616, val_acc: 47.50%: 100%|██████████| 391/391 [06:57<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 417.3764545917511 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-390/391 iter_acc: 37.50%, lr=['9.998903417374228e-05'], iter_loss: 0.2806616425514221, val_acc: 52.50%: 100%|██████████| 391/391 [07:06<00:00,  1.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 426.92018604278564 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-390/391 iter_acc: 51.25%, lr=['9.997532801828658e-05'], iter_loss: 0.2577745318412781, val_acc: 56.77%: 100%|██████████| 391/391 [06:22<00:00,  1.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 382.51020765304565 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-390/391 iter_acc: 43.75%, lr=['9.995614150494293e-05'], iter_loss: 0.28276675939559937, val_acc: 60.28%: 100%|██████████| 391/391 [06:35<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 396.14178824424744 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 5-390/391 iter_acc: 56.25%, lr=['9.99314767377287e-05'], iter_loss: 0.2302343100309372, val_acc: 63.32%: 100%|██████████| 391/391 [06:32<00:00,  1.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 392.51287508010864 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 6-390/391 iter_acc: 58.75%, lr=['9.990133642141359e-05'], iter_loss: 0.22114723920822144, val_acc: 63.77%: 100%|██████████| 391/391 [06:14<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 374.7584457397461 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 7-390/391 iter_acc: 66.25%, lr=['9.986572386122291e-05'], iter_loss: 0.2166895866394043, val_acc: 66.91%: 100%|██████████| 391/391 [06:13<00:00,  1.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 373.168860912323 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 8-390/391 iter_acc: 56.25%, lr=['9.982464296247522e-05'], iter_loss: 0.20392832159996033, val_acc: 67.43%: 100%|██████████| 391/391 [06:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 374.22514510154724 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 9-390/391 iter_acc: 62.50%, lr=['9.9778098230154e-05'], iter_loss: 0.20721040666103363, val_acc: 66.38%: 100%|██████████| 391/391 [06:54<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 414.7671904563904 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 10-390/391 iter_acc: 70.00%, lr=['9.972609476841367e-05'], iter_loss: 0.1904461830854416, val_acc: 69.32%: 100%|██████████| 391/391 [06:44<00:00,  1.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 404.7561414241791 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 11-180/391 iter_acc: 64.84%, lr=['9.966863828001983e-05'], iter_loss: 0.19068889319896698, val_acc: 69.32%:  46%|████▋     | 181/391 [02:43<03:06,  1.12it/s]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'mainotttcifar10_2' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "my_snn_system(  devices = \"3\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = False, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.0001, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename='hyperparameters.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch.spikevision import spikedata\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# root, train=True, transform=None, target_transform=None, download_and_create=True, num_steps=1000, ds=1, dt=1000)\n",
    "train_ds = spikedata.SHD(\"/data2/Heidelberg\", train=True)\n",
    "test_ds = spikedata.SHD(\"/data2/Heidelberg\", train=False)\n",
    "\n",
    "# create dataloaders\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=64) # 8156x2x1000x700\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size=64) # 2264x2x1000x700\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "\n",
    "# choose a random sample\n",
    "n = 6295\n",
    "\n",
    "# initialize figure and axes\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# use spikeplot to generate a raster\n",
    "splt.raster(train_dl.dataset[n][0], ax, s=1.5, c=\"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
