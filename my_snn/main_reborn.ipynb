{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3277/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True and trace_on == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #     criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_212028-gfld578p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfld578p' target=\"_blank\">sandy-night-6863</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfld578p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfld578p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.720291189014991, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3.555718888923306, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0.0, v_decay=0.25, v_threshold=0.720291189014991, v_reset=10000, sg_width=3.555718888923306, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.0, TIME=10, sstep=True, trace_on=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0.0, v_decay=0.25, v_threshold=0.720291189014991, v_reset=10000, sg_width=3.555718888923306, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.0, TIME=10, sstep=True, trace_on=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305131/  2.302411, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.301059/  2.291211, val:  13.75%, val_best:  13.75%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.246874/  2.214486, val:  21.67%, val_best:  21.67%, tr:  14.71%, tr_best:  14.71%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "const2 = False # True # False\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "if const2 == True:\n",
    "    const2 = decay\n",
    "else:\n",
    "    const2 = 0.0\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.720291189014991,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 3.555718888923306, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = ['M', 'M', 200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 5, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = False, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "\n",
    "                last_lif = False,\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# run_name = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'random', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.001]}, #0.00936191669529645\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"decay\": {\"values\": [0.25]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"epoch_num\": {\"values\": [200]},\n",
    "#         \"dvs_duration\": {\"values\": [25_000,50_000,100_000]},\n",
    "#         \"dvs_clipping\": {\"values\": [1,2,3,4,5]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"const2\": {\"values\": [False]},\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "#         \"DFA_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "#         \"e_transport_swap\": {\"values\": [0]},\n",
    "#         \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "#         \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [3.555718888923306]},\n",
    "#         \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.720291189014991]},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "#         \"denoise_on\": {\"values\": [True,False]}, \n",
    "#         \"I_wanna_sweep_at_this_epoch\": {\"values\": [-1]}, \n",
    "#         \"dvs_duration_domain\": {\"values\": [[]]}, \n",
    "#         \"dvs_relative_timestep\": {\"values\": [[False]]}, \n",
    "#         \"extra_train_dataset\": {\"values\": [0]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init(save_code = True)\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     BATCH  =  wandb.config.BATCH\n",
    "#     decay  =  wandb.config.decay\n",
    "#     IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     epoch_num  =  wandb.config.epoch_num \n",
    "#     dvs_duration  =  wandb.config.dvs_duration\n",
    "#     dvs_clipping  =  wandb.config.dvs_clipping\n",
    "#     which_data  =  wandb.config.which_data\n",
    "#     const2  =  wandb.config.const2\n",
    "#     surrogate  =  wandb.config.surrogate\n",
    "#     DFA_on  =  wandb.config.DFA_on\n",
    "#     OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "#     cfg  =  wandb.config.cfg\n",
    "#     e_transport_swap  =  wandb.config.e_transport_swap\n",
    "#     e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "#     drop_rate  =  wandb.config.drop_rate\n",
    "#     exclude_class  =  wandb.config.exclude_class\n",
    "#     merge_polarities  =  wandb.config.merge_polarities\n",
    "#     lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "#     lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "#     e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "#     lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "#     scheduler_name  =  wandb.config.scheduler_name\n",
    "#     denoise_on  =  wandb.config.denoise_on\n",
    "#     I_wanna_sweep_at_this_epoch  =  wandb.config.I_wanna_sweep_at_this_epoch\n",
    "#     dvs_duration_domain  =  wandb.config.dvs_duration_domain\n",
    "#     dvs_relative_timestep  =  wandb.config.dvs_relative_timestep\n",
    "#     extra_train_dataset  =  wandb.config.extra_train_dataset\n",
    "#     if const2 == True:\n",
    "#         const2 = decay\n",
    "#     else:\n",
    "#         const2 = 0.0\n",
    "\n",
    "#     my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = which_data,\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 cfg = cfg,\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = epoch_num,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "#                 drop_rate = drop_rate,\n",
    "\n",
    "#                 exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = denoise_on,\n",
    "\n",
    "#                 I_wanna_sweep_at_this_epoch = I_wanna_sweep_at_this_epoch,\n",
    "#                 dvs_duration_domain = dvs_duration_domain,\n",
    "#                 dvs_relative_timestep = dvs_relative_timestep, # True # False \n",
    "\n",
    "#                 extra_train_dataset = extra_train_dataset,\n",
    "\n",
    "#                 num_workers = 2,\n",
    "#                 chaching_on = True,\n",
    "#                 pin_memory = True, # True # False\n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
