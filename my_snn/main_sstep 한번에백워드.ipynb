{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32073/2809884579.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'sstep_lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        # if (convTrue_fcFalse == False):\n",
    "        #     net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "        #              synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "        #              lif_layer_v_init, lif_layer_v_decay, \n",
    "        #              lif_layer_v_threshold, lif_layer_v_reset,\n",
    "        #              lif_layer_sg_width,\n",
    "        #              tdBN_on,\n",
    "        #              BN_on, TIME,\n",
    "        #              surrogate,\n",
    "        #              BPTT_on).to(device)\n",
    "        # else:\n",
    "        #     net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "        #              synapse_conv_kernel_size, synapse_conv_stride, \n",
    "        #              synapse_conv_padding, synapse_conv_trace_const1, \n",
    "        #              synapse_conv_trace_const2, \n",
    "        #              lif_layer_v_init, lif_layer_v_decay, \n",
    "        #              lif_layer_v_threshold, lif_layer_v_reset,\n",
    "        #              lif_layer_sg_width,\n",
    "        #              synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "        #              tdBN_on,\n",
    "        #              BN_on, TIME,\n",
    "        #              surrogate,\n",
    "        #              BPTT_on,\n",
    "        #              OTTT_sWS_on).to(device)\n",
    "        \n",
    "        # if (nda_net == True):\n",
    "        #     net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "        #               lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        #     net.T = TIME\n",
    "        net = MY_SNN_CONV_ottt_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        net = torch.nn.DataParallel(net) #나중에풀어줘\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            labels = labels.repeat(TIME, 1)\n",
    "            \n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            x_seq = inputs\n",
    "            target_seq = labels\n",
    "            # [T, B, ...]\n",
    "\n",
    "            T = x_seq.shape[0]\n",
    "\n",
    "            batch_loss = 0.\n",
    "            y_all = []\n",
    "            optimizer.zero_grad()\n",
    "            for t in range(T):\n",
    "                y_t = net(x_seq[t])\n",
    "                # print('y_t',y_t.size())#[128, 10])\n",
    "                # print('target_seq[t]',target_seq[t].size())#([1, 1, 1, 128])\n",
    "                y_all.append(y_t)\n",
    "            \n",
    "            # y_all: [B, T, ...]\n",
    "            outputs_all = torch.stack(y_all, dim=1)\n",
    "            mean_out = outputs_all.mean(1) \n",
    "\n",
    "            loss = criterion(mean_out, target_seq[0].contiguous())\n",
    "            batch_loss += loss.data\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            outputs = mean_out\n",
    "            iter_loss = batch_loss\n",
    "\n",
    "\n",
    "\n",
    "            batch = BATCH \n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            assert predicted.size(0) == labels[0].size(0), 'batch값 안맞노'\n",
    "            total = labels.size(1)\n",
    "            correct = (predicted == labels[0]).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "            \n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            running_loss += iter_loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                val_loss = 0.\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        inputs, labels = data\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        # inputs, labels = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "                        outputs_all=[]\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        for tt in range(TIME):\n",
    "                            # compute output\n",
    "                            outputs = net(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            outputs_all.append(outputs.detach())\n",
    "                            val_loss += loss.data\n",
    "                        outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                        mean_out = outputs_all.mean(1)\n",
    "                        assert mean_out.size(0) == labels.size(0), 'batch값 안맞노'\n",
    "                        _, predicted = torch.max(mean_out.data, 1)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                        total += labels.size(0)\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "            wandb.log({\"iter_acc\": iter_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"tr_acc\": tr_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"val_acc_now\": val_acc_now}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### 모듈 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## 모듈 세이브 ###########################################################################################\n",
    "            # np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            # np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            # np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            # with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_193051-edcwq9ah</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/edcwq9ah' target=\"_blank\">drawn-snowflake-67</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/edcwq9ah' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/edcwq9ah</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV_ottt_sstep(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace_sstep()\n",
      "      (1): LIF_layer_trace_sstep()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): Scale()\n",
      "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (7): SYNAPSE_CONV_trace_sstep()\n",
      "      (8): LIF_layer_trace_sstep()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace_sstep()\n",
      "      (11): LIF_layer_trace_sstep()\n",
      "      (12): Scale()\n",
      "      (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (14): SYNAPSE_CONV_trace_sstep()\n",
      "      (15): LIF_layer_trace_sstep()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace_sstep()\n",
      "      (18): LIF_layer_trace_sstep()\n",
      "      (19): Scale()\n",
      "      (20): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (21): SYNAPSE_CONV_trace_sstep()\n",
      "      (22): LIF_layer_trace_sstep()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace_sstep()\n",
      "      (25): LIF_layer_trace_sstep()\n",
      "      (26): Scale()\n",
      "      (27): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (28): DimChanger_for_FC_sstep()\n",
      "      (29): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 38.75%, lr=['0.1'], iter_loss: 0.2799837589263916, val_acc: 49.35%: 100%|██████████| 391/391 [02:44<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 164.3191888332367 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-390/391 iter_acc: 56.25%, lr=['0.09999725846827562'], iter_loss: 0.224091038107872, val_acc: 61.88%: 100%|██████████| 391/391 [02:41<00:00,  2.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 161.5767514705658 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-390/391 iter_acc: 61.25%, lr=['0.09998903417374229'], iter_loss: 0.16715511679649353, val_acc: 69.02%: 100%|██████████| 391/391 [02:41<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 161.98402094841003 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-390/391 iter_acc: 60.00%, lr=['0.0999753280182866'], iter_loss: 0.11642397940158844, val_acc: 72.30%: 100%|██████████| 391/391 [02:41<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 162.10703301429749 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-390/391 iter_acc: 75.00%, lr=['0.09995614150494293'], iter_loss: 0.12210416048765182, val_acc: 74.04%: 100%|██████████| 391/391 [02:45<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 165.984760761261 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 5-390/391 iter_acc: 72.50%, lr=['0.0999314767377287'], iter_loss: 0.17683616280555725, val_acc: 75.86%: 100%|██████████| 391/391 [02:55<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 175.42033314704895 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 6-390/391 iter_acc: 75.00%, lr=['0.09990133642141359'], iter_loss: 0.09561073780059814, val_acc: 78.00%: 100%|██████████| 391/391 [02:57<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.48949670791626 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 7-390/391 iter_acc: 83.75%, lr=['0.0998657238612229'], iter_loss: 0.09094199538230896, val_acc: 79.17%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.6551547050476 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 8-390/391 iter_acc: 75.00%, lr=['0.09982464296247523'], iter_loss: 0.09512108564376831, val_acc: 79.67%: 100%|██████████| 391/391 [02:56<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 176.61702227592468 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 9-390/391 iter_acc: 80.00%, lr=['0.099778098230154'], iter_loss: 0.10286905616521835, val_acc: 79.68%: 100%|██████████| 391/391 [03:00<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.9283926486969 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 10-390/391 iter_acc: 77.50%, lr=['0.09972609476841367'], iter_loss: 0.09432972967624664, val_acc: 81.01%: 100%|██████████| 391/391 [02:53<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 173.5042016506195 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 11-390/391 iter_acc: 83.75%, lr=['0.09966863828001983'], iter_loss: 0.0688430443406105, val_acc: 81.62%: 100%|██████████| 391/391 [02:51<00:00,  2.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 171.61662554740906 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 12-390/391 iter_acc: 81.25%, lr=['0.09960573506572391'], iter_loss: 0.10867485404014587, val_acc: 82.09%: 100%|██████████| 391/391 [03:01<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.72687911987305 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 13-390/391 iter_acc: 78.75%, lr=['0.09953739202357219'], iter_loss: 0.11052244156599045, val_acc: 83.74%: 100%|██████████| 391/391 [03:04<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 184.97942900657654 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 14-390/391 iter_acc: 78.75%, lr=['0.09946361664814943'], iter_loss: 0.06847667694091797, val_acc: 83.68%: 100%|██████████| 391/391 [03:01<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.28383994102478 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 15-390/391 iter_acc: 87.50%, lr=['0.0993844170297569'], iter_loss: 0.06783914566040039, val_acc: 83.97%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.4703540802002 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 16-390/391 iter_acc: 78.75%, lr=['0.09929980185352526'], iter_loss: 0.05581658333539963, val_acc: 83.88%: 100%|██████████| 391/391 [02:57<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.98431277275085 seconds\n",
      "\n",
      "EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 17-390/391 iter_acc: 87.50%, lr=['0.0992097803984621'], iter_loss: 0.07362779974937439, val_acc: 84.68%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.29620099067688 seconds\n",
      "\n",
      "EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 18-390/391 iter_acc: 76.25%, lr=['0.09911436253643445'], iter_loss: 0.08293014019727707, val_acc: 84.54%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.74467372894287 seconds\n",
      "\n",
      "EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 19-390/391 iter_acc: 77.50%, lr=['0.09901355873108611'], iter_loss: 0.07151862978935242, val_acc: 84.89%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.50442957878113 seconds\n",
      "\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 20-390/391 iter_acc: 83.75%, lr=['0.09890738003669029'], iter_loss: 0.06154235824942589, val_acc: 86.35%: 100%|██████████| 391/391 [03:06<00:00,  2.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.17089247703552 seconds\n",
      "\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 21-390/391 iter_acc: 82.50%, lr=['0.09879583809693737'], iter_loss: 0.09271572530269623, val_acc: 85.28%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.46554255485535 seconds\n",
      "\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 22-390/391 iter_acc: 87.50%, lr=['0.09867894514365802'], iter_loss: 0.038459450006484985, val_acc: 85.34%: 100%|██████████| 391/391 [03:00<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.8135483264923 seconds\n",
      "\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 23-390/391 iter_acc: 80.00%, lr=['0.09855671399548181'], iter_loss: 0.08255383372306824, val_acc: 86.02%: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 174.94974040985107 seconds\n",
      "\n",
      "EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 24-390/391 iter_acc: 91.25%, lr=['0.09842915805643157'], iter_loss: 0.08939188718795776, val_acc: 86.52%: 100%|██████████| 391/391 [02:51<00:00,  2.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 171.84647583961487 seconds\n",
      "\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 25-390/391 iter_acc: 95.00%, lr=['0.09829629131445343'], iter_loss: 0.03692958503961563, val_acc: 86.83%: 100%|██████████| 391/391 [02:56<00:00,  2.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 176.9626739025116 seconds\n",
      "\n",
      "EPOCH 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 26-390/391 iter_acc: 92.50%, lr=['0.09815812833988292'], iter_loss: 0.0904407724738121, val_acc: 87.51%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.39027333259583 seconds\n",
      "\n",
      "EPOCH 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 27-390/391 iter_acc: 87.50%, lr=['0.09801468428384717'], iter_loss: 0.03839164972305298, val_acc: 87.40%: 100%|██████████| 391/391 [02:57<00:00,  2.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.2537820339203 seconds\n",
      "\n",
      "EPOCH 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 28-390/391 iter_acc: 90.00%, lr=['0.09786597487660338'], iter_loss: 0.05185789614915848, val_acc: 86.74%: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 174.50618934631348 seconds\n",
      "\n",
      "EPOCH 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 29-390/391 iter_acc: 91.25%, lr=['0.09771201642581387'], iter_loss: 0.055457793176174164, val_acc: 87.24%: 100%|██████████| 391/391 [02:57<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.2617485523224 seconds\n",
      "\n",
      "EPOCH 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 30-390/391 iter_acc: 90.00%, lr=['0.09755282581475772'], iter_loss: 0.07094773650169373, val_acc: 87.13%: 100%|██████████| 391/391 [03:01<00:00,  2.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.55955505371094 seconds\n",
      "\n",
      "EPOCH 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 31-390/391 iter_acc: 92.50%, lr=['0.09738842050047931'], iter_loss: 0.07703697681427002, val_acc: 87.71%: 100%|██████████| 391/391 [02:55<00:00,  2.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 175.55640816688538 seconds\n",
      "\n",
      "EPOCH 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 32-390/391 iter_acc: 92.50%, lr=['0.09721881851187408'], iter_loss: 0.049698080867528915, val_acc: 87.50%: 100%|██████████| 391/391 [02:53<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 174.08998823165894 seconds\n",
      "\n",
      "EPOCH 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 33-390/391 iter_acc: 90.00%, lr=['0.0970440384477113'], iter_loss: 0.06209523603320122, val_acc: 88.03%: 100%|██████████| 391/391 [02:54<00:00,  2.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 175.1356749534607 seconds\n",
      "\n",
      "EPOCH 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 34-390/391 iter_acc: 96.25%, lr=['0.0968640994745946'], iter_loss: 0.07853484153747559, val_acc: 87.55%: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 174.96964049339294 seconds\n",
      "\n",
      "EPOCH 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 35-390/391 iter_acc: 92.50%, lr=['0.0966790213248601'], iter_loss: 0.08548310399055481, val_acc: 88.23%: 100%|██████████| 391/391 [04:15<00:00,  1.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 255.22676134109497 seconds\n",
      "\n",
      "EPOCH 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 36-390/391 iter_acc: 90.00%, lr=['0.09648882429441259'], iter_loss: 0.0765995904803276, val_acc: 87.60%: 100%|██████████| 391/391 [04:35<00:00,  1.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 275.46814012527466 seconds\n",
      "\n",
      "EPOCH 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 37-390/391 iter_acc: 90.00%, lr=['0.09629352924049978'], iter_loss: 0.09359213709831238, val_acc: 87.99%: 100%|██████████| 391/391 [04:03<00:00,  1.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 243.63151168823242 seconds\n",
      "\n",
      "EPOCH 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 38-390/391 iter_acc: 93.75%, lr=['0.09609315757942506'], iter_loss: 0.08521747589111328, val_acc: 87.85%: 100%|██████████| 391/391 [04:33<00:00,  1.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 273.34160017967224 seconds\n",
      "\n",
      "EPOCH 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 39-390/391 iter_acc: 93.75%, lr=['0.09588773128419908'], iter_loss: 0.05100846290588379, val_acc: 88.23%: 100%|██████████| 391/391 [04:10<00:00,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 250.20991921424866 seconds\n",
      "\n",
      "EPOCH 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 40-390/391 iter_acc: 88.75%, lr=['0.09567727288213007'], iter_loss: 0.07132381200790405, val_acc: 88.36%: 100%|██████████| 391/391 [04:09<00:00,  1.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 249.96198797225952 seconds\n",
      "\n",
      "EPOCH 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 41-390/391 iter_acc: 93.75%, lr=['0.09546180545235346'], iter_loss: 0.05705847591161728, val_acc: 88.53%: 100%|██████████| 391/391 [04:50<00:00,  1.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 290.55285120010376 seconds\n",
      "\n",
      "EPOCH 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 42-390/391 iter_acc: 91.25%, lr=['0.09524135262330101'], iter_loss: 0.07149665802717209, val_acc: 88.45%: 100%|██████████| 391/391 [04:37<00:00,  1.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 277.76433062553406 seconds\n",
      "\n",
      "EPOCH 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 43-390/391 iter_acc: 95.00%, lr=['0.09501593857010972'], iter_loss: 0.06139413267374039, val_acc: 89.14%: 100%|██████████| 391/391 [04:27<00:00,  1.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 267.3573589324951 seconds\n",
      "\n",
      "EPOCH 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 44-390/391 iter_acc: 95.00%, lr=['0.09478558801197068'], iter_loss: 0.06589879840612411, val_acc: 89.24%: 100%|██████████| 391/391 [04:12<00:00,  1.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 252.2174835205078 seconds\n",
      "\n",
      "EPOCH 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 45-390/391 iter_acc: 93.75%, lr=['0.09455032620941842'], iter_loss: 0.07544847577810287, val_acc: 88.50%: 100%|██████████| 391/391 [03:57<00:00,  1.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 238.0599226951599 seconds\n",
      "\n",
      "EPOCH 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 46-390/391 iter_acc: 93.75%, lr=['0.09431017896156076'], iter_loss: 0.06768138706684113, val_acc: 88.00%: 100%|██████████| 391/391 [04:10<00:00,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 250.86150693893433 seconds\n",
      "\n",
      "EPOCH 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 47-390/391 iter_acc: 95.00%, lr=['0.09406517260324962'], iter_loss: 0.07341741025447845, val_acc: 89.00%: 100%|██████████| 391/391 [04:05<00:00,  1.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 245.40635204315186 seconds\n",
      "\n",
      "EPOCH 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 48-390/391 iter_acc: 90.00%, lr=['0.09381533400219319'], iter_loss: 0.04409892484545708, val_acc: 88.00%: 100%|██████████| 391/391 [04:37<00:00,  1.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 277.3179244995117 seconds\n",
      "\n",
      "EPOCH 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 49-390/391 iter_acc: 96.25%, lr=['0.09356069055600949'], iter_loss: 0.055717479437589645, val_acc: 89.75%: 100%|██████████| 391/391 [04:22<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 262.69287848472595 seconds\n",
      "\n",
      "EPOCH 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 50-390/391 iter_acc: 95.00%, lr=['0.09330127018922195'], iter_loss: 0.04313477501273155, val_acc: 89.39%: 100%|██████████| 391/391 [04:12<00:00,  1.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 252.4720914363861 seconds\n",
      "\n",
      "EPOCH 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 51-390/391 iter_acc: 96.25%, lr=['0.0930371013501972'], iter_loss: 0.05930852144956589, val_acc: 88.60%: 100%|██████████| 391/391 [03:59<00:00,  1.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 239.7634584903717 seconds\n",
      "\n",
      "EPOCH 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 52-390/391 iter_acc: 91.25%, lr=['0.09276821300802535'], iter_loss: 0.050575755536556244, val_acc: 88.80%: 100%|██████████| 391/391 [04:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 250.15031671524048 seconds\n",
      "\n",
      "EPOCH 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 53-390/391 iter_acc: 96.25%, lr=['0.09249463464934321'], iter_loss: 0.08743991702795029, val_acc: 88.45%: 100%|██████████| 391/391 [03:51<00:00,  1.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 232.1166090965271 seconds\n",
      "\n",
      "EPOCH 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 54-390/391 iter_acc: 90.00%, lr=['0.09221639627510077'], iter_loss: 0.08732067048549652, val_acc: 89.29%: 100%|██████████| 391/391 [02:52<00:00,  2.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 172.18907237052917 seconds\n",
      "\n",
      "EPOCH 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 55-390/391 iter_acc: 95.00%, lr=['0.09193352839727122'], iter_loss: 0.07127629965543747, val_acc: 89.40%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.63066959381104 seconds\n",
      "\n",
      "EPOCH 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 56-390/391 iter_acc: 92.50%, lr=['0.09164606203550499'], iter_loss: 0.05425616353750229, val_acc: 89.48%: 100%|██████████| 391/391 [03:10<00:00,  2.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 191.03497958183289 seconds\n",
      "\n",
      "EPOCH 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 57-390/391 iter_acc: 91.25%, lr=['0.0913540287137281'], iter_loss: 0.050549015402793884, val_acc: 89.56%: 100%|██████████| 391/391 [03:18<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 199.0296585559845 seconds\n",
      "\n",
      "EPOCH 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 58-390/391 iter_acc: 97.50%, lr=['0.09105746045668521'], iter_loss: 0.06108972430229187, val_acc: 89.03%: 100%|██████████| 391/391 [03:06<00:00,  2.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.60748744010925 seconds\n",
      "\n",
      "EPOCH 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 59-390/391 iter_acc: 95.00%, lr=['0.09075638978642771'], iter_loss: 0.057529985904693604, val_acc: 89.47%: 100%|██████████| 391/391 [03:15<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 195.36163091659546 seconds\n",
      "\n",
      "EPOCH 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 60-390/391 iter_acc: 97.50%, lr=['0.09045084971874738'], iter_loss: 0.05785014480352402, val_acc: 89.38%: 100%|██████████| 391/391 [03:12<00:00,  2.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 192.39460968971252 seconds\n",
      "\n",
      "EPOCH 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 61-390/391 iter_acc: 96.25%, lr=['0.09014087375955573'], iter_loss: 0.08829423040151596, val_acc: 89.73%: 100%|██████████| 391/391 [03:19<00:00,  1.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 199.42399287223816 seconds\n",
      "\n",
      "EPOCH 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 62-390/391 iter_acc: 95.00%, lr=['0.08982649590120982'], iter_loss: 0.09448077529668808, val_acc: 89.64%: 100%|██████████| 391/391 [03:20<00:00,  1.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 201.10446906089783 seconds\n",
      "\n",
      "EPOCH 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 63-390/391 iter_acc: 97.50%, lr=['0.08950775061878452'], iter_loss: 0.08150303363800049, val_acc: 89.55%: 100%|██████████| 391/391 [02:52<00:00,  2.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 172.99860429763794 seconds\n",
      "\n",
      "EPOCH 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 64-390/391 iter_acc: 93.75%, lr=['0.089184672866292'], iter_loss: 0.0461706779897213, val_acc: 89.57%: 100%|██████████| 391/391 [03:08<00:00,  2.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 188.30826020240784 seconds\n",
      "\n",
      "EPOCH 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 65-390/391 iter_acc: 93.75%, lr=['0.08885729807284856'], iter_loss: 0.05327855795621872, val_acc: 89.36%: 100%|██████████| 391/391 [03:06<00:00,  2.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.02483415603638 seconds\n",
      "\n",
      "EPOCH 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 66-390/391 iter_acc: 98.75%, lr=['0.08852566213878947'], iter_loss: 0.06543375551700592, val_acc: 89.65%: 100%|██████████| 391/391 [03:01<00:00,  2.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.21163940429688 seconds\n",
      "\n",
      "EPOCH 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 67-390/391 iter_acc: 92.50%, lr=['0.08818980143173213'], iter_loss: 0.07630820572376251, val_acc: 90.23%: 100%|██████████| 391/391 [03:06<00:00,  2.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.9334909915924 seconds\n",
      "\n",
      "EPOCH 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 68-390/391 iter_acc: 97.50%, lr=['0.08784975278258783'], iter_loss: 0.06137590855360031, val_acc: 89.44%: 100%|██████████| 391/391 [03:06<00:00,  2.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.3987319469452 seconds\n",
      "\n",
      "EPOCH 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 69-390/391 iter_acc: 91.25%, lr=['0.08750555348152299'], iter_loss: 0.07964175194501877, val_acc: 89.96%: 100%|██████████| 391/391 [03:09<00:00,  2.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 189.54437971115112 seconds\n",
      "\n",
      "EPOCH 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 70-390/391 iter_acc: 97.50%, lr=['0.08715724127386973'], iter_loss: 0.052083902060985565, val_acc: 89.80%: 100%|██████████| 391/391 [03:09<00:00,  2.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 189.79361391067505 seconds\n",
      "\n",
      "EPOCH 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 71-390/391 iter_acc: 96.25%, lr=['0.08680485435598673'], iter_loss: 0.07011192291975021, val_acc: 90.07%: 100%|██████████| 391/391 [02:51<00:00,  2.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 172.15967345237732 seconds\n",
      "\n",
      "EPOCH 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 72-390/391 iter_acc: 95.00%, lr=['0.0864484313710706'], iter_loss: 0.0993734821677208, val_acc: 89.95%: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 174.49319553375244 seconds\n",
      "\n",
      "EPOCH 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 73-390/391 iter_acc: 96.25%, lr=['0.08608801140491813'], iter_loss: 0.0897129699587822, val_acc: 89.86%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.31772589683533 seconds\n",
      "\n",
      "EPOCH 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 74-390/391 iter_acc: 95.00%, lr=['0.0857236339816402'], iter_loss: 0.08785858750343323, val_acc: 90.04%: 100%|██████████| 391/391 [04:01<00:00,  1.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 241.70281529426575 seconds\n",
      "\n",
      "EPOCH 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 75-390/391 iter_acc: 95.00%, lr=['0.0853553390593274'], iter_loss: 0.1031280979514122, val_acc: 90.02%: 100%|██████████| 391/391 [03:05<00:00,  2.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 185.51950192451477 seconds\n",
      "\n",
      "EPOCH 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 76-390/391 iter_acc: 96.25%, lr=['0.08498316702566831'], iter_loss: 0.05175796151161194, val_acc: 90.16%: 100%|██████████| 391/391 [02:51<00:00,  2.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 171.53329253196716 seconds\n",
      "\n",
      "EPOCH 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 77-390/391 iter_acc: 95.00%, lr=['0.08460715869352037'], iter_loss: 0.0753469169139862, val_acc: 89.77%: 100%|██████████| 391/391 [03:05<00:00,  2.11it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 185.25728392601013 seconds\n",
      "\n",
      "EPOCH 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 78-390/391 iter_acc: 91.25%, lr=['0.08422735529643446'], iter_loss: 0.05134192109107971, val_acc: 90.00%: 100%|██████████| 391/391 [03:01<00:00,  2.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.7774260044098 seconds\n",
      "\n",
      "EPOCH 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 79-390/391 iter_acc: 92.50%, lr=['0.08384379848413306'], iter_loss: 0.05386541038751602, val_acc: 89.94%: 100%|██████████| 391/391 [03:56<00:00,  1.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 236.38248324394226 seconds\n",
      "\n",
      "EPOCH 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 80-390/391 iter_acc: 96.25%, lr=['0.08345653031794294'], iter_loss: 0.042497824877500534, val_acc: 89.54%: 100%|██████████| 391/391 [03:45<00:00,  1.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 225.68375849723816 seconds\n",
      "\n",
      "EPOCH 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 81-390/391 iter_acc: 96.25%, lr=['0.08306559326618262'], iter_loss: 0.045018598437309265, val_acc: 90.20%: 100%|██████████| 391/391 [02:51<00:00,  2.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 171.83654618263245 seconds\n",
      "\n",
      "EPOCH 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 82-390/391 iter_acc: 98.75%, lr=['0.08267103019950531'], iter_loss: 0.07053148001432419, val_acc: 90.27%: 100%|██████████| 391/391 [04:03<00:00,  1.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 243.92193603515625 seconds\n",
      "\n",
      "EPOCH 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 83-390/391 iter_acc: 96.25%, lr=['0.08227288438619755'], iter_loss: 0.09663794934749603, val_acc: 90.08%: 100%|██████████| 391/391 [03:20<00:00,  1.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 201.11508107185364 seconds\n",
      "\n",
      "EPOCH 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 84-390/391 iter_acc: 97.50%, lr=['0.0818711994874345'], iter_loss: 0.07138952612876892, val_acc: 89.82%: 100%|██████████| 391/391 [03:37<00:00,  1.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 218.00922107696533 seconds\n",
      "\n",
      "EPOCH 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 85-390/391 iter_acc: 96.25%, lr=['0.08146601955249189'], iter_loss: 0.060283273458480835, val_acc: 89.94%: 100%|██████████| 391/391 [02:50<00:00,  2.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 170.84169054031372 seconds\n",
      "\n",
      "EPOCH 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 86-390/391 iter_acc: 91.25%, lr=['0.08105738901391554'], iter_loss: 0.12208722531795502, val_acc: 89.80%: 100%|██████████| 391/391 [02:57<00:00,  2.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.36260271072388 seconds\n",
      "\n",
      "EPOCH 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 87-390/391 iter_acc: 96.25%, lr=['0.08064535268264884'], iter_loss: 0.03415908291935921, val_acc: 90.07%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.52029705047607 seconds\n",
      "\n",
      "EPOCH 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 88-390/391 iter_acc: 97.50%, lr=['0.08022995574311877'], iter_loss: 0.0513288788497448, val_acc: 90.01%: 100%|██████████| 391/391 [02:58<00:00,  2.19it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 178.93645453453064 seconds\n",
      "\n",
      "EPOCH 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 89-390/391 iter_acc: 98.75%, lr=['0.0798112437482808'], iter_loss: 0.07581493258476257, val_acc: 89.61%: 100%|██████████| 391/391 [02:55<00:00,  2.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 175.74915432929993 seconds\n",
      "\n",
      "EPOCH 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 90-390/391 iter_acc: 95.00%, lr=['0.07938926261462366'], iter_loss: 0.05387171730399132, val_acc: 90.04%: 100%|██████████| 391/391 [02:53<00:00,  2.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 173.3648111820221 seconds\n",
      "\n",
      "EPOCH 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 91-390/391 iter_acc: 96.25%, lr=['0.07896405861713394'], iter_loss: 0.07161448895931244, val_acc: 89.89%: 100%|██████████| 391/391 [02:52<00:00,  2.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 173.08932542800903 seconds\n",
      "\n",
      "EPOCH 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 92-390/391 iter_acc: 97.50%, lr=['0.0785356783842216'], iter_loss: 0.0674930214881897, val_acc: 90.11%: 100%|██████████| 391/391 [02:56<00:00,  2.21it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 176.84590458869934 seconds\n",
      "\n",
      "EPOCH 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 93-390/391 iter_acc: 95.00%, lr=['0.07810416889260655'], iter_loss: 0.07120131701231003, val_acc: 90.21%: 100%|██████████| 391/391 [03:04<00:00,  2.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 184.37587642669678 seconds\n",
      "\n",
      "EPOCH 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 94-390/391 iter_acc: 95.00%, lr=['0.07766957746216721'], iter_loss: 0.09984602779150009, val_acc: 89.95%: 100%|██████████| 391/391 [02:52<00:00,  2.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 172.2642741203308 seconds\n",
      "\n",
      "EPOCH 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 95-390/391 iter_acc: 96.25%, lr=['0.07723195175075136'], iter_loss: 0.11189406365156174, val_acc: 89.96%: 100%|██████████| 391/391 [02:57<00:00,  2.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.35321974754333 seconds\n",
      "\n",
      "EPOCH 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 96-390/391 iter_acc: 93.75%, lr=['0.07679133974894983'], iter_loss: 0.0766293853521347, val_acc: 90.42%: 100%|██████████| 391/391 [02:58<00:00,  2.19it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 178.44015169143677 seconds\n",
      "\n",
      "EPOCH 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 97-390/391 iter_acc: 97.50%, lr=['0.07634778977483389'], iter_loss: 0.08710283041000366, val_acc: 89.88%: 100%|██████████| 391/391 [02:57<00:00,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 178.02482771873474 seconds\n",
      "\n",
      "EPOCH 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 98-390/391 iter_acc: 96.25%, lr=['0.07590135046865652'], iter_loss: 0.10226382315158844, val_acc: 89.60%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.41890382766724 seconds\n",
      "\n",
      "EPOCH 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 99-390/391 iter_acc: 98.75%, lr=['0.07545207078751857'], iter_loss: 0.0734286904335022, val_acc: 90.52%: 100%|██████████| 391/391 [03:26<00:00,  1.89it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 206.6803719997406 seconds\n",
      "\n",
      "EPOCH 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 100-390/391 iter_acc: 96.25%, lr=['0.07500000000000001'], iter_loss: 0.06092458963394165, val_acc: 90.53%: 100%|██████████| 391/391 [04:04<00:00,  1.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 244.18065690994263 seconds\n",
      "\n",
      "EPOCH 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 101-343/391 iter_acc: 96.88%, lr=['0.07454518768075706'], iter_loss: 0.03801862895488739, val_acc: 90.53%:  88%|████████▊ | 344/391 [03:15<00:50,  1.06s/it]  "
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "wandb.init(project= f'my_snn {unique_name}')\n",
    "my_snn_system(  devices = \"3\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.1, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 02uhuz1p\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hghhiqdy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.1911562407482998\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_111153-hghhiqdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hghhiqdy' target=\"_blank\">lyric-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/02uhuz1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hghhiqdy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hghhiqdy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace()\n",
      "      (1): LIF_layer_trace()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace()\n",
      "      (4): LIF_layer_trace()\n",
      "      (5): Scale()\n",
      "      (6): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (7): SYNAPSE_CONV_trace()\n",
      "      (8): LIF_layer_trace()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace()\n",
      "      (11): LIF_layer_trace()\n",
      "      (12): Scale()\n",
      "      (13): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (14): SYNAPSE_CONV_trace()\n",
      "      (15): LIF_layer_trace()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace()\n",
      "      (18): LIF_layer_trace()\n",
      "      (19): Scale()\n",
      "      (20): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (21): SYNAPSE_CONV_trace()\n",
      "      (22): LIF_layer_trace()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace()\n",
      "      (25): LIF_layer_trace()\n",
      "      (26): Scale()\n",
      "      (27): DimChanger_for_pooling(\n",
      "        (ann_module): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      )\n",
      "      (28): DimChanger_for_FC()\n",
      "      (29): SYNAPSE_FC_trace()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-258/391 iter_acc: 10.94%, lr=['1.1911562407482998'], iter_loss: 0.3571101129055023, val_acc: 0.00%:  66%|██████▌   | 258/391 [01:56<00:59,  2.23it/s] "
     ]
    }
   ],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0]},\n",
    "#         \"batch_size\": {\"values\": [64, 96, 128]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init()\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     decay  =  wandb.config.decay\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                     unique_name = unique_name,\n",
    "#                     my_seed = 42,\n",
    "#                     TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                     BATCH = batch_size, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                     IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "#                     # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                     #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                     # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                     which_data = 'CIFAR10',\n",
    "#     # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "#     # 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                     # CLASS_NUM = 10,\n",
    "#                     data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                     rate_coding = False, # True # False\n",
    "\n",
    "#                     lif_layer_v_init = 0.0,\n",
    "#                     lif_layer_v_decay = decay,\n",
    "#                     lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                     lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                     lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                     # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                     synapse_conv_kernel_size = 3,\n",
    "#                     synapse_conv_stride = 1,\n",
    "#                     synapse_conv_padding = 1,\n",
    "#                     synapse_conv_trace_const1 = 1,\n",
    "#                     synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     # synapse_fc_out_features = CLASS_NUM,\n",
    "#                     synapse_fc_trace_const1 = 1,\n",
    "#                     synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     pre_trained = False, # True # False\n",
    "#                     convTrue_fcFalse = True, # True # False\n",
    "\n",
    "#                     # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                     # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                     # cfg = [64],\n",
    "#                     # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                     cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "#                     # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                     # cfg = [20001,10001], # depthwise, separable\n",
    "#                     # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                     # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                     # cfg = [], \n",
    "                    \n",
    "#                     net_print = True, # True # False\n",
    "#                     weight_count_print = False, # True # False\n",
    "                    \n",
    "#                     pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "#                     learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                     epoch_num = 4,\n",
    "#                     verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                     validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                     tdBN_on = False,  # True # False\n",
    "#                     BN_on = False,  # True # False\n",
    "                    \n",
    "#                     surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                    \n",
    "#                     gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                     BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                     optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                     scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "#                     ddp_on = False,   # True # False\n",
    "\n",
    "#                     nda_net = False,   # True # False\n",
    "\n",
    "#                     domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                    \n",
    "#                     dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "#                     OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                    \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
