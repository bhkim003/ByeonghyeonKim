{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23140/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                \n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if convTrue_fcFalse == False:\n",
    "        assert OTTT_sWS_on == False\n",
    "    if pre_trained == True:\n",
    "        print(\"\\nCaution! pre_trained is True\\n\")    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    \n",
    "    print('\\nyour OTTT_sWS_on', OTTT_sWS_on,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "    else:\n",
    "        net = net.to(device)\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "                        \n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter:{100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            val_loss=0\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += loss.data\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss}, tr:{100 * tr_acc:.2f}%, val:{100 * val_acc_now:.2f}%, val_best:{100 * val_acc:.2f}%\")  \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240813_140606-gw1swuts</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gw1swuts' target=\"_blank\">trim-wave-1918</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gw1swuts' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gw1swuts</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "your OTTT_sWS_on False \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC_trace_sstep()\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 1,054,731, system's param_num : 1,054,731\n",
      "Memory: 4.02MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-16/17 iter:28.30%, lr=['0.005'], iter_loss:1.7200300693511963, tr:21.54%, val:34.47%, val_best:34.47%: 100%|██████████| 17/17 [01:09<00:00,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 70.07511711120605 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1-16/17 iter:56.60%, lr=['0.00499986292341378'], iter_loss:1.7453968524932861, tr:42.62%, val:47.73%, val_best:47.73%: 100%|██████████| 17/17 [01:16<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 76.43018245697021 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2-16/17 iter:50.94%, lr=['0.004999451708687114'], iter_loss:0.9333574771881104, tr:55.71%, val:54.55%, val_best:54.55%: 100%|██████████| 17/17 [01:15<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 75.97305512428284 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3-16/17 iter:58.49%, lr=['0.004998766400914329'], iter_loss:1.6185634136199951, tr:68.99%, val:55.30%, val_best:55.30%: 100%|██████████| 17/17 [01:16<00:00,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 76.72912836074829 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4-16/17 iter:79.25%, lr=['0.004997807075247145'], iter_loss:1.3157978057861328, tr:80.41%, val:59.85%, val_best:59.85%: 100%|██████████| 17/17 [01:15<00:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 75.57337808609009 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5-16/17 iter:88.68%, lr=['0.004996573836886434'], iter_loss:1.3812508583068848, tr:88.39%, val:59.85%, val_best:59.85%: 100%|██████████| 17/17 [01:11<00:00,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 71.82743430137634 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6-16/17 iter:98.11%, lr=['0.004995066821070679'], iter_loss:1.6310923099517822, tr:93.22%, val:59.09%, val_best:59.85%: 100%|██████████| 17/17 [01:15<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 75.84641122817993 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7-16/17 iter:98.11%, lr=['0.004993286193061145'], iter_loss:1.4689780473709106, tr:96.84%, val:60.98%, val_best:60.98%: 100%|██████████| 17/17 [01:14<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 74.85250473022461 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8-16/17 iter:100.00%, lr=['0.004991232148123761'], iter_loss:1.7908499240875244, tr:98.70%, val:62.88%, val_best:62.88%: 100%|██████████| 17/17 [01:17<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 77.27197527885437 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9-16/17 iter:98.11%, lr=['0.0049889049115077'], iter_loss:1.7890264987945557, tr:99.26%, val:61.36%, val_best:62.88%: 100%|██████████| 17/17 [01:01<00:00,  3.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 61.88347339630127 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10-16/17 iter:100.00%, lr=['0.0049863047384206835'], iter_loss:2.181119441986084, tr:99.63%, val:60.98%, val_best:62.88%: 100%|██████████| 17/17 [01:16<00:00,  4.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 76.50283932685852 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11-16/17 iter:100.00%, lr=['0.004983431914000991'], iter_loss:2.0620665550231934, tr:99.72%, val:61.74%, val_best:62.88%: 100%|██████████| 17/17 [01:16<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 76.34730219841003 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12-16/17 iter:100.00%, lr=['0.004980286753286195'], iter_loss:2.324615955352783, tr:99.81%, val:62.50%, val_best:62.88%: 100%|██████████| 17/17 [01:16<00:00,  4.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 76.99663019180298 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13-16/17 iter:100.00%, lr=['0.004976869601178609'], iter_loss:2.233433723449707, tr:99.91%, val:62.12%, val_best:62.88%: 100%|██████████| 17/17 [01:18<00:00,  4.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 79.10324788093567 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14-16/17 iter:100.00%, lr=['0.004973180832407471'], iter_loss:2.315080404281616, tr:99.91%, val:63.64%, val_best:63.64%: 100%|██████████| 17/17 [01:11<00:00,  4.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 71.82460331916809 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15-16/17 iter:100.00%, lr=['0.0049692208514878445'], iter_loss:2.252535343170166, tr:100.00%, val:64.02%, val_best:64.02%: 100%|██████████| 17/17 [01:13<00:00,  4.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 73.64255118370056 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "16-16/17 iter:100.00%, lr=['0.004964990092676262'], iter_loss:2.3499436378479004, tr:100.00%, val:63.26%, val_best:64.02%: 100%|██████████| 17/17 [01:12<00:00,  4.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 73.1200020313263 seconds\n",
      "\n",
      "EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17-16/17 iter:100.00%, lr=['0.004960489019923104'], iter_loss:2.358250856399536, tr:100.00%, val:62.12%, val_best:64.02%: 100%|██████████| 17/17 [01:15<00:00,  4.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 75.93000602722168 seconds\n",
      "\n",
      "EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "18-16/17 iter:100.00%, lr=['0.004955718126821722'], iter_loss:2.3516767024993896, tr:100.00%, val:63.26%, val_best:64.02%: 100%|██████████| 17/17 [01:18<00:00,  4.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 78.83170938491821 seconds\n",
      "\n",
      "EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "19-16/17 iter:100.00%, lr=['0.004950677936554305'], iter_loss:2.423563003540039, tr:100.00%, val:64.02%, val_best:64.02%: 100%|██████████| 17/17 [01:17<00:00,  4.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 77.87895083427429 seconds\n",
      "\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20-16/17 iter:100.00%, lr=['0.004945369001834514'], iter_loss:2.389603614807129, tr:100.00%, val:63.64%, val_best:64.02%: 100%|██████████| 17/17 [01:12<00:00,  4.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 73.09159088134766 seconds\n",
      "\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21-16/17 iter:100.00%, lr=['0.004939791904846868'], iter_loss:2.3423447608947754, tr:100.00%, val:62.88%, val_best:64.02%: 100%|██████████| 17/17 [01:13<00:00,  4.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 73.18948101997375 seconds\n",
      "\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "22-16/17 iter:100.00%, lr=['0.0049339472571829'], iter_loss:2.394538402557373, tr:100.00%, val:62.88%, val_best:64.02%: 100%|██████████| 17/17 [01:12<00:00,  4.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 72.65222191810608 seconds\n",
      "\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "23-16/17 iter:100.00%, lr=['0.00492783569977409'], iter_loss:2.4643476009368896, tr:100.00%, val:63.26%, val_best:64.02%: 100%|██████████| 17/17 [01:15<00:00,  4.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 75.87006258964539 seconds\n",
      "\n",
      "EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "24-16/17 iter:100.00%, lr=['0.004921457902821577'], iter_loss:2.4813432693481445, tr:100.00%, val:63.26%, val_best:64.02%: 100%|██████████| 17/17 [01:16<00:00,  4.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 76.57895874977112 seconds\n",
      "\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25-9/17 iter:100.00%, lr=['0.004914814565722669'], iter_loss:0.17275093495845795, tr:100.00%, val:63.26%, val_best:64.02%:  59%|█████▉    | 10/17 [00:35<00:21,  3.08s/it]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.4 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "const2 = True\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "if const2 == True:\n",
    "    const2 = decay\n",
    "else:\n",
    "    const2 = 0.0\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "my_snn_system(  devices = \"3\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 64, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                cfg = ['M','M',512],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.005, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = 5_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = True, # True # False # 맨 처음 input에 trace 적용\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# DDP 실행 코드\n",
    "'''\n",
    "ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# run_name = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"min\": 0.0001, \"max\": 0.01},\n",
    "#         \"BATCH\": {\"values\": [64,128,256,512]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"TIME\": {\"values\": [5,6,7,8,9,10]},\n",
    "#         \"epoch_num\": {\"values\": [20]},\n",
    "#         \"dvs_duration\": {\"values\": [10_000, 100_000, 25_000, 50_000]},\n",
    "#         \"dvs_clipping\": {\"values\": [0,1,2,4]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "#         \"const2\": {\"values\": [True, False]},\n",
    "#         \"surrogate\": {\"values\": ['rectangle', 'sigmoid']},\n",
    "#         \"DFA_on\": {\"values\": [True, False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [True, False]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init(save_code = True)\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     BATCH  =  wandb.config.BATCH\n",
    "#     decay  =  wandb.config.decay\n",
    "#     IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     epoch_num  =  wandb.config.epoch_num \n",
    "#     dvs_duration  =  wandb.config.dvs_duration\n",
    "#     dvs_clipping  =  wandb.config.dvs_clipping\n",
    "#     which_data  =  wandb.config.which_data\n",
    "#     OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "#     const2  =  wandb.config.const2\n",
    "#     surrogate  =  wandb.config.surrogate\n",
    "#     DFA_on  =  wandb.config.DFA_on\n",
    "#     OTTT_input_trace_on  =  wandb.config.surrogate\n",
    "\n",
    "#     if const2 == True:\n",
    "#         const2 = decay\n",
    "#     else:\n",
    "#         const2 = 0.0\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = which_data,\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = epoch_num,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
