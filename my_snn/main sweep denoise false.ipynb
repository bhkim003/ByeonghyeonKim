{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17489/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on, )\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_val_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_tr_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################         \n",
    "                               \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                loss /= TIME\n",
    "            tr_epoch_loss_temp += loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                val_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on, )\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_val_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_tr_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################         \n",
    "                               \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                loss /= TIME\n",
    "            tr_epoch_loss_temp += loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                val_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"2\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.3102821334243646,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 2.570969004857107, # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',200,200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.01, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 60,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 2, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "\n",
    "#                 drop_rate = 0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (NMNIST) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"4\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 34, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'NMNIST_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.009, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 10_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "                \n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: yp7c5ffh\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f8d2wrxk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.042539877688782674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.1264730966520364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.2794223708289947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_011328-f8d2wrxk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f8d2wrxk' target=\"_blank\">avid-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f8d2wrxk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f8d2wrxk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0425399'], tr/val_loss:  2.281641/  2.054224, tr:  25.64%, val:  32.50%, val_best:  32.50%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-1   lr=['0.0425294'], tr/val_loss:  2.281519/  2.481132, tr:  29.93%, val:  32.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-2   lr=['0.0424979'], tr/val_loss:  2.526548/  3.587850, tr:  29.93%, val:  25.83%, val_best:  32.92%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-3   lr=['0.0424455'], tr/val_loss:  2.741554/  2.571349, tr:  27.07%, val:  30.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-4   lr=['0.0423722'], tr/val_loss:  3.778472/  4.352206, tr:  23.80%, val:  14.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:22<00:00,  2.73it/s]\n",
      "epoch-5   lr=['0.0422780'], tr/val_loss:  2.996126/  3.918631, tr:  25.33%, val:  23.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:21<00:00,  2.84it/s]\n",
      "epoch-6   lr=['0.0421631'], tr/val_loss:  2.478024/  2.837862, tr:  30.85%, val:  31.25%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-7   lr=['0.0420276'], tr/val_loss:  2.642229/  4.301363, tr:  23.19%, val:  12.50%, val_best:  32.92%: 100%|██████████| 62/62 [01:02<00:00,  1.02s/it]\n",
      "epoch-8   lr=['0.0418716'], tr/val_loss:  3.431968/  3.597000, tr:  16.34%, val:  16.67%, val_best:  32.92%: 100%|██████████| 62/62 [01:07<00:00,  1.08s/it]\n",
      "epoch-9   lr=['0.0416953'], tr/val_loss:  3.236514/  4.044101, tr:  17.57%, val:  18.33%, val_best:  32.92%: 100%|██████████| 62/62 [01:08<00:00,  1.10s/it]\n",
      "epoch-10  lr=['0.0414989'], tr/val_loss:  3.194016/  3.231830, tr:  19.00%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [01:00<00:00,  1.03it/s]\n",
      "epoch-11  lr=['0.0412824'], tr/val_loss:  3.177689/  3.082228, tr:  18.28%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [01:08<00:00,  1.10s/it]\n",
      "epoch-12  lr=['0.0410462'], tr/val_loss:  3.115338/  3.773866, tr:  16.96%, val:  12.92%, val_best:  32.92%: 100%|██████████| 62/62 [01:05<00:00,  1.06s/it]\n",
      "epoch-13  lr=['0.0407905'], tr/val_loss:  3.711569/  4.428544, tr:  15.22%, val:  10.00%, val_best:  32.92%: 100%|██████████| 62/62 [01:01<00:00,  1.00it/s]\n",
      "epoch-14  lr=['0.0405156'], tr/val_loss:  3.169416/  3.174422, tr:  16.75%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [01:10<00:00,  1.14s/it]\n",
      "epoch-15  lr=['0.0402216'], tr/val_loss:  3.425395/  3.597406, tr:  16.96%, val:  10.00%, val_best:  32.92%: 100%|██████████| 62/62 [01:09<00:00,  1.11s/it]\n",
      "epoch-16  lr=['0.0399089'], tr/val_loss:  2.807594/  3.092946, tr:  19.20%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-17  lr=['0.0395779'], tr/val_loss:  3.327022/  3.327313, tr:  18.90%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-18  lr=['0.0392287'], tr/val_loss:  3.606660/  3.324344, tr:  18.49%, val:  18.75%, val_best:  32.92%: 100%|██████████| 62/62 [01:11<00:00,  1.16s/it]\n",
      "epoch-19  lr=['0.0388619'], tr/val_loss:  3.061546/  3.831638, tr:  14.71%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [01:10<00:00,  1.13s/it]\n",
      "epoch-20  lr=['0.0384777'], tr/val_loss:  3.471815/  3.371005, tr:  19.00%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [01:08<00:00,  1.11s/it]\n",
      "epoch-21  lr=['0.0380765'], tr/val_loss:  3.309494/  2.997134, tr:  16.96%, val:  16.25%, val_best:  32.92%: 100%|██████████| 62/62 [01:07<00:00,  1.09s/it]\n",
      "epoch-22  lr=['0.0376587'], tr/val_loss:  2.956574/  2.701170, tr:  16.55%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:59<00:00,  1.05it/s]\n",
      "epoch-23  lr=['0.0372248'], tr/val_loss:  2.989983/  2.424825, tr:  18.18%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.07it/s]\n",
      "epoch-24  lr=['0.0367751'], tr/val_loss:  2.947761/  2.644358, tr:  17.06%, val:  12.92%, val_best:  32.92%: 100%|██████████| 62/62 [01:07<00:00,  1.08s/it]\n",
      "epoch-25  lr=['0.0363101'], tr/val_loss:  2.874109/  2.413440, tr:  17.77%, val:  23.33%, val_best:  32.92%: 100%|██████████| 62/62 [01:06<00:00,  1.08s/it]\n",
      "epoch-26  lr=['0.0358302'], tr/val_loss:  2.966989/  2.734317, tr:  17.88%, val:  16.67%, val_best:  32.92%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-27  lr=['0.0353360'], tr/val_loss:  2.708235/  2.491185, tr:  18.39%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-28  lr=['0.0348279'], tr/val_loss:  2.775979/  3.560044, tr:  17.98%, val:  11.67%, val_best:  32.92%: 100%|██████████| 62/62 [01:18<00:00,  1.26s/it]\n",
      "epoch-29  lr=['0.0343064'], tr/val_loss:  3.260614/  3.538290, tr:  13.79%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [01:01<00:00,  1.01it/s]\n",
      "epoch-30  lr=['0.0337721'], tr/val_loss:  2.983894/  3.485371, tr:  19.10%, val:  17.50%, val_best:  32.92%: 100%|██████████| 62/62 [01:17<00:00,  1.25s/it]\n",
      "epoch-31  lr=['0.0332254'], tr/val_loss:  3.079067/  4.502847, tr:  17.26%, val:  10.00%, val_best:  32.92%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-32  lr=['0.0326669'], tr/val_loss:  2.930657/  2.820235, tr:  17.88%, val:  12.08%, val_best:  32.92%: 100%|██████████| 62/62 [01:09<00:00,  1.12s/it]\n",
      "epoch-33  lr=['0.0320972'], tr/val_loss:  2.628242/  2.484211, tr:  17.88%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:47<00:00,  1.31it/s]\n",
      "epoch-34  lr=['0.0315168'], tr/val_loss:  2.885056/  3.156907, tr:  16.96%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-35  lr=['0.0309263'], tr/val_loss:  3.485003/  2.995976, tr:  18.39%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-36  lr=['0.0303262'], tr/val_loss:  3.094756/  4.484817, tr:  18.90%, val:  10.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:59<00:00,  1.04it/s]\n",
      "epoch-37  lr=['0.0297173'], tr/val_loss:  3.363517/  2.574833, tr:  19.20%, val:  20.83%, val_best:  32.92%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-38  lr=['0.0290999'], tr/val_loss:  3.108218/  3.960515, tr:  17.57%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:43<00:00,  1.43it/s]\n",
      "epoch-39  lr=['0.0284749'], tr/val_loss:  3.050262/  3.935514, tr:  18.49%, val:  12.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.13it/s]\n",
      "epoch-40  lr=['0.0278427'], tr/val_loss:  2.934154/  3.144148, tr:  19.51%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-41  lr=['0.0272041'], tr/val_loss:  2.757596/  2.559002, tr:  18.69%, val:  21.67%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-42  lr=['0.0265596'], tr/val_loss:  2.708758/  2.597469, tr:  18.90%, val:  17.50%, val_best:  32.92%: 100%|██████████| 62/62 [00:59<00:00,  1.05it/s]\n",
      "epoch-43  lr=['0.0259098'], tr/val_loss:  2.584555/  2.551606, tr:  17.36%, val:  17.50%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.13it/s]\n",
      "epoch-44  lr=['0.0252555'], tr/val_loss:  2.663801/  3.662827, tr:  18.08%, val:  12.08%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-45  lr=['0.0245973'], tr/val_loss:  2.936683/  3.681864, tr:  17.26%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:45<00:00,  1.36it/s]\n",
      "epoch-46  lr=['0.0239358'], tr/val_loss:  2.912541/  2.636872, tr:  19.31%, val:  21.25%, val_best:  32.92%: 100%|██████████| 62/62 [00:48<00:00,  1.27it/s]\n",
      "epoch-47  lr=['0.0232716'], tr/val_loss:  2.559453/  3.503728, tr:  19.31%, val:  23.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-48  lr=['0.0226055'], tr/val_loss:  2.691600/  2.352437, tr:  18.69%, val:  17.50%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-49  lr=['0.0219380'], tr/val_loss:  2.814383/  2.406790, tr:  18.79%, val:  23.75%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-50  lr=['0.0212699'], tr/val_loss:  2.392658/  2.612989, tr:  21.55%, val:  10.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-51  lr=['0.0206018'], tr/val_loss:  2.574546/  2.446110, tr:  17.88%, val:  21.25%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-52  lr=['0.0199344'], tr/val_loss:  2.589127/  2.446345, tr:  18.90%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-53  lr=['0.0192683'], tr/val_loss:  2.516691/  2.208471, tr:  17.88%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-54  lr=['0.0186041'], tr/val_loss:  2.423425/  2.530670, tr:  18.39%, val:  17.08%, val_best:  32.92%: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n",
      "epoch-55  lr=['0.0179426'], tr/val_loss:  2.414416/  2.487508, tr:  17.36%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-56  lr=['0.0172843'], tr/val_loss:  2.816595/  2.853795, tr:  12.16%, val:  11.67%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-57  lr=['0.0166300'], tr/val_loss:  2.832153/  2.828084, tr:  13.69%, val:  15.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.15it/s]\n",
      "epoch-58  lr=['0.0159803'], tr/val_loss:  2.540329/  2.572013, tr:  14.30%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-59  lr=['0.0153358'], tr/val_loss:  2.422604/  2.258466, tr:  19.00%, val:  18.75%, val_best:  32.92%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-60  lr=['0.0146972'], tr/val_loss:  2.211874/  2.465710, tr:  20.43%, val:  17.50%, val_best:  32.92%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-61  lr=['0.0140650'], tr/val_loss:  2.389854/  2.276423, tr:  18.39%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-62  lr=['0.0134400'], tr/val_loss:  2.196988/  2.306704, tr:  20.74%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-63  lr=['0.0128226'], tr/val_loss:  2.291091/  2.475180, tr:  20.74%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-64  lr=['0.0122136'], tr/val_loss:  2.255544/  2.242815, tr:  20.22%, val:  20.42%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-65  lr=['0.0116136'], tr/val_loss:  2.273552/  2.487208, tr:  19.31%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-66  lr=['0.0110231'], tr/val_loss:  2.284377/  2.426609, tr:  19.71%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-67  lr=['0.0104427'], tr/val_loss:  2.152043/  2.212429, tr:  20.94%, val:  20.83%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-68  lr=['0.0098729'], tr/val_loss:  2.105246/  2.109290, tr:  18.49%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:47<00:00,  1.32it/s]\n",
      "epoch-69  lr=['0.0093145'], tr/val_loss:  2.100431/  2.089369, tr:  22.57%, val:  18.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-70  lr=['0.0087678'], tr/val_loss:  2.069950/  2.308608, tr:  21.65%, val:  21.67%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.07it/s]\n",
      "epoch-71  lr=['0.0082334'], tr/val_loss:  2.134401/  2.380199, tr:  22.06%, val:  18.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.09it/s]\n",
      "epoch-72  lr=['0.0077120'], tr/val_loss:  2.160884/  2.248426, tr:  20.12%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-73  lr=['0.0072039'], tr/val_loss:  2.118538/  2.075031, tr:  19.10%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-74  lr=['0.0067097'], tr/val_loss:  2.018689/  2.099964, tr:  19.82%, val:  18.75%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-75  lr=['0.0062298'], tr/val_loss:  2.059632/  2.057385, tr:  20.33%, val:  21.67%, val_best:  32.92%: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n",
      "epoch-76  lr=['0.0057648'], tr/val_loss:  2.023918/  2.040190, tr:  22.06%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-77  lr=['0.0053151'], tr/val_loss:  2.030422/  2.012724, tr:  20.43%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:48<00:00,  1.27it/s]\n",
      "epoch-78  lr=['0.0048812'], tr/val_loss:  1.969875/  2.037390, tr:  22.57%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-79  lr=['0.0044634'], tr/val_loss:  1.988502/  2.009357, tr:  17.77%, val:  23.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-80  lr=['0.0040622'], tr/val_loss:  1.963672/  2.007484, tr:  20.84%, val:  19.58%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-81  lr=['0.0036780'], tr/val_loss:  1.943406/  2.037862, tr:  20.53%, val:  19.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-82  lr=['0.0033111'], tr/val_loss:  1.965761/  1.984539, tr:  19.92%, val:  22.08%, val_best:  32.92%: 100%|██████████| 62/62 [00:49<00:00,  1.25it/s]\n",
      "epoch-83  lr=['0.0029620'], tr/val_loss:  1.944635/  1.982206, tr:  20.12%, val:  22.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.09it/s]\n",
      "epoch-84  lr=['0.0026309'], tr/val_loss:  1.956071/  1.979834, tr:  20.22%, val:  23.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-85  lr=['0.0023183'], tr/val_loss:  1.936407/  1.980685, tr:  19.41%, val:  22.08%, val_best:  32.92%: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n",
      "epoch-86  lr=['0.0020243'], tr/val_loss:  1.930043/  1.971419, tr:  20.94%, val:  21.25%, val_best:  32.92%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-87  lr=['0.0017494'], tr/val_loss:  1.908641/  1.943838, tr:  22.47%, val:  17.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-88  lr=['0.0014936'], tr/val_loss:  1.917143/  1.956748, tr:  22.47%, val:  26.25%, val_best:  32.92%: 100%|██████████| 62/62 [01:00<00:00,  1.03it/s]\n",
      "epoch-89  lr=['0.0012575'], tr/val_loss:  1.911103/  1.943877, tr:  21.86%, val:  20.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-90  lr=['0.0010410'], tr/val_loss:  1.901674/  1.950091, tr:  20.43%, val:  23.75%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-91  lr=['0.0008446'], tr/val_loss:  1.893771/  1.947894, tr:  21.45%, val:  21.67%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-92  lr=['0.0006682'], tr/val_loss:  1.898540/  1.947561, tr:  23.80%, val:  27.08%, val_best:  32.92%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-93  lr=['0.0005122'], tr/val_loss:  1.890160/  1.941747, tr:  20.74%, val:  24.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:57<00:00,  1.09it/s]\n",
      "epoch-94  lr=['0.0003767'], tr/val_loss:  1.884895/  1.938404, tr:  20.43%, val:  24.17%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-95  lr=['0.0002619'], tr/val_loss:  1.876441/  1.937045, tr:  24.72%, val:  25.83%, val_best:  32.92%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-96  lr=['0.0001677'], tr/val_loss:  1.879716/  1.940238, tr:  25.54%, val:  27.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.15it/s]\n",
      "epoch-97  lr=['0.0000944'], tr/val_loss:  1.879124/  1.935741, tr:  25.33%, val:  24.58%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-98  lr=['0.0000420'], tr/val_loss:  1.879338/  1.935414, tr:  25.23%, val:  25.00%, val_best:  32.92%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-99  lr=['0.0000105'], tr/val_loss:  1.871843/  1.935507, tr:  25.94%, val:  23.33%, val_best:  32.92%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796a563ff7e549ba9c52fbfaa3338ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.064 MB of 7.064 MB uploaded (2.424 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 33.1%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▇▅▅▄▃▆█▄▂▅▆▄▅▃▁▄▄▄▅▄▂▄▃▃▁▃▃▃▅▃▂▆▄▅▂▂▆▃▆▃</td></tr><tr><td>summary_val_acc</td><td>█▆▂▁▃▁▃▄▄▂▁▃▃▁▃▄▁▃▁▅▅▄▃▂▃▄▃▄▄▃▄▃▅▄▅▃▄▆▆▅</td></tr><tr><td>tr_acc</td><td>▆█▅▅▃▂▂▃▁▂▂▃▁▃▃▃▃▃▃▃▃▃▃▁▃▃▃▄▄▄▄▄▃▄▄▅▅▅▆▆</td></tr><tr><td>tr_epoch_loss</td><td>▂▃█▄▆▆▆▆▅▆▅▅▆▅▇▆▅▄▄▄▄▄▃▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>█▆▂▁▃▁▃▄▄▂▁▃▃▁▃▄▁▃▁▅▅▄▃▂▃▄▃▄▄▃▄▃▅▄▅▃▄▆▆▅</td></tr><tr><td>val_loss</td><td>▁▆██▇▆▅▅▆▄▃▃▆▄▄▃▇▃▆▆▂▂▃▄▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.25945</td></tr><tr><td>tr_epoch_loss</td><td>1.87184</td></tr><tr><td>val_acc_best</td><td>0.32917</td></tr><tr><td>val_acc_now</td><td>0.23333</td></tr><tr><td>val_loss</td><td>1.93551</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f8d2wrxk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f8d2wrxk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 15 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_011328-f8d2wrxk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zhgb7u6r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07852170338455244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.0392464446598377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.791568324642507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_024657-zhgb7u6r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zhgb7u6r' target=\"_blank\">whole-sweep-4</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zhgb7u6r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zhgb7u6r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0785217'], tr/val_loss:  2.387783/  2.413250, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:08<00:00,  7.70it/s]\n",
      "epoch-1   lr=['0.0785023'], tr/val_loss:  2.394230/  2.437929, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.78it/s]\n",
      "epoch-2   lr=['0.0784442'], tr/val_loss:  2.383810/  2.368744, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.92it/s]\n",
      "epoch-3   lr=['0.0783475'], tr/val_loss:  2.397177/  2.434021, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:44<00:00,  1.40it/s]\n",
      "epoch-4   lr=['0.0782121'], tr/val_loss:  2.478199/  2.405739, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:49<00:00,  1.25it/s]\n",
      "epoch-5   lr=['0.0780383'], tr/val_loss:  2.440390/  2.491393, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:31<00:00,  1.99it/s]\n",
      "epoch-6   lr=['0.0778263'], tr/val_loss:  2.267211/  2.378748, tr:  14.50%, val:  11.67%, val_best:  11.67%: 100%|██████████| 62/62 [00:18<00:00,  3.33it/s]\n",
      "epoch-7   lr=['0.0775762'], tr/val_loss:  2.484113/  3.559322, tr:  20.22%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-8   lr=['0.0772883'], tr/val_loss:  3.584454/  5.690865, tr:  15.53%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-9   lr=['0.0769628'], tr/val_loss:  4.887191/  6.515916, tr:  11.24%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.11it/s]\n",
      "epoch-10  lr=['0.0766001'], tr/val_loss:  4.194951/  4.896520, tr:   9.30%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-11  lr=['0.0762006'], tr/val_loss:  4.359175/  5.852947, tr:  10.11%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-12  lr=['0.0757647'], tr/val_loss:  4.271838/  3.725998, tr:   9.70%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-13  lr=['0.0752927'], tr/val_loss:  5.417613/  5.041588, tr:  10.83%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-14  lr=['0.0747851'], tr/val_loss:  4.562609/  4.218489, tr:   9.81%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-15  lr=['0.0742425'], tr/val_loss:  3.999473/  6.503647, tr:  11.85%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-16  lr=['0.0736654'], tr/val_loss:  4.192882/  3.704317, tr:  10.93%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-17  lr=['0.0730543'], tr/val_loss:  4.872806/  5.144350, tr:  10.83%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-18  lr=['0.0724099'], tr/val_loss:  4.567706/  5.096107, tr:  10.62%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-19  lr=['0.0717327'], tr/val_loss:  4.063662/  3.459455, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-20  lr=['0.0710235'], tr/val_loss:  3.911285/  4.877476, tr:   9.19%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-21  lr=['0.0702830'], tr/val_loss:  3.484633/  3.576211, tr:   9.30%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-22  lr=['0.0695119'], tr/val_loss:  4.256412/  4.582218, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-23  lr=['0.0687109'], tr/val_loss:  4.143925/  3.823836, tr:  11.24%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-24  lr=['0.0678808'], tr/val_loss:  3.935965/  3.513715, tr:  10.52%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-25  lr=['0.0670225'], tr/val_loss:  4.240165/  7.711887, tr:   9.60%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-26  lr=['0.0661368'], tr/val_loss:  4.370141/  3.503739, tr:  11.03%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "epoch-27  lr=['0.0652245'], tr/val_loss:  3.841743/  4.958250, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-28  lr=['0.0642867'], tr/val_loss:  4.457293/  5.131752, tr:   9.50%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-29  lr=['0.0633241'], tr/val_loss:  4.049130/  4.003278, tr:   8.78%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-30  lr=['0.0623378'], tr/val_loss:  3.937541/  3.897738, tr:  11.13%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-31  lr=['0.0613287'], tr/val_loss:  3.883701/  3.583240, tr:   9.19%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-32  lr=['0.0602979'], tr/val_loss:  4.218272/  4.324170, tr:  10.83%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-33  lr=['0.0592463'], tr/val_loss:  3.232299/  3.067709, tr:   8.99%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "epoch-34  lr=['0.0581749'], tr/val_loss:  3.363490/  4.819374, tr:   9.91%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-35  lr=['0.0570849'], tr/val_loss:  3.796302/  3.927221, tr:   8.99%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-36  lr=['0.0559773'], tr/val_loss:  4.408511/  3.850185, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-37  lr=['0.0548532'], tr/val_loss:  3.995970/  2.972471, tr:  11.85%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-38  lr=['0.0537137'], tr/val_loss:  3.728804/  3.552871, tr:  10.01%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:57<00:00,  1.07it/s]\n",
      "epoch-39  lr=['0.0525600'], tr/val_loss:  3.496266/  4.451629, tr:  10.52%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-40  lr=['0.0513931'], tr/val_loss:  3.288307/  4.543753, tr:  11.64%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-41  lr=['0.0502143'], tr/val_loss:  3.421434/  3.839721, tr:  10.42%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-42  lr=['0.0490246'], tr/val_loss:  3.158572/  2.880618, tr:   9.70%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-43  lr=['0.0478253'], tr/val_loss:  2.998271/  2.741500, tr:  10.73%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-44  lr=['0.0466176'], tr/val_loss:  3.418792/  3.810721, tr:   9.70%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-45  lr=['0.0454026'], tr/val_loss:  3.292472/  4.672248, tr:  13.38%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-46  lr=['0.0441815'], tr/val_loss:  3.403872/  2.739441, tr:   9.30%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s]\n",
      "epoch-47  lr=['0.0429556'], tr/val_loss:  3.190001/  3.220573, tr:   9.09%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-48  lr=['0.0417261'], tr/val_loss:  3.060363/  3.073434, tr:   8.99%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-49  lr=['0.0404941'], tr/val_loss:  3.474630/  3.726246, tr:   9.19%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-50  lr=['0.0392609'], tr/val_loss:  2.925073/  3.082487, tr:   9.81%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-51  lr=['0.0380276'], tr/val_loss:  3.092716/  3.086046, tr:  10.21%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-52  lr=['0.0367956'], tr/val_loss:  3.126448/  3.277999, tr:   9.60%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-53  lr=['0.0355661'], tr/val_loss:  3.066883/  2.697296, tr:  11.34%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-54  lr=['0.0343402'], tr/val_loss:  2.862316/  2.942903, tr:  11.24%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:57<00:00,  1.09it/s]\n",
      "epoch-55  lr=['0.0331191'], tr/val_loss:  2.993490/  3.252221, tr:   9.91%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-56  lr=['0.0319041'], tr/val_loss:  3.168128/  3.598278, tr:   8.89%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:49<00:00,  1.25it/s]\n",
      "epoch-57  lr=['0.0306964'], tr/val_loss:  3.137809/  3.097549, tr:  10.32%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-58  lr=['0.0294971'], tr/val_loss:  2.829563/  3.188309, tr:   9.40%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-59  lr=['0.0283074'], tr/val_loss:  2.810994/  2.817624, tr:   9.91%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-60  lr=['0.0271286'], tr/val_loss:  2.709296/  2.830512, tr:  11.34%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-61  lr=['0.0259617'], tr/val_loss:  2.852829/  2.985395, tr:   8.27%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-62  lr=['0.0248080'], tr/val_loss:  2.800847/  3.007827, tr:   9.60%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-63  lr=['0.0236685'], tr/val_loss:  2.746900/  2.647000, tr:  10.11%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-64  lr=['0.0225444'], tr/val_loss:  2.636220/  2.754757, tr:   9.40%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-65  lr=['0.0214368'], tr/val_loss:  2.694703/  2.899941, tr:   9.91%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-66  lr=['0.0203468'], tr/val_loss:  2.742857/  2.993854, tr:   8.89%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-67  lr=['0.0192755'], tr/val_loss:  2.642798/  2.715771, tr:   9.09%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-68  lr=['0.0182238'], tr/val_loss:  2.561192/  2.633973, tr:   9.81%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:57<00:00,  1.07it/s]\n",
      "epoch-69  lr=['0.0171930'], tr/val_loss:  2.535721/  2.394969, tr:   9.50%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:49<00:00,  1.25it/s]\n",
      "epoch-70  lr=['0.0161839'], tr/val_loss:  2.517652/  2.897427, tr:   8.48%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-71  lr=['0.0151976'], tr/val_loss:  2.547411/  2.741709, tr:   9.40%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-72  lr=['0.0142350'], tr/val_loss:  2.527460/  2.609993, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-73  lr=['0.0132972'], tr/val_loss:  2.558592/  2.521574, tr:  10.32%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-74  lr=['0.0123849'], tr/val_loss:  2.495292/  2.560040, tr:   9.30%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-75  lr=['0.0114992'], tr/val_loss:  2.489996/  2.402881, tr:  11.34%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-76  lr=['0.0106409'], tr/val_loss:  2.435309/  2.533838, tr:  10.21%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-77  lr=['0.0098109'], tr/val_loss:  2.465042/  2.388262, tr:   8.78%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-78  lr=['0.0090098'], tr/val_loss:  2.430827/  2.411241, tr:   9.91%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-79  lr=['0.0082387'], tr/val_loss:  2.434997/  2.442079, tr:   9.40%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-80  lr=['0.0074982'], tr/val_loss:  2.417320/  2.397017, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-81  lr=['0.0067890'], tr/val_loss:  2.394985/  2.401329, tr:   9.70%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:35<00:00,  1.75it/s]\n",
      "epoch-82  lr=['0.0061118'], tr/val_loss:  2.410008/  2.344266, tr:   8.48%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:16<00:00,  3.68it/s]\n",
      "epoch-83  lr=['0.0054674'], tr/val_loss:  2.397271/  2.367844, tr:   7.87%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:18<00:00,  3.44it/s]\n",
      "epoch-84  lr=['0.0048563'], tr/val_loss:  2.399881/  2.342658, tr:   8.78%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:15<00:00,  3.88it/s]\n",
      "epoch-85  lr=['0.0042792'], tr/val_loss:  2.381329/  2.359506, tr:   8.68%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:18<00:00,  3.40it/s]\n",
      "epoch-86  lr=['0.0037366'], tr/val_loss:  2.364710/  2.362453, tr:   9.81%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:17<00:00,  3.61it/s]\n",
      "epoch-87  lr=['0.0032290'], tr/val_loss:  2.351752/  2.317406, tr:   8.38%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:17<00:00,  3.60it/s]\n",
      "epoch-88  lr=['0.0027570'], tr/val_loss:  2.350662/  2.343060, tr:  10.01%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:15<00:00,  3.97it/s]\n",
      "epoch-89  lr=['0.0023211'], tr/val_loss:  2.342712/  2.320765, tr:   9.19%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:17<00:00,  3.61it/s]\n",
      "epoch-90  lr=['0.0019216'], tr/val_loss:  2.340423/  2.314919, tr:   8.58%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:16<00:00,  3.67it/s]\n",
      "epoch-91  lr=['0.0015589'], tr/val_loss:  2.330347/  2.340579, tr:  10.32%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:18<00:00,  3.37it/s]\n",
      "epoch-92  lr=['0.0012335'], tr/val_loss:  2.324403/  2.314017, tr:   8.07%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n",
      "epoch-93  lr=['0.0009455'], tr/val_loss:  2.321285/  2.305238, tr:   9.50%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:14<00:00,  4.17it/s]\n",
      "epoch-94  lr=['0.0006954'], tr/val_loss:  2.316473/  2.305671, tr:   7.46%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:17<00:00,  3.47it/s]\n",
      "epoch-95  lr=['0.0004834'], tr/val_loss:  2.309634/  2.304738, tr:   8.17%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:15<00:00,  4.05it/s]\n",
      "epoch-96  lr=['0.0003096'], tr/val_loss:  2.309446/  2.302930, tr:  10.32%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:17<00:00,  3.50it/s]\n",
      "epoch-97  lr=['0.0001742'], tr/val_loss:  2.308599/  2.302914, tr:   8.17%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:13<00:00,  4.51it/s]\n",
      "epoch-98  lr=['0.0000775'], tr/val_loss:  2.304218/  2.302711, tr:   8.89%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-99  lr=['0.0000194'], tr/val_loss:  2.302853/  2.302685, tr:  10.01%, val:  10.00%, val_best:  11.67%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee3de97dbcd4fba8d5b5087cc7b939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▆▄▁▄▄▂▂▁▂▄▆▂▄▂▂▄▂▄▄▂▄▄▂▄▁▂▁▄▁▂▂▅▄▂▁▁▆▂█▁</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▁▂▂█▃▂▂▃▁▂▂▃▁▃▂▃▂▂▂▂▂▂▃▂▂▁▂▂▁▁▃▁▂▁▁▁▂▁▁▁</td></tr><tr><td>tr_epoch_loss</td><td>▁▁▁▁█▆▇█▆▄▅▇▆▆▅▆▄▃▄▃▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁█████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▃█▃▄▆▃▃▃▃▄▄▄▂▅▂▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30285</td></tr><tr><td>val_acc_best</td><td>0.11667</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30268</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-4</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zhgb7u6r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zhgb7u6r</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_024657-zhgb7u6r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1jn498ps with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03161683977793694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.2611111838229028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.309858426382848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_040350-1jn498ps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1jn498ps' target=\"_blank\">dauntless-sweep-7</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1jn498ps' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1jn498ps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0316168'], tr/val_loss:  2.073566/  1.731933, tr:  21.55%, val:  35.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:12<00:00,  4.95it/s]\n",
      "epoch-1   lr=['0.0316090'], tr/val_loss:  1.718457/  1.911899, tr:  36.47%, val:  37.92%, val_best:  37.92%: 100%|██████████| 62/62 [00:15<00:00,  3.90it/s]\n",
      "epoch-2   lr=['0.0315856'], tr/val_loss:  1.780290/  1.843106, tr:  39.02%, val:  36.25%, val_best:  37.92%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-3   lr=['0.0315467'], tr/val_loss:  1.669585/  1.817825, tr:  42.39%, val:  43.75%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-4   lr=['0.0314922'], tr/val_loss:  1.803820/  1.824520, tr:  37.49%, val:  35.42%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-5   lr=['0.0314222'], tr/val_loss:  1.846706/  2.125006, tr:  38.41%, val:  37.92%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-6   lr=['0.0313368'], tr/val_loss:  2.019328/  2.059902, tr:  34.01%, val:  29.17%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-7   lr=['0.0312361'], tr/val_loss:  2.019261/  2.103956, tr:  35.24%, val:  31.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-8   lr=['0.0311202'], tr/val_loss:  1.945642/  2.278959, tr:  33.09%, val:  26.67%, val_best:  43.75%: 100%|██████████| 62/62 [00:08<00:00,  7.46it/s]\n",
      "epoch-9   lr=['0.0309891'], tr/val_loss:  1.907792/  2.095513, tr:  34.22%, val:  31.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.42it/s]\n",
      "epoch-10  lr=['0.0308431'], tr/val_loss:  1.714375/  2.629782, tr:  36.06%, val:  26.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  4.11it/s]\n",
      "epoch-11  lr=['0.0306823'], tr/val_loss:  1.991505/  2.491920, tr:  31.46%, val:  29.58%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.25it/s]\n",
      "epoch-12  lr=['0.0305067'], tr/val_loss:  2.104976/  2.100712, tr:  31.26%, val:  30.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:12<00:00,  4.93it/s]\n",
      "epoch-13  lr=['0.0303167'], tr/val_loss:  2.044463/  2.029782, tr:  33.30%, val:  32.92%, val_best:  43.75%: 100%|██████████| 62/62 [00:12<00:00,  4.92it/s]\n",
      "epoch-14  lr=['0.0301123'], tr/val_loss:  1.770781/  1.975056, tr:  35.85%, val:  26.67%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  3.89it/s]\n",
      "epoch-15  lr=['0.0298938'], tr/val_loss:  1.962914/  1.989104, tr:  31.26%, val:  31.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  4.07it/s]\n",
      "epoch-16  lr=['0.0296614'], tr/val_loss:  1.963413/  2.291112, tr:  31.46%, val:  27.08%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.39it/s]\n",
      "epoch-17  lr=['0.0294154'], tr/val_loss:  2.494295/  2.584320, tr:  21.65%, val:  15.83%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.59it/s]\n",
      "epoch-18  lr=['0.0291559'], tr/val_loss:  2.882778/  2.563226, tr:  13.07%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.68it/s]\n",
      "epoch-19  lr=['0.0288833'], tr/val_loss:  2.698991/  2.651589, tr:   8.99%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:19<00:00,  3.18it/s]\n",
      "epoch-20  lr=['0.0285977'], tr/val_loss:  2.720475/  2.547786, tr:  10.83%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.80it/s]\n",
      "epoch-21  lr=['0.0282995'], tr/val_loss:  2.703630/  2.741641, tr:  10.21%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.53it/s]\n",
      "epoch-22  lr=['0.0279890'], tr/val_loss:  2.719026/  2.539074, tr:   8.89%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.15it/s]\n",
      "epoch-23  lr=['0.0276665'], tr/val_loss:  2.683928/  2.972427, tr:  10.83%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.54it/s]\n",
      "epoch-24  lr=['0.0273323'], tr/val_loss:  2.758139/  2.827274, tr:  10.42%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.39it/s]\n",
      "epoch-25  lr=['0.0269867'], tr/val_loss:  2.670735/  2.719050, tr:   9.50%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.71it/s]\n",
      "epoch-26  lr=['0.0266300'], tr/val_loss:  2.691015/  2.766621, tr:   8.89%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.64it/s]\n",
      "epoch-27  lr=['0.0262627'], tr/val_loss:  2.669958/  2.495012, tr:   9.50%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.19it/s]\n",
      "epoch-28  lr=['0.0258851'], tr/val_loss:  2.699608/  3.237792, tr:  11.44%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  3.95it/s]\n",
      "epoch-29  lr=['0.0254975'], tr/val_loss:  2.837326/  2.548522, tr:   8.78%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:20<00:00,  3.10it/s]\n",
      "epoch-30  lr=['0.0251004'], tr/val_loss:  2.698781/  2.851321, tr:   9.40%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:19<00:00,  3.20it/s]\n",
      "epoch-31  lr=['0.0246941'], tr/val_loss:  2.689559/  2.719567, tr:  10.32%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:18<00:00,  3.42it/s]\n",
      "epoch-32  lr=['0.0242790'], tr/val_loss:  2.662934/  2.986812, tr:   9.19%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:18<00:00,  3.44it/s]\n",
      "epoch-33  lr=['0.0238556'], tr/val_loss:  2.672304/  2.512784, tr:  10.73%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.79it/s]\n",
      "epoch-34  lr=['0.0234242'], tr/val_loss:  2.713033/  2.607906, tr:  10.83%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.48it/s]\n",
      "epoch-35  lr=['0.0229853'], tr/val_loss:  2.697285/  2.640822, tr:   9.60%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.19it/s]\n",
      "epoch-36  lr=['0.0225393'], tr/val_loss:  2.751357/  3.179129, tr:   9.40%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  4.13it/s]\n",
      "epoch-37  lr=['0.0220867'], tr/val_loss:  2.872444/  2.745210, tr:   9.91%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:14<00:00,  4.31it/s]\n",
      "epoch-38  lr=['0.0216279'], tr/val_loss:  2.637221/  2.449816, tr:   9.81%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  4.08it/s]\n",
      "epoch-39  lr=['0.0211633'], tr/val_loss:  2.613076/  2.506721, tr:  11.13%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.45it/s]\n",
      "epoch-40  lr=['0.0206935'], tr/val_loss:  2.592921/  2.968668, tr:   9.81%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:18<00:00,  3.38it/s]\n",
      "epoch-41  lr=['0.0202188'], tr/val_loss:  2.605260/  2.731597, tr:   8.68%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.83it/s]\n",
      "epoch-42  lr=['0.0197398'], tr/val_loss:  2.545946/  2.450781, tr:  10.42%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  3.94it/s]\n",
      "epoch-43  lr=['0.0192569'], tr/val_loss:  2.520157/  2.857828, tr:  12.26%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.68it/s]\n",
      "epoch-44  lr=['0.0187706'], tr/val_loss:  2.562533/  2.613498, tr:   8.78%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:18<00:00,  3.28it/s]\n",
      "epoch-45  lr=['0.0182814'], tr/val_loss:  2.633051/  2.630225, tr:  12.26%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.70it/s]\n",
      "epoch-46  lr=['0.0177897'], tr/val_loss:  2.664960/  2.658783, tr:   9.81%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.77it/s]\n",
      "epoch-47  lr=['0.0172961'], tr/val_loss:  2.537839/  2.642200, tr:   8.78%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.85it/s]\n",
      "epoch-48  lr=['0.0168010'], tr/val_loss:  2.537461/  2.501683, tr:   8.99%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:16<00:00,  3.84it/s]\n",
      "epoch-49  lr=['0.0163050'], tr/val_loss:  2.581949/  2.751579, tr:   8.27%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:19<00:00,  3.13it/s]\n",
      "epoch-50  lr=['0.0158084'], tr/val_loss:  2.535048/  2.555135, tr:  10.62%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:19<00:00,  3.13it/s]\n",
      "epoch-51  lr=['0.0153119'], tr/val_loss:  2.565202/  2.456596, tr:   9.50%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:18<00:00,  3.43it/s]\n",
      "epoch-52  lr=['0.0148158'], tr/val_loss:  2.555283/  2.335625, tr:  10.93%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.52it/s]\n",
      "epoch-53  lr=['0.0143207'], tr/val_loss:  2.534153/  2.483699, tr:  10.62%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:15<00:00,  4.13it/s]\n",
      "epoch-54  lr=['0.0138271'], tr/val_loss:  2.491310/  2.415285, tr:   9.40%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:18<00:00,  3.28it/s]\n",
      "epoch-55  lr=['0.0133354'], tr/val_loss:  2.467739/  2.495896, tr:  10.11%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:13<00:00,  4.59it/s]\n",
      "epoch-56  lr=['0.0128462'], tr/val_loss:  2.589641/  2.391102, tr:  10.21%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.49it/s]\n",
      "epoch-57  lr=['0.0123599'], tr/val_loss:  2.502815/  2.391801, tr:  10.01%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.48it/s]\n",
      "epoch-58  lr=['0.0118770'], tr/val_loss:  2.455852/  2.424405, tr:   9.30%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:17<00:00,  3.52it/s]\n",
      "epoch-59  lr=['0.0113980'], tr/val_loss:  2.470054/  2.396247, tr:   9.70%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:19<00:00,  3.17it/s]\n",
      "epoch-60  lr=['0.0109233'], tr/val_loss:  2.456419/  2.428098, tr:   8.89%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:08<00:00,  7.48it/s]\n",
      "epoch-61  lr=['0.0104535'], tr/val_loss:  2.480589/  2.494488, tr:  10.73%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-62  lr=['0.0099890'], tr/val_loss:  2.444496/  2.353848, tr:   9.19%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-63  lr=['0.0095301'], tr/val_loss:  2.452529/  2.355566, tr:   8.78%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.23it/s]\n",
      "epoch-64  lr=['0.0090775'], tr/val_loss:  2.376422/  2.373574, tr:   8.99%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-65  lr=['0.0086315'], tr/val_loss:  2.462951/  2.484991, tr:  10.52%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-66  lr=['0.0081927'], tr/val_loss:  2.410382/  2.397321, tr:   8.38%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-67  lr=['0.0077613'], tr/val_loss:  2.412724/  2.334810, tr:  11.34%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-68  lr=['0.0073378'], tr/val_loss:  2.402778/  2.356647, tr:  10.52%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-69  lr=['0.0069228'], tr/val_loss:  2.383478/  2.407065, tr:  11.75%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-70  lr=['0.0065165'], tr/val_loss:  2.392370/  2.332562, tr:  10.42%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-71  lr=['0.0061193'], tr/val_loss:  2.384573/  2.353776, tr:  10.11%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-72  lr=['0.0057318'], tr/val_loss:  2.370943/  2.396682, tr:  10.01%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-73  lr=['0.0053541'], tr/val_loss:  2.382890/  2.409580, tr:   9.09%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-74  lr=['0.0049868'], tr/val_loss:  2.376266/  2.344858, tr:  10.11%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-75  lr=['0.0046302'], tr/val_loss:  2.379663/  2.387307, tr:  10.11%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-76  lr=['0.0042846'], tr/val_loss:  2.349659/  2.324634, tr:  10.32%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-77  lr=['0.0039503'], tr/val_loss:  2.358487/  2.324640, tr:   9.40%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-78  lr=['0.0036278'], tr/val_loss:  2.347887/  2.325644, tr:  11.03%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-79  lr=['0.0033173'], tr/val_loss:  2.347778/  2.348716, tr:   9.81%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-80  lr=['0.0030191'], tr/val_loss:  2.348751/  2.341411, tr:   7.25%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-81  lr=['0.0027336'], tr/val_loss:  2.329554/  2.369004, tr:  10.83%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-82  lr=['0.0024609'], tr/val_loss:  2.349552/  2.310929, tr:   8.48%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-83  lr=['0.0022014'], tr/val_loss:  2.323574/  2.321452, tr:   9.30%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-84  lr=['0.0019554'], tr/val_loss:  2.339740/  2.324716, tr:   9.60%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-85  lr=['0.0017230'], tr/val_loss:  2.329237/  2.314444, tr:   8.17%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-86  lr=['0.0015045'], tr/val_loss:  2.322068/  2.322771, tr:   9.50%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-87  lr=['0.0013002'], tr/val_loss:  2.319014/  2.311475, tr:   9.91%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-88  lr=['0.0011101'], tr/val_loss:  2.323942/  2.311337, tr:   8.89%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-89  lr=['0.0009346'], tr/val_loss:  2.319843/  2.310168, tr:   9.19%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  8.93it/s]\n",
      "epoch-90  lr=['0.0007737'], tr/val_loss:  2.315604/  2.306609, tr:   8.78%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-91  lr=['0.0006277'], tr/val_loss:  2.314039/  2.305553, tr:   9.40%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-92  lr=['0.0004967'], tr/val_loss:  2.311791/  2.303355, tr:   7.46%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-93  lr=['0.0003807'], tr/val_loss:  2.308563/  2.303033, tr:   8.48%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-94  lr=['0.0002800'], tr/val_loss:  2.307933/  2.302841, tr:   6.23%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-95  lr=['0.0001946'], tr/val_loss:  2.305858/  2.302735, tr:   8.17%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-96  lr=['0.0001247'], tr/val_loss:  2.305019/  2.302795, tr:   8.38%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-97  lr=['0.0000702'], tr/val_loss:  2.304889/  2.302685, tr:   9.60%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-98  lr=['0.0000312'], tr/val_loss:  2.303181/  2.302649, tr:  10.01%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-99  lr=['0.0000078'], tr/val_loss:  2.302796/  2.302641, tr:  10.01%, val:  10.00%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200d0703a16b4c0e9c70b60b52f4c71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▇▄▆█▇▅▇▄▁▄▅▁▂▃▅▄▂▂▅▃▄▂▄▁▁▁▃▃▂▂▁▂▁▃▃▃▁▂▁▂</td></tr><tr><td>summary_val_acc</td><td>███▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▄██▇▇▆▇▄▁▂▂▁▁▁▁▂▂▂▁▁▁▂▁▂▁▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁</td></tr><tr><td>tr_epoch_loss</td><td>▃▁▁▃▂▃▁▆▇▇▇▇█▇▇█▆▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄</td></tr><tr><td>val_acc_best</td><td>▁▃██████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>███▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▂▂▃▃▃▂▆▆▇▇▇▆█▆▇▅▅▆▆▇▄▅▅▅▅▅▄▄▅▅▄▄▄▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.3028</td></tr><tr><td>val_acc_best</td><td>0.4375</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-7</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1jn498ps' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1jn498ps</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_040350-1jn498ps/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 41bhc3p4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.028778461763390217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4.377548475017431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.9907471892000173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_042409-41bhc3p4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/41bhc3p4' target=\"_blank\">clear-sweep-8</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/41bhc3p4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/41bhc3p4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0287785'], tr/val_loss:  2.339773/  2.334881, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-1   lr=['0.0287714'], tr/val_loss:  2.336841/  2.347242, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-2   lr=['0.0287501'], tr/val_loss:  2.338273/  2.337858, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-3   lr=['0.0287146'], tr/val_loss:  2.330541/  2.340309, tr:  11.95%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-4   lr=['0.0286650'], tr/val_loss:  2.369220/  2.331531, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-5   lr=['0.0286013'], tr/val_loss:  2.340745/  2.359048, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-6   lr=['0.0285236'], tr/val_loss:  2.358993/  2.328631, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-7   lr=['0.0284319'], tr/val_loss:  2.355525/  2.321956, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-8   lr=['0.0283264'], tr/val_loss:  2.338306/  2.320661, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-9   lr=['0.0282071'], tr/val_loss:  2.337030/  2.379342, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-10  lr=['0.0280742'], tr/val_loss:  2.347335/  2.335093, tr:   7.25%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-11  lr=['0.0279278'], tr/val_loss:  2.356348/  2.339602, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-12  lr=['0.0277680'], tr/val_loss:  2.348958/  2.309522, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-13  lr=['0.0275950'], tr/val_loss:  2.336398/  2.351704, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.08it/s]\n",
      "epoch-14  lr=['0.0274090'], tr/val_loss:  2.345081/  2.345060, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-15  lr=['0.0272101'], tr/val_loss:  2.357286/  2.371338, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-16  lr=['0.0269986'], tr/val_loss:  2.343860/  2.354487, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-17  lr=['0.0267746'], tr/val_loss:  2.339835/  2.323605, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-18  lr=['0.0265385'], tr/val_loss:  2.362690/  2.315381, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-19  lr=['0.0262903'], tr/val_loss:  2.339963/  2.337905, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-20  lr=['0.0260304'], tr/val_loss:  2.336681/  2.351972, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-21  lr=['0.0257590'], tr/val_loss:  2.338445/  2.328212, tr:  11.03%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-22  lr=['0.0254763'], tr/val_loss:  2.336225/  2.321311, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-23  lr=['0.0251828'], tr/val_loss:  2.343995/  2.350061, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-24  lr=['0.0248785'], tr/val_loss:  2.355021/  2.348894, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-25  lr=['0.0245640'], tr/val_loss:  2.355023/  2.340331, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-26  lr=['0.0242393'], tr/val_loss:  2.337730/  2.319881, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-27  lr=['0.0239050'], tr/val_loss:  2.339381/  2.312740, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-28  lr=['0.0235613'], tr/val_loss:  2.343717/  2.321712, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-29  lr=['0.0232085'], tr/val_loss:  2.343935/  2.324174, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-30  lr=['0.0228470'], tr/val_loss:  2.337089/  2.329713, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-31  lr=['0.0224772'], tr/val_loss:  2.330798/  2.319549, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-32  lr=['0.0220994'], tr/val_loss:  2.334295/  2.334088, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-33  lr=['0.0217139'], tr/val_loss:  2.329444/  2.313009, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-34  lr=['0.0213213'], tr/val_loss:  2.339221/  2.327121, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-35  lr=['0.0209218'], tr/val_loss:  2.334518/  2.327225, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-36  lr=['0.0205159'], tr/val_loss:  2.348536/  2.318403, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-37  lr=['0.0201039'], tr/val_loss:  2.339239/  2.322352, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-38  lr=['0.0196863'], tr/val_loss:  2.336214/  2.318084, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-39  lr=['0.0192634'], tr/val_loss:  2.333457/  2.326061, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-40  lr=['0.0188357'], tr/val_loss:  2.331918/  2.336850, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-41  lr=['0.0184037'], tr/val_loss:  2.333885/  2.311568, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-42  lr=['0.0179677'], tr/val_loss:  2.330783/  2.314323, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-43  lr=['0.0175281'], tr/val_loss:  2.337828/  2.325627, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-44  lr=['0.0170855'], tr/val_loss:  2.331449/  2.307659, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-45  lr=['0.0166402'], tr/val_loss:  2.337375/  2.336733, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  7.99it/s]\n",
      "epoch-46  lr=['0.0161927'], tr/val_loss:  2.337136/  2.325999, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-47  lr=['0.0157434'], tr/val_loss:  2.325666/  2.342918, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-48  lr=['0.0152927'], tr/val_loss:  2.325798/  2.318530, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-49  lr=['0.0148412'], tr/val_loss:  2.334567/  2.316277, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-50  lr=['0.0143892'], tr/val_loss:  2.320311/  2.338622, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-51  lr=['0.0139373'], tr/val_loss:  2.331639/  2.319673, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-52  lr=['0.0134857'], tr/val_loss:  2.329102/  2.319311, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-53  lr=['0.0130351'], tr/val_loss:  2.329692/  2.315116, tr:   8.07%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-54  lr=['0.0125858'], tr/val_loss:  2.317414/  2.317265, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-55  lr=['0.0121383'], tr/val_loss:  2.326655/  2.309505, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-56  lr=['0.0116930'], tr/val_loss:  2.328097/  2.312543, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-57  lr=['0.0112503'], tr/val_loss:  2.321171/  2.307720, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-58  lr=['0.0108108'], tr/val_loss:  2.317641/  2.309400, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-59  lr=['0.0103748'], tr/val_loss:  2.322886/  2.308800, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-60  lr=['0.0099427'], tr/val_loss:  2.316873/  2.308610, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-61  lr=['0.0095151'], tr/val_loss:  2.322983/  2.309871, tr:   7.87%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-62  lr=['0.0090922'], tr/val_loss:  2.318236/  2.310487, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-63  lr=['0.0086746'], tr/val_loss:  2.315720/  2.310812, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-64  lr=['0.0082626'], tr/val_loss:  2.314702/  2.305706, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-65  lr=['0.0078567'], tr/val_loss:  2.320449/  2.309075, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-66  lr=['0.0074572'], tr/val_loss:  2.315225/  2.307687, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-67  lr=['0.0070645'], tr/val_loss:  2.318645/  2.309548, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-68  lr=['0.0066791'], tr/val_loss:  2.317489/  2.304957, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-69  lr=['0.0063013'], tr/val_loss:  2.318635/  2.309982, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-70  lr=['0.0059315'], tr/val_loss:  2.312500/  2.305675, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-71  lr=['0.0055700'], tr/val_loss:  2.319673/  2.308976, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-72  lr=['0.0052172'], tr/val_loss:  2.309403/  2.303508, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-73  lr=['0.0048735'], tr/val_loss:  2.312596/  2.303667, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-74  lr=['0.0045391'], tr/val_loss:  2.311126/  2.304196, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-75  lr=['0.0042145'], tr/val_loss:  2.312529/  2.303612, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-76  lr=['0.0038999'], tr/val_loss:  2.308658/  2.303903, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-77  lr=['0.0035957'], tr/val_loss:  2.310598/  2.303234, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-78  lr=['0.0033021'], tr/val_loss:  2.310493/  2.303872, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-79  lr=['0.0030195'], tr/val_loss:  2.308181/  2.303061, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-80  lr=['0.0027481'], tr/val_loss:  2.306639/  2.302979, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-81  lr=['0.0024882'], tr/val_loss:  2.308324/  2.302817, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-82  lr=['0.0022400'], tr/val_loss:  2.306146/  2.302863, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-83  lr=['0.0020038'], tr/val_loss:  2.306428/  2.302827, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-84  lr=['0.0017799'], tr/val_loss:  2.306357/  2.302718, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-85  lr=['0.0015683'], tr/val_loss:  2.306251/  2.302734, tr:   8.17%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-86  lr=['0.0013695'], tr/val_loss:  2.304851/  2.302656, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-87  lr=['0.0011834'], tr/val_loss:  2.303955/  2.302713, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-88  lr=['0.0010105'], tr/val_loss:  2.305039/  2.302789, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-89  lr=['0.0008507'], tr/val_loss:  2.304651/  2.302675, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-90  lr=['0.0007043'], tr/val_loss:  2.303918/  2.302632, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-91  lr=['0.0005713'], tr/val_loss:  2.303844/  2.302610, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-92  lr=['0.0004521'], tr/val_loss:  2.303355/  2.302620, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-93  lr=['0.0003465'], tr/val_loss:  2.303087/  2.302620, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-94  lr=['0.0002549'], tr/val_loss:  2.303145/  2.302623, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-95  lr=['0.0001772'], tr/val_loss:  2.302969/  2.302623, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-96  lr=['0.0001135'], tr/val_loss:  2.302850/  2.302613, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-97  lr=['0.0000639'], tr/val_loss:  2.302864/  2.302611, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-98  lr=['0.0000284'], tr/val_loss:  2.302555/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-99  lr=['0.0000071'], tr/val_loss:  2.302649/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4639abdfb1f3470eb99f6a1ad03db512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▅▃▃▁▃▆▆█▃▆▁▁▅▅▃▃▃▅▃▅▅▅▁▃▁▃▃▅▅▆▁▆▅▅▁▁▃▁▅</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▇▅▄▃▅▇▄▂▇█▃▂▆▆▄▄▃▃▄▇▆▃▇▆▂▁▃▆▄▅▃▅▃▅▆▆▅▃▆▆</td></tr><tr><td>tr_epoch_loss</td><td>▅▅█▇▅▆▅▅▅▅▇▅▅▄▄▅▄▄▄▃▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄▄▄▃█▂▅▃▄▃▅▃▃▄▃▃▃▂▁▅▂▃▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30265</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-sweep-8</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/41bhc3p4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/41bhc3p4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_042409-41bhc3p4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ls1n03c0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06376118395822784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.7041093783675638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.360766325593478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_043440-ls1n03c0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ls1n03c0' target=\"_blank\">lemon-sweep-11</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ls1n03c0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ls1n03c0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0637612'], tr/val_loss:  1.925349/  1.983902, tr:  31.05%, val:  30.83%, val_best:  30.83%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-1   lr=['0.0637455'], tr/val_loss:  2.202056/  2.131369, tr:  29.52%, val:  30.83%, val_best:  30.83%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-2   lr=['0.0636983'], tr/val_loss:  2.348781/  2.868961, tr:  30.23%, val:  27.50%, val_best:  30.83%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-3   lr=['0.0636197'], tr/val_loss:  2.406187/  2.350328, tr:  26.97%, val:  33.33%, val_best:  33.33%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-4   lr=['0.0635098'], tr/val_loss:  3.106572/  2.572119, tr:  25.03%, val:  24.58%, val_best:  33.33%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-5   lr=['0.0633687'], tr/val_loss:  2.797110/  2.754735, tr:  24.00%, val:  10.00%, val_best:  33.33%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-6   lr=['0.0631965'], tr/val_loss:  2.734142/  3.169259, tr:  24.51%, val:  35.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-7   lr=['0.0629934'], tr/val_loss:  2.875893/  2.698862, tr:  18.90%, val:  16.25%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-8   lr=['0.0627596'], tr/val_loss:  2.900490/  2.388555, tr:  18.18%, val:  27.08%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-9   lr=['0.0624953'], tr/val_loss:  2.632071/  2.882137, tr:  26.97%, val:  30.42%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-10  lr=['0.0622008'], tr/val_loss:  2.631279/  3.043442, tr:  22.57%, val:  19.17%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-11  lr=['0.0618764'], tr/val_loss:  2.889361/  3.866492, tr:  13.07%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-12  lr=['0.0615224'], tr/val_loss:  3.085387/  2.924763, tr:   9.81%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-13  lr=['0.0611392'], tr/val_loss:  3.324417/  3.969601, tr:   9.81%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-14  lr=['0.0607270'], tr/val_loss:  3.089063/  3.520478, tr:   9.40%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-15  lr=['0.0602864'], tr/val_loss:  3.336102/  3.070366, tr:  10.83%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-16  lr=['0.0598178'], tr/val_loss:  3.005734/  3.127145, tr:  10.62%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-17  lr=['0.0593216'], tr/val_loss:  3.509584/  3.863130, tr:   9.60%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-18  lr=['0.0587983'], tr/val_loss:  3.455539/  3.529072, tr:   7.46%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-19  lr=['0.0582484'], tr/val_loss:  2.959939/  3.847479, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-20  lr=['0.0576725'], tr/val_loss:  3.359323/  3.608993, tr:   8.48%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-21  lr=['0.0570712'], tr/val_loss:  3.207136/  3.169118, tr:   9.60%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-22  lr=['0.0564450'], tr/val_loss:  3.051809/  3.014522, tr:  10.73%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-23  lr=['0.0557946'], tr/val_loss:  3.309895/  3.194298, tr:   8.89%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-24  lr=['0.0551205'], tr/val_loss:  3.198614/  3.429670, tr:  10.32%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-25  lr=['0.0544236'], tr/val_loss:  3.151923/  3.198147, tr:   9.19%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-26  lr=['0.0537044'], tr/val_loss:  2.973173/  3.080897, tr:  10.21%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-27  lr=['0.0529636'], tr/val_loss:  3.021211/  3.349319, tr:   8.99%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]\n",
      "epoch-28  lr=['0.0522020'], tr/val_loss:  2.752439/  3.953296, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-29  lr=['0.0514204'], tr/val_loss:  3.284544/  2.769226, tr:   8.48%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-30  lr=['0.0506195'], tr/val_loss:  3.035362/  4.513438, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-31  lr=['0.0498001'], tr/val_loss:  3.141513/  3.137788, tr:   9.30%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-32  lr=['0.0489631'], tr/val_loss:  2.883645/  3.157476, tr:  11.44%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-33  lr=['0.0481091'], tr/val_loss:  2.924057/  2.572380, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-34  lr=['0.0472392'], tr/val_loss:  2.979059/  3.727414, tr:  10.11%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-35  lr=['0.0463541'], tr/val_loss:  3.138093/  2.887804, tr:  11.34%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-36  lr=['0.0454547'], tr/val_loss:  3.272498/  3.391282, tr:  10.01%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-37  lr=['0.0445419'], tr/val_loss:  3.297791/  3.097778, tr:  10.11%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-38  lr=['0.0436166'], tr/val_loss:  3.101126/  3.027743, tr:   9.70%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-39  lr=['0.0426798'], tr/val_loss:  2.818855/  3.477269, tr:  11.13%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-40  lr=['0.0417322'], tr/val_loss:  2.938569/  3.093797, tr:  10.52%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-41  lr=['0.0407750'], tr/val_loss:  2.899248/  3.081054, tr:  10.21%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-42  lr=['0.0398090'], tr/val_loss:  2.804842/  2.655284, tr:   9.09%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-43  lr=['0.0388351'], tr/val_loss:  2.800218/  2.718151, tr:   9.91%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-44  lr=['0.0378544'], tr/val_loss:  2.897857/  3.295636, tr:   8.68%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-45  lr=['0.0368678'], tr/val_loss:  2.934412/  3.286167, tr:   9.50%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-46  lr=['0.0358763'], tr/val_loss:  3.110281/  2.942751, tr:  11.24%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-47  lr=['0.0348808'], tr/val_loss:  2.898307/  3.565180, tr:  10.01%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-48  lr=['0.0338824'], tr/val_loss:  2.912669/  2.525376, tr:  10.32%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-49  lr=['0.0328820'], tr/val_loss:  2.990877/  2.899103, tr:   8.68%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-50  lr=['0.0318806'], tr/val_loss:  2.660147/  2.590699, tr:  10.93%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-51  lr=['0.0308792'], tr/val_loss:  2.797235/  2.814004, tr:   8.27%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-52  lr=['0.0298788'], tr/val_loss:  2.823581/  3.035373, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-53  lr=['0.0288804'], tr/val_loss:  2.785593/  2.610813, tr:  10.01%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-54  lr=['0.0278849'], tr/val_loss:  2.615401/  2.644503, tr:   9.40%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-55  lr=['0.0268934'], tr/val_loss:  2.625299/  2.617368, tr:   9.09%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-56  lr=['0.0259068'], tr/val_loss:  2.737149/  2.729386, tr:   8.89%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-57  lr=['0.0249261'], tr/val_loss:  2.800542/  2.589283, tr:   9.60%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-58  lr=['0.0239522'], tr/val_loss:  2.586182/  2.730484, tr:  10.11%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-59  lr=['0.0229862'], tr/val_loss:  2.679538/  2.406009, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-60  lr=['0.0220289'], tr/val_loss:  2.581161/  2.416213, tr:  10.11%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-61  lr=['0.0210814'], tr/val_loss:  2.613393/  2.506954, tr:   9.50%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-62  lr=['0.0201446'], tr/val_loss:  2.546232/  2.528607, tr:  10.32%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-63  lr=['0.0192193'], tr/val_loss:  2.636192/  2.625715, tr:   9.60%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-64  lr=['0.0183065'], tr/val_loss:  2.521340/  2.461996, tr:   8.78%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-65  lr=['0.0174071'], tr/val_loss:  2.562956/  2.901560, tr:  10.62%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.13it/s]\n",
      "epoch-66  lr=['0.0165220'], tr/val_loss:  2.620759/  2.562108, tr:   8.68%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-67  lr=['0.0156521'], tr/val_loss:  2.534735/  2.488067, tr:  10.73%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-68  lr=['0.0147981'], tr/val_loss:  2.471119/  2.481378, tr:   8.99%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-69  lr=['0.0139610'], tr/val_loss:  2.468844/  2.482042, tr:  10.73%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-70  lr=['0.0131417'], tr/val_loss:  2.463931/  2.432221, tr:  10.32%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-71  lr=['0.0123408'], tr/val_loss:  2.439636/  2.473164, tr:  10.93%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-72  lr=['0.0115591'], tr/val_loss:  2.451833/  2.527036, tr:   9.30%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-73  lr=['0.0107976'], tr/val_loss:  2.458912/  2.477152, tr:  10.11%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-74  lr=['0.0100568'], tr/val_loss:  2.416423/  2.490021, tr:   9.40%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-75  lr=['0.0093376'], tr/val_loss:  2.445020/  2.393197, tr:   8.89%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-76  lr=['0.0086406'], tr/val_loss:  2.388455/  2.330809, tr:  10.42%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-77  lr=['0.0079666'], tr/val_loss:  2.407938/  2.386120, tr:  10.21%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-78  lr=['0.0073162'], tr/val_loss:  2.379957/  2.377963, tr:  11.54%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-79  lr=['0.0066900'], tr/val_loss:  2.377424/  2.372693, tr:   8.89%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-80  lr=['0.0060887'], tr/val_loss:  2.374253/  2.371243, tr:   9.50%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-81  lr=['0.0055128'], tr/val_loss:  2.360247/  2.388636, tr:  10.93%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-82  lr=['0.0049629'], tr/val_loss:  2.381997/  2.330209, tr:   8.17%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-83  lr=['0.0044396'], tr/val_loss:  2.350407/  2.337688, tr:   9.19%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-84  lr=['0.0039434'], tr/val_loss:  2.364750/  2.343988, tr:  10.21%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-85  lr=['0.0034748'], tr/val_loss:  2.346135/  2.333114, tr:   8.48%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-86  lr=['0.0030342'], tr/val_loss:  2.340172/  2.336284, tr:   9.30%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-87  lr=['0.0026220'], tr/val_loss:  2.333099/  2.309319, tr:   9.40%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-88  lr=['0.0022388'], tr/val_loss:  2.337818/  2.322251, tr:   8.78%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-89  lr=['0.0018848'], tr/val_loss:  2.333341/  2.311469, tr:   9.30%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-90  lr=['0.0015603'], tr/val_loss:  2.326097/  2.311604, tr:   8.17%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-91  lr=['0.0012659'], tr/val_loss:  2.321267/  2.318297, tr:   9.50%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-92  lr=['0.0010016'], tr/val_loss:  2.318848/  2.305569, tr:   8.07%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-93  lr=['0.0007678'], tr/val_loss:  2.314223/  2.303881, tr:   8.99%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-94  lr=['0.0005647'], tr/val_loss:  2.311908/  2.303409, tr:   7.05%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-95  lr=['0.0003925'], tr/val_loss:  2.307877/  2.303141, tr:   8.27%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-96  lr=['0.0002514'], tr/val_loss:  2.307006/  2.302916, tr:   9.70%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-97  lr=['0.0001415'], tr/val_loss:  2.306556/  2.302725, tr:   9.30%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-98  lr=['0.0000629'], tr/val_loss:  2.303624/  2.302665, tr:   9.70%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-99  lr=['0.0000157'], tr/val_loss:  2.302808/  2.302643, tr:  10.01%, val:  10.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d812160fc87c435ab9885661759d54f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▅▅▁▅▂▄▆▂▅▂▄▄▂▁▂▂▄▄▄▁▄▁▄▂▁█▂▄▂▁▅▁▄▄▁▁▂█▂</td></tr><tr><td>summary_val_acc</td><td>█▇▆▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>██▆▄▇▂▁▁▂▁▂▂▁▂▂▂▂▁▁▂▁▂▁▁▂▁▂▂▂▁▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>tr_epoch_loss</td><td>▁▃▆▅▄▆▆█▆▇▇▆▇▅▆▇▅▅▅▅▆▅▄▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>val_acc_best</td><td>▁▁▅█████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>█▇▆▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▄▃▄▄▅▇██▅▆▅▄▅▄▅▇▄▆▇▄▅▃▃▃▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30281</td></tr><tr><td>val_acc_best</td><td>0.35</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-11</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ls1n03c0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ls1n03c0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_043440-ls1n03c0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d2oc6n1k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03598060060388845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.4577644978445106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.1967019611003349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_044509-d2oc6n1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d2oc6n1k' target=\"_blank\">giddy-sweep-13</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d2oc6n1k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d2oc6n1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0359806'], tr/val_loss:  1.930392/  1.869487, tr:  30.54%, val:  30.42%, val_best:  30.42%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-1   lr=['0.0359717'], tr/val_loss:  2.034766/  1.778094, tr:  31.15%, val:  39.58%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-2   lr=['0.0359451'], tr/val_loss:  2.139713/  2.923828, tr:  28.40%, val:  32.50%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-3   lr=['0.0359008'], tr/val_loss:  2.636695/  2.927464, tr:  25.64%, val:  23.75%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-4   lr=['0.0358387'], tr/val_loss:  3.156893/  2.761775, tr:  22.17%, val:  22.08%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-5   lr=['0.0357591'], tr/val_loss:  3.158231/  4.135785, tr:  20.33%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-6   lr=['0.0356619'], tr/val_loss:  2.808592/  3.274436, tr:  19.51%, val:  11.25%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-7   lr=['0.0355473'], tr/val_loss:  3.243803/  4.816444, tr:  10.11%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-8   lr=['0.0354154'], tr/val_loss:  3.568200/  3.801810, tr:  10.52%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-9   lr=['0.0352663'], tr/val_loss:  3.297554/  3.511115, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-10  lr=['0.0351001'], tr/val_loss:  3.356224/  3.347488, tr:  10.83%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-11  lr=['0.0349170'], tr/val_loss:  3.467820/  4.372221, tr:  10.52%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-12  lr=['0.0347173'], tr/val_loss:  3.152158/  2.992778, tr:  11.64%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-13  lr=['0.0345010'], tr/val_loss:  3.592709/  3.911133, tr:   9.60%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-14  lr=['0.0342684'], tr/val_loss:  3.360706/  3.805705, tr:   9.50%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-15  lr=['0.0340198'], tr/val_loss:  3.858919/  3.676421, tr:  10.01%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-16  lr=['0.0337553'], tr/val_loss:  3.205163/  4.116338, tr:  10.21%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-17  lr=['0.0334753'], tr/val_loss:  3.884337/  4.579669, tr:  10.32%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-18  lr=['0.0331800'], tr/val_loss:  4.144923/  3.990754, tr:   9.70%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-19  lr=['0.0328697'], tr/val_loss:  3.361893/  3.675412, tr:   8.38%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.33it/s]\n",
      "epoch-20  lr=['0.0325448'], tr/val_loss:  3.331200/  3.598161, tr:   8.89%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-21  lr=['0.0322054'], tr/val_loss:  3.201140/  3.353937, tr:   9.19%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-22  lr=['0.0318521'], tr/val_loss:  3.070404/  2.877251, tr:  10.11%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-23  lr=['0.0314850'], tr/val_loss:  3.379195/  3.340756, tr:  11.34%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-24  lr=['0.0311047'], tr/val_loss:  3.152406/  2.863750, tr:  10.83%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-25  lr=['0.0307114'], tr/val_loss:  3.221375/  3.232217, tr:  10.52%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-26  lr=['0.0303055'], tr/val_loss:  3.092474/  3.230397, tr:   8.99%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-27  lr=['0.0298875'], tr/val_loss:  3.083752/  3.370004, tr:   8.89%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-28  lr=['0.0294577'], tr/val_loss:  2.767051/  3.884421, tr:  10.52%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-29  lr=['0.0290167'], tr/val_loss:  3.268424/  2.917157, tr:   8.99%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-30  lr=['0.0285647'], tr/val_loss:  3.171238/  4.704379, tr:   9.81%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-31  lr=['0.0281023'], tr/val_loss:  3.233571/  3.067757, tr:   9.09%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-32  lr=['0.0276300'], tr/val_loss:  2.913297/  3.111581, tr:   9.81%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-33  lr=['0.0271481'], tr/val_loss:  2.904019/  2.685421, tr:   9.19%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-34  lr=['0.0266572'], tr/val_loss:  3.068445/  3.886117, tr:   9.60%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-35  lr=['0.0261577'], tr/val_loss:  3.213711/  2.995086, tr:  10.52%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-36  lr=['0.0256502'], tr/val_loss:  3.305193/  3.470650, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-37  lr=['0.0251351'], tr/val_loss:  3.459412/  3.227578, tr:   8.78%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:07<00:00,  8.80it/s]\n",
      "epoch-38  lr=['0.0246130'], tr/val_loss:  3.156862/  3.111776, tr:  10.21%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-39  lr=['0.0240843'], tr/val_loss:  2.843345/  3.654110, tr:  11.34%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-40  lr=['0.0235496'], tr/val_loss:  3.023977/  3.294176, tr:  11.44%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-41  lr=['0.0230094'], tr/val_loss:  2.976962/  3.121349, tr:  10.52%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-42  lr=['0.0224643'], tr/val_loss:  2.850564/  2.675262, tr:   8.68%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-43  lr=['0.0219148'], tr/val_loss:  2.834680/  2.656434, tr:  10.62%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-44  lr=['0.0213613'], tr/val_loss:  2.922549/  3.421414, tr:   8.68%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-45  lr=['0.0208046'], tr/val_loss:  3.020989/  3.425329, tr:   9.70%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-46  lr=['0.0202451'], tr/val_loss:  3.170496/  2.983745, tr:  10.93%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-47  lr=['0.0196833'], tr/val_loss:  2.928765/  3.660027, tr:  10.21%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-48  lr=['0.0191199'], tr/val_loss:  2.952242/  2.511858, tr:  10.42%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-49  lr=['0.0185554'], tr/val_loss:  3.046059/  2.953130, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-50  lr=['0.0179903'], tr/val_loss:  2.675827/  2.670281, tr:  10.42%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-51  lr=['0.0174252'], tr/val_loss:  2.845668/  2.846521, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-52  lr=['0.0168607'], tr/val_loss:  2.841122/  3.107852, tr:  10.21%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-53  lr=['0.0162973'], tr/val_loss:  2.824938/  2.567441, tr:  10.11%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-54  lr=['0.0157355'], tr/val_loss:  2.659549/  2.689393, tr:   9.09%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-55  lr=['0.0151760'], tr/val_loss:  2.653572/  2.621448, tr:   9.19%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-56  lr=['0.0146193'], tr/val_loss:  2.760442/  2.788785, tr:   9.40%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-57  lr=['0.0140658'], tr/val_loss:  2.838770/  2.644284, tr:   9.09%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-58  lr=['0.0135163'], tr/val_loss:  2.603098/  2.762855, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-59  lr=['0.0129712'], tr/val_loss:  2.693475/  2.446387, tr:  10.42%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-60  lr=['0.0124310'], tr/val_loss:  2.602472/  2.417766, tr:   9.50%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:07<00:00,  8.72it/s]\n",
      "epoch-61  lr=['0.0118963'], tr/val_loss:  2.642481/  2.521149, tr:   9.19%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-62  lr=['0.0113676'], tr/val_loss:  2.560609/  2.549759, tr:  10.42%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-63  lr=['0.0108455'], tr/val_loss:  2.651571/  2.651220, tr:  10.32%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-64  lr=['0.0103304'], tr/val_loss:  2.539601/  2.486340, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-65  lr=['0.0098229'], tr/val_loss:  2.580304/  2.882870, tr:  11.13%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-66  lr=['0.0093234'], tr/val_loss:  2.635349/  2.608033, tr:   8.48%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-67  lr=['0.0088325'], tr/val_loss:  2.543888/  2.501289, tr:  11.13%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-68  lr=['0.0083506'], tr/val_loss:  2.480617/  2.501917, tr:   9.40%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-69  lr=['0.0078783'], tr/val_loss:  2.476961/  2.475777, tr:  10.62%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-70  lr=['0.0074159'], tr/val_loss:  2.472671/  2.474358, tr:  10.11%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-71  lr=['0.0069639'], tr/val_loss:  2.449080/  2.505585, tr:  11.03%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-72  lr=['0.0065229'], tr/val_loss:  2.460808/  2.561027, tr:   9.40%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-73  lr=['0.0060931'], tr/val_loss:  2.470927/  2.487909, tr:  10.32%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-74  lr=['0.0056751'], tr/val_loss:  2.424798/  2.491823, tr:   9.30%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-75  lr=['0.0052692'], tr/val_loss:  2.450420/  2.387844, tr:  10.11%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-76  lr=['0.0048759'], tr/val_loss:  2.393596/  2.341641, tr:  10.32%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-77  lr=['0.0044956'], tr/val_loss:  2.414530/  2.397081, tr:  10.83%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-78  lr=['0.0041285'], tr/val_loss:  2.384361/  2.386617, tr:  11.24%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-79  lr=['0.0037752'], tr/val_loss:  2.382498/  2.376226, tr:   8.89%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-80  lr=['0.0034358'], tr/val_loss:  2.378679/  2.369020, tr:  10.01%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-81  lr=['0.0031109'], tr/val_loss:  2.364249/  2.391365, tr:  10.83%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-82  lr=['0.0028006'], tr/val_loss:  2.385305/  2.334925, tr:   8.38%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-83  lr=['0.0025053'], tr/val_loss:  2.354990/  2.341248, tr:   9.40%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-84  lr=['0.0022253'], tr/val_loss:  2.368253/  2.344894, tr:   9.91%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-85  lr=['0.0019608'], tr/val_loss:  2.349135/  2.335274, tr:   8.07%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-86  lr=['0.0017122'], tr/val_loss:  2.342637/  2.337588, tr:   9.40%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-87  lr=['0.0014796'], tr/val_loss:  2.334981/  2.309187, tr:   9.19%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-88  lr=['0.0012633'], tr/val_loss:  2.339331/  2.323889, tr:   9.09%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-89  lr=['0.0010636'], tr/val_loss:  2.334880/  2.311573, tr:   9.19%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-90  lr=['0.0008805'], tr/val_loss:  2.327561/  2.311869, tr:   7.87%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-91  lr=['0.0007143'], tr/val_loss:  2.322218/  2.320513, tr:   9.70%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-92  lr=['0.0005652'], tr/val_loss:  2.319571/  2.306088, tr:   8.27%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-93  lr=['0.0004333'], tr/val_loss:  2.315016/  2.303994, tr:   9.50%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-94  lr=['0.0003187'], tr/val_loss:  2.312407/  2.303558, tr:   7.25%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-95  lr=['0.0002215'], tr/val_loss:  2.308096/  2.303241, tr:   8.48%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-96  lr=['0.0001419'], tr/val_loss:  2.307274/  2.302919, tr:  10.01%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-97  lr=['0.0000798'], tr/val_loss:  2.306772/  2.302738, tr:   8.99%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-98  lr=['0.0000355'], tr/val_loss:  2.303682/  2.302664, tr:   9.60%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-99  lr=['0.0000089'], tr/val_loss:  2.302809/  2.302648, tr:  10.01%, val:  10.00%, val_best:  39.58%: 100%|██████████| 62/62 [34:45<00:00, 33.64s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51559bb775b4a50bfe390f87f291b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▆▆█▂▂▂▂▂▂▅▂▄▄▂▁▄▂▄▂▄▁▄▂▄▂▁█▂▄▂▁▅▁▄▁▁▁▂█▁</td></tr><tr><td>summary_val_acc</td><td>▇█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>█▇▅▂▂▂▁▂▁▁▂▁▁▁▂▁▂▁▁▂▂▂▁▁▂▁▂▂▂▁▂▂▁▁▂▁▁▁▁▁</td></tr><tr><td>tr_epoch_loss</td><td>▁▂▅▆▆▅▆█▆▆▅▅▆▅▆▆▄▄▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▇█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▄▃█▅▄▆▇▅▅▃▄▃▄▄▄▅▃▅▅▄▄▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30281</td></tr><tr><td>val_acc_best</td><td>0.39583</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-13</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d2oc6n1k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d2oc6n1k</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_044509-d2oc6n1k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k8x58621 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.020101989540250532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.818954878309186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.8579401232931938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_053025-k8x58621</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k8x58621' target=\"_blank\">firm-sweep-19</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k8x58621' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k8x58621</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0201020'], tr/val_loss:  1.718626/  1.490150, tr:  38.41%, val:  44.58%, val_best:  44.58%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-1   lr=['0.0200970'], tr/val_loss:  1.312460/  1.392895, tr:  49.03%, val:  51.25%, val_best:  51.25%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-2   lr=['0.0200822'], tr/val_loss:  1.225218/  1.454066, tr:  52.91%, val:  45.83%, val_best:  51.25%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-3   lr=['0.0200574'], tr/val_loss:  1.099009/  1.568477, tr:  60.47%, val:  50.42%, val_best:  51.25%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-4   lr=['0.0200227'], tr/val_loss:  1.131011/  1.399345, tr:  57.00%, val:  50.00%, val_best:  51.25%: 100%|██████████| 62/62 [01:24<00:00,  1.36s/it]\n",
      "epoch-5   lr=['0.0199782'], tr/val_loss:  1.034480/  1.661380, tr:  60.67%, val:  45.42%, val_best:  51.25%: 100%|██████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "epoch-6   lr=['0.0199240'], tr/val_loss:  1.065985/  1.614216, tr:  59.75%, val:  44.58%, val_best:  51.25%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-7   lr=['0.0198599'], tr/val_loss:  1.026543/  1.602564, tr:  63.33%, val:  45.83%, val_best:  51.25%: 100%|██████████| 62/62 [01:18<00:00,  1.26s/it]\n",
      "epoch-8   lr=['0.0197862'], tr/val_loss:  0.978670/  1.355440, tr:  62.82%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-9   lr=['0.0197029'], tr/val_loss:  0.933126/  1.377306, tr:  62.82%, val:  47.92%, val_best:  57.08%: 100%|██████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "epoch-10  lr=['0.0196101'], tr/val_loss:  0.839765/  1.268493, tr:  70.68%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-11  lr=['0.0195078'], tr/val_loss:  0.888819/  1.485599, tr:  67.62%, val:  54.58%, val_best:  63.33%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-12  lr=['0.0193962'], tr/val_loss:  0.821094/  1.243962, tr:  69.36%, val:  62.92%, val_best:  63.33%: 100%|██████████| 62/62 [01:20<00:00,  1.31s/it]\n",
      "epoch-13  lr=['0.0192753'], tr/val_loss:  0.767961/  1.335105, tr:  71.91%, val:  61.25%, val_best:  63.33%: 100%|██████████| 62/62 [01:10<00:00,  1.14s/it]\n",
      "epoch-14  lr=['0.0191454'], tr/val_loss:  0.724862/  1.352588, tr:  74.67%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-15  lr=['0.0190065'], tr/val_loss:  0.693817/  1.326779, tr:  74.46%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [01:24<00:00,  1.36s/it]\n",
      "epoch-16  lr=['0.0188587'], tr/val_loss:  0.758981/  1.469458, tr:  73.44%, val:  55.00%, val_best:  64.17%: 100%|██████████| 62/62 [01:20<00:00,  1.31s/it]\n",
      "epoch-17  lr=['0.0187023'], tr/val_loss:  0.711605/  1.270527, tr:  70.89%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [01:24<00:00,  1.37s/it]\n",
      "epoch-18  lr=['0.0185373'], tr/val_loss:  0.706773/  1.233220, tr:  74.77%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-19  lr=['0.0183640'], tr/val_loss:  0.626031/  1.255076, tr:  77.22%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-20  lr=['0.0181824'], tr/val_loss:  0.590598/  1.393753, tr:  77.73%, val:  61.25%, val_best:  68.33%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-21  lr=['0.0179928'], tr/val_loss:  0.575038/  1.392720, tr:  78.55%, val:  62.08%, val_best:  68.33%: 100%|██████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "epoch-22  lr=['0.0177954'], tr/val_loss:  0.662673/  1.303829, tr:  75.59%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-23  lr=['0.0175904'], tr/val_loss:  0.607656/  1.544635, tr:  78.86%, val:  65.83%, val_best:  70.42%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-24  lr=['0.0173779'], tr/val_loss:  0.635851/  1.649046, tr:  78.35%, val:  51.25%, val_best:  70.42%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-25  lr=['0.0171581'], tr/val_loss:  0.588332/  1.413005, tr:  80.08%, val:  66.25%, val_best:  70.42%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-26  lr=['0.0169314'], tr/val_loss:  0.525010/  1.396679, tr:  80.69%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-27  lr=['0.0166978'], tr/val_loss:  0.482935/  1.436512, tr:  82.02%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-28  lr=['0.0164577'], tr/val_loss:  0.470482/  1.413606, tr:  85.80%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-29  lr=['0.0162113'], tr/val_loss:  0.463396/  1.452413, tr:  83.66%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-30  lr=['0.0159588'], tr/val_loss:  0.492837/  1.291167, tr:  83.35%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [01:22<00:00,  1.34s/it]\n",
      "epoch-31  lr=['0.0157005'], tr/val_loss:  0.496576/  1.546581, tr:  84.88%, val:  60.42%, val_best:  73.75%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-32  lr=['0.0154366'], tr/val_loss:  0.513199/  1.489127, tr:  82.53%, val:  62.08%, val_best:  73.75%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-33  lr=['0.0151674'], tr/val_loss:  0.412635/  1.464644, tr:  85.70%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-34  lr=['0.0148931'], tr/val_loss:  0.412868/  1.541319, tr:  86.31%, val:  69.58%, val_best:  73.75%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-35  lr=['0.0146141'], tr/val_loss:  0.427750/  1.632041, tr:  85.39%, val:  65.42%, val_best:  73.75%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-36  lr=['0.0143305'], tr/val_loss:  0.423241/  1.662618, tr:  86.52%, val:  60.42%, val_best:  73.75%: 100%|██████████| 62/62 [01:22<00:00,  1.32s/it]\n",
      "epoch-37  lr=['0.0140427'], tr/val_loss:  0.408716/  1.475594, tr:  85.80%, val:  69.17%, val_best:  73.75%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-38  lr=['0.0137510'], tr/val_loss:  0.375203/  1.577042, tr:  89.79%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [01:24<00:00,  1.36s/it]\n",
      "epoch-39  lr=['0.0134556'], tr/val_loss:  0.354423/  1.700191, tr:  91.93%, val:  61.67%, val_best:  73.75%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-40  lr=['0.0131569'], tr/val_loss:  0.405343/  1.615460, tr:  87.13%, val:  68.33%, val_best:  73.75%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-41  lr=['0.0128551'], tr/val_loss:  0.322500/  1.386996, tr:  91.52%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-42  lr=['0.0125506'], tr/val_loss:  0.274260/  1.544804, tr:  93.56%, val:  71.67%, val_best:  74.58%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-43  lr=['0.0122436'], tr/val_loss:  0.276529/  1.591758, tr:  94.48%, val:  71.67%, val_best:  74.58%: 100%|██████████| 62/62 [01:18<00:00,  1.27s/it]\n",
      "epoch-44  lr=['0.0119344'], tr/val_loss:  0.263200/  1.512654, tr:  95.40%, val:  71.67%, val_best:  74.58%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-45  lr=['0.0116233'], tr/val_loss:  0.228918/  1.576266, tr:  94.89%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [01:19<00:00,  1.29s/it]\n",
      "epoch-46  lr=['0.0113107'], tr/val_loss:  0.224946/  1.593752, tr:  97.04%, val:  71.67%, val_best:  76.67%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-47  lr=['0.0109969'], tr/val_loss:  0.241304/  1.637122, tr:  96.53%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-48  lr=['0.0106821'], tr/val_loss:  0.233778/  1.646004, tr:  96.32%, val:  71.25%, val_best:  76.67%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-49  lr=['0.0103667'], tr/val_loss:  0.234099/  1.706774, tr:  93.77%, val:  67.50%, val_best:  76.67%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-50  lr=['0.0100510'], tr/val_loss:  0.170846/  1.607846, tr:  96.83%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [01:19<00:00,  1.29s/it]\n",
      "epoch-51  lr=['0.0097353'], tr/val_loss:  0.149048/  1.671792, tr:  98.57%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-52  lr=['0.0094199'], tr/val_loss:  0.147608/  1.720298, tr:  98.88%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-53  lr=['0.0091051'], tr/val_loss:  0.124774/  1.821490, tr:  99.28%, val:  69.58%, val_best:  76.67%: 100%|██████████| 62/62 [01:19<00:00,  1.29s/it]\n",
      "epoch-54  lr=['0.0087913'], tr/val_loss:  0.120402/  1.866749, tr:  98.47%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-55  lr=['0.0084787'], tr/val_loss:  0.098955/  1.807588, tr:  99.39%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-56  lr=['0.0081676'], tr/val_loss:  0.080527/  1.801162, tr:  99.69%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-57  lr=['0.0078584'], tr/val_loss:  0.078146/  1.827042, tr:  99.69%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-58  lr=['0.0075514'], tr/val_loss:  0.079323/  1.879178, tr:  99.69%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-59  lr=['0.0072469'], tr/val_loss:  0.053450/  1.848819, tr:  99.90%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [01:06<00:00,  1.07s/it]\n",
      "epoch-60  lr=['0.0069451'], tr/val_loss:  0.048390/  1.880153, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-61  lr=['0.0066463'], tr/val_loss:  0.048811/  1.804243, tr:  99.80%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-62  lr=['0.0063510'], tr/val_loss:  0.034911/  1.871319, tr:  99.90%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [01:24<00:00,  1.36s/it]\n",
      "epoch-63  lr=['0.0060593'], tr/val_loss:  0.033497/  1.898828, tr: 100.00%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-64  lr=['0.0057715'], tr/val_loss:  0.028172/  1.960273, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-65  lr=['0.0054879'], tr/val_loss:  0.022980/  1.961927, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-66  lr=['0.0052089'], tr/val_loss:  0.022870/  1.961380, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-67  lr=['0.0049346'], tr/val_loss:  0.023980/  1.984280, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:22<00:00,  1.32s/it]\n",
      "epoch-68  lr=['0.0046654'], tr/val_loss:  0.019448/  1.985840, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-69  lr=['0.0044015'], tr/val_loss:  0.012024/  1.962334, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-70  lr=['0.0041432'], tr/val_loss:  0.011318/  2.002807, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-71  lr=['0.0038907'], tr/val_loss:  0.010180/  1.978691, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-72  lr=['0.0036442'], tr/val_loss:  0.008314/  1.998940, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:22<00:00,  1.32s/it]\n",
      "epoch-73  lr=['0.0034042'], tr/val_loss:  0.007733/  1.994331, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-74  lr=['0.0031706'], tr/val_loss:  0.007279/  2.012377, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-75  lr=['0.0029439'], tr/val_loss:  0.006701/  2.022716, tr: 100.00%, val:  75.83%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-76  lr=['0.0027241'], tr/val_loss:  0.006411/  2.019274, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-77  lr=['0.0025116'], tr/val_loss:  0.006195/  2.020207, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "epoch-78  lr=['0.0023066'], tr/val_loss:  0.006012/  2.030965, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-79  lr=['0.0021092'], tr/val_loss:  0.006012/  2.040053, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-80  lr=['0.0019196'], tr/val_loss:  0.005585/  2.044768, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-81  lr=['0.0017380'], tr/val_loss:  0.005277/  2.045243, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-82  lr=['0.0015647'], tr/val_loss:  0.005155/  2.046843, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:18<00:00,  1.26s/it]\n",
      "epoch-83  lr=['0.0013997'], tr/val_loss:  0.005066/  2.058183, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:18<00:00,  1.26s/it]\n",
      "epoch-84  lr=['0.0012432'], tr/val_loss:  0.005649/  2.058575, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-85  lr=['0.0010955'], tr/val_loss:  0.005214/  2.056457, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-86  lr=['0.0009566'], tr/val_loss:  0.005144/  2.055889, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-87  lr=['0.0008266'], tr/val_loss:  0.005146/  2.060539, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-88  lr=['0.0007058'], tr/val_loss:  0.004921/  2.059515, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:19<00:00,  1.29s/it]\n",
      "epoch-89  lr=['0.0005942'], tr/val_loss:  0.004902/  2.058138, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-90  lr=['0.0004919'], tr/val_loss:  0.004872/  2.061027, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-91  lr=['0.0003991'], tr/val_loss:  0.004984/  2.053725, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-92  lr=['0.0003158'], tr/val_loss:  0.004937/  2.054008, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:19<00:00,  1.29s/it]\n",
      "epoch-93  lr=['0.0002421'], tr/val_loss:  0.005311/  2.056679, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:19<00:00,  1.27s/it]\n",
      "epoch-94  lr=['0.0001780'], tr/val_loss:  0.004827/  2.053202, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:20<00:00,  1.29s/it]\n",
      "epoch-95  lr=['0.0001237'], tr/val_loss:  0.004957/  2.054786, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:19<00:00,  1.28s/it]\n",
      "epoch-96  lr=['0.0000793'], tr/val_loss:  0.004801/  2.052810, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-97  lr=['0.0000446'], tr/val_loss:  0.005011/  2.052624, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:00<00:00,  1.02it/s]\n",
      "epoch-98  lr=['0.0000198'], tr/val_loss:  0.005115/  2.052220, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-99  lr=['0.0000050'], tr/val_loss:  0.004847/  2.052227, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [01:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f452b461cc4c25a5a23e3f0b425ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▅▅▄▄▇▇▆▇▇▇▅▇▇▇█▇██████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▁▂▅▅▅▆▅▂▇▆▅▅▆▅▇▇▇▆▇▇▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇█▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▆▅▅▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▁▂▅▅▅▆▅▂▇▆▅▅▆▅▇▇▇▆▇▇▇████████████████</td></tr><tr><td>val_loss</td><td>▃▃▂▄▂▁▂▁▁▂▄▂▃▃▄▃▅▄▃▄▅▅▆▆▆▆▇▇█▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00485</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.77083</td></tr><tr><td>val_loss</td><td>2.05223</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-sweep-19</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k8x58621' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k8x58621</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_053025-k8x58621/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iohluhpq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.037843012711135125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5.435274277021482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.3011636125865671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_074521-iohluhpq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iohluhpq' target=\"_blank\">dark-sweep-22</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iohluhpq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iohluhpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0378430'], tr/val_loss: 13.158938/ 22.987381, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.18s/it]\n",
      "epoch-1   lr=['0.0378337'], tr/val_loss: 22.999079/ 18.889345, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.23s/it]\n",
      "epoch-2   lr=['0.0378057'], tr/val_loss: 22.843861/ 13.544803, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-3   lr=['0.0377590'], tr/val_loss: 16.242373/ 17.822638, tr:   8.07%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-4   lr=['0.0376938'], tr/val_loss: 22.018347/ 23.075563, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-5   lr=['0.0376101'], tr/val_loss: 20.534506/ 22.403992, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-6   lr=['0.0375079'], tr/val_loss: 18.775911/ 22.234364, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-7   lr=['0.0373873'], tr/val_loss: 15.244994/ 14.441061, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.18s/it]\n",
      "epoch-8   lr=['0.0372486'], tr/val_loss: 12.621840/ 11.944543, tr:  11.54%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-9   lr=['0.0370917'], tr/val_loss: 19.428846/ 33.807877, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-10  lr=['0.0369169'], tr/val_loss: 23.219435/  9.742591, tr:  11.44%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-11  lr=['0.0367244'], tr/val_loss: 15.797117/ 20.651819, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-12  lr=['0.0365143'], tr/val_loss: 18.074823/  8.895080, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-13  lr=['0.0362868'], tr/val_loss: 14.210412/ 15.299587, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-14  lr=['0.0360422'], tr/val_loss: 17.889509/ 13.977843, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:11<00:00,  1.15s/it]\n",
      "epoch-15  lr=['0.0357807'], tr/val_loss: 13.995255/ 14.477330, tr:  11.64%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:12<00:00,  1.18s/it]\n",
      "epoch-16  lr=['0.0355025'], tr/val_loss: 12.109818/ 12.045649, tr:  11.54%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-17  lr=['0.0352080'], tr/val_loss: 17.989588/ 30.389872, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-18  lr=['0.0348975'], tr/val_loss: 16.322950/ 20.179234, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-19  lr=['0.0345711'], tr/val_loss: 13.453792/ 11.665455, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-20  lr=['0.0342293'], tr/val_loss: 13.102453/ 14.055929, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-21  lr=['0.0338724'], tr/val_loss: 14.258857/ 12.840472, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.19s/it]\n",
      "epoch-22  lr=['0.0335008'], tr/val_loss: 16.526302/ 22.542425, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-23  lr=['0.0331147'], tr/val_loss: 15.626584/ 14.071692, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-24  lr=['0.0327147'], tr/val_loss: 14.571072/ 21.879147, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-25  lr=['0.0323010'], tr/val_loss: 15.028559/ 22.436073, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-26  lr=['0.0318742'], tr/val_loss: 14.815506/ 17.795238, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-27  lr=['0.0314345'], tr/val_loss: 11.775043/ 14.369175, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-28  lr=['0.0309825'], tr/val_loss:  9.860979/ 12.280842, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-29  lr=['0.0305186'], tr/val_loss: 13.364914/ 13.149187, tr:   8.17%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-30  lr=['0.0300433'], tr/val_loss: 13.625161/ 15.807867, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-31  lr=['0.0295570'], tr/val_loss: 11.379663/  9.933127, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-32  lr=['0.0290602'], tr/val_loss: 11.254408/ 11.805030, tr:  12.26%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-33  lr=['0.0285533'], tr/val_loss:  9.674646/  7.063887, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-34  lr=['0.0280370'], tr/val_loss:  8.153267/ 10.556433, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-35  lr=['0.0275117'], tr/val_loss: 13.065858/ 13.483060, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-36  lr=['0.0269779'], tr/val_loss: 10.936093/ 10.847510, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-37  lr=['0.0264361'], tr/val_loss:  9.511142/ 11.542411, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-38  lr=['0.0258870'], tr/val_loss: 10.656338/  7.028604, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-39  lr=['0.0253309'], tr/val_loss:  8.075347/  9.774806, tr:   8.07%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-40  lr=['0.0247686'], tr/val_loss:  7.435929/  9.266936, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-41  lr=['0.0242004'], tr/val_loss:  6.681050/  5.624969, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.19s/it]\n",
      "epoch-42  lr=['0.0236271'], tr/val_loss:  5.760995/  5.916770, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-43  lr=['0.0230491'], tr/val_loss:  4.801374/  6.534895, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-44  lr=['0.0224670'], tr/val_loss:  5.779376/  5.810256, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-45  lr=['0.0218815'], tr/val_loss:  6.689043/  8.163252, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-46  lr=['0.0212930'], tr/val_loss:  6.624290/  4.481664, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-47  lr=['0.0207022'], tr/val_loss:  4.520663/  4.791018, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:01<00:00,  1.01it/s]\n",
      "epoch-48  lr=['0.0201096'], tr/val_loss:  4.100790/  5.068082, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-49  lr=['0.0195158'], tr/val_loss:  5.335816/  6.391071, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:07<00:00,  1.09s/it]\n",
      "epoch-50  lr=['0.0189215'], tr/val_loss:  4.983250/  5.018270, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.19s/it]\n",
      "epoch-51  lr=['0.0183272'], tr/val_loss:  4.086581/  4.974405, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.18s/it]\n",
      "epoch-52  lr=['0.0177334'], tr/val_loss:  4.636518/  4.789020, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-53  lr=['0.0171408'], tr/val_loss:  3.737579/  4.396493, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-54  lr=['0.0165500'], tr/val_loss:  4.179279/  4.039693, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-55  lr=['0.0159615'], tr/val_loss:  3.899569/  4.466188, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-56  lr=['0.0153760'], tr/val_loss:  4.151864/  4.602840, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-57  lr=['0.0147939'], tr/val_loss:  3.647976/  4.115547, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-58  lr=['0.0142159'], tr/val_loss:  3.700432/  3.190111, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-59  lr=['0.0136426'], tr/val_loss:  3.191945/  3.083470, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:17<00:00,  1.25s/it]\n",
      "epoch-60  lr=['0.0130744'], tr/val_loss:  3.206058/  4.024092, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-61  lr=['0.0125121'], tr/val_loss:  3.251591/  3.398818, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-62  lr=['0.0119560'], tr/val_loss:  3.128858/  3.170881, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-63  lr=['0.0114069'], tr/val_loss:  3.232427/  3.564587, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-64  lr=['0.0108651'], tr/val_loss:  2.909825/  3.976343, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:17<00:00,  1.24s/it]\n",
      "epoch-65  lr=['0.0103313'], tr/val_loss:  3.225389/  3.886010, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.23s/it]\n",
      "epoch-66  lr=['0.0098060'], tr/val_loss:  3.208461/  3.452258, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-67  lr=['0.0092897'], tr/val_loss:  2.917884/  4.196651, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.18s/it]\n",
      "epoch-68  lr=['0.0087829'], tr/val_loss:  2.910167/  2.943513, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-69  lr=['0.0082860'], tr/val_loss:  2.792737/  2.871251, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-70  lr=['0.0077997'], tr/val_loss:  2.848993/  3.314120, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-71  lr=['0.0073244'], tr/val_loss:  2.739800/  2.951408, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-72  lr=['0.0068605'], tr/val_loss:  2.734560/  2.843078, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-73  lr=['0.0064085'], tr/val_loss:  2.799525/  2.523295, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-74  lr=['0.0059688'], tr/val_loss:  2.838185/  2.616094, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-75  lr=['0.0055420'], tr/val_loss:  2.687971/  2.515236, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-76  lr=['0.0051283'], tr/val_loss:  2.569609/  2.841897, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-77  lr=['0.0047283'], tr/val_loss:  2.591812/  2.439533, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-78  lr=['0.0043422'], tr/val_loss:  2.570457/  2.438604, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-79  lr=['0.0039706'], tr/val_loss:  2.568421/  2.568383, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.21s/it]\n",
      "epoch-80  lr=['0.0036137'], tr/val_loss:  2.546252/  2.377064, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-81  lr=['0.0032719'], tr/val_loss:  2.492897/  2.469637, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-82  lr=['0.0029456'], tr/val_loss:  2.516310/  2.360765, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-83  lr=['0.0026350'], tr/val_loss:  2.496650/  2.375846, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-84  lr=['0.0023405'], tr/val_loss:  2.468775/  2.378841, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:17<00:00,  1.25s/it]\n",
      "epoch-85  lr=['0.0020623'], tr/val_loss:  2.446750/  2.493843, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.19s/it]\n",
      "epoch-86  lr=['0.0018008'], tr/val_loss:  2.399462/  2.413397, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-87  lr=['0.0015562'], tr/val_loss:  2.392914/  2.363135, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.19s/it]\n",
      "epoch-88  lr=['0.0013287'], tr/val_loss:  2.382248/  2.383802, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-89  lr=['0.0011186'], tr/val_loss:  2.353099/  2.382069, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.24s/it]\n",
      "epoch-90  lr=['0.0009261'], tr/val_loss:  2.368233/  2.337036, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.21s/it]\n",
      "epoch-91  lr=['0.0007513'], tr/val_loss:  2.351243/  2.373865, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-92  lr=['0.0005945'], tr/val_loss:  2.341167/  2.345632, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-93  lr=['0.0004557'], tr/val_loss:  2.332589/  2.311177, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-94  lr=['0.0003352'], tr/val_loss:  2.327053/  2.316927, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-95  lr=['0.0002330'], tr/val_loss:  2.314475/  2.311881, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-96  lr=['0.0001492'], tr/val_loss:  2.313819/  2.304580, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-97  lr=['0.0000840'], tr/val_loss:  2.313953/  2.304210, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:09<00:00,  1.12s/it]\n",
      "epoch-98  lr=['0.0000373'], tr/val_loss:  2.305980/  2.302932, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:13<00:00,  1.18s/it]\n",
      "epoch-99  lr=['0.0000093'], tr/val_loss:  2.303242/  2.302855, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf78e68cdd94ddaa80fc20b5458d839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▅▄▅▄▂▂▅▁▂▂▄▂▄▆▁▂▂▄▂▂▄▁▅▆▅▁▂▁▄▄▁▂▁▂█▁▂▂█▁</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▄▃▆▅▃▅▃▃▆▃▅▃▁█▃▃▁▃▄▃▆▅▅▃▆▅▅▄▃▃▄▃▄▃▅▄▃▃▂▃</td></tr><tr><td>tr_epoch_loss</td><td>▅██▅▇▆▆▆▅▅▅▅▅▄▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆▃▆▄█▂▄▇▃▃▅▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30324</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-22</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iohluhpq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iohluhpq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_074521-iohluhpq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wasa26jf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05019297124260629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5.777224711831658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5106121126406806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_095101-wasa26jf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wasa26jf' target=\"_blank\">lilac-sweep-24</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wasa26jf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wasa26jf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0501930'], tr/val_loss: 19.201517/ 15.059686, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:16<00:00,  1.23s/it]\n",
      "epoch-1   lr=['0.0501806'], tr/val_loss: 25.770563/ 28.424782, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:15<00:00,  1.22s/it]\n",
      "epoch-2   lr=['0.0501434'], tr/val_loss: 36.636837/ 35.789715, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:05<00:00,  1.05s/it]\n",
      "epoch-3   lr=['0.0500816'], tr/val_loss: 24.896149/ 22.418095, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-4   lr=['0.0499951'], tr/val_loss: 26.675701/ 29.653011, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.13it/s]\n",
      "epoch-5   lr=['0.0498840'], tr/val_loss: 25.298290/ 50.164406, tr:  11.03%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-6   lr=['0.0497484'], tr/val_loss: 27.935263/ 11.002198, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-7   lr=['0.0495886'], tr/val_loss: 22.550053/ 20.651808, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.07it/s]\n",
      "epoch-8   lr=['0.0494045'], tr/val_loss: 27.584612/ 33.905190, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:48<00:00,  1.27it/s]\n",
      "epoch-9   lr=['0.0491965'], tr/val_loss: 27.664282/ 34.713528, tr:  11.44%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-10  lr=['0.0489647'], tr/val_loss: 31.142208/ 41.482929, tr:   8.07%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-11  lr=['0.0487093'], tr/val_loss: 28.815287/ 22.917631, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-12  lr=['0.0484306'], tr/val_loss: 28.624876/ 20.966820, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-13  lr=['0.0481289'], tr/val_loss: 24.260075/ 29.789032, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-14  lr=['0.0478045'], tr/val_loss: 20.809076/ 24.024477, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-15  lr=['0.0474576'], tr/val_loss: 21.574598/ 21.518915, tr:  11.03%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-16  lr=['0.0470887'], tr/val_loss: 20.752789/ 26.087172, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-17  lr=['0.0466981'], tr/val_loss: 27.003654/ 23.438072, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-18  lr=['0.0462861'], tr/val_loss: 25.246489/ 22.279224, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-19  lr=['0.0458533'], tr/val_loss: 24.487839/ 21.526318, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-20  lr=['0.0454000'], tr/val_loss: 19.682528/ 19.941795, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-21  lr=['0.0449266'], tr/val_loss: 19.372122/ 27.962233, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "epoch-22  lr=['0.0444337'], tr/val_loss: 25.691845/ 31.298698, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:59<00:00,  1.05it/s]\n",
      "epoch-23  lr=['0.0439216'], tr/val_loss: 27.561142/ 14.045168, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-24  lr=['0.0433910'], tr/val_loss: 23.896626/ 13.161321, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-25  lr=['0.0428424'], tr/val_loss: 21.212187/ 28.428755, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-26  lr=['0.0422762'], tr/val_loss: 21.379602/ 12.528810, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-27  lr=['0.0416931'], tr/val_loss: 15.067629/ 18.263153, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-28  lr=['0.0410936'], tr/val_loss: 19.429546/ 14.856223, tr:  11.95%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-29  lr=['0.0404783'], tr/val_loss: 22.708544/ 24.737637, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-30  lr=['0.0398478'], tr/val_loss: 21.828110/ 23.479671, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-31  lr=['0.0392028'], tr/val_loss: 16.206503/  9.718151, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-32  lr=['0.0385439'], tr/val_loss: 19.437904/ 23.778864, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-33  lr=['0.0378716'], tr/val_loss: 13.527038/ 14.196597, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:21<00:00,  1.32s/it]\n",
      "epoch-34  lr=['0.0371868'], tr/val_loss: 16.332930/ 13.616319, tr:  11.03%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:20<00:00,  1.30s/it]\n",
      "epoch-35  lr=['0.0364901'], tr/val_loss: 18.727057/ 21.065849, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:23<00:00,  1.34s/it]\n",
      "epoch-36  lr=['0.0357820'], tr/val_loss: 14.779724/ 16.297472, tr:  11.03%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:22<00:00,  1.34s/it]\n",
      "epoch-37  lr=['0.0350635'], tr/val_loss: 13.295086/ 12.871147, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:22<00:00,  1.33s/it]\n",
      "epoch-38  lr=['0.0343351'], tr/val_loss: 16.521181/ 16.170958, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:19<00:00,  1.29s/it]\n",
      "epoch-39  lr=['0.0335976'], tr/val_loss: 15.422006/ 12.629364, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:21<00:00,  1.31s/it]\n",
      "epoch-40  lr=['0.0328517'], tr/val_loss: 13.573430/ 10.678759, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "epoch-41  lr=['0.0320982'], tr/val_loss: 11.732159/ 16.387136, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "epoch-42  lr=['0.0313377'], tr/val_loss: 13.045207/ 11.617029, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.11it/s]\n",
      "epoch-43  lr=['0.0305711'], tr/val_loss: 10.130001/ 14.967375, tr:  11.85%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:49<00:00,  1.27it/s]\n",
      "epoch-44  lr=['0.0297991'], tr/val_loss: 10.700365/ 13.328027, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.81it/s]\n",
      "epoch-45  lr=['0.0290224'], tr/val_loss: 10.353122/  9.982436, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:37<00:00,  1.65it/s]\n",
      "epoch-46  lr=['0.0282419'], tr/val_loss: 12.520981/  6.186064, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-47  lr=['0.0274583'], tr/val_loss:  6.854315/  6.415185, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-48  lr=['0.0266723'], tr/val_loss:  6.817013/  6.242249, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-49  lr=['0.0258848'], tr/val_loss:  8.837132/  7.900086, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.11it/s]\n",
      "epoch-50  lr=['0.0250965'], tr/val_loss:  6.398689/ 11.129424, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-51  lr=['0.0243082'], tr/val_loss:  7.455904/  4.639318, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-52  lr=['0.0235207'], tr/val_loss:  6.124445/  4.086516, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n",
      "epoch-53  lr=['0.0227347'], tr/val_loss:  5.402380/  9.046468, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-54  lr=['0.0219511'], tr/val_loss:  4.951212/  5.231352, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "epoch-55  lr=['0.0211705'], tr/val_loss:  4.499743/  4.770945, tr:  11.44%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-56  lr=['0.0203939'], tr/val_loss:  5.944092/  8.833549, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.15it/s]\n",
      "epoch-57  lr=['0.0196219'], tr/val_loss:  4.527726/  3.752771, tr:  11.54%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-58  lr=['0.0188552'], tr/val_loss:  4.196671/  6.562785, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-59  lr=['0.0180948'], tr/val_loss:  4.118454/  4.544919, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-60  lr=['0.0173412'], tr/val_loss:  3.780039/  5.969730, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-61  lr=['0.0165954'], tr/val_loss:  4.045675/  5.489482, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "epoch-62  lr=['0.0158579'], tr/val_loss:  4.322501/  3.619447, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-63  lr=['0.0151295'], tr/val_loss:  3.553215/  3.422484, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-64  lr=['0.0144109'], tr/val_loss:  3.154299/  4.747283, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.15it/s]\n",
      "epoch-65  lr=['0.0137029'], tr/val_loss:  3.554636/  3.300723, tr:  11.44%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.07it/s]\n",
      "epoch-66  lr=['0.0130062'], tr/val_loss:  4.152098/  3.792546, tr:   6.95%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n",
      "epoch-67  lr=['0.0123213'], tr/val_loss:  3.218562/  4.781596, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-68  lr=['0.0116491'], tr/val_loss:  3.102174/  3.466722, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-69  lr=['0.0109902'], tr/val_loss:  3.021308/  2.832771, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-70  lr=['0.0103451'], tr/val_loss:  2.965322/  2.690220, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-71  lr=['0.0097147'], tr/val_loss:  2.786283/  2.661292, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-72  lr=['0.0090994'], tr/val_loss:  2.869943/  2.951049, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-73  lr=['0.0084999'], tr/val_loss:  2.928211/  3.202627, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-74  lr=['0.0079168'], tr/val_loss:  2.940752/  2.660022, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-75  lr=['0.0073506'], tr/val_loss:  2.720480/  2.669429, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-76  lr=['0.0068019'], tr/val_loss:  2.693419/  3.057766, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-77  lr=['0.0062713'], tr/val_loss:  2.725755/  2.603841, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-78  lr=['0.0057593'], tr/val_loss:  2.684548/  2.584604, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-79  lr=['0.0052664'], tr/val_loss:  2.629880/  2.588838, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-80  lr=['0.0047930'], tr/val_loss:  2.666560/  2.449238, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-81  lr=['0.0043397'], tr/val_loss:  2.610032/  2.584236, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-82  lr=['0.0039068'], tr/val_loss:  2.592672/  2.351235, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-83  lr=['0.0034949'], tr/val_loss:  2.562409/  2.356139, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.13it/s]\n",
      "epoch-84  lr=['0.0031043'], tr/val_loss:  2.527835/  2.491802, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-85  lr=['0.0027354'], tr/val_loss:  2.489895/  2.542197, tr:   8.07%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-86  lr=['0.0023885'], tr/val_loss:  2.415174/  2.367502, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-87  lr=['0.0020641'], tr/val_loss:  2.411196/  2.367779, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-88  lr=['0.0017624'], tr/val_loss:  2.405771/  2.361924, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:58<00:00,  1.07it/s]\n",
      "epoch-89  lr=['0.0014837'], tr/val_loss:  2.368238/  2.393224, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:37<00:00,  1.64it/s]\n",
      "epoch-90  lr=['0.0012283'], tr/val_loss:  2.378715/  2.361655, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:23<00:00,  2.67it/s]\n",
      "epoch-91  lr=['0.0009965'], tr/val_loss:  2.363735/  2.375041, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-92  lr=['0.0007885'], tr/val_loss:  2.354275/  2.365494, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-93  lr=['0.0006044'], tr/val_loss:  2.338267/  2.312105, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:59<00:00,  1.04it/s]\n",
      "epoch-94  lr=['0.0004445'], tr/val_loss:  2.334071/  2.325684, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-95  lr=['0.0003090'], tr/val_loss:  2.318673/  2.316515, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-96  lr=['0.0001979'], tr/val_loss:  2.316173/  2.306723, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-97  lr=['0.0001114'], tr/val_loss:  2.317120/  2.305920, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-98  lr=['0.0000495'], tr/val_loss:  2.307409/  2.303073, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-99  lr=['0.0000124'], tr/val_loss:  2.303535/  2.302939, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435266a52845408baa93538f7e05ec70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▄▄▁▅▄▁▄▅▂▂▄▄▆▄▂▂▄▂▄▂▅▆▂▁▂▁▄▂▁▂▁▂█▁▂▂█▁</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▄▃▅▄█▅▆▅▄▂▄▅▅▄▁▅▃▅▃▄▂▇▅█▆▃█▅▇▂▆▂▄▆▅▅▃▂▃▅</td></tr><tr><td>tr_epoch_loss</td><td>▄█▆▅▆▆▅▆▆▄▅▅▅▄▄▃▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄█▇▅█▅▆▅▅▆▃▃▆▅▅▃▃▃▃▂▂▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.08274</td></tr><tr><td>tr_epoch_loss</td><td>2.30354</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30294</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-sweep-24</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wasa26jf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wasa26jf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_095101-wasa26jf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1q97wf6i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.021849536024135256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.3276561331714338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.3914660997717616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_112655-1q97wf6i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1q97wf6i' target=\"_blank\">northern-sweep-27</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1q97wf6i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1q97wf6i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0218495'], tr/val_loss:  1.697275/  1.514532, tr:  39.12%, val:  44.58%, val_best:  44.58%: 100%|██████████| 62/62 [00:21<00:00,  2.83it/s]\n",
      "epoch-1   lr=['0.0218441'], tr/val_loss:  1.338258/  1.433266, tr:  48.52%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-2   lr=['0.0218280'], tr/val_loss:  1.165848/  1.592104, tr:  56.08%, val:  43.75%, val_best:  48.33%: 100%|██████████| 62/62 [00:28<00:00,  2.19it/s]\n",
      "epoch-3   lr=['0.0218011'], tr/val_loss:  1.070189/  1.456777, tr:  61.18%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:33<00:00,  1.85it/s]\n",
      "epoch-4   lr=['0.0217634'], tr/val_loss:  1.004244/  1.521978, tr:  59.96%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-5   lr=['0.0217150'], tr/val_loss:  1.011676/  1.669498, tr:  63.23%, val:  47.50%, val_best:  52.08%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-6   lr=['0.0216560'], tr/val_loss:  0.932822/  1.391996, tr:  65.68%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-7   lr=['0.0215864'], tr/val_loss:  0.954894/  1.562623, tr:  63.13%, val:  51.25%, val_best:  54.58%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-8   lr=['0.0215063'], tr/val_loss:  0.935870/  1.358803, tr:  64.45%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-9   lr=['0.0214158'], tr/val_loss:  0.749633/  1.385813, tr:  69.87%, val:  57.92%, val_best:  60.00%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-10  lr=['0.0213148'], tr/val_loss:  0.725971/  1.443524, tr:  71.09%, val:  59.58%, val_best:  60.00%: 100%|██████████| 62/62 [00:54<00:00,  1.15it/s]\n",
      "epoch-11  lr=['0.0212037'], tr/val_loss:  0.696054/  1.452697, tr:  71.91%, val:  57.50%, val_best:  60.00%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-12  lr=['0.0210824'], tr/val_loss:  0.713058/  1.444105, tr:  70.79%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-13  lr=['0.0209510'], tr/val_loss:  0.598634/  1.617101, tr:  77.02%, val:  60.83%, val_best:  65.42%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-14  lr=['0.0208098'], tr/val_loss:  0.575276/  1.350435, tr:  78.75%, val:  65.00%, val_best:  65.42%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-15  lr=['0.0206588'], tr/val_loss:  0.561862/  1.427157, tr:  77.53%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-16  lr=['0.0204982'], tr/val_loss:  0.546059/  1.614636, tr:  78.96%, val:  62.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-17  lr=['0.0203282'], tr/val_loss:  0.537242/  1.576956, tr:  79.47%, val:  61.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:57<00:00,  1.08it/s]\n",
      "epoch-18  lr=['0.0201489'], tr/val_loss:  0.461864/  1.475257, tr:  82.53%, val:  66.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-19  lr=['0.0199604'], tr/val_loss:  0.446402/  1.430238, tr:  85.39%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-20  lr=['0.0197631'], tr/val_loss:  0.414639/  1.478844, tr:  85.29%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-21  lr=['0.0195570'], tr/val_loss:  0.409862/  1.629913, tr:  85.90%, val:  65.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-22  lr=['0.0193424'], tr/val_loss:  0.432994/  1.632852, tr:  85.90%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n",
      "epoch-23  lr=['0.0191196'], tr/val_loss:  0.401788/  1.594540, tr:  87.03%, val:  66.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-24  lr=['0.0188886'], tr/val_loss:  0.358790/  1.514000, tr:  88.56%, val:  67.08%, val_best:  71.67%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-25  lr=['0.0186497'], tr/val_loss:  0.390547/  1.894474, tr:  90.50%, val:  67.08%, val_best:  71.67%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-26  lr=['0.0184033'], tr/val_loss:  0.355636/  1.523308, tr:  91.83%, val:  66.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-27  lr=['0.0181494'], tr/val_loss:  0.331282/  1.572864, tr:  93.77%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-28  lr=['0.0178885'], tr/val_loss:  0.258102/  1.538915, tr:  96.42%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-29  lr=['0.0176206'], tr/val_loss:  0.289560/  1.554971, tr:  92.34%, val:  70.42%, val_best:  72.50%: 100%|██████████| 62/62 [00:56<00:00,  1.11it/s]\n",
      "epoch-30  lr=['0.0173462'], tr/val_loss:  0.246775/  1.516324, tr:  95.20%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-31  lr=['0.0170654'], tr/val_loss:  0.224711/  1.694027, tr:  96.83%, val:  69.17%, val_best:  77.92%: 100%|██████████| 62/62 [00:56<00:00,  1.11it/s]\n",
      "epoch-32  lr=['0.0167786'], tr/val_loss:  0.248299/  1.734670, tr:  95.71%, val:  70.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:52<00:00,  1.17it/s]\n",
      "epoch-33  lr=['0.0164859'], tr/val_loss:  0.205195/  1.672844, tr:  94.59%, val:  72.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-34  lr=['0.0161878'], tr/val_loss:  0.172022/  1.677180, tr:  97.96%, val:  74.17%, val_best:  77.92%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-35  lr=['0.0158845'], tr/val_loss:  0.118601/  1.758030, tr:  99.39%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-36  lr=['0.0155763'], tr/val_loss:  0.100491/  1.847436, tr:  99.69%, val:  74.17%, val_best:  77.92%: 100%|██████████| 62/62 [00:57<00:00,  1.09it/s]\n",
      "epoch-37  lr=['0.0152635'], tr/val_loss:  0.123604/  1.745777, tr:  98.57%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:38<00:00,  1.62it/s]\n",
      "epoch-38  lr=['0.0149464'], tr/val_loss:  0.110042/  1.756347, tr:  99.28%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:27<00:00,  2.23it/s]\n",
      "epoch-39  lr=['0.0146254'], tr/val_loss:  0.090656/  1.860827, tr:  99.49%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-40  lr=['0.0143007'], tr/val_loss:  0.051809/  1.899326, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:53<00:00,  1.15it/s]\n",
      "epoch-41  lr=['0.0139727'], tr/val_loss:  0.049620/  1.906965, tr:  99.80%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-42  lr=['0.0136416'], tr/val_loss:  0.047688/  2.025797, tr:  99.90%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-43  lr=['0.0133079'], tr/val_loss:  0.026304/  1.940644, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n",
      "epoch-44  lr=['0.0129719'], tr/val_loss:  0.022479/  2.030582, tr: 100.00%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-45  lr=['0.0126338'], tr/val_loss:  0.018675/  1.988937, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-46  lr=['0.0122940'], tr/val_loss:  0.010092/  2.027132, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-47  lr=['0.0119529'], tr/val_loss:  0.009301/  2.064484, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:56<00:00,  1.09it/s]\n",
      "epoch-48  lr=['0.0116107'], tr/val_loss:  0.004672/  2.089317, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-49  lr=['0.0112679'], tr/val_loss:  0.003535/  2.070850, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:54<00:00,  1.14it/s]\n",
      "epoch-50  lr=['0.0109248'], tr/val_loss:  0.003883/  2.110038, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-51  lr=['0.0105816'], tr/val_loss:  0.004360/  2.074720, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-52  lr=['0.0102388'], tr/val_loss:  0.002883/  2.115533, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "epoch-53  lr=['0.0098967'], tr/val_loss:  0.001761/  2.114926, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-54  lr=['0.0095555'], tr/val_loss:  0.001547/  2.118929, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n",
      "epoch-55  lr=['0.0092158'], tr/val_loss:  0.001355/  2.140296, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n",
      "epoch-56  lr=['0.0088777'], tr/val_loss:  0.001294/  2.163895, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n",
      "epoch-57  lr=['0.0085416'], tr/val_loss:  0.001180/  2.171626, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:54<00:00,  1.15it/s]\n",
      "epoch-58  lr=['0.0082079'], tr/val_loss:  0.001140/  2.180158, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n",
      "epoch-59  lr=['0.0078769'], tr/val_loss:  0.001152/  2.187448, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:55<00:00,  1.11it/s]\n",
      "epoch-60  lr=['0.0075488'], tr/val_loss:  0.001108/  2.182475, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-61  lr=['0.0072241'], tr/val_loss:  0.001103/  2.199882, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-62  lr=['0.0069031'], tr/val_loss:  0.001033/  2.203042, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]\n",
      "epoch-63  lr=['0.0065860'], tr/val_loss:  0.000955/  2.198484, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:58<00:00,  1.06it/s]\n",
      "epoch-64  lr=['0.0062732'], tr/val_loss:  0.000969/  2.207434, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:56<00:00,  1.10it/s]\n",
      "epoch-65  lr=['0.0059650'], tr/val_loss:  0.000858/  2.211414, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]\n",
      "epoch-66  lr=['0.0056617'], tr/val_loss:  0.000885/  2.194755, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:10<00:00,  6.11it/s]\n",
      "epoch-67  lr=['0.0053636'], tr/val_loss:  0.000822/  2.201252, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-68  lr=['0.0050710'], tr/val_loss:  0.000786/  2.197039, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.14it/s]\n",
      "epoch-69  lr=['0.0047841'], tr/val_loss:  0.000772/  2.208156, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-70  lr=['0.0045034'], tr/val_loss:  0.000748/  2.211455, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-71  lr=['0.0042289'], tr/val_loss:  0.000737/  2.218406, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-72  lr=['0.0039611'], tr/val_loss:  0.000717/  2.224630, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-73  lr=['0.0037001'], tr/val_loss:  0.000759/  2.225981, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  8.88it/s]\n",
      "epoch-74  lr=['0.0034462'], tr/val_loss:  0.000717/  2.229529, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:11<00:00,  5.41it/s]\n",
      "epoch-75  lr=['0.0031998'], tr/val_loss:  0.000690/  2.232377, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:17<00:00,  3.62it/s]\n",
      "epoch-76  lr=['0.0029610'], tr/val_loss:  0.000691/  2.228047, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:18<00:00,  3.28it/s]\n",
      "epoch-77  lr=['0.0027300'], tr/val_loss:  0.000713/  2.225429, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:19<00:00,  3.16it/s]\n",
      "epoch-78  lr=['0.0025071'], tr/val_loss:  0.000695/  2.229329, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:17<00:00,  3.54it/s]\n",
      "epoch-79  lr=['0.0022925'], tr/val_loss:  0.000675/  2.231552, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:20<00:00,  3.03it/s]\n",
      "epoch-80  lr=['0.0020864'], tr/val_loss:  0.000671/  2.229035, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.16it/s]\n",
      "epoch-81  lr=['0.0018891'], tr/val_loss:  0.000691/  2.231297, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:13<00:00,  4.68it/s]\n",
      "epoch-82  lr=['0.0017007'], tr/val_loss:  0.000681/  2.238115, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-83  lr=['0.0015214'], tr/val_loss:  0.000654/  2.236368, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-84  lr=['0.0013513'], tr/val_loss:  0.000661/  2.238166, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.04it/s]\n",
      "epoch-85  lr=['0.0011907'], tr/val_loss:  0.000652/  2.240401, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:14<00:00,  4.30it/s]\n",
      "epoch-86  lr=['0.0010397'], tr/val_loss:  0.000655/  2.240591, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  3.09it/s]\n",
      "epoch-87  lr=['0.0008985'], tr/val_loss:  0.000655/  2.240894, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:17<00:00,  3.54it/s]\n",
      "epoch-88  lr=['0.0007672'], tr/val_loss:  0.000651/  2.240126, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.23it/s]\n",
      "epoch-89  lr=['0.0006459'], tr/val_loss:  0.000644/  2.241639, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:17<00:00,  3.63it/s]\n",
      "epoch-90  lr=['0.0005347'], tr/val_loss:  0.000646/  2.241556, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:17<00:00,  3.54it/s]\n",
      "epoch-91  lr=['0.0004338'], tr/val_loss:  0.000769/  2.239758, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:16<00:00,  3.85it/s]\n",
      "epoch-92  lr=['0.0003432'], tr/val_loss:  0.000653/  2.239106, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-93  lr=['0.0002631'], tr/val_loss:  0.000668/  2.239488, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-94  lr=['0.0001935'], tr/val_loss:  0.000657/  2.238837, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:08<00:00,  7.65it/s]\n",
      "epoch-95  lr=['0.0001345'], tr/val_loss:  0.000660/  2.238447, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:13<00:00,  4.52it/s]\n",
      "epoch-96  lr=['0.0000861'], tr/val_loss:  0.000645/  2.238357, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.14it/s]\n",
      "epoch-97  lr=['0.0000485'], tr/val_loss:  0.000647/  2.238376, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:17<00:00,  3.56it/s]\n",
      "epoch-98  lr=['0.0000216'], tr/val_loss:  0.000714/  2.238384, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:16<00:00,  3.85it/s]\n",
      "epoch-99  lr=['0.0000054'], tr/val_loss:  0.000638/  2.238078, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  7.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f3f204e36845e49d7840c6597f1c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.958 MB of 3.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▁▃▄▅▇▄███▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▃▂▄▅▅▄▆▅▅▅▆▆▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▃▄▅▅▆▆▆▆▇▇▇███████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇██████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▃▂▄▅▅▄▆▅▅▅▆▆▇▇▇▇▇█████████████████████</td></tr><tr><td>val_loss</td><td>▂▃▂▃▁▂▁▃▂▃▂▂▃▄▄▄▅▆▆▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00064</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.23808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-27</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1q97wf6i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1q97wf6i</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_112655-1q97wf6i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zyub33du with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06358131668522124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.5994300391954994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.5258417727420035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_123308-zyub33du</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyub33du' target=\"_blank\">fancy-sweep-30</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyub33du' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyub33du</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0635813'], tr/val_loss:  1.974152/  1.894129, tr:  29.32%, val:  36.67%, val_best:  36.67%: 100%|██████████| 62/62 [00:11<00:00,  5.47it/s]\n",
      "epoch-1   lr=['0.0635656'], tr/val_loss:  1.712894/  1.516920, tr:  40.86%, val:  39.17%, val_best:  39.17%: 100%|██████████| 62/62 [00:16<00:00,  3.78it/s]\n",
      "epoch-2   lr=['0.0635186'], tr/val_loss:  1.648932/  1.991924, tr:  39.02%, val:  33.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:08<00:00,  7.59it/s]\n",
      "epoch-3   lr=['0.0634402'], tr/val_loss:  1.947586/  1.898876, tr:  32.69%, val:  28.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-4   lr=['0.0633306'], tr/val_loss:  2.429467/  2.951332, tr:  31.15%, val:  27.08%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-5   lr=['0.0631899'], tr/val_loss:  2.146902/  2.579264, tr:  34.01%, val:  35.42%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-6   lr=['0.0630182'], tr/val_loss:  1.970722/  2.281238, tr:  34.63%, val:  28.33%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-7   lr=['0.0628157'], tr/val_loss:  1.989866/  1.892145, tr:  36.26%, val:  35.83%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.14it/s]\n",
      "epoch-8   lr=['0.0625826'], tr/val_loss:  2.397622/  2.124975, tr:  30.13%, val:  27.92%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-9   lr=['0.0623190'], tr/val_loss:  2.228863/  2.095690, tr:  32.38%, val:  33.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n",
      "epoch-10  lr=['0.0620254'], tr/val_loss:  2.064730/  3.032025, tr:  29.42%, val:  21.67%, val_best:  39.17%: 100%|██████████| 62/62 [00:17<00:00,  3.53it/s]\n",
      "epoch-11  lr=['0.0617019'], tr/val_loss:  2.247015/  2.898093, tr:  28.70%, val:  31.67%, val_best:  39.17%: 100%|██████████| 62/62 [00:17<00:00,  3.52it/s]\n",
      "epoch-12  lr=['0.0613489'], tr/val_loss:  2.327746/  2.120383, tr:  31.05%, val:  35.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:17<00:00,  3.64it/s]\n",
      "epoch-13  lr=['0.0609667'], tr/val_loss:  2.338109/  2.426258, tr:  28.60%, val:  28.33%, val_best:  39.17%: 100%|██████████| 62/62 [00:17<00:00,  3.47it/s]\n",
      "epoch-14  lr=['0.0605557'], tr/val_loss:  2.345596/  2.382987, tr:  28.40%, val:  24.17%, val_best:  39.17%: 100%|██████████| 62/62 [00:18<00:00,  3.34it/s]\n",
      "epoch-15  lr=['0.0601163'], tr/val_loss:  2.553272/  2.529532, tr:  26.76%, val:  25.83%, val_best:  39.17%: 100%|██████████| 62/62 [00:16<00:00,  3.73it/s]\n",
      "epoch-16  lr=['0.0596490'], tr/val_loss:  2.226109/  2.295613, tr:  31.26%, val:  29.58%, val_best:  39.17%: 100%|██████████| 62/62 [00:07<00:00,  8.34it/s]\n",
      "epoch-17  lr=['0.0591542'], tr/val_loss:  2.370548/  2.822164, tr:  30.85%, val:  21.67%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-18  lr=['0.0586324'], tr/val_loss:  2.436823/  2.770471, tr:  27.27%, val:  20.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-19  lr=['0.0580841'], tr/val_loss:  2.188789/  2.891530, tr:  30.75%, val:  32.92%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-20  lr=['0.0575098'], tr/val_loss:  2.310131/  2.564814, tr:  28.70%, val:  28.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-21  lr=['0.0569102'], tr/val_loss:  2.274956/  2.234348, tr:  28.60%, val:  30.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-22  lr=['0.0562858'], tr/val_loss:  2.182718/  2.256820, tr:  32.69%, val:  28.33%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-23  lr=['0.0556372'], tr/val_loss:  2.205393/  2.096305, tr:  30.54%, val:  25.42%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-24  lr=['0.0549651'], tr/val_loss:  2.120599/  2.347600, tr:  35.34%, val:  29.17%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-25  lr=['0.0542700'], tr/val_loss:  1.999871/  2.321442, tr:  32.89%, val:  29.17%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-26  lr=['0.0535529'], tr/val_loss:  2.141800/  2.049994, tr:  30.64%, val:  34.58%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-27  lr=['0.0528142'], tr/val_loss:  2.116293/  2.432898, tr:  31.15%, val:  32.92%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-28  lr=['0.0520548'], tr/val_loss:  2.304403/  2.317128, tr:  30.95%, val:  30.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-29  lr=['0.0512754'], tr/val_loss:  2.237301/  1.900171, tr:  31.97%, val:  33.33%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-30  lr=['0.0504767'], tr/val_loss:  2.051067/  2.398141, tr:  31.26%, val:  31.67%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-31  lr=['0.0496597'], tr/val_loss:  1.984047/  2.353765, tr:  33.09%, val:  30.42%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-32  lr=['0.0488249'], tr/val_loss:  2.016058/  1.839116, tr:  31.36%, val:  33.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-33  lr=['0.0479734'], tr/val_loss:  2.007845/  1.978675, tr:  32.48%, val:  34.17%, val_best:  39.17%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-34  lr=['0.0471059'], tr/val_loss:  2.034165/  2.309740, tr:  31.15%, val:  30.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-35  lr=['0.0462233'], tr/val_loss:  2.136435/  2.626612, tr:  31.66%, val:  25.83%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-36  lr=['0.0453265'], tr/val_loss:  2.212711/  2.503804, tr:  31.97%, val:  28.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-37  lr=['0.0444163'], tr/val_loss:  2.280652/  2.275492, tr:  30.44%, val:  25.42%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-38  lr=['0.0434936'], tr/val_loss:  2.287820/  2.507314, tr:  29.32%, val:  25.83%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-39  lr=['0.0425594'], tr/val_loss:  2.059721/  2.289678, tr:  31.05%, val:  27.92%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-40  lr=['0.0416145'], tr/val_loss:  2.246728/  2.382976, tr:  29.32%, val:  18.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-41  lr=['0.0406600'], tr/val_loss:  2.455198/  2.906517, tr:  25.13%, val:  26.67%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-42  lr=['0.0396967'], tr/val_loss:  2.168651/  2.137169, tr:  30.13%, val:  38.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-43  lr=['0.0387256'], tr/val_loss:  1.915516/  1.898639, tr:  30.34%, val:  29.58%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-44  lr=['0.0377476'], tr/val_loss:  2.042242/  2.363944, tr:  30.85%, val:  30.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-45  lr=['0.0367638'], tr/val_loss:  2.082429/  2.085363, tr:  32.99%, val:  32.92%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-46  lr=['0.0357751'], tr/val_loss:  2.120010/  2.330743, tr:  34.01%, val:  27.08%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-47  lr=['0.0347824'], tr/val_loss:  2.027354/  2.347462, tr:  35.04%, val:  33.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-48  lr=['0.0337868'], tr/val_loss:  1.985360/  2.045030, tr:  32.89%, val:  38.75%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-49  lr=['0.0327892'], tr/val_loss:  2.100173/  2.038649, tr:  32.07%, val:  33.33%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-50  lr=['0.0317907'], tr/val_loss:  1.909303/  2.064051, tr:  36.57%, val:  25.00%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-51  lr=['0.0307921'], tr/val_loss:  1.888006/  2.162666, tr:  32.99%, val:  30.42%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-52  lr=['0.0297945'], tr/val_loss:  2.039812/  1.964892, tr:  34.32%, val:  27.08%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-53  lr=['0.0287989'], tr/val_loss:  1.805582/  2.057201, tr:  35.04%, val:  27.50%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-54  lr=['0.0278062'], tr/val_loss:  1.850694/  1.944670, tr:  38.51%, val:  37.92%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-55  lr=['0.0268175'], tr/val_loss:  1.798796/  2.352319, tr:  36.87%, val:  31.25%, val_best:  39.17%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-56  lr=['0.0258337'], tr/val_loss:  1.929078/  1.941318, tr:  34.01%, val:  40.42%, val_best:  40.42%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-57  lr=['0.0248557'], tr/val_loss:  1.828411/  1.984731, tr:  34.32%, val:  36.25%, val_best:  40.42%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-58  lr=['0.0238846'], tr/val_loss:  1.751969/  2.176064, tr:  38.92%, val:  32.08%, val_best:  40.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-59  lr=['0.0229213'], tr/val_loss:  1.735150/  1.988551, tr:  37.49%, val:  39.58%, val_best:  40.42%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-60  lr=['0.0219668'], tr/val_loss:  1.644736/  1.826399, tr:  40.86%, val:  40.83%, val_best:  40.83%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-61  lr=['0.0210220'], tr/val_loss:  1.666867/  1.805687, tr:  40.35%, val:  42.92%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-62  lr=['0.0200877'], tr/val_loss:  1.594107/  1.773776, tr:  41.37%, val:  38.33%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-63  lr=['0.0191651'], tr/val_loss:  1.684157/  1.965095, tr:  39.84%, val:  41.67%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-64  lr=['0.0182549'], tr/val_loss:  1.635372/  1.711856, tr:  41.37%, val:  38.75%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-65  lr=['0.0173580'], tr/val_loss:  1.640749/  1.870382, tr:  40.55%, val:  43.33%, val_best:  43.33%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-66  lr=['0.0164754'], tr/val_loss:  1.652918/  1.815276, tr:  40.86%, val:  41.67%, val_best:  43.33%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-67  lr=['0.0156079'], tr/val_loss:  1.530396/  1.695579, tr:  45.66%, val:  43.33%, val_best:  43.33%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-68  lr=['0.0147564'], tr/val_loss:  1.483002/  1.692201, tr:  44.74%, val:  45.83%, val_best:  45.83%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-69  lr=['0.0139217'], tr/val_loss:  1.446670/  1.657154, tr:  48.62%, val:  43.33%, val_best:  45.83%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-70  lr=['0.0131046'], tr/val_loss:  1.456190/  1.675229, tr:  47.19%, val:  43.75%, val_best:  45.83%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-71  lr=['0.0123059'], tr/val_loss:  1.463532/  1.710223, tr:  45.76%, val:  43.75%, val_best:  45.83%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-72  lr=['0.0115265'], tr/val_loss:  1.422479/  1.710345, tr:  48.93%, val:  46.67%, val_best:  46.67%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-73  lr=['0.0107671'], tr/val_loss:  1.443054/  1.765968, tr:  48.62%, val:  35.00%, val_best:  46.67%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-74  lr=['0.0100285'], tr/val_loss:  1.355682/  1.643482, tr:  47.91%, val:  37.92%, val_best:  46.67%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-75  lr=['0.0093113'], tr/val_loss:  1.382904/  1.607747, tr:  47.09%, val:  49.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-76  lr=['0.0086163'], tr/val_loss:  1.376761/  1.555672, tr:  48.93%, val:  47.50%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-77  lr=['0.0079441'], tr/val_loss:  1.374844/  1.560501, tr:  48.83%, val:  51.25%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-78  lr=['0.0072955'], tr/val_loss:  1.325324/  1.578694, tr:  49.13%, val:  47.50%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-79  lr=['0.0066711'], tr/val_loss:  1.314155/  1.560900, tr:  53.22%, val:  50.42%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-80  lr=['0.0060715'], tr/val_loss:  1.315394/  1.610478, tr:  51.17%, val:  42.08%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-81  lr=['0.0054972'], tr/val_loss:  1.283682/  1.539690, tr:  54.85%, val:  45.42%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-82  lr=['0.0049489'], tr/val_loss:  1.276786/  1.556804, tr:  52.30%, val:  48.75%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-83  lr=['0.0044271'], tr/val_loss:  1.276079/  1.546588, tr:  54.85%, val:  50.42%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-84  lr=['0.0039323'], tr/val_loss:  1.278329/  1.524101, tr:  52.20%, val:  48.75%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-85  lr=['0.0034650'], tr/val_loss:  1.234037/  1.531137, tr:  57.20%, val:  49.17%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-86  lr=['0.0030256'], tr/val_loss:  1.221543/  1.542257, tr:  56.69%, val:  50.83%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-87  lr=['0.0026146'], tr/val_loss:  1.218413/  1.495014, tr:  55.57%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-88  lr=['0.0022325'], tr/val_loss:  1.221350/  1.507462, tr:  55.77%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-89  lr=['0.0018794'], tr/val_loss:  1.201654/  1.501428, tr:  59.75%, val:  48.33%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-90  lr=['0.0015559'], tr/val_loss:  1.197091/  1.517086, tr:  57.10%, val:  48.75%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-91  lr=['0.0012623'], tr/val_loss:  1.189823/  1.516329, tr:  59.45%, val:  50.42%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-92  lr=['0.0009988'], tr/val_loss:  1.176873/  1.512695, tr:  60.16%, val:  50.83%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-93  lr=['0.0007656'], tr/val_loss:  1.164809/  1.529022, tr:  59.65%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-94  lr=['0.0005631'], tr/val_loss:  1.154400/  1.526888, tr:  61.49%, val:  48.33%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-95  lr=['0.0003914'], tr/val_loss:  1.143283/  1.521224, tr:  61.39%, val:  51.67%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-96  lr=['0.0002507'], tr/val_loss:  1.147050/  1.523931, tr:  62.41%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-97  lr=['0.0001411'], tr/val_loss:  1.140905/  1.526009, tr:  62.92%, val:  52.08%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-98  lr=['0.0000627'], tr/val_loss:  1.146851/  1.525781, tr:  63.74%, val:  52.08%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-99  lr=['0.0000157'], tr/val_loss:  1.134890/  1.526030, tr:  64.04%, val:  52.92%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef19f9e6126a40b78950f179e851f35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.946 MB of 3.946 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▄▂▂▂▂▂▁▂▃▃▃▃▃▂▃▄▂▂▂▂▃▁▃▂▁▄▂▃▄▄▂▄▅▄▃▅▅▄█▃</td></tr><tr><td>summary_val_acc</td><td>▄▄▂▄▄▄▂▁▄▃▃▄▄▄▂▂▂▅▃▄▄▂▅▄▅▆▆▆▆▇▇██▇▇█▇███</td></tr><tr><td>tr_acc</td><td>▁▃▂▃▂▂▁▁▁▁▂▁▂▂▂▁▂▁▁▂▂▂▃▂▃▃▃▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>tr_epoch_loss</td><td>▆▄█▆▇▇██▇▇▆▆▇▆▆▇▆▇▆▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▅▅▆▆▆▆▇▇▇▇█</td></tr><tr><td>val_acc_now</td><td>▄▄▂▄▄▄▂▁▄▃▃▄▄▄▂▂▂▅▃▄▄▂▅▄▅▆▆▆▆▇▇██▇▇█▇███</td></tr><tr><td>val_loss</td><td>▃▃█▃▄▄▅▇█▅▅▄▃▃▆▅▅▄▅▅▄▃▃▃▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.64045</td></tr><tr><td>tr_epoch_loss</td><td>1.13489</td></tr><tr><td>val_acc_best</td><td>0.5625</td></tr><tr><td>val_acc_now</td><td>0.52917</td></tr><tr><td>val_loss</td><td>1.52603</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-30</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyub33du' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyub33du</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_123308-zyub33du/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2jnpp8d0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07113796052961463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.6038710047522942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.17493353728952754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_124439-2jnpp8d0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2jnpp8d0' target=\"_blank\">happy-sweep-33</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2jnpp8d0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2jnpp8d0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0711380'], tr/val_loss:  3.467273/  3.840114, tr:  16.55%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-1   lr=['0.0711204'], tr/val_loss:  4.020397/  3.083806, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-2   lr=['0.0710678'], tr/val_loss:  3.775768/  4.017398, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-3   lr=['0.0709801'], tr/val_loss:  4.019374/  4.638201, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-4   lr=['0.0708575'], tr/val_loss:  4.617502/  4.327353, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-5   lr=['0.0707000'], tr/val_loss:  4.802790/  6.173367, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-6   lr=['0.0705079'], tr/val_loss:  4.206653/  3.470586, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-7   lr=['0.0702813'], tr/val_loss:  3.931509/  6.602537, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-8   lr=['0.0700205'], tr/val_loss:  4.119847/  3.899670, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-9   lr=['0.0697256'], tr/val_loss:  4.651328/  6.730553, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-10  lr=['0.0693971'], tr/val_loss:  4.291652/  3.735289, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-11  lr=['0.0690351'], tr/val_loss:  4.347375/  6.904266, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-12  lr=['0.0686402'], tr/val_loss:  3.935829/  3.113221, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-13  lr=['0.0682126'], tr/val_loss:  4.612084/  5.857225, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-14  lr=['0.0677528'], tr/val_loss:  4.413891/  4.665977, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-15  lr=['0.0672612'], tr/val_loss:  3.768557/  4.613785, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-16  lr=['0.0667383'], tr/val_loss:  3.667417/  3.373657, tr:  12.05%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-17  lr=['0.0661847'], tr/val_loss:  4.311005/  5.868925, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-18  lr=['0.0656009'], tr/val_loss:  4.417591/  3.347512, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-19  lr=['0.0649874'], tr/val_loss:  3.639404/  3.664420, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-20  lr=['0.0643449'], tr/val_loss:  3.751542/  4.083839, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-21  lr=['0.0636740'], tr/val_loss:  3.481558/  4.167528, tr:  10.83%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-22  lr=['0.0629754'], tr/val_loss:  3.646432/  2.848489, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-23  lr=['0.0622497'], tr/val_loss:  3.460649/  3.200060, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-24  lr=['0.0614977'], tr/val_loss:  3.749690/  3.961665, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-25  lr=['0.0607200'], tr/val_loss:  3.773242/  3.870440, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-26  lr=['0.0599176'], tr/val_loss:  3.618527/  3.037776, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-27  lr=['0.0590912'], tr/val_loss:  3.408452/  3.936488, tr:   7.87%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-28  lr=['0.0582415'], tr/val_loss:  3.474852/  3.731269, tr:  10.73%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-29  lr=['0.0573695'], tr/val_loss:  3.748502/  3.114277, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-30  lr=['0.0564759'], tr/val_loss:  3.527410/  4.279519, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-31  lr=['0.0555617'], tr/val_loss:  3.692869/  3.950407, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-32  lr=['0.0546278'], tr/val_loss:  3.422308/  4.264327, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-33  lr=['0.0536751'], tr/val_loss:  3.111245/  3.327707, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-34  lr=['0.0527045'], tr/val_loss:  3.483132/  4.681092, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-35  lr=['0.0517170'], tr/val_loss:  3.794974/  2.702901, tr:  10.93%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-36  lr=['0.0507135'], tr/val_loss:  3.950181/  4.259299, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-37  lr=['0.0496951'], tr/val_loss:  4.814967/  4.235248, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-38  lr=['0.0486628'], tr/val_loss:  3.618710/  3.817455, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-39  lr=['0.0476175'], tr/val_loss:  3.177928/  3.128181, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-40  lr=['0.0465604'], tr/val_loss:  3.081389/  4.318181, tr:  11.44%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-41  lr=['0.0454924'], tr/val_loss:  3.278666/  3.366416, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-42  lr=['0.0444146'], tr/val_loss:  2.948727/  2.842936, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-43  lr=['0.0433281'], tr/val_loss:  2.915717/  2.701850, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-44  lr=['0.0422339'], tr/val_loss:  3.161289/  3.744581, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-45  lr=['0.0411332'], tr/val_loss:  3.416690/  4.283102, tr:  11.24%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-46  lr=['0.0400270'], tr/val_loss:  3.203844/  2.595824, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-47  lr=['0.0389163'], tr/val_loss:  3.015057/  3.311958, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-48  lr=['0.0378024'], tr/val_loss:  3.000912/  3.070023, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-49  lr=['0.0366862'], tr/val_loss:  3.366661/  3.114000, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-50  lr=['0.0355690'], tr/val_loss:  2.767477/  2.968785, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-51  lr=['0.0344517'], tr/val_loss:  3.020338/  3.032527, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-52  lr=['0.0333356'], tr/val_loss:  2.990335/  3.179481, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-53  lr=['0.0322216'], tr/val_loss:  2.962813/  2.513817, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-54  lr=['0.0311110'], tr/val_loss:  2.847811/  2.896127, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-55  lr=['0.0300048'], tr/val_loss:  2.879062/  3.005560, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-56  lr=['0.0289040'], tr/val_loss:  3.015701/  3.294453, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-57  lr=['0.0278098'], tr/val_loss:  3.047874/  3.065943, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-58  lr=['0.0267233'], tr/val_loss:  2.763690/  3.080704, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-59  lr=['0.0256456'], tr/val_loss:  2.781624/  2.743455, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-60  lr=['0.0245776'], tr/val_loss:  2.677078/  2.693683, tr:  10.32%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-61  lr=['0.0235204'], tr/val_loss:  2.779339/  2.767531, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-62  lr=['0.0224752'], tr/val_loss:  2.699210/  2.837087, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-63  lr=['0.0214428'], tr/val_loss:  2.718147/  2.701094, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-64  lr=['0.0204244'], tr/val_loss:  2.609677/  2.634510, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-65  lr=['0.0194210'], tr/val_loss:  2.649268/  2.813790, tr:  10.52%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-66  lr=['0.0184335'], tr/val_loss:  2.684999/  2.972367, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-67  lr=['0.0174629'], tr/val_loss:  2.604452/  2.615882, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-68  lr=['0.0165102'], tr/val_loss:  2.529873/  2.610329, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-69  lr=['0.0155762'], tr/val_loss:  2.517138/  2.405701, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-70  lr=['0.0146621'], tr/val_loss:  2.500908/  2.785964, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-71  lr=['0.0137685'], tr/val_loss:  2.518840/  2.652313, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-72  lr=['0.0128965'], tr/val_loss:  2.501964/  2.628983, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-73  lr=['0.0120468'], tr/val_loss:  2.533715/  2.527074, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-74  lr=['0.0112203'], tr/val_loss:  2.475884/  2.510434, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-75  lr=['0.0104179'], tr/val_loss:  2.478825/  2.387560, tr:  10.62%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-76  lr=['0.0096403'], tr/val_loss:  2.421894/  2.470309, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-77  lr=['0.0088883'], tr/val_loss:  2.452407/  2.409426, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-78  lr=['0.0081626'], tr/val_loss:  2.415908/  2.416744, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-79  lr=['0.0074640'], tr/val_loss:  2.418618/  2.413277, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-80  lr=['0.0067931'], tr/val_loss:  2.405305/  2.378085, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-81  lr=['0.0061506'], tr/val_loss:  2.386715/  2.400033, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-82  lr=['0.0055371'], tr/val_loss:  2.402725/  2.345259, tr:   8.27%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-83  lr=['0.0049533'], tr/val_loss:  2.383910/  2.363286, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-84  lr=['0.0043996'], tr/val_loss:  2.390428/  2.343276, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-85  lr=['0.0038768'], tr/val_loss:  2.370710/  2.349642, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-86  lr=['0.0033852'], tr/val_loss:  2.357813/  2.351762, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-87  lr=['0.0029254'], tr/val_loss:  2.346416/  2.312941, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-88  lr=['0.0024978'], tr/val_loss:  2.347349/  2.336111, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-89  lr=['0.0021028'], tr/val_loss:  2.341232/  2.316126, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-90  lr=['0.0017409'], tr/val_loss:  2.336476/  2.313588, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-91  lr=['0.0014123'], tr/val_loss:  2.327864/  2.334436, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-92  lr=['0.0011175'], tr/val_loss:  2.323071/  2.310964, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-93  lr=['0.0008566'], tr/val_loss:  2.319510/  2.304765, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-94  lr=['0.0006300'], tr/val_loss:  2.315255/  2.304869, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-95  lr=['0.0004379'], tr/val_loss:  2.309206/  2.304162, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-96  lr=['0.0002805'], tr/val_loss:  2.308813/  2.302915, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-97  lr=['0.0001579'], tr/val_loss:  2.308035/  2.302844, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-98  lr=['0.0000702'], tr/val_loss:  2.304047/  2.302691, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-99  lr=['0.0000176'], tr/val_loss:  2.302832/  2.302668, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090cd84e77904878bb80706d77999969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.946 MB of 3.946 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▆▂▄▅▄▂▂▁▂▁▂▄▄▄▁▂▂▄▄▂▁▄▂▄▂▆▁▁▁▂▂▅▄▄▁▁▆▂█▁</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>█▃▃▃▂▂▂▃▃▃▃▃▂▃▄▂▃▃▃▂▂▂▃▃▃▂▃▃▃▂▃▂▃▁▂▂▂▁▁▂</td></tr><tr><td>tr_epoch_loss</td><td>▄▅▇▆█▆▇▇▅▄▅▅▅▄▅█▃▃▃▃▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▃▄▄██▂▅▇▃▄▄▂▂▄▂▄▂▂▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30283</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30267</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-33</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2jnpp8d0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2jnpp8d0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_124439-2jnpp8d0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kuvafs1t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015617733619427704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.601214873699441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.6314439260769604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_125333-kuvafs1t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kuvafs1t' target=\"_blank\">eternal-sweep-35</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kuvafs1t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kuvafs1t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0156177'], tr/val_loss:  1.682661/  1.450036, tr:  39.22%, val:  41.25%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-1   lr=['0.0156139'], tr/val_loss:  1.271093/  1.494678, tr:  52.71%, val:  49.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-2   lr=['0.0156023'], tr/val_loss:  1.131699/  1.635695, tr:  58.12%, val:  45.42%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-3   lr=['0.0155831'], tr/val_loss:  1.005050/  1.621576, tr:  63.64%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-4   lr=['0.0155562'], tr/val_loss:  1.028474/  1.356485, tr:  62.82%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-5   lr=['0.0155216'], tr/val_loss:  0.883898/  1.401708, tr:  67.21%, val:  50.83%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-6   lr=['0.0154794'], tr/val_loss:  0.872560/  1.341743, tr:  67.42%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-7   lr=['0.0154297'], tr/val_loss:  0.824443/  1.466824, tr:  69.05%, val:  52.50%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-8   lr=['0.0153724'], tr/val_loss:  0.817836/  1.363590, tr:  68.85%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-9   lr=['0.0153077'], tr/val_loss:  0.639135/  1.448978, tr:  74.87%, val:  60.83%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-10  lr=['0.0152355'], tr/val_loss:  0.630081/  1.304829, tr:  76.20%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-11  lr=['0.0151561'], tr/val_loss:  0.572414/  1.531990, tr:  79.26%, val:  57.92%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-12  lr=['0.0150694'], tr/val_loss:  0.671026/  1.448604, tr:  76.00%, val:  58.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-13  lr=['0.0149755'], tr/val_loss:  0.554097/  1.388266, tr:  79.67%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-14  lr=['0.0148745'], tr/val_loss:  0.526183/  1.209710, tr:  81.10%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-15  lr=['0.0147666'], tr/val_loss:  0.509558/  1.347754, tr:  82.02%, val:  70.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-16  lr=['0.0146518'], tr/val_loss:  0.489787/  1.577352, tr:  83.76%, val:  69.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-17  lr=['0.0145303'], tr/val_loss:  0.511968/  1.467687, tr:  83.15%, val:  62.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-18  lr=['0.0144021'], tr/val_loss:  0.431691/  1.387980, tr:  84.68%, val:  64.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-19  lr=['0.0142674'], tr/val_loss:  0.482080/  1.639460, tr:  84.68%, val:  60.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-20  lr=['0.0141264'], tr/val_loss:  0.356611/  1.488514, tr:  88.87%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-21  lr=['0.0139791'], tr/val_loss:  0.330116/  1.604149, tr:  89.68%, val:  62.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-22  lr=['0.0138257'], tr/val_loss:  0.318760/  1.515109, tr:  91.32%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-23  lr=['0.0136664'], tr/val_loss:  0.298271/  1.592346, tr:  90.40%, val:  67.92%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-24  lr=['0.0135013'], tr/val_loss:  0.307297/  1.560572, tr:  89.68%, val:  73.33%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-25  lr=['0.0133306'], tr/val_loss:  0.240068/  1.657417, tr:  96.22%, val:  71.25%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-26  lr=['0.0131544'], tr/val_loss:  0.203140/  1.772161, tr:  96.73%, val:  67.50%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-27  lr=['0.0129730'], tr/val_loss:  0.219307/  1.812152, tr:  96.12%, val:  72.92%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-28  lr=['0.0127864'], tr/val_loss:  0.171897/  1.719318, tr:  97.75%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-29  lr=['0.0125950'], tr/val_loss:  0.169212/  1.938298, tr:  98.98%, val:  65.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-30  lr=['0.0123988'], tr/val_loss:  0.257236/  1.805106, tr:  96.12%, val:  70.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-31  lr=['0.0121981'], tr/val_loss:  0.110883/  1.894374, tr:  99.18%, val:  72.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-32  lr=['0.0119931'], tr/val_loss:  0.079667/  1.847852, tr:  99.80%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-33  lr=['0.0117839'], tr/val_loss:  0.088166/  1.924898, tr: 100.00%, val:  73.75%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-34  lr=['0.0115708'], tr/val_loss:  0.060409/  2.048487, tr: 100.00%, val:  73.33%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-35  lr=['0.0113540'], tr/val_loss:  0.103001/  2.086243, tr:  99.69%, val:  70.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-36  lr=['0.0111337'], tr/val_loss:  0.080077/  1.915192, tr:  99.39%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-37  lr=['0.0109101'], tr/val_loss:  0.033464/  2.037356, tr: 100.00%, val:  74.58%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-38  lr=['0.0106835'], tr/val_loss:  0.022634/  2.080922, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-39  lr=['0.0104540'], tr/val_loss:  0.019939/  2.104054, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-40  lr=['0.0102219'], tr/val_loss:  0.013158/  2.122739, tr: 100.00%, val:  73.75%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-41  lr=['0.0099875'], tr/val_loss:  0.011703/  2.086744, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-42  lr=['0.0097509'], tr/val_loss:  0.009015/  2.147641, tr: 100.00%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-43  lr=['0.0095123'], tr/val_loss:  0.007995/  2.133599, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-44  lr=['0.0092721'], tr/val_loss:  0.003971/  2.129570, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-45  lr=['0.0090304'], tr/val_loss:  0.003790/  2.134526, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-46  lr=['0.0087876'], tr/val_loss:  0.003998/  2.178571, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-47  lr=['0.0085437'], tr/val_loss:  0.002105/  2.159181, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-48  lr=['0.0082992'], tr/val_loss:  0.001965/  2.157454, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-49  lr=['0.0080541'], tr/val_loss:  0.001371/  2.200537, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-50  lr=['0.0078089'], tr/val_loss:  0.001211/  2.197888, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-51  lr=['0.0075636'], tr/val_loss:  0.001074/  2.202867, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-52  lr=['0.0073185'], tr/val_loss:  0.000957/  2.218155, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-53  lr=['0.0070740'], tr/val_loss:  0.000939/  2.220651, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-54  lr=['0.0068302'], tr/val_loss:  0.000889/  2.225272, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-55  lr=['0.0065873'], tr/val_loss:  0.000850/  2.239687, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-56  lr=['0.0063456'], tr/val_loss:  0.000802/  2.239961, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-57  lr=['0.0061054'], tr/val_loss:  0.000793/  2.251590, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-58  lr=['0.0058669'], tr/val_loss:  0.000751/  2.252016, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-59  lr=['0.0056303'], tr/val_loss:  0.000742/  2.262437, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-60  lr=['0.0053958'], tr/val_loss:  0.000692/  2.265810, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-61  lr=['0.0051637'], tr/val_loss:  0.000743/  2.266478, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-62  lr=['0.0049342'], tr/val_loss:  0.000675/  2.272756, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-63  lr=['0.0047076'], tr/val_loss:  0.000684/  2.279559, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-64  lr=['0.0044840'], tr/val_loss:  0.000663/  2.287084, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-65  lr=['0.0042637'], tr/val_loss:  0.000648/  2.297806, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-66  lr=['0.0040469'], tr/val_loss:  0.000652/  2.298837, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-67  lr=['0.0038338'], tr/val_loss:  0.000620/  2.301871, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-68  lr=['0.0036247'], tr/val_loss:  0.000613/  2.302799, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-69  lr=['0.0034196'], tr/val_loss:  0.000598/  2.302693, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-70  lr=['0.0032189'], tr/val_loss:  0.000585/  2.299431, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-71  lr=['0.0030228'], tr/val_loss:  0.000611/  2.299629, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-72  lr=['0.0028313'], tr/val_loss:  0.000572/  2.296306, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-73  lr=['0.0026448'], tr/val_loss:  0.000583/  2.304452, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-74  lr=['0.0024633'], tr/val_loss:  0.000559/  2.292069, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-75  lr=['0.0022872'], tr/val_loss:  0.000557/  2.293866, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-76  lr=['0.0021164'], tr/val_loss:  0.000557/  2.292623, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-77  lr=['0.0019513'], tr/val_loss:  0.000569/  2.296151, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-78  lr=['0.0017920'], tr/val_loss:  0.000558/  2.301564, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-79  lr=['0.0016387'], tr/val_loss:  0.000577/  2.297717, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-80  lr=['0.0014914'], tr/val_loss:  0.000560/  2.304471, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-81  lr=['0.0013503'], tr/val_loss:  0.000531/  2.299438, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-82  lr=['0.0012156'], tr/val_loss:  0.000529/  2.301249, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-83  lr=['0.0010874'], tr/val_loss:  0.000523/  2.305715, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-84  lr=['0.0009659'], tr/val_loss:  0.000531/  2.302247, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-85  lr=['0.0008511'], tr/val_loss:  0.000536/  2.302871, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-86  lr=['0.0007432'], tr/val_loss:  0.000530/  2.304147, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-87  lr=['0.0006422'], tr/val_loss:  0.000542/  2.306639, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-88  lr=['0.0005484'], tr/val_loss:  0.000524/  2.302906, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-89  lr=['0.0004617'], tr/val_loss:  0.000531/  2.304414, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-90  lr=['0.0003822'], tr/val_loss:  0.000537/  2.305321, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-91  lr=['0.0003101'], tr/val_loss:  0.000543/  2.305500, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-92  lr=['0.0002453'], tr/val_loss:  0.000559/  2.303037, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-93  lr=['0.0001881'], tr/val_loss:  0.000568/  2.303329, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-94  lr=['0.0001383'], tr/val_loss:  0.000532/  2.302970, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-95  lr=['0.0000961'], tr/val_loss:  0.000535/  2.302842, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-96  lr=['0.0000616'], tr/val_loss:  0.000525/  2.302111, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-97  lr=['0.0000347'], tr/val_loss:  0.000519/  2.302125, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.21it/s]\n",
      "epoch-98  lr=['0.0000154'], tr/val_loss:  0.000551/  2.302130, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-99  lr=['0.0000039'], tr/val_loss:  0.000514/  2.302130, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d9d73b2d7b43209408601de47e53b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.946 MB of 3.946 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▃▃▄▆▆▆▇█▇▇██▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▃▅▄█▅▅▅▇▆▅█▆▇█▇██████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▄▅▅▆▆▆▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▅▆▆██████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▃▅▄█▅▅▅▇▆▅█▆▇█▇██████████████████████</td></tr><tr><td>val_loss</td><td>▃▄▂▃▃▃▁▃▄▄▃▅▆▅▇▆▇▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00051</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>2.30213</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-sweep-35</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kuvafs1t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kuvafs1t</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_125333-kuvafs1t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5dknpthu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07132030490780493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.1470840343391355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7803211797176584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_130234-5dknpthu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5dknpthu' target=\"_blank\">soft-sweep-37</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5dknpthu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5dknpthu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0713203'], tr/val_loss:  1.927781/  2.253462, tr:  35.85%, val:  25.83%, val_best:  25.83%: 100%|██████████| 62/62 [00:04<00:00, 13.11it/s]\n",
      "epoch-1   lr=['0.0713027'], tr/val_loss:  1.868333/  2.271128, tr:  38.00%, val:  35.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-2   lr=['0.0712499'], tr/val_loss:  1.918411/  3.043423, tr:  39.63%, val:  32.50%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-3   lr=['0.0711620'], tr/val_loss:  2.169713/  2.133290, tr:  37.79%, val:  30.42%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-4   lr=['0.0710391'], tr/val_loss:  2.625085/  2.823114, tr:  31.56%, val:  29.17%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-5   lr=['0.0708813'], tr/val_loss:  2.843049/  2.843154, tr:  29.32%, val:  23.75%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-6   lr=['0.0706887'], tr/val_loss:  2.475907/  3.473426, tr:  32.28%, val:  18.33%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-7   lr=['0.0704615'], tr/val_loss:  2.447177/  2.403504, tr:  26.66%, val:  32.50%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-8   lr=['0.0702000'], tr/val_loss:  2.535806/  2.827765, tr:  31.97%, val:  30.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-9   lr=['0.0699044'], tr/val_loss:  2.343559/  2.763652, tr:  33.91%, val:  37.08%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-10  lr=['0.0695750'], tr/val_loss:  2.359003/  2.910823, tr:  30.34%, val:  29.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-11  lr=['0.0692121'], tr/val_loss:  2.372031/  3.090694, tr:  30.64%, val:  32.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-12  lr=['0.0688161'], tr/val_loss:  2.370277/  2.282723, tr:  30.64%, val:  33.75%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-13  lr=['0.0683874'], tr/val_loss:  2.547292/  2.779733, tr:  30.44%, val:  27.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-14  lr=['0.0679264'], tr/val_loss:  2.462811/  2.784370, tr:  27.48%, val:  25.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-15  lr=['0.0674336'], tr/val_loss:  2.858148/  2.182145, tr:  26.66%, val:  25.83%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-16  lr=['0.0669094'], tr/val_loss:  2.307913/  2.715593, tr:  32.38%, val:  23.75%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-17  lr=['0.0663543'], tr/val_loss:  2.715981/  2.759743, tr:  28.09%, val:  17.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-18  lr=['0.0657690'], tr/val_loss:  2.739991/  3.014572, tr:  24.41%, val:  30.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-19  lr=['0.0651540'], tr/val_loss:  2.366400/  2.970806, tr:  27.99%, val:  22.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-20  lr=['0.0645098'], tr/val_loss:  2.492825/  2.427891, tr:  25.64%, val:  26.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-21  lr=['0.0638372'], tr/val_loss:  2.582072/  2.086387, tr:  25.54%, val:  30.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-22  lr=['0.0631368'], tr/val_loss:  2.183293/  2.259734, tr:  30.64%, val:  34.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-23  lr=['0.0624092'], tr/val_loss:  2.169388/  2.765779, tr:  30.95%, val:  21.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-24  lr=['0.0616553'], tr/val_loss:  3.077076/  2.938773, tr:  19.51%, val:  25.83%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-25  lr=['0.0608757'], tr/val_loss:  2.660924/  2.751518, tr:  18.08%, val:  11.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-26  lr=['0.0600712'], tr/val_loss:  2.752923/  3.191612, tr:  17.67%, val:  13.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-27  lr=['0.0592426'], tr/val_loss:  2.659346/  2.793268, tr:  18.28%, val:  10.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-28  lr=['0.0583908'], tr/val_loss:  2.560592/  3.543282, tr:  19.41%, val:  21.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-29  lr=['0.0575165'], tr/val_loss:  2.788654/  2.457984, tr:  19.41%, val:  18.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-30  lr=['0.0566207'], tr/val_loss:  2.782629/  4.010114, tr:  18.79%, val:  17.08%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-31  lr=['0.0557041'], tr/val_loss:  2.742604/  3.095635, tr:  17.77%, val:  18.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-32  lr=['0.0547678'], tr/val_loss:  2.700683/  2.718590, tr:  21.35%, val:  18.75%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-33  lr=['0.0538126'], tr/val_loss:  2.460083/  2.283985, tr:  20.22%, val:  25.83%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-34  lr=['0.0528396'], tr/val_loss:  2.494242/  3.142467, tr:  20.43%, val:  18.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-35  lr=['0.0518495'], tr/val_loss:  2.666026/  2.365260, tr:  20.63%, val:  17.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-36  lr=['0.0508435'], tr/val_loss:  2.810192/  3.422825, tr:  17.98%, val:  15.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-37  lr=['0.0498225'], tr/val_loss:  2.853959/  3.150762, tr:  18.59%, val:  17.92%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-38  lr=['0.0487875'], tr/val_loss:  2.718295/  3.096755, tr:  16.55%, val:  10.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-39  lr=['0.0477396'], tr/val_loss:  2.453408/  2.739386, tr:  19.51%, val:  22.92%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-40  lr=['0.0466797'], tr/val_loss:  2.521858/  2.895729, tr:  19.71%, val:  19.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-41  lr=['0.0456090'], tr/val_loss:  2.488054/  2.778369, tr:  18.28%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-42  lr=['0.0445285'], tr/val_loss:  2.423138/  2.377037, tr:  18.79%, val:  25.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-43  lr=['0.0434392'], tr/val_loss:  2.369675/  2.169512, tr:  22.17%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-44  lr=['0.0423422'], tr/val_loss:  2.467858/  2.755096, tr:  18.08%, val:  16.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-45  lr=['0.0412386'], tr/val_loss:  2.504226/  2.605325, tr:  19.31%, val:  23.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-46  lr=['0.0401296'], tr/val_loss:  2.693384/  2.489341, tr:  21.65%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-47  lr=['0.0390161'], tr/val_loss:  2.499312/  2.861881, tr:  18.39%, val:  24.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-48  lr=['0.0378993'], tr/val_loss:  2.431371/  2.253591, tr:  18.79%, val:  23.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-49  lr=['0.0367803'], tr/val_loss:  2.493276/  2.781417, tr:  22.37%, val:  16.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-50  lr=['0.0356602'], tr/val_loss:  2.337471/  2.187132, tr:  19.20%, val:  20.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-51  lr=['0.0345400'], tr/val_loss:  2.307675/  2.374221, tr:  19.10%, val:  23.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-52  lr=['0.0334210'], tr/val_loss:  2.464308/  2.462841, tr:  19.71%, val:  17.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-53  lr=['0.0323042'], tr/val_loss:  2.337754/  2.522909, tr:  19.20%, val:  22.08%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-54  lr=['0.0311908'], tr/val_loss:  2.195743/  2.231086, tr:  21.45%, val:  24.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-55  lr=['0.0300817'], tr/val_loss:  2.198176/  2.393955, tr:  21.65%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-56  lr=['0.0289781'], tr/val_loss:  2.329560/  2.395951, tr:  19.61%, val:  15.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-57  lr=['0.0278811'], tr/val_loss:  2.347213/  2.272683, tr:  21.25%, val:  19.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-58  lr=['0.0267918'], tr/val_loss:  2.136813/  2.340746, tr:  19.31%, val:  18.75%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-59  lr=['0.0257113'], tr/val_loss:  2.248307/  2.309311, tr:  19.51%, val:  14.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-60  lr=['0.0246406'], tr/val_loss:  2.112735/  2.085693, tr:  20.74%, val:  19.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-61  lr=['0.0235807'], tr/val_loss:  2.178537/  2.070562, tr:  22.27%, val:  17.92%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-62  lr=['0.0225328'], tr/val_loss:  2.058739/  2.124643, tr:  19.00%, val:  20.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-63  lr=['0.0214978'], tr/val_loss:  2.141587/  2.294601, tr:  20.33%, val:  21.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-64  lr=['0.0204768'], tr/val_loss:  2.071913/  2.269067, tr:  19.10%, val:  17.08%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-65  lr=['0.0194708'], tr/val_loss:  2.117153/  2.361390, tr:  18.90%, val:  20.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-66  lr=['0.0184807'], tr/val_loss:  2.070579/  2.176343, tr:  18.69%, val:  16.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-67  lr=['0.0175077'], tr/val_loss:  2.013430/  2.174975, tr:  23.80%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-68  lr=['0.0165525'], tr/val_loss:  1.983569/  2.103751, tr:  20.63%, val:  22.92%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-69  lr=['0.0156162'], tr/val_loss:  1.965422/  2.063606, tr:  23.90%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-70  lr=['0.0146996'], tr/val_loss:  1.955832/  2.045249, tr:  22.27%, val:  22.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-71  lr=['0.0138038'], tr/val_loss:  1.953670/  2.111507, tr:  21.76%, val:  22.92%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-72  lr=['0.0129295'], tr/val_loss:  1.951913/  2.149817, tr:  22.37%, val:  18.75%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-73  lr=['0.0120777'], tr/val_loss:  1.986668/  2.106268, tr:  20.12%, val:  16.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-74  lr=['0.0112491'], tr/val_loss:  1.937951/  2.085764, tr:  19.10%, val:  21.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-75  lr=['0.0104446'], tr/val_loss:  1.975359/  2.087365, tr:  20.22%, val:  20.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-76  lr=['0.0096650'], tr/val_loss:  1.912490/  1.967216, tr:  21.35%, val:  23.33%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-77  lr=['0.0089111'], tr/val_loss:  1.945937/  2.026209, tr:  20.12%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-78  lr=['0.0081835'], tr/val_loss:  1.885013/  1.984146, tr:  19.61%, val:  25.00%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-79  lr=['0.0074831'], tr/val_loss:  1.907183/  2.042502, tr:  19.71%, val:  21.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-80  lr=['0.0068105'], tr/val_loss:  1.886484/  1.996565, tr:  20.02%, val:  20.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-81  lr=['0.0061663'], tr/val_loss:  1.875770/  2.004758, tr:  21.45%, val:  19.17%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-82  lr=['0.0055513'], tr/val_loss:  1.878965/  1.961721, tr:  18.69%, val:  17.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-83  lr=['0.0049660'], tr/val_loss:  1.855132/  1.968727, tr:  20.63%, val:  25.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-84  lr=['0.0044109'], tr/val_loss:  1.873108/  1.970720, tr:  21.35%, val:  24.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-85  lr=['0.0038867'], tr/val_loss:  1.842873/  1.970632, tr:  19.51%, val:  19.58%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-86  lr=['0.0033939'], tr/val_loss:  1.837559/  1.950780, tr:  19.31%, val:  17.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-87  lr=['0.0029329'], tr/val_loss:  1.829726/  1.947711, tr:  20.02%, val:  20.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-88  lr=['0.0025042'], tr/val_loss:  1.837471/  1.959350, tr:  20.02%, val:  22.08%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-89  lr=['0.0021082'], tr/val_loss:  1.835057/  1.943067, tr:  20.74%, val:  18.75%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-90  lr=['0.0017453'], tr/val_loss:  1.824319/  1.951532, tr:  19.41%, val:  22.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-91  lr=['0.0014159'], tr/val_loss:  1.826283/  1.957726, tr:  20.63%, val:  20.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-92  lr=['0.0011203'], tr/val_loss:  1.813400/  1.944425, tr:  20.02%, val:  25.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-93  lr=['0.0008588'], tr/val_loss:  1.817262/  1.942693, tr:  20.94%, val:  20.83%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-94  lr=['0.0006316'], tr/val_loss:  1.813346/  1.945114, tr:  22.78%, val:  26.67%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-95  lr=['0.0004390'], tr/val_loss:  1.806672/  1.948235, tr:  19.82%, val:  25.42%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-96  lr=['0.0002812'], tr/val_loss:  1.810148/  1.946630, tr:  24.21%, val:  27.50%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-97  lr=['0.0001583'], tr/val_loss:  1.809704/  1.947857, tr:  23.39%, val:  27.08%, val_best:  37.08%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-98  lr=['0.0000704'], tr/val_loss:  1.803311/  1.945782, tr:  24.62%, val:  26.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 13.11it/s]\n",
      "epoch-99  lr=['0.0000176'], tr/val_loss:  1.804066/  1.945779, tr:  24.72%, val:  26.25%, val_best:  37.08%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3679d775f3646fa899902afb763a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.946 MB of 3.946 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▄▃▄▄▅▄▄▄▄▄▄▄▄▄▄▃▃▃▄▃▃▄▃▅▄▄▅▄▄▂▁▃▃▃▂▃▇▃█▃</td></tr><tr><td>summary_val_acc</td><td>▅▇▆▇█▇▅▂▄▆▅▁▂▃▂▂▄▄▂▄▂▂▄▃▁▂▃▃▄▃▃▃▃▂▄▃▃▅▅▅</td></tr><tr><td>tr_acc</td><td>▇█▅▄▆▅▄▄▄▄▂▁▂▂▂▁▂▁▁▁▂▂▂▂▂▂▁▃▂▂▂▂▂▁▂▂▂▂▂▃</td></tr><tr><td>tr_epoch_loss</td><td>▂▂▆▅▄▄▅▆▄▅█▆▆▆▆▇▅▄▅▅▅▅▃▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▅▇▆▇█▇▅▂▄▆▅▁▂▃▂▂▄▄▂▄▂▂▄▃▁▂▃▃▄▃▃▃▃▂▄▃▃▅▅▅</td></tr><tr><td>val_loss</td><td>▃▇▆▄▆▃▆▆▇▂▇█▄▅▃█▅▃▆▆▆▄▃▃▃▂▃▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.24719</td></tr><tr><td>tr_epoch_loss</td><td>1.80407</td></tr><tr><td>val_acc_best</td><td>0.37083</td></tr><tr><td>val_acc_now</td><td>0.2625</td></tr><tr><td>val_loss</td><td>1.94578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-sweep-37</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5dknpthu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5dknpthu</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_130234-5dknpthu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f5d40ikh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007792791616977195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.1442624833711643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7396053867330743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_131127-f5d40ikh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5d40ikh' target=\"_blank\">unique-sweep-39</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5d40ikh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5d40ikh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0077928'], tr/val_loss:  1.689063/  1.433368, tr:  41.27%, val:  46.67%, val_best:  46.67%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-1   lr=['0.0077909'], tr/val_loss:  1.309322/  1.434953, tr:  51.28%, val:  47.50%, val_best:  47.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-2   lr=['0.0077851'], tr/val_loss:  1.104999/  1.380172, tr:  57.61%, val:  49.58%, val_best:  49.58%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-3   lr=['0.0077755'], tr/val_loss:  1.030632/  1.389967, tr:  63.33%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-4   lr=['0.0077621'], tr/val_loss:  1.021865/  1.251325, tr:  60.57%, val:  55.42%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-5   lr=['0.0077448'], tr/val_loss:  0.908397/  1.313461, tr:  67.52%, val:  52.92%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-6   lr=['0.0077238'], tr/val_loss:  0.855681/  1.283810, tr:  68.74%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-7   lr=['0.0076990'], tr/val_loss:  0.857175/  1.577767, tr:  68.34%, val:  48.75%, val_best:  60.83%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-8   lr=['0.0076704'], tr/val_loss:  0.829246/  1.288969, tr:  70.38%, val:  59.17%, val_best:  60.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-9   lr=['0.0076381'], tr/val_loss:  0.754902/  1.445901, tr:  71.91%, val:  59.58%, val_best:  60.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-10  lr=['0.0076021'], tr/val_loss:  0.727012/  1.401295, tr:  74.36%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-11  lr=['0.0075624'], tr/val_loss:  0.683626/  1.354722, tr:  76.20%, val:  62.08%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-12  lr=['0.0075192'], tr/val_loss:  0.709506/  1.324156, tr:  73.44%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-13  lr=['0.0074723'], tr/val_loss:  0.651978/  1.437773, tr:  77.43%, val:  58.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-14  lr=['0.0074220'], tr/val_loss:  0.676286/  1.303159, tr:  76.00%, val:  65.42%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-15  lr=['0.0073681'], tr/val_loss:  0.629781/  1.409575, tr:  76.92%, val:  66.67%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-16  lr=['0.0073108'], tr/val_loss:  0.661262/  1.461339, tr:  78.35%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-17  lr=['0.0072502'], tr/val_loss:  0.621113/  1.368423, tr:  78.65%, val:  62.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-18  lr=['0.0071862'], tr/val_loss:  0.584617/  1.385659, tr:  80.80%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-19  lr=['0.0071190'], tr/val_loss:  0.556685/  1.556154, tr:  82.33%, val:  64.58%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-20  lr=['0.0070486'], tr/val_loss:  0.512258/  1.432616, tr:  82.12%, val:  63.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-21  lr=['0.0069752'], tr/val_loss:  0.444223/  1.498551, tr:  87.03%, val:  63.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-22  lr=['0.0068986'], tr/val_loss:  0.461021/  1.386107, tr:  85.50%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-23  lr=['0.0068191'], tr/val_loss:  0.437675/  1.430218, tr:  85.19%, val:  67.08%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-24  lr=['0.0067367'], tr/val_loss:  0.457181/  1.653096, tr:  87.13%, val:  64.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-25  lr=['0.0066516'], tr/val_loss:  0.410832/  1.671856, tr:  88.76%, val:  62.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-26  lr=['0.0065637'], tr/val_loss:  0.382300/  1.512873, tr:  89.68%, val:  67.50%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-27  lr=['0.0064731'], tr/val_loss:  0.361937/  1.665844, tr:  93.05%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-28  lr=['0.0063801'], tr/val_loss:  0.331130/  1.581517, tr:  93.26%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-29  lr=['0.0062845'], tr/val_loss:  0.341054/  1.710721, tr:  92.85%, val:  66.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-30  lr=['0.0061866'], tr/val_loss:  0.366773/  1.670254, tr:  91.93%, val:  68.75%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-31  lr=['0.0060865'], tr/val_loss:  0.322825/  1.665852, tr:  95.51%, val:  68.33%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-32  lr=['0.0059842'], tr/val_loss:  0.278370/  1.673535, tr:  93.87%, val:  68.75%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-33  lr=['0.0058798'], tr/val_loss:  0.260793/  1.651470, tr:  96.02%, val:  67.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-34  lr=['0.0057735'], tr/val_loss:  0.252028/  1.616883, tr:  95.30%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-35  lr=['0.0056653'], tr/val_loss:  0.224663/  1.679557, tr:  96.63%, val:  67.92%, val_best:  72.08%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-36  lr=['0.0055554'], tr/val_loss:  0.193463/  1.772938, tr:  97.85%, val:  68.75%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-37  lr=['0.0054438'], tr/val_loss:  0.214006/  1.698150, tr:  96.83%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-38  lr=['0.0053308'], tr/val_loss:  0.176722/  1.852557, tr:  98.57%, val:  71.67%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-39  lr=['0.0052163'], tr/val_loss:  0.162990/  1.692089, tr:  98.98%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-40  lr=['0.0051004'], tr/val_loss:  0.195754/  1.752989, tr:  97.24%, val:  73.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-41  lr=['0.0049835'], tr/val_loss:  0.184052/  1.595275, tr:  96.94%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-42  lr=['0.0048654'], tr/val_loss:  0.143680/  1.739977, tr:  98.06%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-43  lr=['0.0047464'], tr/val_loss:  0.106130/  1.696144, tr:  99.49%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-44  lr=['0.0046265'], tr/val_loss:  0.104782/  1.808637, tr:  99.59%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-45  lr=['0.0045059'], tr/val_loss:  0.115395/  1.808802, tr:  99.28%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-46  lr=['0.0043847'], tr/val_loss:  0.084393/  1.806619, tr:  99.90%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-47  lr=['0.0042631'], tr/val_loss:  0.077992/  1.815108, tr:  99.59%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-48  lr=['0.0041411'], tr/val_loss:  0.051603/  1.917994, tr:  99.90%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-49  lr=['0.0040188'], tr/val_loss:  0.057035/  1.841515, tr:  99.80%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-50  lr=['0.0038964'], tr/val_loss:  0.052336/  1.977058, tr: 100.00%, val:  70.00%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-51  lr=['0.0037740'], tr/val_loss:  0.040100/  2.021231, tr: 100.00%, val:  72.50%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-52  lr=['0.0036517'], tr/val_loss:  0.040696/  1.978079, tr:  99.90%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-53  lr=['0.0035297'], tr/val_loss:  0.026630/  1.968720, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-54  lr=['0.0034080'], tr/val_loss:  0.018456/  2.037194, tr: 100.00%, val:  72.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-55  lr=['0.0032869'], tr/val_loss:  0.011314/  2.000398, tr: 100.00%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-56  lr=['0.0031663'], tr/val_loss:  0.008426/  1.989450, tr: 100.00%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-57  lr=['0.0030464'], tr/val_loss:  0.006650/  2.015023, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-58  lr=['0.0029274'], tr/val_loss:  0.005769/  2.039474, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-59  lr=['0.0028093'], tr/val_loss:  0.004981/  2.039760, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-60  lr=['0.0026923'], tr/val_loss:  0.005001/  2.044847, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-61  lr=['0.0025765'], tr/val_loss:  0.004456/  2.032876, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-62  lr=['0.0024620'], tr/val_loss:  0.004007/  2.037347, tr: 100.00%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-63  lr=['0.0023490'], tr/val_loss:  0.003695/  2.033188, tr: 100.00%, val:  75.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-64  lr=['0.0022374'], tr/val_loss:  0.003535/  2.055013, tr: 100.00%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-65  lr=['0.0021275'], tr/val_loss:  0.003447/  2.057874, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-66  lr=['0.0020193'], tr/val_loss:  0.003347/  2.068615, tr: 100.00%, val:  75.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-67  lr=['0.0019130'], tr/val_loss:  0.003221/  2.064323, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-68  lr=['0.0018086'], tr/val_loss:  0.002979/  2.064249, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-69  lr=['0.0017063'], tr/val_loss:  0.002829/  2.070837, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-70  lr=['0.0016062'], tr/val_loss:  0.002803/  2.062185, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-71  lr=['0.0015083'], tr/val_loss:  0.002726/  2.064442, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-72  lr=['0.0014127'], tr/val_loss:  0.002687/  2.068564, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-73  lr=['0.0013197'], tr/val_loss:  0.002723/  2.075982, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-74  lr=['0.0012291'], tr/val_loss:  0.002546/  2.079985, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-75  lr=['0.0011412'], tr/val_loss:  0.002479/  2.078394, tr: 100.00%, val:  75.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-76  lr=['0.0010560'], tr/val_loss:  0.002445/  2.076069, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-77  lr=['0.0009737'], tr/val_loss:  0.002430/  2.075060, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-78  lr=['0.0008942'], tr/val_loss:  0.002438/  2.083193, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-79  lr=['0.0008176'], tr/val_loss:  0.002370/  2.088954, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-80  lr=['0.0007441'], tr/val_loss:  0.002366/  2.093461, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-81  lr=['0.0006738'], tr/val_loss:  0.002383/  2.089672, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-82  lr=['0.0006066'], tr/val_loss:  0.002308/  2.089254, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-83  lr=['0.0005426'], tr/val_loss:  0.002337/  2.090937, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-84  lr=['0.0004820'], tr/val_loss:  0.002274/  2.095432, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-85  lr=['0.0004247'], tr/val_loss:  0.002315/  2.099635, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-86  lr=['0.0003708'], tr/val_loss:  0.002274/  2.100210, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-87  lr=['0.0003205'], tr/val_loss:  0.002292/  2.102348, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-88  lr=['0.0002736'], tr/val_loss:  0.002261/  2.097234, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-89  lr=['0.0002304'], tr/val_loss:  0.002261/  2.099317, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-90  lr=['0.0001907'], tr/val_loss:  0.002265/  2.097955, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-91  lr=['0.0001547'], tr/val_loss:  0.002318/  2.097922, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-92  lr=['0.0001224'], tr/val_loss:  0.002290/  2.094697, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-93  lr=['0.0000938'], tr/val_loss:  0.002295/  2.095962, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-94  lr=['0.0000690'], tr/val_loss:  0.002233/  2.095317, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-95  lr=['0.0000480'], tr/val_loss:  0.002309/  2.096341, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-96  lr=['0.0000307'], tr/val_loss:  0.002225/  2.095579, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-97  lr=['0.0000173'], tr/val_loss:  0.002244/  2.095602, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-98  lr=['0.0000077'], tr/val_loss:  0.002382/  2.095612, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-99  lr=['0.0000019'], tr/val_loss:  0.002208/  2.095617, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afbb38f9e654f8f939f57787bc65016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▃▂▃▃▅▆▇▇▇▆▆█▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▁▄▆▅▅▅▅▅▆▆▆▆▇▇▇█▇██▇█████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▃▄▅▅▅▅▆▆▆▇▇▇██████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▄▄▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▁▄▆▅▅▅▅▅▆▆▆▆▇▇▇█▇██▇█████████████████</td></tr><tr><td>val_loss</td><td>▂▂▁▄▃▂▁▂▄▃▄▃▅▄▅▅▅▅▆▆▆▇▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00221</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>2.09562</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-39</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5d40ikh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5d40ikh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_131127-f5d40ikh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: chzww06p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.014398285400411204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.546884448462287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7470916028824692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_132026-chzww06p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/chzww06p' target=\"_blank\">royal-sweep-40</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/chzww06p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/chzww06p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0143983'], tr/val_loss:  1.661746/  1.403072, tr:  39.33%, val:  44.58%, val_best:  44.58%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-1   lr=['0.0143947'], tr/val_loss:  1.266306/  1.378956, tr:  53.83%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-2   lr=['0.0143841'], tr/val_loss:  1.099919/  1.467287, tr:  58.84%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-3   lr=['0.0143663'], tr/val_loss:  0.998412/  1.495926, tr:  64.66%, val:  52.08%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-4   lr=['0.0143415'], tr/val_loss:  1.020633/  1.296458, tr:  60.78%, val:  50.83%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-5   lr=['0.0143097'], tr/val_loss:  0.883149/  1.296842, tr:  67.72%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-6   lr=['0.0142708'], tr/val_loss:  0.791485/  1.321912, tr:  68.95%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-7   lr=['0.0142249'], tr/val_loss:  0.807037/  1.385931, tr:  69.56%, val:  56.67%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-8   lr=['0.0141721'], tr/val_loss:  0.787945/  1.149087, tr:  70.58%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-9   lr=['0.0141124'], tr/val_loss:  0.655190/  1.298554, tr:  74.77%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-10  lr=['0.0140459'], tr/val_loss:  0.664057/  1.234031, tr:  76.71%, val:  65.83%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-11  lr=['0.0139727'], tr/val_loss:  0.586820/  1.367942, tr:  77.83%, val:  62.08%, val_best:  66.67%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-12  lr=['0.0138927'], tr/val_loss:  0.592848/  1.314480, tr:  78.14%, val:  65.00%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-13  lr=['0.0138062'], tr/val_loss:  0.549225/  1.464884, tr:  81.72%, val:  61.25%, val_best:  66.67%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-14  lr=['0.0137131'], tr/val_loss:  0.512465/  1.324831, tr:  83.45%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-15  lr=['0.0136136'], tr/val_loss:  0.485556/  1.379044, tr:  84.27%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-16  lr=['0.0135078'], tr/val_loss:  0.460130/  1.592335, tr:  85.29%, val:  61.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-17  lr=['0.0133957'], tr/val_loss:  0.536291/  1.441290, tr:  83.76%, val:  67.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-18  lr=['0.0132776'], tr/val_loss:  0.512797/  1.516476, tr:  86.31%, val:  58.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-19  lr=['0.0131534'], tr/val_loss:  0.416524/  1.432735, tr:  89.17%, val:  73.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-20  lr=['0.0130234'], tr/val_loss:  0.349491/  1.476347, tr:  89.79%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-21  lr=['0.0128876'], tr/val_loss:  0.298982/  1.590684, tr:  93.05%, val:  70.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-22  lr=['0.0127462'], tr/val_loss:  0.269424/  1.484379, tr:  93.87%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-23  lr=['0.0125993'], tr/val_loss:  0.279131/  1.551335, tr:  92.03%, val:  71.67%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-24  lr=['0.0124471'], tr/val_loss:  0.245729/  1.681211, tr:  95.61%, val:  72.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-25  lr=['0.0122897'], tr/val_loss:  0.184657/  1.697833, tr:  97.45%, val:  73.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-26  lr=['0.0121273'], tr/val_loss:  0.193665/  1.852681, tr:  97.04%, val:  69.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-27  lr=['0.0119600'], tr/val_loss:  0.152842/  1.690318, tr:  98.77%, val:  76.25%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-28  lr=['0.0117880'], tr/val_loss:  0.120847/  1.708719, tr:  99.18%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-29  lr=['0.0116115'], tr/val_loss:  0.156413/  1.648953, tr:  98.16%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-30  lr=['0.0114307'], tr/val_loss:  0.160974/  1.606571, tr:  98.98%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-31  lr=['0.0112457'], tr/val_loss:  0.093977/  1.661234, tr:  99.90%, val:  76.67%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-32  lr=['0.0110566'], tr/val_loss:  0.041759/  1.875427, tr: 100.00%, val:  74.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-33  lr=['0.0108638'], tr/val_loss:  0.036386/  1.805199, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-34  lr=['0.0106674'], tr/val_loss:  0.030302/  1.695324, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-35  lr=['0.0104675'], tr/val_loss:  0.015878/  1.840360, tr: 100.00%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-36  lr=['0.0102644'], tr/val_loss:  0.017742/  1.914730, tr: 100.00%, val:  76.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-37  lr=['0.0100583'], tr/val_loss:  0.008331/  1.892669, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-38  lr=['0.0098493'], tr/val_loss:  0.012470/  1.947288, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-39  lr=['0.0096378'], tr/val_loss:  0.007201/  1.972325, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-40  lr=['0.0094238'], tr/val_loss:  0.007012/  1.989958, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-41  lr=['0.0092076'], tr/val_loss:  0.006920/  1.968198, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-42  lr=['0.0089895'], tr/val_loss:  0.003193/  1.977909, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-43  lr=['0.0087696'], tr/val_loss:  0.001870/  2.022772, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-44  lr=['0.0085481'], tr/val_loss:  0.002250/  2.047371, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-45  lr=['0.0083253'], tr/val_loss:  0.001635/  2.060411, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-46  lr=['0.0081014'], tr/val_loss:  0.001329/  2.079362, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-47  lr=['0.0078766'], tr/val_loss:  0.001187/  2.071548, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-48  lr=['0.0076512'], tr/val_loss:  0.001206/  2.081600, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-49  lr=['0.0074253'], tr/val_loss:  0.001069/  2.087416, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-50  lr=['0.0071991'], tr/val_loss:  0.001002/  2.097572, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-51  lr=['0.0069730'], tr/val_loss:  0.000928/  2.102391, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-52  lr=['0.0067471'], tr/val_loss:  0.000919/  2.109152, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-53  lr=['0.0065216'], tr/val_loss:  0.000882/  2.109967, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-54  lr=['0.0062969'], tr/val_loss:  0.000860/  2.118754, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-55  lr=['0.0060729'], tr/val_loss:  0.000810/  2.125134, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-56  lr=['0.0058502'], tr/val_loss:  0.000737/  2.135104, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-57  lr=['0.0056287'], tr/val_loss:  0.000730/  2.146504, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-58  lr=['0.0054088'], tr/val_loss:  0.000712/  2.140991, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-59  lr=['0.0051906'], tr/val_loss:  0.000680/  2.138627, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-60  lr=['0.0049745'], tr/val_loss:  0.000680/  2.152065, tr: 100.00%, val:  79.58%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-61  lr=['0.0047605'], tr/val_loss:  0.000650/  2.159142, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-62  lr=['0.0045490'], tr/val_loss:  0.000639/  2.143481, tr: 100.00%, val:  79.58%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-63  lr=['0.0043400'], tr/val_loss:  0.000645/  2.145117, tr: 100.00%, val:  79.17%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-64  lr=['0.0041339'], tr/val_loss:  0.000620/  2.145037, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-65  lr=['0.0039308'], tr/val_loss:  0.000586/  2.142015, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-66  lr=['0.0037309'], tr/val_loss:  0.000584/  2.133727, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-67  lr=['0.0035345'], tr/val_loss:  0.000574/  2.140111, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-68  lr=['0.0033416'], tr/val_loss:  0.000614/  2.148931, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-69  lr=['0.0031526'], tr/val_loss:  0.000561/  2.147511, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-70  lr=['0.0029676'], tr/val_loss:  0.000547/  2.146222, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-71  lr=['0.0027867'], tr/val_loss:  0.000551/  2.151343, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-72  lr=['0.0026102'], tr/val_loss:  0.000549/  2.150576, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-73  lr=['0.0024383'], tr/val_loss:  0.000587/  2.157537, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-74  lr=['0.0022710'], tr/val_loss:  0.000532/  2.162345, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-75  lr=['0.0021086'], tr/val_loss:  0.000533/  2.168794, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-76  lr=['0.0019512'], tr/val_loss:  0.000545/  2.178144, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-77  lr=['0.0017990'], tr/val_loss:  0.000541/  2.174745, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-78  lr=['0.0016521'], tr/val_loss:  0.000531/  2.176218, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-79  lr=['0.0015107'], tr/val_loss:  0.000519/  2.174682, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-80  lr=['0.0013749'], tr/val_loss:  0.000516/  2.167759, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-81  lr=['0.0012449'], tr/val_loss:  0.000519/  2.170661, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-82  lr=['0.0011207'], tr/val_loss:  0.000516/  2.172370, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-83  lr=['0.0010025'], tr/val_loss:  0.000512/  2.169334, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-84  lr=['0.0008905'], tr/val_loss:  0.000514/  2.167209, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-85  lr=['0.0007847'], tr/val_loss:  0.000506/  2.169235, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-86  lr=['0.0006852'], tr/val_loss:  0.000502/  2.170240, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-87  lr=['0.0005921'], tr/val_loss:  0.000512/  2.170285, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-88  lr=['0.0005055'], tr/val_loss:  0.000518/  2.168756, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-89  lr=['0.0004256'], tr/val_loss:  0.000503/  2.170958, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-90  lr=['0.0003524'], tr/val_loss:  0.000508/  2.171664, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-91  lr=['0.0002859'], tr/val_loss:  0.000517/  2.170989, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-92  lr=['0.0002262'], tr/val_loss:  0.000501/  2.171206, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-93  lr=['0.0001734'], tr/val_loss:  0.000504/  2.171422, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-94  lr=['0.0001275'], tr/val_loss:  0.000511/  2.171478, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-95  lr=['0.0000886'], tr/val_loss:  0.000501/  2.171468, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-96  lr=['0.0000568'], tr/val_loss:  0.000497/  2.171585, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-97  lr=['0.0000320'], tr/val_loss:  0.000499/  2.171600, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-98  lr=['0.0000142'], tr/val_loss:  0.000558/  2.171605, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-99  lr=['0.0000036'], tr/val_loss:  0.000501/  2.171606, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0010372e9c63469b949152e18deb6b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▆▅▅▅▇▇▆█▇▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▂▃▅▅▆▅▆▆▆▆▇▆▇█▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▃▄▅▅▆▆▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▅▅▆▆▆▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▂▃▅▅▆▅▆▆▆▆▇▆▇█▇███████████████████████</td></tr><tr><td>val_loss</td><td>▂▂▁▂▁▁▁▂▂▃▄▅▄▆▅▆▆▆▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0005</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.17161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-40</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/chzww06p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/chzww06p</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_132026-chzww06p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 84y4d092 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.038554710644712026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.892567294008218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.1017891079803046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_132935-84y4d092</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/84y4d092' target=\"_blank\">drawn-sweep-42</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/84y4d092' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/84y4d092</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0385547'], tr/val_loss:  1.835215/  1.651857, tr:  35.04%, val:  40.42%, val_best:  40.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-1   lr=['0.0385452'], tr/val_loss:  1.498314/  1.590219, tr:  44.74%, val:  41.25%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-2   lr=['0.0385167'], tr/val_loss:  1.377431/  1.645277, tr:  50.36%, val:  42.08%, val_best:  42.08%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-3   lr=['0.0384692'], tr/val_loss:  1.400380/  1.557953, tr:  49.64%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-4   lr=['0.0384027'], tr/val_loss:  1.393450/  1.604772, tr:  49.95%, val:  42.08%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-5   lr=['0.0383174'], tr/val_loss:  1.411489/  1.706138, tr:  49.34%, val:  41.67%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-6   lr=['0.0382133'], tr/val_loss:  1.370911/  1.776452, tr:  47.19%, val:  43.75%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-7   lr=['0.0380904'], tr/val_loss:  1.371513/  1.657670, tr:  48.93%, val:  43.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-8   lr=['0.0379491'], tr/val_loss:  1.382653/  1.599677, tr:  50.56%, val:  49.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-9   lr=['0.0377893'], tr/val_loss:  1.414038/  1.928964, tr:  47.40%, val:  34.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-10  lr=['0.0376112'], tr/val_loss:  1.375710/  1.557392, tr:  48.21%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-11  lr=['0.0374150'], tr/val_loss:  1.279692/  1.529450, tr:  53.73%, val:  50.00%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-12  lr=['0.0372010'], tr/val_loss:  1.313335/  1.427265, tr:  53.12%, val:  51.25%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-13  lr=['0.0369692'], tr/val_loss:  1.266477/  1.606811, tr:  54.55%, val:  42.50%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-14  lr=['0.0367200'], tr/val_loss:  1.317272/  1.537952, tr:  53.12%, val:  46.67%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-15  lr=['0.0364536'], tr/val_loss:  1.307306/  1.645927, tr:  53.83%, val:  46.25%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-16  lr=['0.0361702'], tr/val_loss:  1.336485/  1.536457, tr:  54.14%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-17  lr=['0.0358702'], tr/val_loss:  1.291371/  1.592103, tr:  52.20%, val:  49.17%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-18  lr=['0.0355538'], tr/val_loss:  1.416374/  1.649064, tr:  51.28%, val:  45.42%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-19  lr=['0.0352213'], tr/val_loss:  1.360852/  1.545430, tr:  52.30%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-20  lr=['0.0348731'], tr/val_loss:  1.380226/  1.504063, tr:  53.52%, val:  48.33%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-21  lr=['0.0345095'], tr/val_loss:  1.263722/  1.859049, tr:  56.49%, val:  45.00%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-22  lr=['0.0341308'], tr/val_loss:  1.413239/  1.758666, tr:  51.48%, val:  45.00%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-23  lr=['0.0337375'], tr/val_loss:  1.361861/  1.504545, tr:  53.22%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-24  lr=['0.0333299'], tr/val_loss:  1.311281/  1.671562, tr:  55.77%, val:  51.67%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-25  lr=['0.0329085'], tr/val_loss:  1.229611/  1.634563, tr:  58.12%, val:  39.58%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-26  lr=['0.0324736'], tr/val_loss:  1.254884/  1.607018, tr:  56.28%, val:  44.17%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-27  lr=['0.0320257'], tr/val_loss:  1.272818/  1.578358, tr:  55.77%, val:  49.58%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-28  lr=['0.0315652'], tr/val_loss:  1.272512/  1.460006, tr:  54.85%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-29  lr=['0.0310926'], tr/val_loss:  1.232600/  1.466540, tr:  57.20%, val:  45.00%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-30  lr=['0.0306083'], tr/val_loss:  1.276649/  1.510756, tr:  55.77%, val:  50.42%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-31  lr=['0.0301128'], tr/val_loss:  1.170485/  1.493453, tr:  58.43%, val:  50.83%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-32  lr=['0.0296067'], tr/val_loss:  1.278111/  1.586122, tr:  54.75%, val:  45.83%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-33  lr=['0.0290903'], tr/val_loss:  1.205804/  1.368204, tr:  55.57%, val:  52.08%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-34  lr=['0.0285643'], tr/val_loss:  1.137367/  1.504918, tr:  58.63%, val:  46.67%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-35  lr=['0.0280291'], tr/val_loss:  1.138579/  1.639129, tr:  57.81%, val:  44.17%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-36  lr=['0.0274853'], tr/val_loss:  1.150211/  1.534125, tr:  57.51%, val:  45.42%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-37  lr=['0.0269333'], tr/val_loss:  1.144525/  1.541672, tr:  58.22%, val:  50.00%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-38  lr=['0.0263738'], tr/val_loss:  1.111539/  1.465878, tr:  60.47%, val:  50.83%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-39  lr=['0.0258073'], tr/val_loss:  1.077742/  1.534713, tr:  62.41%, val:  50.00%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-40  lr=['0.0252344'], tr/val_loss:  1.066813/  1.379171, tr:  60.98%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-41  lr=['0.0246556'], tr/val_loss:  1.085414/  1.504084, tr:  59.65%, val:  51.67%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-42  lr=['0.0240714'], tr/val_loss:  1.100429/  1.641265, tr:  60.16%, val:  50.42%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-43  lr=['0.0234826'], tr/val_loss:  1.073012/  1.535303, tr:  60.78%, val:  51.67%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-44  lr=['0.0228896'], tr/val_loss:  1.044534/  1.429688, tr:  60.98%, val:  52.50%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-45  lr=['0.0222930'], tr/val_loss:  1.024464/  1.325506, tr:  62.00%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-46  lr=['0.0216934'], tr/val_loss:  1.027570/  1.401902, tr:  62.10%, val:  50.83%, val_best:  54.17%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-47  lr=['0.0210915'], tr/val_loss:  0.999963/  1.372998, tr:  63.74%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-48  lr=['0.0204878'], tr/val_loss:  1.007321/  1.512337, tr:  63.64%, val:  50.42%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-49  lr=['0.0198829'], tr/val_loss:  0.996230/  1.480346, tr:  62.00%, val:  50.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-50  lr=['0.0192774'], tr/val_loss:  0.971176/  1.514425, tr:  63.74%, val:  51.67%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-51  lr=['0.0186718'], tr/val_loss:  0.995673/  1.410451, tr:  62.82%, val:  51.67%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-52  lr=['0.0180669'], tr/val_loss:  0.950583/  1.412353, tr:  65.37%, val:  55.00%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-53  lr=['0.0174632'], tr/val_loss:  0.935560/  1.436432, tr:  64.76%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-54  lr=['0.0168613'], tr/val_loss:  0.918636/  1.404575, tr:  67.31%, val:  55.42%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-55  lr=['0.0162617'], tr/val_loss:  0.927692/  1.489390, tr:  67.01%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-56  lr=['0.0156651'], tr/val_loss:  0.897521/  1.354947, tr:  66.29%, val:  55.42%, val_best:  56.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-57  lr=['0.0150721'], tr/val_loss:  0.886147/  1.447413, tr:  67.72%, val:  55.00%, val_best:  56.67%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-58  lr=['0.0144833'], tr/val_loss:  0.848052/  1.370273, tr:  68.54%, val:  52.50%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-59  lr=['0.0138991'], tr/val_loss:  0.854307/  1.442652, tr:  68.03%, val:  52.92%, val_best:  56.67%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-60  lr=['0.0133203'], tr/val_loss:  0.849993/  1.393299, tr:  68.74%, val:  50.83%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-61  lr=['0.0127474'], tr/val_loss:  0.828740/  1.390621, tr:  69.25%, val:  53.75%, val_best:  56.67%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-62  lr=['0.0121809'], tr/val_loss:  0.800348/  1.411735, tr:  70.07%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-63  lr=['0.0116214'], tr/val_loss:  0.794908/  1.362782, tr:  68.74%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-64  lr=['0.0110695'], tr/val_loss:  0.774815/  1.351693, tr:  70.17%, val:  59.58%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-65  lr=['0.0105256'], tr/val_loss:  0.780552/  1.438280, tr:  69.05%, val:  55.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-66  lr=['0.0099904'], tr/val_loss:  0.766672/  1.468954, tr:  71.40%, val:  53.75%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-67  lr=['0.0094644'], tr/val_loss:  0.756299/  1.415309, tr:  70.79%, val:  52.92%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-68  lr=['0.0089480'], tr/val_loss:  0.711668/  1.477034, tr:  71.60%, val:  55.83%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-69  lr=['0.0084419'], tr/val_loss:  0.693873/  1.470007, tr:  74.57%, val:  52.92%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-70  lr=['0.0079464'], tr/val_loss:  0.714583/  1.474379, tr:  72.73%, val:  55.42%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-71  lr=['0.0074621'], tr/val_loss:  0.718147/  1.433923, tr:  73.75%, val:  57.92%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-72  lr=['0.0069895'], tr/val_loss:  0.683210/  1.396675, tr:  77.53%, val:  59.58%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-73  lr=['0.0065290'], tr/val_loss:  0.694122/  1.464664, tr:  75.38%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-74  lr=['0.0060811'], tr/val_loss:  0.661023/  1.449859, tr:  76.92%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-75  lr=['0.0056462'], tr/val_loss:  0.654161/  1.437941, tr:  76.10%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-76  lr=['0.0052248'], tr/val_loss:  0.636382/  1.455582, tr:  76.92%, val:  60.00%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-77  lr=['0.0048172'], tr/val_loss:  0.631193/  1.489205, tr:  79.57%, val:  59.17%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-78  lr=['0.0044239'], tr/val_loss:  0.598850/  1.499151, tr:  80.69%, val:  57.92%, val_best:  61.67%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-79  lr=['0.0040453'], tr/val_loss:  0.580955/  1.464377, tr:  82.23%, val:  57.08%, val_best:  61.67%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-80  lr=['0.0036816'], tr/val_loss:  0.570170/  1.458549, tr:  83.35%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-81  lr=['0.0033334'], tr/val_loss:  0.557357/  1.470778, tr:  85.09%, val:  60.42%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-82  lr=['0.0030009'], tr/val_loss:  0.556930/  1.486298, tr:  84.98%, val:  60.83%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-83  lr=['0.0026845'], tr/val_loss:  0.528067/  1.475264, tr:  86.01%, val:  61.67%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-84  lr=['0.0023845'], tr/val_loss:  0.517167/  1.496220, tr:  87.74%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-85  lr=['0.0021011'], tr/val_loss:  0.508080/  1.512264, tr:  87.95%, val:  60.42%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-86  lr=['0.0018347'], tr/val_loss:  0.494826/  1.502873, tr:  89.17%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-87  lr=['0.0015855'], tr/val_loss:  0.489416/  1.487952, tr:  89.48%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-88  lr=['0.0013537'], tr/val_loss:  0.492840/  1.486688, tr:  88.05%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-89  lr=['0.0011397'], tr/val_loss:  0.479487/  1.508859, tr:  89.07%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-90  lr=['0.0009435'], tr/val_loss:  0.472153/  1.516661, tr:  90.09%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-91  lr=['0.0007654'], tr/val_loss:  0.473004/  1.519751, tr:  91.32%, val:  63.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-92  lr=['0.0006056'], tr/val_loss:  0.468028/  1.535000, tr:  91.11%, val:  64.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-93  lr=['0.0004643'], tr/val_loss:  0.455405/  1.533225, tr:  91.62%, val:  65.00%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-94  lr=['0.0003415'], tr/val_loss:  0.449736/  1.529643, tr:  92.44%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-95  lr=['0.0002373'], tr/val_loss:  0.443769/  1.535763, tr:  91.62%, val:  64.58%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-96  lr=['0.0001520'], tr/val_loss:  0.449238/  1.526819, tr:  92.13%, val:  64.58%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-97  lr=['0.0000856'], tr/val_loss:  0.439540/  1.526576, tr:  91.62%, val:  64.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-98  lr=['0.0000380'], tr/val_loss:  0.444547/  1.525886, tr:  91.83%, val:  65.00%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-99  lr=['0.0000095'], tr/val_loss:  0.437351/  1.528498, tr:  91.93%, val:  64.58%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7821f9d5024ed0986f1b3096055920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▃▂▂▂▄▂▅▅▅▄▂▁▃▄▅▃▃▄▂▂▄▄▅▅▇▇▆▄▄▆▇▆▆▇▇██▅</td></tr><tr><td>summary_val_acc</td><td>▂▃▃▃▁▅▄▄▅▃▅▃▃▄▃▅▅▅▅▆▅▆▆▆▅▆▆▅▆▇▇▇▆▇██████</td></tr><tr><td>tr_acc</td><td>▁▃▃▃▃▃▃▃▃▄▄▄▄▃▄▄▄▄▄▅▄▅▅▅▅▅▅▅▆▆▆▇▇▇██████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▆▆▆▅▅▅▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇██████</td></tr><tr><td>val_acc_now</td><td>▂▃▃▃▁▅▄▄▅▃▅▃▃▄▃▅▅▅▅▆▅▆▆▆▅▆▆▅▆▇▇▇▆▇██████</td></tr><tr><td>val_loss</td><td>▅▄▄▅█▂▃▄▃▇▅▄▂▄▄▃▃▄▂▁▂▁▁▂▂▁▂▂▂▁▂▂▂▂▃▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.91931</td></tr><tr><td>tr_epoch_loss</td><td>0.43735</td></tr><tr><td>val_acc_best</td><td>0.65833</td></tr><tr><td>val_acc_now</td><td>0.64583</td></tr><tr><td>val_loss</td><td>1.5285</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-42</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/84y4d092' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/84y4d092</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_132935-84y4d092/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jwkpawt4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00688574154315935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.7482957003378687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.18558520275264925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_133845-jwkpawt4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jwkpawt4' target=\"_blank\">blooming-sweep-44</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jwkpawt4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jwkpawt4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0068857'], tr/val_loss:  1.594987/  1.338995, tr:  44.64%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-1   lr=['0.0068840'], tr/val_loss:  1.210565/  1.363038, tr:  53.52%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-2   lr=['0.0068789'], tr/val_loss:  0.987410/  1.425512, tr:  61.08%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-3   lr=['0.0068705'], tr/val_loss:  0.846523/  1.371296, tr:  68.23%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-4   lr=['0.0068586'], tr/val_loss:  0.812110/  1.284606, tr:  69.05%, val:  55.42%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-5   lr=['0.0068434'], tr/val_loss:  0.683518/  1.134523, tr:  74.87%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-6   lr=['0.0068248'], tr/val_loss:  0.661060/  1.187594, tr:  73.95%, val:  61.67%, val_best:  63.33%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-7   lr=['0.0068028'], tr/val_loss:  0.576270/  1.406192, tr:  79.78%, val:  59.58%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-8   lr=['0.0067776'], tr/val_loss:  0.515628/  1.289734, tr:  79.98%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-9   lr=['0.0067490'], tr/val_loss:  0.464989/  1.245001, tr:  84.07%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-10  lr=['0.0067172'], tr/val_loss:  0.325998/  1.736031, tr:  88.76%, val:  63.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-11  lr=['0.0066822'], tr/val_loss:  0.343695/  1.558917, tr:  90.09%, val:  70.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-12  lr=['0.0066440'], tr/val_loss:  0.316064/  1.424676, tr:  92.03%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-13  lr=['0.0066026'], tr/val_loss:  0.261880/  1.385074, tr:  92.34%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-14  lr=['0.0065581'], tr/val_loss:  0.158016/  1.348508, tr:  97.14%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-15  lr=['0.0065105'], tr/val_loss:  0.172044/  1.483662, tr:  96.32%, val:  72.08%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-16  lr=['0.0064599'], tr/val_loss:  0.106747/  1.512661, tr:  98.47%, val:  72.50%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-17  lr=['0.0064063'], tr/val_loss:  0.124937/  1.558349, tr:  97.34%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-18  lr=['0.0063498'], tr/val_loss:  0.082830/  1.608343, tr:  98.67%, val:  73.33%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-19  lr=['0.0062904'], tr/val_loss:  0.051928/  1.559261, tr:  99.08%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-20  lr=['0.0062282'], tr/val_loss:  0.021548/  1.669011, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-21  lr=['0.0061633'], tr/val_loss:  0.009176/  1.653200, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-22  lr=['0.0060956'], tr/val_loss:  0.005644/  1.668183, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-23  lr=['0.0060254'], tr/val_loss:  0.003095/  1.701850, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-24  lr=['0.0059526'], tr/val_loss:  0.003165/  1.742178, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-25  lr=['0.0058773'], tr/val_loss:  0.002617/  1.715083, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-26  lr=['0.0057997'], tr/val_loss:  0.001781/  1.735590, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-27  lr=['0.0057197'], tr/val_loss:  0.001523/  1.754457, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-28  lr=['0.0056374'], tr/val_loss:  0.001287/  1.757101, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-29  lr=['0.0055530'], tr/val_loss:  0.001215/  1.769547, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-30  lr=['0.0054665'], tr/val_loss:  0.001106/  1.786592, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-31  lr=['0.0053781'], tr/val_loss:  0.001019/  1.785033, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-32  lr=['0.0052877'], tr/val_loss:  0.000959/  1.796480, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-33  lr=['0.0051954'], tr/val_loss:  0.000867/  1.802261, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-34  lr=['0.0051015'], tr/val_loss:  0.000817/  1.810979, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-35  lr=['0.0050059'], tr/val_loss:  0.000790/  1.815903, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-36  lr=['0.0049088'], tr/val_loss:  0.000752/  1.814735, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-37  lr=['0.0048102'], tr/val_loss:  0.000719/  1.820913, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-38  lr=['0.0047103'], tr/val_loss:  0.000728/  1.828351, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-39  lr=['0.0046091'], tr/val_loss:  0.000661/  1.832258, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-40  lr=['0.0045068'], tr/val_loss:  0.000656/  1.848312, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-41  lr=['0.0044034'], tr/val_loss:  0.000624/  1.850603, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-42  lr=['0.0042991'], tr/val_loss:  0.000600/  1.854968, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-43  lr=['0.0041939'], tr/val_loss:  0.000598/  1.850787, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-44  lr=['0.0040880'], tr/val_loss:  0.000565/  1.855420, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-45  lr=['0.0039815'], tr/val_loss:  0.000547/  1.862888, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-46  lr=['0.0038744'], tr/val_loss:  0.000542/  1.863786, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-47  lr=['0.0037669'], tr/val_loss:  0.000531/  1.865399, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-48  lr=['0.0036591'], tr/val_loss:  0.000515/  1.859478, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-49  lr=['0.0035510'], tr/val_loss:  0.000488/  1.863177, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-50  lr=['0.0034429'], tr/val_loss:  0.000497/  1.869733, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-51  lr=['0.0033347'], tr/val_loss:  0.000493/  1.881264, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-52  lr=['0.0032267'], tr/val_loss:  0.000503/  1.879818, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-53  lr=['0.0031189'], tr/val_loss:  0.000461/  1.884723, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-54  lr=['0.0030114'], tr/val_loss:  0.000458/  1.887179, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-55  lr=['0.0029043'], tr/val_loss:  0.000448/  1.891539, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-56  lr=['0.0027977'], tr/val_loss:  0.000451/  1.889761, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-57  lr=['0.0026918'], tr/val_loss:  0.000445/  1.892705, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-58  lr=['0.0025867'], tr/val_loss:  0.000427/  1.895760, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-59  lr=['0.0024823'], tr/val_loss:  0.000427/  1.898069, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-60  lr=['0.0023790'], tr/val_loss:  0.000430/  1.897407, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-61  lr=['0.0022766'], tr/val_loss:  0.000422/  1.897227, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-62  lr=['0.0021755'], tr/val_loss:  0.000414/  1.901698, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-63  lr=['0.0020755'], tr/val_loss:  0.000417/  1.900127, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-64  lr=['0.0019770'], tr/val_loss:  0.000407/  1.899531, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-65  lr=['0.0018798'], tr/val_loss:  0.000401/  1.901243, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-66  lr=['0.0017843'], tr/val_loss:  0.000402/  1.907799, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-67  lr=['0.0016903'], tr/val_loss:  0.000394/  1.906961, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-68  lr=['0.0015981'], tr/val_loss:  0.000394/  1.908753, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-69  lr=['0.0015077'], tr/val_loss:  0.000388/  1.911542, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-70  lr=['0.0014192'], tr/val_loss:  0.000385/  1.906035, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-71  lr=['0.0013327'], tr/val_loss:  0.000383/  1.901887, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-72  lr=['0.0012483'], tr/val_loss:  0.000381/  1.902853, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-73  lr=['0.0011661'], tr/val_loss:  0.000390/  1.905189, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-74  lr=['0.0010861'], tr/val_loss:  0.000378/  1.905834, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-75  lr=['0.0010084'], tr/val_loss:  0.000375/  1.907054, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-76  lr=['0.0009331'], tr/val_loss:  0.000376/  1.905176, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-77  lr=['0.0008603'], tr/val_loss:  0.000388/  1.907742, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-78  lr=['0.0007901'], tr/val_loss:  0.000370/  1.904397, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-79  lr=['0.0007225'], tr/val_loss:  0.000372/  1.900950, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-80  lr=['0.0006575'], tr/val_loss:  0.000372/  1.902161, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-81  lr=['0.0005953'], tr/val_loss:  0.000371/  1.899670, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-82  lr=['0.0005360'], tr/val_loss:  0.000372/  1.902039, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-83  lr=['0.0004794'], tr/val_loss:  0.000379/  1.904863, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-84  lr=['0.0004259'], tr/val_loss:  0.000370/  1.904742, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-85  lr=['0.0003753'], tr/val_loss:  0.000367/  1.904539, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-86  lr=['0.0003277'], tr/val_loss:  0.000369/  1.902566, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-87  lr=['0.0002832'], tr/val_loss:  0.000368/  1.904548, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-88  lr=['0.0002418'], tr/val_loss:  0.000371/  1.902987, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-89  lr=['0.0002035'], tr/val_loss:  0.000369/  1.904740, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-90  lr=['0.0001685'], tr/val_loss:  0.000374/  1.905071, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-91  lr=['0.0001367'], tr/val_loss:  0.000370/  1.907279, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-92  lr=['0.0001082'], tr/val_loss:  0.000367/  1.907533, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-93  lr=['0.0000829'], tr/val_loss:  0.000373/  1.907295, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-94  lr=['0.0000610'], tr/val_loss:  0.000370/  1.906192, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-95  lr=['0.0000424'], tr/val_loss:  0.000369/  1.906518, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-96  lr=['0.0000271'], tr/val_loss:  0.000371/  1.906530, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-97  lr=['0.0000153'], tr/val_loss:  0.000364/  1.906536, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-98  lr=['0.0000068'], tr/val_loss:  0.000387/  1.906538, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-99  lr=['0.0000017'], tr/val_loss:  0.000365/  1.906538, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24c89de7aeb4ba09d527361d547caf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▆▅██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▃▆▆▇▇▇█▇█████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▂▄▆▆▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▃▆▆▇▇▇█▇█████████████████████████████</td></tr><tr><td>val_loss</td><td>▂▃▁▃▁▃▂▄▄▅▆▆▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00036</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>1.90654</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-44</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jwkpawt4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jwkpawt4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_133845-jwkpawt4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uk846qi3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.010087016819617402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.0026620077675408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.499622640462124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_134752-uk846qi3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uk846qi3' target=\"_blank\">faithful-sweep-46</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uk846qi3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uk846qi3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100870'], tr/val_loss:  1.876292/  1.390005, tr:  32.89%, val:  49.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-1   lr=['0.0100845'], tr/val_loss:  1.274734/  1.368072, tr:  54.85%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-2   lr=['0.0100771'], tr/val_loss:  1.024754/  1.233301, tr:  63.43%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-3   lr=['0.0100646'], tr/val_loss:  0.886887/  1.218584, tr:  67.52%, val:  61.67%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-4   lr=['0.0100472'], tr/val_loss:  0.806243/  1.185992, tr:  71.71%, val:  56.67%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-5   lr=['0.0100249'], tr/val_loss:  0.736884/  1.213220, tr:  73.24%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-6   lr=['0.0099977'], tr/val_loss:  0.658430/  1.306619, tr:  75.18%, val:  61.67%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-7   lr=['0.0099656'], tr/val_loss:  0.613808/  1.434751, tr:  80.08%, val:  60.00%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-8   lr=['0.0099286'], tr/val_loss:  0.526801/  1.333379, tr:  81.82%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-9   lr=['0.0098868'], tr/val_loss:  0.436318/  1.423998, tr:  87.13%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-10  lr=['0.0098402'], tr/val_loss:  0.388288/  1.514916, tr:  88.76%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-11  lr=['0.0097888'], tr/val_loss:  0.354498/  1.617363, tr:  90.50%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-12  lr=['0.0097328'], tr/val_loss:  0.271284/  1.439254, tr:  93.97%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-13  lr=['0.0096722'], tr/val_loss:  0.244330/  1.504961, tr:  93.26%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-14  lr=['0.0096070'], tr/val_loss:  0.170397/  1.565569, tr:  97.45%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-15  lr=['0.0095373'], tr/val_loss:  0.162162/  1.645405, tr:  97.24%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-16  lr=['0.0094632'], tr/val_loss:  0.101500/  2.012747, tr:  99.49%, val:  68.75%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-17  lr=['0.0093847'], tr/val_loss:  0.220261/  1.755796, tr:  95.30%, val:  72.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-18  lr=['0.0093019'], tr/val_loss:  0.116429/  1.747520, tr:  98.98%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-19  lr=['0.0092149'], tr/val_loss:  0.041256/  1.796604, tr:  99.80%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-20  lr=['0.0091238'], tr/val_loss:  0.026126/  1.974523, tr: 100.00%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-21  lr=['0.0090287'], tr/val_loss:  0.009385/  1.922827, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-22  lr=['0.0089296'], tr/val_loss:  0.005985/  1.958171, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-23  lr=['0.0088267'], tr/val_loss:  0.003869/  1.979514, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-24  lr=['0.0087201'], tr/val_loss:  0.003598/  2.013725, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-25  lr=['0.0086098'], tr/val_loss:  0.002712/  2.056926, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-26  lr=['0.0084960'], tr/val_loss:  0.002025/  2.063767, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-27  lr=['0.0083788'], tr/val_loss:  0.001669/  2.064962, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-28  lr=['0.0082584'], tr/val_loss:  0.001470/  2.095231, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-29  lr=['0.0081347'], tr/val_loss:  0.001315/  2.102882, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-30  lr=['0.0080080'], tr/val_loss:  0.001233/  2.107822, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-31  lr=['0.0078784'], tr/val_loss:  0.001159/  2.129092, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-32  lr=['0.0077460'], tr/val_loss:  0.001057/  2.135180, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-33  lr=['0.0076109'], tr/val_loss:  0.000987/  2.149448, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-34  lr=['0.0074732'], tr/val_loss:  0.000936/  2.166308, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-35  lr=['0.0073332'], tr/val_loss:  0.000903/  2.174253, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-36  lr=['0.0071909'], tr/val_loss:  0.000875/  2.179569, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-37  lr=['0.0070465'], tr/val_loss:  0.000827/  2.172427, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-38  lr=['0.0069001'], tr/val_loss:  0.000783/  2.186548, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-39  lr=['0.0067519'], tr/val_loss:  0.000764/  2.188464, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-40  lr=['0.0066020'], tr/val_loss:  0.000736/  2.194344, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 13.03it/s]\n",
      "epoch-41  lr=['0.0064506'], tr/val_loss:  0.000691/  2.188570, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-42  lr=['0.0062978'], tr/val_loss:  0.000684/  2.203325, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-43  lr=['0.0061437'], tr/val_loss:  0.000630/  2.205778, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-44  lr=['0.0059886'], tr/val_loss:  0.000634/  2.217919, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-45  lr=['0.0058325'], tr/val_loss:  0.000603/  2.218467, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-46  lr=['0.0056756'], tr/val_loss:  0.000569/  2.220727, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-47  lr=['0.0055181'], tr/val_loss:  0.000588/  2.232086, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-48  lr=['0.0053602'], tr/val_loss:  0.000559/  2.238071, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-49  lr=['0.0052019'], tr/val_loss:  0.000529/  2.236129, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-50  lr=['0.0050435'], tr/val_loss:  0.000546/  2.229254, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-51  lr=['0.0048851'], tr/val_loss:  0.000522/  2.238073, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-52  lr=['0.0047268'], tr/val_loss:  0.000518/  2.246801, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-53  lr=['0.0045689'], tr/val_loss:  0.000508/  2.251716, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-54  lr=['0.0044114'], tr/val_loss:  0.000497/  2.250600, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-55  lr=['0.0042545'], tr/val_loss:  0.000491/  2.254389, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-56  lr=['0.0040984'], tr/val_loss:  0.000471/  2.257606, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-57  lr=['0.0039433'], tr/val_loss:  0.000474/  2.263680, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-58  lr=['0.0037892'], tr/val_loss:  0.000462/  2.255864, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-59  lr=['0.0036364'], tr/val_loss:  0.000456/  2.261857, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-60  lr=['0.0034850'], tr/val_loss:  0.000448/  2.261583, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-61  lr=['0.0033351'], tr/val_loss:  0.000447/  2.261446, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-62  lr=['0.0031869'], tr/val_loss:  0.000442/  2.270083, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-63  lr=['0.0030405'], tr/val_loss:  0.000436/  2.270257, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-64  lr=['0.0028961'], tr/val_loss:  0.000428/  2.270400, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-65  lr=['0.0027538'], tr/val_loss:  0.000424/  2.271814, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-66  lr=['0.0026138'], tr/val_loss:  0.000424/  2.265516, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-67  lr=['0.0024762'], tr/val_loss:  0.000427/  2.270365, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-68  lr=['0.0023411'], tr/val_loss:  0.000416/  2.273771, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-69  lr=['0.0022086'], tr/val_loss:  0.000412/  2.276164, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-70  lr=['0.0020790'], tr/val_loss:  0.000414/  2.276606, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-71  lr=['0.0019523'], tr/val_loss:  0.000400/  2.280285, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-72  lr=['0.0018287'], tr/val_loss:  0.000402/  2.282425, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-73  lr=['0.0017082'], tr/val_loss:  0.000425/  2.283635, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-74  lr=['0.0015910'], tr/val_loss:  0.000410/  2.277392, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-75  lr=['0.0014772'], tr/val_loss:  0.000400/  2.279497, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-76  lr=['0.0013669'], tr/val_loss:  0.000407/  2.283978, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-77  lr=['0.0012603'], tr/val_loss:  0.000402/  2.284959, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-78  lr=['0.0011574'], tr/val_loss:  0.000395/  2.287774, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-79  lr=['0.0010584'], tr/val_loss:  0.000395/  2.287518, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-80  lr=['0.0009632'], tr/val_loss:  0.000390/  2.288628, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-81  lr=['0.0008721'], tr/val_loss:  0.000391/  2.286260, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-82  lr=['0.0007851'], tr/val_loss:  0.000382/  2.284221, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-83  lr=['0.0007023'], tr/val_loss:  0.000386/  2.284317, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-84  lr=['0.0006238'], tr/val_loss:  0.000380/  2.283627, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-85  lr=['0.0005497'], tr/val_loss:  0.000379/  2.283342, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-86  lr=['0.0004800'], tr/val_loss:  0.000382/  2.283971, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-87  lr=['0.0004148'], tr/val_loss:  0.000380/  2.285024, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-88  lr=['0.0003542'], tr/val_loss:  0.000377/  2.285325, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-89  lr=['0.0002982'], tr/val_loss:  0.000382/  2.285685, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-90  lr=['0.0002468'], tr/val_loss:  0.000381/  2.285919, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-91  lr=['0.0002003'], tr/val_loss:  0.000386/  2.286004, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-92  lr=['0.0001585'], tr/val_loss:  0.000382/  2.286281, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]\n",
      "epoch-93  lr=['0.0001215'], tr/val_loss:  0.000388/  2.286714, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-94  lr=['0.0000893'], tr/val_loss:  0.000388/  2.285891, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-95  lr=['0.0000621'], tr/val_loss:  0.000391/  2.285830, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-96  lr=['0.0000398'], tr/val_loss:  0.000379/  2.286706, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-97  lr=['0.0000224'], tr/val_loss:  0.000380/  2.286288, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-98  lr=['0.0000100'], tr/val_loss:  0.000386/  2.286291, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-99  lr=['0.0000025'], tr/val_loss:  0.000383/  2.286291, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7fae8b06804335b13382ae32c7ce82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▅▆▆██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▃▃▅▇▇▆▇███████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▄▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▃▃▅▇▇▆▇███████████████████████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▃▃▃▃▅▅▆▆▇▇▇▇▇▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00038</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.82083</td></tr><tr><td>val_loss</td><td>2.28629</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-46</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uk846qi3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uk846qi3</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_134752-uk846qi3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zy8w9nh5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008241673295728464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.0082183589453813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7501220736674783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_135715-zy8w9nh5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zy8w9nh5' target=\"_blank\">clean-sweep-48</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zy8w9nh5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zy8w9nh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0082417'], tr/val_loss:  1.671780/  1.382286, tr:  39.94%, val:  48.75%, val_best:  48.75%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-1   lr=['0.0082396'], tr/val_loss:  1.212777/  1.321682, tr:  55.26%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-2   lr=['0.0082335'], tr/val_loss:  1.034191/  1.377741, tr:  62.10%, val:  49.17%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-3   lr=['0.0082234'], tr/val_loss:  0.949646/  1.244096, tr:  64.66%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-4   lr=['0.0082092'], tr/val_loss:  0.925284/  1.254680, tr:  67.11%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-5   lr=['0.0081909'], tr/val_loss:  0.837790/  1.353700, tr:  70.07%, val:  55.42%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-6   lr=['0.0081687'], tr/val_loss:  0.800349/  1.431172, tr:  70.07%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-7   lr=['0.0081424'], tr/val_loss:  0.809981/  1.358391, tr:  70.68%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-8   lr=['0.0081122'], tr/val_loss:  0.706762/  1.238616, tr:  74.67%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-9   lr=['0.0080781'], tr/val_loss:  0.526907/  1.399421, tr:  80.18%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-10  lr=['0.0080400'], tr/val_loss:  0.472845/  1.364218, tr:  84.27%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-11  lr=['0.0079981'], tr/val_loss:  0.493143/  1.457994, tr:  83.66%, val:  66.25%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-12  lr=['0.0079523'], tr/val_loss:  0.494693/  1.304152, tr:  84.47%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-13  lr=['0.0079028'], tr/val_loss:  0.457101/  1.395100, tr:  85.80%, val:  62.92%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-14  lr=['0.0078495'], tr/val_loss:  0.383418/  1.304498, tr:  89.68%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-15  lr=['0.0077925'], tr/val_loss:  0.389548/  1.403353, tr:  90.50%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-16  lr=['0.0077320'], tr/val_loss:  0.329179/  1.495600, tr:  93.16%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-17  lr=['0.0076678'], tr/val_loss:  0.343063/  1.393248, tr:  92.24%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-18  lr=['0.0076002'], tr/val_loss:  0.307711/  1.601844, tr:  92.44%, val:  69.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-19  lr=['0.0075291'], tr/val_loss:  0.269863/  1.537535, tr:  95.81%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-20  lr=['0.0074547'], tr/val_loss:  0.235300/  1.609232, tr:  94.89%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-21  lr=['0.0073769'], tr/val_loss:  0.206285/  1.584463, tr:  96.94%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-22  lr=['0.0072960'], tr/val_loss:  0.223953/  1.497917, tr:  97.14%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-23  lr=['0.0072119'], tr/val_loss:  0.170376/  1.570580, tr:  96.83%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-24  lr=['0.0071248'], tr/val_loss:  0.121703/  1.900459, tr:  99.59%, val:  70.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-25  lr=['0.0070347'], tr/val_loss:  0.124595/  1.736933, tr:  99.49%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-26  lr=['0.0069417'], tr/val_loss:  0.088862/  1.759437, tr:  99.69%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-27  lr=['0.0068460'], tr/val_loss:  0.060557/  1.862275, tr: 100.00%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-28  lr=['0.0067476'], tr/val_loss:  0.047967/  1.716236, tr:  99.90%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-29  lr=['0.0066465'], tr/val_loss:  0.034358/  1.960239, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-30  lr=['0.0065430'], tr/val_loss:  0.115539/  2.014014, tr:  98.98%, val:  74.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-31  lr=['0.0064371'], tr/val_loss:  0.076214/  1.831396, tr:  99.80%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-32  lr=['0.0063289'], tr/val_loss:  0.042993/  1.841294, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-33  lr=['0.0062185'], tr/val_loss:  0.021061/  1.809885, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-34  lr=['0.0061061'], tr/val_loss:  0.012562/  1.908831, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-35  lr=['0.0059917'], tr/val_loss:  0.006549/  1.942861, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-36  lr=['0.0058754'], tr/val_loss:  0.004829/  1.950894, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-37  lr=['0.0057574'], tr/val_loss:  0.004062/  1.986275, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-38  lr=['0.0056378'], tr/val_loss:  0.002664/  2.006557, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-39  lr=['0.0055167'], tr/val_loss:  0.002039/  2.003803, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-40  lr=['0.0053942'], tr/val_loss:  0.001887/  2.018498, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-41  lr=['0.0052705'], tr/val_loss:  0.001781/  2.043268, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-42  lr=['0.0051456'], tr/val_loss:  0.001703/  2.049548, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-43  lr=['0.0050198'], tr/val_loss:  0.001524/  2.044431, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-44  lr=['0.0048930'], tr/val_loss:  0.001285/  2.050044, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-45  lr=['0.0047655'], tr/val_loss:  0.001247/  2.046140, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-46  lr=['0.0046373'], tr/val_loss:  0.001259/  2.048019, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-47  lr=['0.0045086'], tr/val_loss:  0.001176/  2.062969, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-48  lr=['0.0043796'], tr/val_loss:  0.001140/  2.070545, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-49  lr=['0.0042503'], tr/val_loss:  0.001057/  2.087136, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-50  lr=['0.0041208'], tr/val_loss:  0.001030/  2.073544, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-51  lr=['0.0039914'], tr/val_loss:  0.001004/  2.073244, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-52  lr=['0.0038621'], tr/val_loss:  0.001116/  2.088277, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-53  lr=['0.0037330'], tr/val_loss:  0.000958/  2.109685, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-54  lr=['0.0036044'], tr/val_loss:  0.000897/  2.116795, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-55  lr=['0.0034762'], tr/val_loss:  0.000856/  2.124053, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-56  lr=['0.0033487'], tr/val_loss:  0.000798/  2.121807, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-57  lr=['0.0032219'], tr/val_loss:  0.000794/  2.121902, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-58  lr=['0.0030960'], tr/val_loss:  0.000794/  2.118965, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-59  lr=['0.0029712'], tr/val_loss:  0.000764/  2.121241, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-60  lr=['0.0028474'], tr/val_loss:  0.000752/  2.115511, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-61  lr=['0.0027250'], tr/val_loss:  0.000755/  2.116996, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-62  lr=['0.0026039'], tr/val_loss:  0.000768/  2.120868, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-63  lr=['0.0024843'], tr/val_loss:  0.000744/  2.123647, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-64  lr=['0.0023663'], tr/val_loss:  0.000706/  2.123217, tr: 100.00%, val:  80.00%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-65  lr=['0.0022500'], tr/val_loss:  0.000693/  2.125311, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-66  lr=['0.0021356'], tr/val_loss:  0.000687/  2.131545, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-67  lr=['0.0020232'], tr/val_loss:  0.000684/  2.132978, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-68  lr=['0.0019128'], tr/val_loss:  0.000665/  2.132520, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-69  lr=['0.0018046'], tr/val_loss:  0.000660/  2.137923, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-70  lr=['0.0016987'], tr/val_loss:  0.000665/  2.140533, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-71  lr=['0.0015951'], tr/val_loss:  0.000665/  2.141231, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-72  lr=['0.0014941'], tr/val_loss:  0.000666/  2.142060, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-73  lr=['0.0013957'], tr/val_loss:  0.000699/  2.142189, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-74  lr=['0.0012999'], tr/val_loss:  0.000642/  2.141089, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-75  lr=['0.0012070'], tr/val_loss:  0.000626/  2.144942, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-76  lr=['0.0011169'], tr/val_loss:  0.000639/  2.146179, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-77  lr=['0.0010298'], tr/val_loss:  0.000630/  2.143186, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-78  lr=['0.0009457'], tr/val_loss:  0.000629/  2.147753, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-79  lr=['0.0008647'], tr/val_loss:  0.000620/  2.146623, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-80  lr=['0.0007870'], tr/val_loss:  0.000629/  2.150451, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-81  lr=['0.0007126'], tr/val_loss:  0.000625/  2.149610, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-82  lr=['0.0006415'], tr/val_loss:  0.000615/  2.152292, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-83  lr=['0.0005739'], tr/val_loss:  0.000607/  2.154866, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-84  lr=['0.0005097'], tr/val_loss:  0.000600/  2.154853, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-85  lr=['0.0004491'], tr/val_loss:  0.000604/  2.154949, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-86  lr=['0.0003922'], tr/val_loss:  0.000594/  2.154570, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-87  lr=['0.0003389'], tr/val_loss:  0.000617/  2.154174, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-88  lr=['0.0002894'], tr/val_loss:  0.000589/  2.154059, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-89  lr=['0.0002436'], tr/val_loss:  0.000593/  2.154278, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-90  lr=['0.0002017'], tr/val_loss:  0.000602/  2.154238, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-91  lr=['0.0001636'], tr/val_loss:  0.000658/  2.152770, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-92  lr=['0.0001295'], tr/val_loss:  0.000594/  2.154947, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-93  lr=['0.0000992'], tr/val_loss:  0.000602/  2.155039, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-94  lr=['0.0000730'], tr/val_loss:  0.000602/  2.155534, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-95  lr=['0.0000507'], tr/val_loss:  0.000602/  2.153749, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-96  lr=['0.0000325'], tr/val_loss:  0.000592/  2.153683, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-97  lr=['0.0000183'], tr/val_loss:  0.000596/  2.153694, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-98  lr=['0.0000081'], tr/val_loss:  0.000635/  2.153698, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-99  lr=['0.0000020'], tr/val_loss:  0.000583/  2.153699, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ced54cb194b1eacc2d5899a81e477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▆▅▇▇▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▃▃▅▆▇▆▆▇▅▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▆▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▅▆▆▆▆▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▃▃▅▆▇▆▆▇▅▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▂▂▁▂▂▁▁▂▃▄▆▅▆▆▆▇▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00058</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>2.1537</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-sweep-48</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zy8w9nh5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zy8w9nh5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_135715-zy8w9nh5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 03dx1m8y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.021217432938301247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.5032692997223798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.0075894687112101344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab49d7e664b438a978b2539fd3a114b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113727175527149, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_140642-03dx1m8y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/03dx1m8y' target=\"_blank\">celestial-sweep-50</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/03dx1m8y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/03dx1m8y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0212174'], tr/val_loss:  1.844529/  1.810152, tr:  38.51%, val:  40.42%, val_best:  40.42%: 100%|██████████| 62/62 [00:07<00:00,  8.47it/s]\n",
      "epoch-1   lr=['0.0212122'], tr/val_loss:  1.402719/  1.532416, tr:  50.77%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-2   lr=['0.0211965'], tr/val_loss:  1.130833/  1.644334, tr:  60.67%, val:  44.58%, val_best:  48.33%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-3   lr=['0.0211704'], tr/val_loss:  0.999259/  1.371517, tr:  64.45%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-4   lr=['0.0211338'], tr/val_loss:  0.946228/  1.439885, tr:  68.64%, val:  54.58%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-5   lr=['0.0210868'], tr/val_loss:  0.861557/  1.541853, tr:  70.48%, val:  55.00%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-6   lr=['0.0210295'], tr/val_loss:  0.801380/  1.481497, tr:  73.75%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-7   lr=['0.0209619'], tr/val_loss:  0.677660/  1.561486, tr:  75.49%, val:  60.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-8   lr=['0.0208841'], tr/val_loss:  0.574035/  1.525195, tr:  83.35%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-9   lr=['0.0207962'], tr/val_loss:  0.454929/  1.675457, tr:  85.70%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-10  lr=['0.0206982'], tr/val_loss:  0.382775/  1.505373, tr:  88.46%, val:  63.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-11  lr=['0.0205903'], tr/val_loss:  0.347007/  1.773083, tr:  90.91%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-12  lr=['0.0204725'], tr/val_loss:  0.268044/  1.732963, tr:  94.08%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-13  lr=['0.0203449'], tr/val_loss:  0.239563/  1.779204, tr:  95.51%, val:  67.50%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-14  lr=['0.0202078'], tr/val_loss:  0.141007/  1.700978, tr:  98.37%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-15  lr=['0.0200612'], tr/val_loss:  0.147692/  1.836288, tr:  97.45%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-16  lr=['0.0199052'], tr/val_loss:  0.106621/  1.942618, tr:  99.18%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-17  lr=['0.0197401'], tr/val_loss:  0.070948/  2.134584, tr:  99.39%, val:  72.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-18  lr=['0.0195660'], tr/val_loss:  0.070076/  1.928739, tr:  99.08%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-19  lr=['0.0193830'], tr/val_loss:  0.027851/  2.003838, tr: 100.00%, val:  74.58%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-20  lr=['0.0191913'], tr/val_loss:  0.017718/  2.036415, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-21  lr=['0.0189912'], tr/val_loss:  0.008236/  2.194746, tr: 100.00%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-22  lr=['0.0187829'], tr/val_loss:  0.005244/  2.213108, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-23  lr=['0.0185664'], tr/val_loss:  0.003795/  2.221753, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-24  lr=['0.0183421'], tr/val_loss:  0.003122/  2.267241, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-25  lr=['0.0181102'], tr/val_loss:  0.002336/  2.286376, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-26  lr=['0.0178709'], tr/val_loss:  0.001815/  2.297504, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-27  lr=['0.0176244'], tr/val_loss:  0.001692/  2.320224, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-28  lr=['0.0173710'], tr/val_loss:  0.001488/  2.347248, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-29  lr=['0.0171109'], tr/val_loss:  0.001278/  2.345711, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-30  lr=['0.0168444'], tr/val_loss:  0.001234/  2.359645, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-31  lr=['0.0165717'], tr/val_loss:  0.001061/  2.364525, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-32  lr=['0.0162932'], tr/val_loss:  0.000976/  2.354237, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-33  lr=['0.0160090'], tr/val_loss:  0.001152/  2.382058, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-34  lr=['0.0157195'], tr/val_loss:  0.000841/  2.371535, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-35  lr=['0.0154250'], tr/val_loss:  0.000742/  2.393962, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-36  lr=['0.0151257'], tr/val_loss:  0.000772/  2.415009, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-37  lr=['0.0148219'], tr/val_loss:  0.000721/  2.420472, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-38  lr=['0.0145140'], tr/val_loss:  0.000625/  2.418615, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-39  lr=['0.0142023'], tr/val_loss:  0.000622/  2.416678, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-40  lr=['0.0138870'], tr/val_loss:  0.000648/  2.414495, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-41  lr=['0.0135685'], tr/val_loss:  0.000583/  2.436257, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-42  lr=['0.0132470'], tr/val_loss:  0.000544/  2.432802, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-43  lr=['0.0129229'], tr/val_loss:  0.000508/  2.442432, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-44  lr=['0.0125966'], tr/val_loss:  0.000516/  2.459762, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-45  lr=['0.0122683'], tr/val_loss:  0.000497/  2.456687, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-46  lr=['0.0119383'], tr/val_loss:  0.000478/  2.473010, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-47  lr=['0.0116071'], tr/val_loss:  0.000464/  2.480888, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-48  lr=['0.0112748'], tr/val_loss:  0.000479/  2.486328, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-49  lr=['0.0109419'], tr/val_loss:  0.000444/  2.494659, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-50  lr=['0.0106087'], tr/val_loss:  0.000436/  2.498649, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-51  lr=['0.0102755'], tr/val_loss:  0.000430/  2.499254, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-52  lr=['0.0099426'], tr/val_loss:  0.000405/  2.498876, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-53  lr=['0.0096103'], tr/val_loss:  0.000424/  2.504150, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-54  lr=['0.0092791'], tr/val_loss:  0.000402/  2.514133, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-55  lr=['0.0089491'], tr/val_loss:  0.000380/  2.508737, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-56  lr=['0.0086208'], tr/val_loss:  0.000373/  2.512090, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-57  lr=['0.0082945'], tr/val_loss:  0.000373/  2.518461, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-58  lr=['0.0079704'], tr/val_loss:  0.000348/  2.520057, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-59  lr=['0.0076490'], tr/val_loss:  0.000374/  2.517034, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-60  lr=['0.0073304'], tr/val_loss:  0.000366/  2.524402, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-61  lr=['0.0070151'], tr/val_loss:  0.000346/  2.535176, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-62  lr=['0.0067034'], tr/val_loss:  0.000341/  2.538927, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-63  lr=['0.0063955'], tr/val_loss:  0.000348/  2.539608, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-64  lr=['0.0060917'], tr/val_loss:  0.000353/  2.543965, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-65  lr=['0.0057925'], tr/val_loss:  0.000364/  2.547053, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-66  lr=['0.0054979'], tr/val_loss:  0.000338/  2.548432, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-67  lr=['0.0052084'], tr/val_loss:  0.000333/  2.547442, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-68  lr=['0.0049243'], tr/val_loss:  0.000325/  2.544954, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-69  lr=['0.0046457'], tr/val_loss:  0.000314/  2.544153, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-70  lr=['0.0043731'], tr/val_loss:  0.000335/  2.546254, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-71  lr=['0.0041066'], tr/val_loss:  0.000317/  2.545825, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-72  lr=['0.0038465'], tr/val_loss:  0.000324/  2.547425, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-73  lr=['0.0035930'], tr/val_loss:  0.000337/  2.542729, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-74  lr=['0.0033466'], tr/val_loss:  0.000333/  2.546074, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-75  lr=['0.0031072'], tr/val_loss:  0.000322/  2.543373, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-76  lr=['0.0028753'], tr/val_loss:  0.000310/  2.544265, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-77  lr=['0.0026510'], tr/val_loss:  0.000330/  2.543483, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-78  lr=['0.0024346'], tr/val_loss:  0.000312/  2.549433, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-79  lr=['0.0022262'], tr/val_loss:  0.000318/  2.547993, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-80  lr=['0.0020261'], tr/val_loss:  0.000310/  2.552245, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-81  lr=['0.0018345'], tr/val_loss:  0.000329/  2.552705, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-82  lr=['0.0016515'], tr/val_loss:  0.000318/  2.557324, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-83  lr=['0.0014773'], tr/val_loss:  0.000309/  2.558957, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-84  lr=['0.0013122'], tr/val_loss:  0.000312/  2.558758, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-85  lr=['0.0011563'], tr/val_loss:  0.000312/  2.559841, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-86  lr=['0.0010097'], tr/val_loss:  0.000310/  2.560287, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-87  lr=['0.0008725'], tr/val_loss:  0.000334/  2.559319, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-88  lr=['0.0007450'], tr/val_loss:  0.000318/  2.559735, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-89  lr=['0.0006272'], tr/val_loss:  0.000315/  2.559444, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-90  lr=['0.0005192'], tr/val_loss:  0.000302/  2.559376, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-91  lr=['0.0004212'], tr/val_loss:  0.000323/  2.559205, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-92  lr=['0.0003333'], tr/val_loss:  0.000309/  2.562574, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-93  lr=['0.0002555'], tr/val_loss:  0.000313/  2.562623, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-94  lr=['0.0001879'], tr/val_loss:  0.000307/  2.562757, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-95  lr=['0.0001306'], tr/val_loss:  0.000311/  2.562794, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-96  lr=['0.0000837'], tr/val_loss:  0.000308/  2.562810, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-97  lr=['0.0000471'], tr/val_loss:  0.000301/  2.562800, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-98  lr=['0.0000209'], tr/val_loss:  0.000309/  2.562822, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-99  lr=['0.0000052'], tr/val_loss:  0.000299/  2.562823, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4b918712914a0fac9b4522adc6f56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆▇▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▆▆█▇▇▇██████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▆▆██████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▆▆█▇▇▇██████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▂▂▃▃▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0003</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.56282</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-50</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/03dx1m8y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/03dx1m8y</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_140642-03dx1m8y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q1ua0k0j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0147144727038417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.463472836695015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.0333660367883768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_141601-q1ua0k0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q1ua0k0j' target=\"_blank\">polished-sweep-53</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q1ua0k0j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q1ua0k0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0147145'], tr/val_loss:  1.881642/  1.477955, tr:  32.89%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-1   lr=['0.0147108'], tr/val_loss:  1.340352/  1.568266, tr:  53.32%, val:  47.08%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-2   lr=['0.0147000'], tr/val_loss:  1.140018/  1.153028, tr:  60.57%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-3   lr=['0.0146818'], tr/val_loss:  0.997089/  1.172206, tr:  67.11%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-4   lr=['0.0146565'], tr/val_loss:  0.981238/  1.279556, tr:  67.82%, val:  55.42%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-5   lr=['0.0146239'], tr/val_loss:  0.872205/  1.290342, tr:  71.60%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-6   lr=['0.0145842'], tr/val_loss:  0.804990/  1.320511, tr:  73.03%, val:  58.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-7   lr=['0.0145373'], tr/val_loss:  0.751841/  1.427446, tr:  73.54%, val:  58.75%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-8   lr=['0.0144833'], tr/val_loss:  0.711113/  1.270748, tr:  76.51%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-9   lr=['0.0144223'], tr/val_loss:  0.592996/  1.397906, tr:  79.78%, val:  64.17%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-10  lr=['0.0143544'], tr/val_loss:  0.487940/  1.404536, tr:  86.31%, val:  68.75%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-11  lr=['0.0142795'], tr/val_loss:  0.452733/  1.593042, tr:  86.52%, val:  63.33%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-12  lr=['0.0141978'], tr/val_loss:  0.423558/  1.450576, tr:  89.17%, val:  68.75%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-13  lr=['0.0141094'], tr/val_loss:  0.351258/  1.564118, tr:  92.03%, val:  67.08%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-14  lr=['0.0140143'], tr/val_loss:  0.288647/  1.376946, tr:  93.67%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-15  lr=['0.0139126'], tr/val_loss:  0.310718/  1.548988, tr:  92.95%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-16  lr=['0.0138044'], tr/val_loss:  0.265522/  2.015471, tr:  96.02%, val:  66.25%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-17  lr=['0.0136899'], tr/val_loss:  0.374514/  1.565741, tr:  91.01%, val:  62.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-18  lr=['0.0135692'], tr/val_loss:  0.354822/  1.485281, tr:  90.19%, val:  68.75%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-19  lr=['0.0134423'], tr/val_loss:  0.211098/  1.607627, tr:  97.65%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-20  lr=['0.0133094'], tr/val_loss:  0.142514/  1.778056, tr:  98.37%, val:  69.58%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-21  lr=['0.0131706'], tr/val_loss:  0.102692/  1.725820, tr:  99.80%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-22  lr=['0.0130261'], tr/val_loss:  0.097405/  1.901264, tr:  99.18%, val:  70.00%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-23  lr=['0.0128760'], tr/val_loss:  0.069813/  1.930941, tr: 100.00%, val:  70.83%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-24  lr=['0.0127204'], tr/val_loss:  0.099966/  1.892201, tr:  98.06%, val:  74.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-25  lr=['0.0125596'], tr/val_loss:  0.052706/  2.041884, tr: 100.00%, val:  72.08%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-26  lr=['0.0123936'], tr/val_loss:  0.042431/  2.096398, tr:  99.90%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-27  lr=['0.0122227'], tr/val_loss:  0.030312/  2.164903, tr: 100.00%, val:  69.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-28  lr=['0.0120469'], tr/val_loss:  0.017369/  2.223404, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-29  lr=['0.0118665'], tr/val_loss:  0.015629/  2.239166, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-30  lr=['0.0116817'], tr/val_loss:  0.011619/  2.312860, tr: 100.00%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-31  lr=['0.0114926'], tr/val_loss:  0.009354/  2.342095, tr: 100.00%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-32  lr=['0.0112994'], tr/val_loss:  0.007680/  2.353036, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-33  lr=['0.0111024'], tr/val_loss:  0.006711/  2.405226, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-34  lr=['0.0109016'], tr/val_loss:  0.004974/  2.391537, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-35  lr=['0.0106974'], tr/val_loss:  0.004863/  2.416060, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-36  lr=['0.0104898'], tr/val_loss:  0.004254/  2.449069, tr: 100.00%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-37  lr=['0.0102791'], tr/val_loss:  0.007561/  2.499567, tr: 100.00%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-38  lr=['0.0100656'], tr/val_loss:  0.005973/  2.506468, tr: 100.00%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-39  lr=['0.0098494'], tr/val_loss:  0.003328/  2.479499, tr: 100.00%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-40  lr=['0.0096307'], tr/val_loss:  0.003358/  2.529376, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-41  lr=['0.0094098'], tr/val_loss:  0.002513/  2.531856, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-42  lr=['0.0091869'], tr/val_loss:  0.002156/  2.522125, tr: 100.00%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-43  lr=['0.0089622'], tr/val_loss:  0.001999/  2.529830, tr: 100.00%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-44  lr=['0.0087358'], tr/val_loss:  0.001766/  2.558847, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-45  lr=['0.0085082'], tr/val_loss:  0.001639/  2.560732, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-46  lr=['0.0082793'], tr/val_loss:  0.001524/  2.583387, tr: 100.00%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-47  lr=['0.0080496'], tr/val_loss:  0.001433/  2.614686, tr: 100.00%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-48  lr=['0.0078192'], tr/val_loss:  0.001502/  2.602417, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-49  lr=['0.0075883'], tr/val_loss:  0.001264/  2.611198, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-50  lr=['0.0073572'], tr/val_loss:  0.001371/  2.613814, tr: 100.00%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-51  lr=['0.0071261'], tr/val_loss:  0.001356/  2.636466, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-52  lr=['0.0068953'], tr/val_loss:  0.001340/  2.616104, tr: 100.00%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-53  lr=['0.0066649'], tr/val_loss:  0.001203/  2.637114, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-54  lr=['0.0064351'], tr/val_loss:  0.001045/  2.641255, tr: 100.00%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-55  lr=['0.0062063'], tr/val_loss:  0.001062/  2.640569, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-56  lr=['0.0059786'], tr/val_loss:  0.001004/  2.662566, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-57  lr=['0.0057523'], tr/val_loss:  0.001033/  2.661377, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-58  lr=['0.0055276'], tr/val_loss:  0.000954/  2.656375, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-59  lr=['0.0053046'], tr/val_loss:  0.000924/  2.663215, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-60  lr=['0.0050837'], tr/val_loss:  0.000946/  2.663353, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-61  lr=['0.0048651'], tr/val_loss:  0.000924/  2.668370, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-62  lr=['0.0046489'], tr/val_loss:  0.000884/  2.665703, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-63  lr=['0.0044353'], tr/val_loss:  0.000862/  2.666460, tr: 100.00%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-64  lr=['0.0042247'], tr/val_loss:  0.000820/  2.674930, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-65  lr=['0.0040171'], tr/val_loss:  0.000924/  2.670650, tr: 100.00%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-66  lr=['0.0038129'], tr/val_loss:  0.000837/  2.681680, tr: 100.00%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-67  lr=['0.0036121'], tr/val_loss:  0.000817/  2.685203, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-68  lr=['0.0034150'], tr/val_loss:  0.000773/  2.698905, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-69  lr=['0.0032219'], tr/val_loss:  0.000779/  2.696697, tr: 100.00%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-70  lr=['0.0030328'], tr/val_loss:  0.000764/  2.693398, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-71  lr=['0.0028479'], tr/val_loss:  0.000804/  2.691494, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-72  lr=['0.0026676'], tr/val_loss:  0.000759/  2.695376, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-73  lr=['0.0024918'], tr/val_loss:  0.000764/  2.691616, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-74  lr=['0.0023209'], tr/val_loss:  0.000699/  2.693851, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-75  lr=['0.0021549'], tr/val_loss:  0.000699/  2.696199, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-76  lr=['0.0019940'], tr/val_loss:  0.000699/  2.700619, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-77  lr=['0.0018385'], tr/val_loss:  0.000707/  2.707479, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-78  lr=['0.0016884'], tr/val_loss:  0.000725/  2.706323, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-79  lr=['0.0015439'], tr/val_loss:  0.000739/  2.703600, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-80  lr=['0.0014051'], tr/val_loss:  0.000700/  2.704593, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-81  lr=['0.0012722'], tr/val_loss:  0.000686/  2.708782, tr: 100.00%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-82  lr=['0.0011453'], tr/val_loss:  0.000681/  2.703792, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-83  lr=['0.0010246'], tr/val_loss:  0.000684/  2.703239, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-84  lr=['0.0009100'], tr/val_loss:  0.000669/  2.706007, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-85  lr=['0.0008019'], tr/val_loss:  0.000668/  2.705610, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-86  lr=['0.0007002'], tr/val_loss:  0.000681/  2.705772, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-87  lr=['0.0006051'], tr/val_loss:  0.000657/  2.705542, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-88  lr=['0.0005167'], tr/val_loss:  0.000658/  2.708734, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-89  lr=['0.0004350'], tr/val_loss:  0.000682/  2.706848, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-90  lr=['0.0003601'], tr/val_loss:  0.000665/  2.709218, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-91  lr=['0.0002921'], tr/val_loss:  0.000683/  2.707151, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-92  lr=['0.0002311'], tr/val_loss:  0.000658/  2.712617, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-93  lr=['0.0001772'], tr/val_loss:  0.000664/  2.712118, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-94  lr=['0.0001303'], tr/val_loss:  0.000682/  2.710280, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-95  lr=['0.0000906'], tr/val_loss:  0.000654/  2.710032, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:07<00:00,  8.20it/s]\n",
      "epoch-96  lr=['0.0000580'], tr/val_loss:  0.000679/  2.709074, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-97  lr=['0.0000327'], tr/val_loss:  0.000664/  2.709908, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-98  lr=['0.0000145'], tr/val_loss:  0.000680/  2.709911, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-99  lr=['0.0000036'], tr/val_loss:  0.000648/  2.709911, tr: 100.00%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a525152d6d4701a2932a33e2a7af9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▅▅▇▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▂▃▄▆▇▄▇█████▇███▇█▇█▇▇▇▇█▇█▇▇██▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▄▆▆▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▂▃▄▆▇▄▇█████▇███▇█▇█▇▇▇▇█▇█▇▇██▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▂▂▂▂▂▃▃▄▄▅▆▆▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00065</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>2.70991</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-sweep-53</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q1ua0k0j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q1ua0k0j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_141601-q1ua0k0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ge8fv2f1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00829981116389257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.431558921750308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.8106487281996928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee402209cfdb4a55aafa8defa9876939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113901167280144, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_142510-ge8fv2f1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ge8fv2f1' target=\"_blank\">denim-sweep-54</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ge8fv2f1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ge8fv2f1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0082998'], tr/val_loss:  2.308157/  2.227171, tr:  10.01%, val:  18.75%, val_best:  18.75%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-1   lr=['0.0082978'], tr/val_loss:  1.682053/  1.657457, tr:  41.16%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-2   lr=['0.0082916'], tr/val_loss:  1.279190/  1.321128, tr:  55.16%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-3   lr=['0.0082814'], tr/val_loss:  1.114491/  1.294669, tr:  62.31%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-4   lr=['0.0082671'], tr/val_loss:  1.090699/  1.249954, tr:  61.90%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-5   lr=['0.0082487'], tr/val_loss:  1.011813/  1.263506, tr:  66.19%, val:  58.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-6   lr=['0.0082263'], tr/val_loss:  0.911699/  1.165140, tr:  68.85%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-7   lr=['0.0081999'], tr/val_loss:  0.877851/  1.232498, tr:  69.97%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-8   lr=['0.0081694'], tr/val_loss:  0.805624/  1.130100, tr:  72.73%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-9   lr=['0.0081350'], tr/val_loss:  0.698998/  1.364174, tr:  77.83%, val:  58.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-10  lr=['0.0080967'], tr/val_loss:  0.691195/  1.202325, tr:  78.75%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-11  lr=['0.0080545'], tr/val_loss:  0.626860/  1.296877, tr:  80.59%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-12  lr=['0.0080084'], tr/val_loss:  0.619623/  1.189981, tr:  82.84%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-13  lr=['0.0079585'], tr/val_loss:  0.556772/  1.334689, tr:  84.47%, val:  60.83%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-14  lr=['0.0079049'], tr/val_loss:  0.539920/  1.186092, tr:  84.07%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-15  lr=['0.0078475'], tr/val_loss:  0.499944/  1.271803, tr:  87.54%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-16  lr=['0.0077865'], tr/val_loss:  0.471070/  1.485011, tr:  88.76%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-17  lr=['0.0077219'], tr/val_loss:  0.494928/  1.476956, tr:  87.64%, val:  64.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-18  lr=['0.0076538'], tr/val_loss:  0.453267/  1.365643, tr:  87.13%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-19  lr=['0.0075822'], tr/val_loss:  0.383452/  1.371711, tr:  93.26%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-20  lr=['0.0075072'], tr/val_loss:  0.354702/  1.462203, tr:  93.36%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-21  lr=['0.0074290'], tr/val_loss:  0.289322/  1.486662, tr:  95.20%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-22  lr=['0.0073475'], tr/val_loss:  0.286304/  1.503389, tr:  94.89%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-23  lr=['0.0072628'], tr/val_loss:  0.282569/  1.541886, tr:  94.69%, val:  70.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-24  lr=['0.0071751'], tr/val_loss:  0.268379/  1.620940, tr:  95.91%, val:  71.25%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-25  lr=['0.0070843'], tr/val_loss:  0.223597/  1.641518, tr:  97.65%, val:  70.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-26  lr=['0.0069907'], tr/val_loss:  0.217928/  1.633225, tr:  97.34%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-27  lr=['0.0068943'], tr/val_loss:  0.189086/  1.634740, tr:  98.47%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-28  lr=['0.0067952'], tr/val_loss:  0.155173/  1.695906, tr:  99.59%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-29  lr=['0.0066934'], tr/val_loss:  0.154177/  1.811827, tr:  99.28%, val:  72.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-30  lr=['0.0065892'], tr/val_loss:  0.148627/  1.747410, tr:  99.49%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-31  lr=['0.0064825'], tr/val_loss:  0.118365/  1.863627, tr:  99.80%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-32  lr=['0.0063735'], tr/val_loss:  0.109126/  1.898588, tr:  99.90%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-33  lr=['0.0062624'], tr/val_loss:  0.097013/  1.929748, tr:  99.90%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-34  lr=['0.0061491'], tr/val_loss:  0.084524/  1.917044, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-35  lr=['0.0060339'], tr/val_loss:  0.085284/  2.001340, tr:  99.69%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-36  lr=['0.0059168'], tr/val_loss:  0.070331/  2.060030, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-37  lr=['0.0057980'], tr/val_loss:  0.072170/  2.093632, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-38  lr=['0.0056776'], tr/val_loss:  0.079042/  2.133739, tr:  99.90%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-39  lr=['0.0055556'], tr/val_loss:  0.053554/  2.115814, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-40  lr=['0.0054323'], tr/val_loss:  0.077725/  2.165961, tr:  99.80%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-41  lr=['0.0053077'], tr/val_loss:  0.072957/  2.159309, tr:  99.39%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-42  lr=['0.0051819'], tr/val_loss:  0.047256/  2.212233, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-43  lr=['0.0050552'], tr/val_loss:  0.039204/  2.247839, tr: 100.00%, val:  73.75%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-44  lr=['0.0049275'], tr/val_loss:  0.040678/  2.317502, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-45  lr=['0.0047991'], tr/val_loss:  0.040297/  2.320393, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-46  lr=['0.0046700'], tr/val_loss:  0.032967/  2.327729, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-47  lr=['0.0045404'], tr/val_loss:  0.026340/  2.353197, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-48  lr=['0.0044105'], tr/val_loss:  0.021418/  2.378277, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-49  lr=['0.0042803'], tr/val_loss:  0.021674/  2.413195, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-50  lr=['0.0041499'], tr/val_loss:  0.018262/  2.432008, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-51  lr=['0.0040196'], tr/val_loss:  0.018715/  2.449278, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-52  lr=['0.0038893'], tr/val_loss:  0.016598/  2.480093, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-53  lr=['0.0037594'], tr/val_loss:  0.013430/  2.463171, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-54  lr=['0.0036298'], tr/val_loss:  0.014419/  2.527454, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-55  lr=['0.0035007'], tr/val_loss:  0.013466/  2.530056, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-56  lr=['0.0033723'], tr/val_loss:  0.012396/  2.531857, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-57  lr=['0.0032446'], tr/val_loss:  0.011015/  2.557838, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-58  lr=['0.0031179'], tr/val_loss:  0.010360/  2.577893, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-59  lr=['0.0029921'], tr/val_loss:  0.010132/  2.600952, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-60  lr=['0.0028675'], tr/val_loss:  0.010182/  2.587204, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-61  lr=['0.0027442'], tr/val_loss:  0.009816/  2.606236, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-62  lr=['0.0026222'], tr/val_loss:  0.008028/  2.601253, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-63  lr=['0.0025018'], tr/val_loss:  0.008569/  2.625700, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-64  lr=['0.0023830'], tr/val_loss:  0.008514/  2.634122, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-65  lr=['0.0022659'], tr/val_loss:  0.007692/  2.647376, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-66  lr=['0.0021507'], tr/val_loss:  0.008610/  2.661137, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-67  lr=['0.0020374'], tr/val_loss:  0.008362/  2.684477, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-68  lr=['0.0019263'], tr/val_loss:  0.007825/  2.672934, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-69  lr=['0.0018173'], tr/val_loss:  0.007001/  2.691355, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-70  lr=['0.0017107'], tr/val_loss:  0.007006/  2.696834, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-71  lr=['0.0016064'], tr/val_loss:  0.006796/  2.684441, tr: 100.00%, val:  74.17%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-72  lr=['0.0015047'], tr/val_loss:  0.006371/  2.684614, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-73  lr=['0.0014055'], tr/val_loss:  0.007459/  2.673039, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-74  lr=['0.0013091'], tr/val_loss:  0.007042/  2.696243, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-75  lr=['0.0012155'], tr/val_loss:  0.006207/  2.701694, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-76  lr=['0.0011248'], tr/val_loss:  0.006411/  2.705966, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-77  lr=['0.0010370'], tr/val_loss:  0.006230/  2.713019, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-78  lr=['0.0009523'], tr/val_loss:  0.005649/  2.711337, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-79  lr=['0.0008708'], tr/val_loss:  0.005822/  2.718530, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-80  lr=['0.0007926'], tr/val_loss:  0.005612/  2.716919, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-81  lr=['0.0007176'], tr/val_loss:  0.005507/  2.718539, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-82  lr=['0.0006460'], tr/val_loss:  0.005556/  2.731596, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-83  lr=['0.0005779'], tr/val_loss:  0.005652/  2.725855, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-84  lr=['0.0005133'], tr/val_loss:  0.005465/  2.723918, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-85  lr=['0.0004523'], tr/val_loss:  0.005187/  2.724371, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-86  lr=['0.0003950'], tr/val_loss:  0.005199/  2.714400, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-87  lr=['0.0003413'], tr/val_loss:  0.005283/  2.726495, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-88  lr=['0.0002914'], tr/val_loss:  0.005401/  2.726453, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-89  lr=['0.0002453'], tr/val_loss:  0.005122/  2.728112, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-90  lr=['0.0002031'], tr/val_loss:  0.005269/  2.727363, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-91  lr=['0.0001648'], tr/val_loss:  0.005220/  2.723481, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-92  lr=['0.0001304'], tr/val_loss:  0.005157/  2.727840, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-93  lr=['0.0000999'], tr/val_loss:  0.004969/  2.724244, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-94  lr=['0.0000735'], tr/val_loss:  0.004964/  2.724829, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-95  lr=['0.0000511'], tr/val_loss:  0.004921/  2.722414, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-96  lr=['0.0000327'], tr/val_loss:  0.004845/  2.720908, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-97  lr=['0.0000184'], tr/val_loss:  0.004917/  2.721091, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-98  lr=['0.0000082'], tr/val_loss:  0.004905/  2.721514, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-99  lr=['0.0000020'], tr/val_loss:  0.004915/  2.721151, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7682a42e7bca4ca79768582878b2ed7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆█▇▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▇▇▆█▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▇▇▆█▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▆▂▁▁▂▁▁▂▂▂▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00492</td></tr><tr><td>val_acc_best</td><td>0.78333</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>2.72115</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sweep-54</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ge8fv2f1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ge8fv2f1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_142510-ge8fv2f1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wpap6nsf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.012599610172941887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.1987837223426796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.1859751843078354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_143423-wpap6nsf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wpap6nsf' target=\"_blank\">pleasant-sweep-56</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wpap6nsf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wpap6nsf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0125996'], tr/val_loss:  1.725952/  1.445775, tr:  38.10%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-1   lr=['0.0125965'], tr/val_loss:  1.219880/  1.391902, tr:  53.22%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-2   lr=['0.0125872'], tr/val_loss:  0.998331/  1.491352, tr:  63.02%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-3   lr=['0.0125717'], tr/val_loss:  0.947163/  1.311486, tr:  68.03%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-4   lr=['0.0125499'], tr/val_loss:  0.862758/  1.217027, tr:  69.87%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-5   lr=['0.0125220'], tr/val_loss:  0.757011/  1.487142, tr:  73.75%, val:  57.08%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-6   lr=['0.0124880'], tr/val_loss:  0.739949/  1.396945, tr:  73.34%, val:  58.33%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-7   lr=['0.0124479'], tr/val_loss:  0.789918/  1.324179, tr:  72.63%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-8   lr=['0.0124017'], tr/val_loss:  0.621938/  1.351754, tr:  77.12%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-9   lr=['0.0123495'], tr/val_loss:  0.506129/  1.489915, tr:  81.92%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-10  lr=['0.0122913'], tr/val_loss:  0.436042/  1.670814, tr:  87.33%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-11  lr=['0.0122272'], tr/val_loss:  0.467849/  1.564355, tr:  85.50%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-12  lr=['0.0121572'], tr/val_loss:  0.480125/  1.391738, tr:  87.84%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-13  lr=['0.0120815'], tr/val_loss:  0.366792/  1.588268, tr:  89.89%, val:  68.33%, val_best:  69.58%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-14  lr=['0.0120000'], tr/val_loss:  0.375428/  1.454245, tr:  91.93%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-15  lr=['0.0119130'], tr/val_loss:  0.345405/  1.732196, tr:  91.62%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-16  lr=['0.0118204'], tr/val_loss:  0.246391/  1.879945, tr:  96.53%, val:  66.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-17  lr=['0.0117223'], tr/val_loss:  0.281693/  1.472361, tr:  94.89%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-18  lr=['0.0116189'], tr/val_loss:  0.192561/  1.690052, tr:  97.55%, val:  69.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-19  lr=['0.0115103'], tr/val_loss:  0.173268/  1.657036, tr:  97.75%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-20  lr=['0.0113965'], tr/val_loss:  0.104054/  1.667091, tr:  99.18%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-21  lr=['0.0112776'], tr/val_loss:  0.044428/  1.848266, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-22  lr=['0.0111539'], tr/val_loss:  0.026459/  2.003091, tr: 100.00%, val:  74.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-23  lr=['0.0110254'], tr/val_loss:  0.015131/  2.025884, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-24  lr=['0.0108922'], tr/val_loss:  0.011147/  2.025828, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-25  lr=['0.0107544'], tr/val_loss:  0.030098/  2.055645, tr:  99.80%, val:  75.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-26  lr=['0.0106123'], tr/val_loss:  0.010599/  2.076811, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-27  lr=['0.0104659'], tr/val_loss:  0.005274/  2.116660, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-28  lr=['0.0103155'], tr/val_loss:  0.002996/  2.124031, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-29  lr=['0.0101610'], tr/val_loss:  0.002256/  2.128901, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-30  lr=['0.0100027'], tr/val_loss:  0.001870/  2.106022, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-31  lr=['0.0098408'], tr/val_loss:  0.001527/  2.117738, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-32  lr=['0.0096754'], tr/val_loss:  0.001146/  2.140500, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-33  lr=['0.0095067'], tr/val_loss:  0.001038/  2.157883, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-34  lr=['0.0093348'], tr/val_loss:  0.000921/  2.148280, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-35  lr=['0.0091599'], tr/val_loss:  0.000872/  2.160375, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-36  lr=['0.0089821'], tr/val_loss:  0.000814/  2.176728, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-37  lr=['0.0088018'], tr/val_loss:  0.000768/  2.177134, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-38  lr=['0.0086189'], tr/val_loss:  0.000722/  2.194019, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-39  lr=['0.0084338'], tr/val_loss:  0.000700/  2.199403, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-40  lr=['0.0082466'], tr/val_loss:  0.000635/  2.211247, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-41  lr=['0.0080574'], tr/val_loss:  0.000590/  2.211604, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-42  lr=['0.0078665'], tr/val_loss:  0.000578/  2.201601, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-43  lr=['0.0076741'], tr/val_loss:  0.000577/  2.218745, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-44  lr=['0.0074803'], tr/val_loss:  0.000551/  2.219149, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-45  lr=['0.0072853'], tr/val_loss:  0.000552/  2.224297, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-46  lr=['0.0070894'], tr/val_loss:  0.000528/  2.233685, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-47  lr=['0.0068927'], tr/val_loss:  0.000536/  2.250626, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-48  lr=['0.0066954'], tr/val_loss:  0.000512/  2.263965, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-49  lr=['0.0064977'], tr/val_loss:  0.000495/  2.268281, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-50  lr=['0.0062998'], tr/val_loss:  0.000470/  2.257780, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-51  lr=['0.0061019'], tr/val_loss:  0.000451/  2.266505, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-52  lr=['0.0059042'], tr/val_loss:  0.000433/  2.275623, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-53  lr=['0.0057069'], tr/val_loss:  0.000435/  2.283892, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-54  lr=['0.0055102'], tr/val_loss:  0.000412/  2.282586, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-55  lr=['0.0053143'], tr/val_loss:  0.000424/  2.293410, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-56  lr=['0.0051193'], tr/val_loss:  0.000412/  2.289248, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-57  lr=['0.0049255'], tr/val_loss:  0.000394/  2.285238, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-58  lr=['0.0047331'], tr/val_loss:  0.000394/  2.286113, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-59  lr=['0.0045422'], tr/val_loss:  0.000371/  2.291430, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-60  lr=['0.0043531'], tr/val_loss:  0.000382/  2.298308, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-61  lr=['0.0041658'], tr/val_loss:  0.000365/  2.300733, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-62  lr=['0.0039807'], tr/val_loss:  0.000367/  2.299794, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-63  lr=['0.0037979'], tr/val_loss:  0.000358/  2.299834, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-64  lr=['0.0036175'], tr/val_loss:  0.000363/  2.301657, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-65  lr=['0.0034398'], tr/val_loss:  0.000354/  2.308820, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-66  lr=['0.0032649'], tr/val_loss:  0.000359/  2.308131, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-67  lr=['0.0030929'], tr/val_loss:  0.000356/  2.311162, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-68  lr=['0.0029242'], tr/val_loss:  0.000341/  2.307462, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-69  lr=['0.0027588'], tr/val_loss:  0.000345/  2.311613, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-70  lr=['0.0025969'], tr/val_loss:  0.000340/  2.316412, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-71  lr=['0.0024386'], tr/val_loss:  0.000341/  2.313100, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-72  lr=['0.0022842'], tr/val_loss:  0.000344/  2.316724, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-73  lr=['0.0021337'], tr/val_loss:  0.000342/  2.314618, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-74  lr=['0.0019873'], tr/val_loss:  0.000330/  2.315551, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-75  lr=['0.0018452'], tr/val_loss:  0.000333/  2.317901, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-76  lr=['0.0017074'], tr/val_loss:  0.000333/  2.318960, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-77  lr=['0.0015743'], tr/val_loss:  0.000320/  2.319090, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-78  lr=['0.0014457'], tr/val_loss:  0.000321/  2.321296, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-79  lr=['0.0013220'], tr/val_loss:  0.000313/  2.324127, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-80  lr=['0.0012032'], tr/val_loss:  0.000315/  2.325284, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-81  lr=['0.0010894'], tr/val_loss:  0.000320/  2.324232, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-82  lr=['0.0009807'], tr/val_loss:  0.000311/  2.326481, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-83  lr=['0.0008773'], tr/val_loss:  0.000309/  2.325377, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-84  lr=['0.0007792'], tr/val_loss:  0.000312/  2.326168, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-85  lr=['0.0006866'], tr/val_loss:  0.000309/  2.326968, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-86  lr=['0.0005996'], tr/val_loss:  0.000311/  2.324692, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-87  lr=['0.0005181'], tr/val_loss:  0.000310/  2.325823, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-88  lr=['0.0004424'], tr/val_loss:  0.000315/  2.327107, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-89  lr=['0.0003724'], tr/val_loss:  0.000308/  2.326976, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-90  lr=['0.0003083'], tr/val_loss:  0.000308/  2.327390, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-91  lr=['0.0002501'], tr/val_loss:  0.000323/  2.327976, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-92  lr=['0.0001979'], tr/val_loss:  0.000310/  2.327451, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-93  lr=['0.0001517'], tr/val_loss:  0.000314/  2.327688, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-94  lr=['0.0001116'], tr/val_loss:  0.000313/  2.327765, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-95  lr=['0.0000776'], tr/val_loss:  0.000313/  2.327743, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-96  lr=['0.0000497'], tr/val_loss:  0.000307/  2.328445, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-97  lr=['0.0000280'], tr/val_loss:  0.000305/  2.328453, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-98  lr=['0.0000124'], tr/val_loss:  0.000317/  2.328455, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-99  lr=['0.0000031'], tr/val_loss:  0.000303/  2.328455, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d72bd505ee74acca593624bfc058686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▆▆▆▆██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▄▅▆▆▇████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▅▆▆▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▄▅▆▆▇████████████████████████████████</td></tr><tr><td>val_loss</td><td>▂▃▁▂▃▂▂▃▄▅▆▆▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0003</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.32845</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-56</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wpap6nsf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wpap6nsf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_143423-wpap6nsf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g4j2lof6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.010267147215542925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.41108600717394345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.9886210681703484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_144324-g4j2lof6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4j2lof6' target=\"_blank\">gallant-sweep-58</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4j2lof6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4j2lof6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0102671'], tr/val_loss:  2.312319/  2.242603, tr:  10.21%, val:  17.08%, val_best:  17.08%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-1   lr=['0.0102646'], tr/val_loss:  1.673786/  1.648814, tr:  40.45%, val:  46.67%, val_best:  46.67%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-2   lr=['0.0102570'], tr/val_loss:  1.279783/  1.288013, tr:  54.14%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-3   lr=['0.0102444'], tr/val_loss:  1.104640/  1.265387, tr:  62.61%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-4   lr=['0.0102267'], tr/val_loss:  1.078382/  1.271140, tr:  63.43%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-5   lr=['0.0102039'], tr/val_loss:  1.005384/  1.278637, tr:  66.91%, val:  58.75%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-6   lr=['0.0101762'], tr/val_loss:  0.895079/  1.205435, tr:  69.36%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-7   lr=['0.0101435'], tr/val_loss:  0.892853/  1.310300, tr:  69.66%, val:  60.00%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-8   lr=['0.0101059'], tr/val_loss:  0.819834/  1.155734, tr:  72.32%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:07<00:00,  8.40it/s]\n",
      "epoch-9   lr=['0.0100633'], tr/val_loss:  0.681684/  1.385012, tr:  78.86%, val:  59.17%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-10  lr=['0.0100159'], tr/val_loss:  0.675432/  1.220913, tr:  79.26%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-11  lr=['0.0099637'], tr/val_loss:  0.610609/  1.362139, tr:  80.59%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-12  lr=['0.0099066'], tr/val_loss:  0.613766/  1.264243, tr:  82.74%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-13  lr=['0.0098449'], tr/val_loss:  0.546756/  1.399756, tr:  85.29%, val:  62.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-14  lr=['0.0097786'], tr/val_loss:  0.519289/  1.216060, tr:  84.68%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-15  lr=['0.0097076'], tr/val_loss:  0.492611/  1.294502, tr:  86.62%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-16  lr=['0.0096322'], tr/val_loss:  0.453335/  1.555039, tr:  88.76%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-17  lr=['0.0095523'], tr/val_loss:  0.471169/  1.493034, tr:  88.25%, val:  65.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-18  lr=['0.0094680'], tr/val_loss:  0.428386/  1.368755, tr:  88.87%, val:  69.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-19  lr=['0.0093795'], tr/val_loss:  0.360718/  1.436057, tr:  93.26%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-20  lr=['0.0092867'], tr/val_loss:  0.348926/  1.530573, tr:  92.54%, val:  68.75%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-21  lr=['0.0091899'], tr/val_loss:  0.272977/  1.535517, tr:  95.91%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-22  lr=['0.0090891'], tr/val_loss:  0.280115/  1.485649, tr:  93.97%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-23  lr=['0.0089843'], tr/val_loss:  0.262085/  1.579268, tr:  95.10%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-24  lr=['0.0088758'], tr/val_loss:  0.249218/  1.666159, tr:  95.51%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-25  lr=['0.0087636'], tr/val_loss:  0.210673/  1.671468, tr:  98.06%, val:  72.08%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-26  lr=['0.0086477'], tr/val_loss:  0.204404/  1.656532, tr:  96.83%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-27  lr=['0.0085285'], tr/val_loss:  0.177508/  1.681918, tr:  98.47%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-28  lr=['0.0084058'], tr/val_loss:  0.132054/  1.810298, tr:  99.90%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-29  lr=['0.0082800'], tr/val_loss:  0.145331/  1.861562, tr:  99.49%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-30  lr=['0.0081510'], tr/val_loss:  0.136560/  1.793313, tr:  99.80%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-31  lr=['0.0080191'], tr/val_loss:  0.097369/  1.947804, tr:  99.90%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-32  lr=['0.0078843'], tr/val_loss:  0.089951/  1.989978, tr:  99.90%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-33  lr=['0.0077468'], tr/val_loss:  0.090400/  1.995993, tr:  99.90%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-34  lr=['0.0076067'], tr/val_loss:  0.074261/  2.030577, tr: 100.00%, val:  75.83%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-35  lr=['0.0074642'], tr/val_loss:  0.072579/  2.098489, tr:  99.69%, val:  75.83%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-36  lr=['0.0073193'], tr/val_loss:  0.060125/  2.190426, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-37  lr=['0.0071724'], tr/val_loss:  0.054543/  2.154617, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-38  lr=['0.0070234'], tr/val_loss:  0.045807/  2.210527, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-39  lr=['0.0068725'], tr/val_loss:  0.038922/  2.239010, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-40  lr=['0.0067199'], tr/val_loss:  0.050864/  2.258123, tr:  99.90%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-41  lr=['0.0065658'], tr/val_loss:  0.079586/  2.241478, tr:  98.77%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-42  lr=['0.0064102'], tr/val_loss:  0.036785/  2.256007, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-43  lr=['0.0062534'], tr/val_loss:  0.028697/  2.328789, tr: 100.00%, val:  75.83%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-44  lr=['0.0060955'], tr/val_loss:  0.030079/  2.346029, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-45  lr=['0.0059366'], tr/val_loss:  0.025798/  2.409814, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-46  lr=['0.0057770'], tr/val_loss:  0.024827/  2.409480, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-47  lr=['0.0056167'], tr/val_loss:  0.025032/  2.456378, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-48  lr=['0.0054559'], tr/val_loss:  0.016038/  2.503546, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-49  lr=['0.0052948'], tr/val_loss:  0.015673/  2.498781, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-50  lr=['0.0051336'], tr/val_loss:  0.016955/  2.513297, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-51  lr=['0.0049723'], tr/val_loss:  0.014143/  2.537778, tr: 100.00%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-52  lr=['0.0048112'], tr/val_loss:  0.012025/  2.554595, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-53  lr=['0.0046505'], tr/val_loss:  0.010372/  2.571070, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-54  lr=['0.0044902'], tr/val_loss:  0.010126/  2.602235, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-55  lr=['0.0043305'], tr/val_loss:  0.009025/  2.612644, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-56  lr=['0.0041716'], tr/val_loss:  0.008908/  2.616131, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-57  lr=['0.0040137'], tr/val_loss:  0.007797/  2.615119, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-58  lr=['0.0038569'], tr/val_loss:  0.008301/  2.645127, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-59  lr=['0.0037014'], tr/val_loss:  0.007443/  2.639167, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-60  lr=['0.0035472'], tr/val_loss:  0.006879/  2.672893, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-61  lr=['0.0033946'], tr/val_loss:  0.006676/  2.664971, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-62  lr=['0.0032438'], tr/val_loss:  0.006495/  2.658615, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-63  lr=['0.0030948'], tr/val_loss:  0.005789/  2.660028, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-64  lr=['0.0029478'], tr/val_loss:  0.005728/  2.687410, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-65  lr=['0.0028030'], tr/val_loss:  0.005786/  2.703571, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-66  lr=['0.0026605'], tr/val_loss:  0.005784/  2.698994, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-67  lr=['0.0025204'], tr/val_loss:  0.005684/  2.690464, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-68  lr=['0.0023829'], tr/val_loss:  0.004949/  2.711841, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-69  lr=['0.0022481'], tr/val_loss:  0.004831/  2.704887, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-70  lr=['0.0021161'], tr/val_loss:  0.004584/  2.711042, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-71  lr=['0.0019872'], tr/val_loss:  0.004556/  2.715652, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-72  lr=['0.0018613'], tr/val_loss:  0.004537/  2.722318, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-73  lr=['0.0017387'], tr/val_loss:  0.005172/  2.725954, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-74  lr=['0.0016194'], tr/val_loss:  0.004556/  2.747738, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-75  lr=['0.0015036'], tr/val_loss:  0.004617/  2.725356, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-76  lr=['0.0013914'], tr/val_loss:  0.004544/  2.720678, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-77  lr=['0.0012828'], tr/val_loss:  0.004865/  2.726652, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-78  lr=['0.0011781'], tr/val_loss:  0.004650/  2.715961, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-79  lr=['0.0010773'], tr/val_loss:  0.004206/  2.720458, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-80  lr=['0.0009804'], tr/val_loss:  0.003898/  2.718002, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-81  lr=['0.0008877'], tr/val_loss:  0.003629/  2.720705, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-82  lr=['0.0007992'], tr/val_loss:  0.004106/  2.726313, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-83  lr=['0.0007149'], tr/val_loss:  0.003715/  2.727889, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-84  lr=['0.0006350'], tr/val_loss:  0.003930/  2.729822, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-85  lr=['0.0005595'], tr/val_loss:  0.003741/  2.730779, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-86  lr=['0.0004886'], tr/val_loss:  0.003579/  2.732213, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-87  lr=['0.0004222'], tr/val_loss:  0.003654/  2.732116, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-88  lr=['0.0003605'], tr/val_loss:  0.003667/  2.726208, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-89  lr=['0.0003035'], tr/val_loss:  0.003578/  2.732806, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-90  lr=['0.0002513'], tr/val_loss:  0.003599/  2.737580, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-91  lr=['0.0002038'], tr/val_loss:  0.003656/  2.739568, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-92  lr=['0.0001613'], tr/val_loss:  0.003638/  2.739004, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-93  lr=['0.0001236'], tr/val_loss:  0.003671/  2.737216, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-94  lr=['0.0000909'], tr/val_loss:  0.003657/  2.738456, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-95  lr=['0.0000632'], tr/val_loss:  0.003580/  2.739765, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-96  lr=['0.0000405'], tr/val_loss:  0.003614/  2.735698, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-97  lr=['0.0000228'], tr/val_loss:  0.003547/  2.736212, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-98  lr=['0.0000101'], tr/val_loss:  0.003623/  2.736079, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-99  lr=['0.0000025'], tr/val_loss:  0.003551/  2.736081, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c26fd777094bb89c95bc446b4d595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆█▆▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▇▇▆▇▇▇██▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▇▇▆▇▇▇██▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▆▁▁▁▂▁▁▂▂▂▃▃▄▅▅▅▆▆▆▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00355</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.73608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-sweep-58</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4j2lof6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4j2lof6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_144324-g4j2lof6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z992aqm4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002647265022521304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.3035377940362074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7171284602520229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_145237-z992aqm4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z992aqm4' target=\"_blank\">neat-sweep-60</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z992aqm4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z992aqm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0026473'], tr/val_loss:  1.642949/  1.390069, tr:  43.92%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 13.44it/s]\n",
      "epoch-1   lr=['0.0026466'], tr/val_loss:  1.121993/  1.359511, tr:  58.22%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:04<00:00, 13.51it/s]\n",
      "epoch-2   lr=['0.0026447'], tr/val_loss:  0.929945/  1.239328, tr:  65.88%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.25it/s]\n",
      "epoch-3   lr=['0.0026414'], tr/val_loss:  0.786439/  1.178702, tr:  71.50%, val:  59.58%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.35it/s]\n",
      "epoch-4   lr=['0.0026368'], tr/val_loss:  0.690767/  1.202775, tr:  75.18%, val:  59.58%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-5   lr=['0.0026310'], tr/val_loss:  0.613137/  1.201803, tr:  79.88%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-6   lr=['0.0026238'], tr/val_loss:  0.530161/  1.202017, tr:  81.72%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-7   lr=['0.0026154'], tr/val_loss:  0.484885/  1.406767, tr:  84.68%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-8   lr=['0.0026057'], tr/val_loss:  0.413427/  1.325718, tr:  88.87%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-9   lr=['0.0025947'], tr/val_loss:  0.297004/  1.435601, tr:  91.73%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-10  lr=['0.0025825'], tr/val_loss:  0.219751/  1.459906, tr:  95.71%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-11  lr=['0.0025690'], tr/val_loss:  0.193317/  1.469612, tr:  96.63%, val:  70.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-12  lr=['0.0025543'], tr/val_loss:  0.132858/  1.419121, tr:  98.77%, val:  70.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-13  lr=['0.0025384'], tr/val_loss:  0.141383/  1.473742, tr:  96.94%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-14  lr=['0.0025213'], tr/val_loss:  0.074095/  1.455997, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-15  lr=['0.0025030'], tr/val_loss:  0.054205/  1.471681, tr:  99.90%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-16  lr=['0.0024835'], tr/val_loss:  0.027036/  1.508904, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-17  lr=['0.0024629'], tr/val_loss:  0.015308/  1.531383, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-18  lr=['0.0024412'], tr/val_loss:  0.010665/  1.586020, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-19  lr=['0.0024184'], tr/val_loss:  0.007841/  1.555635, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-20  lr=['0.0023945'], tr/val_loss:  0.006268/  1.582576, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-21  lr=['0.0023695'], tr/val_loss:  0.005441/  1.601101, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-22  lr=['0.0023435'], tr/val_loss:  0.004388/  1.606098, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-23  lr=['0.0023165'], tr/val_loss:  0.004041/  1.617904, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-24  lr=['0.0022885'], tr/val_loss:  0.003647/  1.625068, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-25  lr=['0.0022596'], tr/val_loss:  0.003460/  1.629577, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-26  lr=['0.0022297'], tr/val_loss:  0.003166/  1.661265, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-27  lr=['0.0021990'], tr/val_loss:  0.002790/  1.647888, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-28  lr=['0.0021673'], tr/val_loss:  0.002605/  1.654758, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-29  lr=['0.0021349'], tr/val_loss:  0.002415/  1.680346, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-30  lr=['0.0021016'], tr/val_loss:  0.002319/  1.675406, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-31  lr=['0.0020676'], tr/val_loss:  0.002103/  1.686416, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-32  lr=['0.0020329'], tr/val_loss:  0.002081/  1.691279, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-33  lr=['0.0019974'], tr/val_loss:  0.001933/  1.695187, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-34  lr=['0.0019613'], tr/val_loss:  0.001875/  1.696805, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-35  lr=['0.0019245'], tr/val_loss:  0.001804/  1.701514, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-36  lr=['0.0018872'], tr/val_loss:  0.001713/  1.712214, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-37  lr=['0.0018493'], tr/val_loss:  0.001646/  1.713502, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-38  lr=['0.0018109'], tr/val_loss:  0.001586/  1.715637, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-39  lr=['0.0017720'], tr/val_loss:  0.001582/  1.725961, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-40  lr=['0.0017327'], tr/val_loss:  0.001527/  1.732643, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-41  lr=['0.0016929'], tr/val_loss:  0.001457/  1.730318, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-42  lr=['0.0016528'], tr/val_loss:  0.001429/  1.733063, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-43  lr=['0.0016124'], tr/val_loss:  0.001392/  1.740013, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-44  lr=['0.0015717'], tr/val_loss:  0.001354/  1.738095, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-45  lr=['0.0015307'], tr/val_loss:  0.001341/  1.745563, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-46  lr=['0.0014895'], tr/val_loss:  0.001303/  1.759198, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-47  lr=['0.0014482'], tr/val_loss:  0.001285/  1.756035, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-48  lr=['0.0014067'], tr/val_loss:  0.001290/  1.758414, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-49  lr=['0.0013652'], tr/val_loss:  0.001218/  1.758516, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-50  lr=['0.0013236'], tr/val_loss:  0.001244/  1.762473, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-51  lr=['0.0012821'], tr/val_loss:  0.001211/  1.763443, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-52  lr=['0.0012405'], tr/val_loss:  0.001187/  1.767562, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-53  lr=['0.0011991'], tr/val_loss:  0.001145/  1.775069, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-54  lr=['0.0011577'], tr/val_loss:  0.001129/  1.765313, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-55  lr=['0.0011166'], tr/val_loss:  0.001118/  1.763662, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-56  lr=['0.0010756'], tr/val_loss:  0.001092/  1.762895, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-57  lr=['0.0010349'], tr/val_loss:  0.001070/  1.768936, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-58  lr=['0.0009945'], tr/val_loss:  0.001068/  1.762969, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-59  lr=['0.0009544'], tr/val_loss:  0.001055/  1.761857, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-60  lr=['0.0009146'], tr/val_loss:  0.001053/  1.761865, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-61  lr=['0.0008753'], tr/val_loss:  0.001034/  1.766066, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-62  lr=['0.0008364'], tr/val_loss:  0.001017/  1.776229, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-63  lr=['0.0007980'], tr/val_loss:  0.001025/  1.766300, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-64  lr=['0.0007601'], tr/val_loss:  0.000986/  1.769106, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-65  lr=['0.0007227'], tr/val_loss:  0.000986/  1.769774, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-66  lr=['0.0006860'], tr/val_loss:  0.000980/  1.776877, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-67  lr=['0.0006498'], tr/val_loss:  0.000974/  1.777082, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-68  lr=['0.0006144'], tr/val_loss:  0.000977/  1.773146, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-69  lr=['0.0005796'], tr/val_loss:  0.000951/  1.773735, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-70  lr=['0.0005456'], tr/val_loss:  0.000939/  1.775956, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-71  lr=['0.0005124'], tr/val_loss:  0.000940/  1.778108, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-72  lr=['0.0004799'], tr/val_loss:  0.000926/  1.774258, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-73  lr=['0.0004483'], tr/val_loss:  0.000945/  1.776192, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-74  lr=['0.0004175'], tr/val_loss:  0.000919/  1.772713, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-75  lr=['0.0003877'], tr/val_loss:  0.000908/  1.774454, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-76  lr=['0.0003587'], tr/val_loss:  0.000923/  1.775159, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-77  lr=['0.0003308'], tr/val_loss:  0.000900/  1.770998, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-78  lr=['0.0003038'], tr/val_loss:  0.000898/  1.770660, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-79  lr=['0.0002778'], tr/val_loss:  0.000895/  1.773339, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-80  lr=['0.0002528'], tr/val_loss:  0.000893/  1.774258, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-81  lr=['0.0002289'], tr/val_loss:  0.000896/  1.774856, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-82  lr=['0.0002061'], tr/val_loss:  0.000882/  1.776348, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-83  lr=['0.0001843'], tr/val_loss:  0.000892/  1.777387, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-84  lr=['0.0001637'], tr/val_loss:  0.000887/  1.777998, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-85  lr=['0.0001443'], tr/val_loss:  0.000883/  1.778595, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-86  lr=['0.0001260'], tr/val_loss:  0.000878/  1.778501, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-87  lr=['0.0001089'], tr/val_loss:  0.000875/  1.778634, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-88  lr=['0.0000930'], tr/val_loss:  0.000892/  1.779266, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-89  lr=['0.0000783'], tr/val_loss:  0.000879/  1.780342, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-90  lr=['0.0000648'], tr/val_loss:  0.000880/  1.782845, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-91  lr=['0.0000526'], tr/val_loss:  0.000881/  1.781893, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-92  lr=['0.0000416'], tr/val_loss:  0.000878/  1.782193, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-93  lr=['0.0000319'], tr/val_loss:  0.000883/  1.782351, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-94  lr=['0.0000234'], tr/val_loss:  0.000881/  1.783285, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-95  lr=['0.0000163'], tr/val_loss:  0.000878/  1.783975, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-96  lr=['0.0000104'], tr/val_loss:  0.000877/  1.784786, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-97  lr=['0.0000059'], tr/val_loss:  0.000873/  1.784792, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-98  lr=['0.0000026'], tr/val_loss:  0.000890/  1.784793, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-99  lr=['0.0000007'], tr/val_loss:  0.000874/  1.784793, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1055d3311b14f4390d7f76cf362d30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▅▃▆▅██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▅▆▇▇▇██▇██▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▅▆▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▅▆▇▇▇██▇██▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▃▄▄▄▅▅▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00087</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>1.78479</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-60</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z992aqm4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z992aqm4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_145237-z992aqm4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wskdtjy2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006718461784238468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.731000873970824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.2164182817755411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_150142-wskdtjy2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wskdtjy2' target=\"_blank\">ancient-sweep-62</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wskdtjy2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wskdtjy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0067185'], tr/val_loss:  1.974466/  1.604718, tr:  27.07%, val:  45.83%, val_best:  45.83%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-1   lr=['0.0067168'], tr/val_loss:  1.274606/  1.375629, tr:  55.26%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-2   lr=['0.0067118'], tr/val_loss:  1.061005/  1.132666, tr:  61.90%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-3   lr=['0.0067036'], tr/val_loss:  0.913231/  1.135837, tr:  68.74%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-4   lr=['0.0066920'], tr/val_loss:  0.865614/  1.150149, tr:  69.77%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-5   lr=['0.0066771'], tr/val_loss:  0.817205/  1.268084, tr:  71.91%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-6   lr=['0.0066590'], tr/val_loss:  0.719215/  1.229649, tr:  76.51%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-7   lr=['0.0066376'], tr/val_loss:  0.667475/  1.315590, tr:  77.12%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-8   lr=['0.0066129'], tr/val_loss:  0.608426/  1.201298, tr:  79.37%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-9   lr=['0.0065851'], tr/val_loss:  0.497455/  1.334729, tr:  83.76%, val:  66.25%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-10  lr=['0.0065540'], tr/val_loss:  0.441479/  1.374856, tr:  89.38%, val:  69.58%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-11  lr=['0.0065199'], tr/val_loss:  0.395833/  1.379740, tr:  89.17%, val:  70.42%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-12  lr=['0.0064826'], tr/val_loss:  0.357601/  1.393285, tr:  91.73%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-13  lr=['0.0064422'], tr/val_loss:  0.308467/  1.459764, tr:  93.97%, val:  70.83%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-14  lr=['0.0063988'], tr/val_loss:  0.277420/  1.404914, tr:  95.30%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-15  lr=['0.0063523'], tr/val_loss:  0.288075/  1.431240, tr:  94.38%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-16  lr=['0.0063029'], tr/val_loss:  0.229826/  1.813274, tr:  96.73%, val:  71.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-17  lr=['0.0062507'], tr/val_loss:  0.249491/  1.671365, tr:  96.12%, val:  67.92%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-18  lr=['0.0061955'], tr/val_loss:  0.215145/  1.547565, tr:  96.53%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-19  lr=['0.0061376'], tr/val_loss:  0.128492/  1.652543, tr:  99.59%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-20  lr=['0.0060769'], tr/val_loss:  0.107026/  1.763803, tr:  99.28%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-21  lr=['0.0060135'], tr/val_loss:  0.074712/  1.821734, tr:  99.80%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-22  lr=['0.0059476'], tr/val_loss:  0.064853/  1.899968, tr:  99.80%, val:  73.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-23  lr=['0.0058790'], tr/val_loss:  0.045261/  1.956747, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-24  lr=['0.0058080'], tr/val_loss:  0.047467/  1.997807, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-25  lr=['0.0057346'], tr/val_loss:  0.031810/  2.027572, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-26  lr=['0.0056588'], tr/val_loss:  0.023116/  2.076265, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-27  lr=['0.0055807'], tr/val_loss:  0.018024/  2.060685, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-28  lr=['0.0055005'], tr/val_loss:  0.016162/  2.104783, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-29  lr=['0.0054181'], tr/val_loss:  0.014588/  2.170266, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-30  lr=['0.0053337'], tr/val_loss:  0.010056/  2.181352, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-31  lr=['0.0052474'], tr/val_loss:  0.007591/  2.208838, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-32  lr=['0.0051592'], tr/val_loss:  0.006569/  2.244601, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-33  lr=['0.0050692'], tr/val_loss:  0.005767/  2.245158, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-34  lr=['0.0049776'], tr/val_loss:  0.005199/  2.248353, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-35  lr=['0.0048843'], tr/val_loss:  0.004803/  2.280380, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-36  lr=['0.0047895'], tr/val_loss:  0.004016/  2.319649, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-37  lr=['0.0046933'], tr/val_loss:  0.004070/  2.316268, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-38  lr=['0.0045958'], tr/val_loss:  0.003511/  2.331604, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-39  lr=['0.0044971'], tr/val_loss:  0.003098/  2.331811, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-40  lr=['0.0043973'], tr/val_loss:  0.003058/  2.346150, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-41  lr=['0.0042964'], tr/val_loss:  0.002858/  2.369864, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-42  lr=['0.0041946'], tr/val_loss:  0.002615/  2.386786, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-43  lr=['0.0040920'], tr/val_loss:  0.002425/  2.394064, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-44  lr=['0.0039887'], tr/val_loss:  0.002343/  2.409607, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-45  lr=['0.0038847'], tr/val_loss:  0.002360/  2.427322, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-46  lr=['0.0037803'], tr/val_loss:  0.002289/  2.413207, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-47  lr=['0.0036754'], tr/val_loss:  0.002140/  2.433728, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-48  lr=['0.0035702'], tr/val_loss:  0.001983/  2.428248, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-49  lr=['0.0034647'], tr/val_loss:  0.001883/  2.429965, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-50  lr=['0.0033592'], tr/val_loss:  0.001964/  2.433492, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-51  lr=['0.0032537'], tr/val_loss:  0.001800/  2.441132, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-52  lr=['0.0031483'], tr/val_loss:  0.001870/  2.441425, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-53  lr=['0.0030431'], tr/val_loss:  0.002076/  2.447026, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-54  lr=['0.0029382'], tr/val_loss:  0.001826/  2.461081, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-55  lr=['0.0028337'], tr/val_loss:  0.001767/  2.459928, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-56  lr=['0.0027298'], tr/val_loss:  0.001863/  2.482718, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-57  lr=['0.0026264'], tr/val_loss:  0.001672/  2.466516, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-58  lr=['0.0025238'], tr/val_loss:  0.001618/  2.459872, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-59  lr=['0.0024220'], tr/val_loss:  0.001717/  2.471326, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-60  lr=['0.0023212'], tr/val_loss:  0.001504/  2.492069, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-61  lr=['0.0022213'], tr/val_loss:  0.001504/  2.494748, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-62  lr=['0.0021226'], tr/val_loss:  0.001516/  2.494448, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-63  lr=['0.0020251'], tr/val_loss:  0.001508/  2.504750, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-64  lr=['0.0019289'], tr/val_loss:  0.001413/  2.505330, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-65  lr=['0.0018342'], tr/val_loss:  0.001411/  2.504818, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-66  lr=['0.0017409'], tr/val_loss:  0.001422/  2.511909, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-67  lr=['0.0016492'], tr/val_loss:  0.001459/  2.497481, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-68  lr=['0.0015593'], tr/val_loss:  0.001457/  2.507453, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-69  lr=['0.0014711'], tr/val_loss:  0.001390/  2.503976, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-70  lr=['0.0013847'], tr/val_loss:  0.001385/  2.510859, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-71  lr=['0.0013003'], tr/val_loss:  0.001350/  2.506392, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-72  lr=['0.0012180'], tr/val_loss:  0.001386/  2.508406, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-73  lr=['0.0011377'], tr/val_loss:  0.001443/  2.505685, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-74  lr=['0.0010597'], tr/val_loss:  0.001299/  2.508240, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-75  lr=['0.0009839'], tr/val_loss:  0.001310/  2.508957, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-76  lr=['0.0009105'], tr/val_loss:  0.001336/  2.508897, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-77  lr=['0.0008394'], tr/val_loss:  0.001311/  2.508192, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-78  lr=['0.0007709'], tr/val_loss:  0.001302/  2.509036, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-79  lr=['0.0007049'], tr/val_loss:  0.001293/  2.512483, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-80  lr=['0.0006416'], tr/val_loss:  0.001304/  2.511843, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-81  lr=['0.0005809'], tr/val_loss:  0.001260/  2.512021, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-82  lr=['0.0005229'], tr/val_loss:  0.001334/  2.511836, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-83  lr=['0.0004678'], tr/val_loss:  0.001262/  2.514240, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-84  lr=['0.0004155'], tr/val_loss:  0.001251/  2.512889, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-85  lr=['0.0003661'], tr/val_loss:  0.001221/  2.515480, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-86  lr=['0.0003197'], tr/val_loss:  0.001207/  2.518601, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-87  lr=['0.0002763'], tr/val_loss:  0.001211/  2.518858, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-88  lr=['0.0002359'], tr/val_loss:  0.001216/  2.520317, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-89  lr=['0.0001986'], tr/val_loss:  0.001191/  2.520259, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-90  lr=['0.0001644'], tr/val_loss:  0.001209/  2.520281, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-91  lr=['0.0001334'], tr/val_loss:  0.001193/  2.523116, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-92  lr=['0.0001055'], tr/val_loss:  0.001219/  2.523936, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-93  lr=['0.0000809'], tr/val_loss:  0.001200/  2.523069, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-94  lr=['0.0000595'], tr/val_loss:  0.001193/  2.523571, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-95  lr=['0.0000414'], tr/val_loss:  0.001206/  2.524312, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-96  lr=['0.0000265'], tr/val_loss:  0.001192/  2.523962, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-97  lr=['0.0000149'], tr/val_loss:  0.001193/  2.523629, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-98  lr=['0.0000066'], tr/val_loss:  0.001213/  2.523654, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-99  lr=['0.0000017'], tr/val_loss:  0.001200/  2.523654, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e923fca570584ee9b9f80ec0fcebb41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▄▆█▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▅▅▇▇▅█▇▇▇████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▅▅▇▇▅█▇▇▇████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▂▂▂▂▄▄▄▅▆▆▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0012</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>2.52365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-62</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wskdtjy2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wskdtjy2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_150142-wskdtjy2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4nzypka8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004703417100750332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.693031557301398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.680892651133618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_151055-4nzypka8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4nzypka8' target=\"_blank\">confused-sweep-64</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4nzypka8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4nzypka8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0047034'], tr/val_loss:  1.627547/  1.366498, tr:  42.49%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-1   lr=['0.0047023'], tr/val_loss:  1.130958/  1.311604, tr:  56.28%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-2   lr=['0.0046988'], tr/val_loss:  0.921344/  1.204911, tr:  65.27%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-3   lr=['0.0046930'], tr/val_loss:  0.762784/  1.186954, tr:  72.63%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-4   lr=['0.0046849'], tr/val_loss:  0.687002/  1.152176, tr:  75.89%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-5   lr=['0.0046745'], tr/val_loss:  0.608815/  1.215164, tr:  79.26%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:11<00:00,  5.62it/s]\n",
      "epoch-6   lr=['0.0046618'], tr/val_loss:  0.541556/  1.217411, tr:  81.61%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-7   lr=['0.0046468'], tr/val_loss:  0.477304/  1.350581, tr:  85.29%, val:  64.17%, val_best:  66.67%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-8   lr=['0.0046295'], tr/val_loss:  0.378148/  1.371172, tr:  88.36%, val:  65.00%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-9   lr=['0.0046100'], tr/val_loss:  0.265683/  1.442457, tr:  92.34%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-10  lr=['0.0045883'], tr/val_loss:  0.208142/  1.438351, tr:  96.22%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-11  lr=['0.0045644'], tr/val_loss:  0.151574/  1.449484, tr:  97.04%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-12  lr=['0.0045383'], tr/val_loss:  0.094728/  1.649885, tr:  99.80%, val:  69.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-13  lr=['0.0045100'], tr/val_loss:  0.149169/  1.596700, tr:  96.94%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-14  lr=['0.0044796'], tr/val_loss:  0.070450/  1.578149, tr:  99.59%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-15  lr=['0.0044471'], tr/val_loss:  0.071196/  1.569128, tr:  98.67%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-16  lr=['0.0044125'], tr/val_loss:  0.032332/  1.706769, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-17  lr=['0.0043759'], tr/val_loss:  0.015518/  1.692383, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-18  lr=['0.0043373'], tr/val_loss:  0.008846/  1.714546, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-19  lr=['0.0042968'], tr/val_loss:  0.005090/  1.742311, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-20  lr=['0.0042543'], tr/val_loss:  0.004195/  1.768598, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-21  lr=['0.0042099'], tr/val_loss:  0.003348/  1.789698, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-22  lr=['0.0041637'], tr/val_loss:  0.002876/  1.787490, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-23  lr=['0.0041158'], tr/val_loss:  0.002454/  1.816253, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-24  lr=['0.0040660'], tr/val_loss:  0.002169/  1.804728, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-25  lr=['0.0040146'], tr/val_loss:  0.002094/  1.832904, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-26  lr=['0.0039616'], tr/val_loss:  0.001776/  1.848685, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-27  lr=['0.0039069'], tr/val_loss:  0.001660/  1.858847, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-28  lr=['0.0038507'], tr/val_loss:  0.001512/  1.864432, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:08<00:00,  7.75it/s]\n",
      "epoch-29  lr=['0.0037931'], tr/val_loss:  0.001423/  1.858816, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-30  lr=['0.0037340'], tr/val_loss:  0.001350/  1.860523, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-31  lr=['0.0036736'], tr/val_loss:  0.001266/  1.869659, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-32  lr=['0.0036118'], tr/val_loss:  0.001226/  1.896092, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-33  lr=['0.0035488'], tr/val_loss:  0.001131/  1.895415, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-34  lr=['0.0034847'], tr/val_loss:  0.001077/  1.905909, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-35  lr=['0.0034194'], tr/val_loss:  0.001055/  1.911922, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-36  lr=['0.0033530'], tr/val_loss:  0.000980/  1.907694, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-37  lr=['0.0032857'], tr/val_loss:  0.000944/  1.908360, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-38  lr=['0.0032174'], tr/val_loss:  0.000915/  1.910001, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-39  lr=['0.0031483'], tr/val_loss:  0.000902/  1.906608, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-40  lr=['0.0030784'], tr/val_loss:  0.000881/  1.923181, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-41  lr=['0.0030078'], tr/val_loss:  0.000853/  1.918223, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-42  lr=['0.0029366'], tr/val_loss:  0.000821/  1.927193, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-43  lr=['0.0028647'], tr/val_loss:  0.000809/  1.926955, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-44  lr=['0.0027924'], tr/val_loss:  0.000784/  1.929281, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-45  lr=['0.0027196'], tr/val_loss:  0.000765/  1.933921, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-46  lr=['0.0026465'], tr/val_loss:  0.000763/  1.937414, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-47  lr=['0.0025730'], tr/val_loss:  0.000734/  1.940938, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-48  lr=['0.0024994'], tr/val_loss:  0.000731/  1.941741, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-49  lr=['0.0024256'], tr/val_loss:  0.000718/  1.949425, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-50  lr=['0.0023517'], tr/val_loss:  0.000731/  1.948534, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-51  lr=['0.0022778'], tr/val_loss:  0.000714/  1.953431, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-52  lr=['0.0022040'], tr/val_loss:  0.000688/  1.956024, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-53  lr=['0.0021304'], tr/val_loss:  0.000683/  1.960443, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-54  lr=['0.0020570'], tr/val_loss:  0.000686/  1.955257, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-55  lr=['0.0019838'], tr/val_loss:  0.000654/  1.951399, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-56  lr=['0.0019110'], tr/val_loss:  0.000661/  1.959527, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-57  lr=['0.0018387'], tr/val_loss:  0.000627/  1.958133, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-58  lr=['0.0017669'], tr/val_loss:  0.000633/  1.962121, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-59  lr=['0.0016956'], tr/val_loss:  0.000628/  1.951355, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-60  lr=['0.0016250'], tr/val_loss:  0.000614/  1.954747, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-61  lr=['0.0015551'], tr/val_loss:  0.000621/  1.954365, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-62  lr=['0.0014860'], tr/val_loss:  0.000619/  1.960716, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-63  lr=['0.0014177'], tr/val_loss:  0.000612/  1.956960, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-64  lr=['0.0013504'], tr/val_loss:  0.000592/  1.965854, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-65  lr=['0.0012841'], tr/val_loss:  0.000581/  1.959264, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-66  lr=['0.0012188'], tr/val_loss:  0.000587/  1.957564, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-67  lr=['0.0011546'], tr/val_loss:  0.000575/  1.956727, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-68  lr=['0.0010916'], tr/val_loss:  0.000583/  1.956433, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-69  lr=['0.0010299'], tr/val_loss:  0.000572/  1.954363, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-70  lr=['0.0009694'], tr/val_loss:  0.000558/  1.956458, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-71  lr=['0.0009103'], tr/val_loss:  0.000555/  1.958888, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-72  lr=['0.0008527'], tr/val_loss:  0.000546/  1.959284, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-73  lr=['0.0007965'], tr/val_loss:  0.000572/  1.960509, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-74  lr=['0.0007419'], tr/val_loss:  0.000553/  1.963464, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-75  lr=['0.0006888'], tr/val_loss:  0.000548/  1.962443, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-76  lr=['0.0006374'], tr/val_loss:  0.000550/  1.965927, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-77  lr=['0.0005877'], tr/val_loss:  0.000548/  1.966737, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-78  lr=['0.0005397'], tr/val_loss:  0.000539/  1.967830, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-79  lr=['0.0004935'], tr/val_loss:  0.000550/  1.968105, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-80  lr=['0.0004491'], tr/val_loss:  0.000538/  1.969402, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-81  lr=['0.0004067'], tr/val_loss:  0.000545/  1.967794, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-82  lr=['0.0003661'], tr/val_loss:  0.000527/  1.964300, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-83  lr=['0.0003275'], tr/val_loss:  0.000539/  1.965496, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-84  lr=['0.0002909'], tr/val_loss:  0.000531/  1.963445, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-85  lr=['0.0002563'], tr/val_loss:  0.000526/  1.962514, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-86  lr=['0.0002238'], tr/val_loss:  0.000531/  1.961119, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-87  lr=['0.0001934'], tr/val_loss:  0.000530/  1.961309, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-88  lr=['0.0001651'], tr/val_loss:  0.000530/  1.962662, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-89  lr=['0.0001390'], tr/val_loss:  0.000524/  1.962161, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-90  lr=['0.0001151'], tr/val_loss:  0.000526/  1.962342, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-91  lr=['0.0000934'], tr/val_loss:  0.000533/  1.963042, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-92  lr=['0.0000739'], tr/val_loss:  0.000520/  1.964127, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-93  lr=['0.0000566'], tr/val_loss:  0.000535/  1.964973, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-94  lr=['0.0000417'], tr/val_loss:  0.000526/  1.964963, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-95  lr=['0.0000290'], tr/val_loss:  0.000526/  1.965481, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-96  lr=['0.0000185'], tr/val_loss:  0.000526/  1.965554, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-97  lr=['0.0000104'], tr/val_loss:  0.000522/  1.965558, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-98  lr=['0.0000046'], tr/val_loss:  0.000548/  1.965560, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-99  lr=['0.0000012'], tr/val_loss:  0.000519/  1.965560, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc000cdbed24375bf1668278dce37bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▇▅██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▄▅▅▇▇█▇██████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▄▅▆▆▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▄▅▅▇▇█▇██████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▃▃▅▅▆▆▆▇▇▇▇█▇▇███████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00052</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>1.96556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-64</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4nzypka8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4nzypka8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_151055-4nzypka8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lochvpea with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.011791224401031057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.6699923985288176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.4424706674840004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_152008-lochvpea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lochvpea' target=\"_blank\">lively-sweep-66</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lochvpea' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lochvpea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0117912'], tr/val_loss:  1.917169/  1.469963, tr:  28.29%, val:  40.83%, val_best:  40.83%: 100%|██████████| 62/62 [00:04<00:00, 13.31it/s]\n",
      "epoch-1   lr=['0.0117883'], tr/val_loss:  1.328810/  1.338305, tr:  51.58%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-2   lr=['0.0117796'], tr/val_loss:  1.118558/  1.534037, tr:  59.14%, val:  52.92%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-3   lr=['0.0117651'], tr/val_loss:  1.040746/  1.389880, tr:  64.56%, val:  57.50%, val_best:  57.50%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-4   lr=['0.0117447'], tr/val_loss:  1.018389/  1.321445, tr:  63.33%, val:  51.67%, val_best:  57.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-5   lr=['0.0117186'], tr/val_loss:  0.857339/  1.502604, tr:  69.15%, val:  52.50%, val_best:  57.50%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-6   lr=['0.0116868'], tr/val_loss:  0.828920/  1.363957, tr:  69.56%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-7   lr=['0.0116492'], tr/val_loss:  0.856751/  1.472330, tr:  68.64%, val:  54.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-8   lr=['0.0116060'], tr/val_loss:  0.778180/  1.298957, tr:  70.58%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-9   lr=['0.0115571'], tr/val_loss:  0.624979/  1.394254, tr:  74.67%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-10  lr=['0.0115027'], tr/val_loss:  0.630469/  1.334193, tr:  78.86%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-11  lr=['0.0114427'], tr/val_loss:  0.602155/  1.347890, tr:  78.24%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-12  lr=['0.0113772'], tr/val_loss:  0.593048/  1.316745, tr:  78.86%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-13  lr=['0.0113063'], tr/val_loss:  0.521651/  1.597286, tr:  83.96%, val:  55.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-14  lr=['0.0112301'], tr/val_loss:  0.528795/  1.463627, tr:  83.45%, val:  62.50%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-15  lr=['0.0111486'], tr/val_loss:  0.537025/  1.466654, tr:  81.00%, val:  68.33%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-16  lr=['0.0110620'], tr/val_loss:  0.479339/  1.546975, tr:  86.72%, val:  66.25%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-17  lr=['0.0109702'], tr/val_loss:  0.505001/  1.399312, tr:  84.58%, val:  66.25%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-18  lr=['0.0108734'], tr/val_loss:  0.441363/  1.451250, tr:  87.54%, val:  67.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-19  lr=['0.0107718'], tr/val_loss:  0.423709/  1.456491, tr:  89.99%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-20  lr=['0.0106653'], tr/val_loss:  0.326393/  1.529120, tr:  92.65%, val:  71.25%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-21  lr=['0.0105541'], tr/val_loss:  0.278331/  1.793398, tr:  94.99%, val:  62.92%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-22  lr=['0.0104383'], tr/val_loss:  0.332625/  1.680669, tr:  94.08%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-23  lr=['0.0103180'], tr/val_loss:  0.281587/  1.732337, tr:  94.69%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-24  lr=['0.0101933'], tr/val_loss:  0.288726/  1.591453, tr:  94.38%, val:  75.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-25  lr=['0.0100644'], tr/val_loss:  0.247192/  1.688435, tr:  96.94%, val:  70.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-26  lr=['0.0099314'], tr/val_loss:  0.206929/  1.787047, tr:  97.14%, val:  70.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-27  lr=['0.0097945'], tr/val_loss:  0.158809/  1.812600, tr:  98.77%, val:  72.92%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-28  lr=['0.0096536'], tr/val_loss:  0.141135/  1.772802, tr:  98.47%, val:  75.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-29  lr=['0.0095091'], tr/val_loss:  0.112063/  2.014344, tr:  99.49%, val:  70.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-30  lr=['0.0093610'], tr/val_loss:  0.185937/  1.832075, tr:  97.75%, val:  74.17%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-31  lr=['0.0092094'], tr/val_loss:  0.074286/  1.959808, tr:  99.69%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-32  lr=['0.0090546'], tr/val_loss:  0.062015/  2.082106, tr: 100.00%, val:  70.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-33  lr=['0.0088967'], tr/val_loss:  0.061063/  2.188705, tr: 100.00%, val:  71.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-34  lr=['0.0087358'], tr/val_loss:  0.051382/  2.097046, tr: 100.00%, val:  73.75%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-35  lr=['0.0085722'], tr/val_loss:  0.028910/  2.201785, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-36  lr=['0.0084058'], tr/val_loss:  0.022423/  2.182620, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-37  lr=['0.0082370'], tr/val_loss:  0.037278/  2.244627, tr:  99.90%, val:  73.75%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-38  lr=['0.0080659'], tr/val_loss:  0.023144/  2.218803, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-39  lr=['0.0078927'], tr/val_loss:  0.015063/  2.298284, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-40  lr=['0.0077175'], tr/val_loss:  0.009913/  2.231371, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-41  lr=['0.0075404'], tr/val_loss:  0.005670/  2.336843, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-42  lr=['0.0073618'], tr/val_loss:  0.005836/  2.372293, tr: 100.00%, val:  73.75%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-43  lr=['0.0071817'], tr/val_loss:  0.005169/  2.319641, tr: 100.00%, val:  73.75%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-44  lr=['0.0070003'], tr/val_loss:  0.003287/  2.353804, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-45  lr=['0.0068179'], tr/val_loss:  0.001922/  2.351329, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-46  lr=['0.0066345'], tr/val_loss:  0.002197/  2.402551, tr: 100.00%, val:  74.17%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-47  lr=['0.0064504'], tr/val_loss:  0.002408/  2.400557, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-48  lr=['0.0062658'], tr/val_loss:  0.001820/  2.397482, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-49  lr=['0.0060808'], tr/val_loss:  0.001467/  2.370792, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-50  lr=['0.0058956'], tr/val_loss:  0.001320/  2.381816, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-51  lr=['0.0057104'], tr/val_loss:  0.001236/  2.387344, tr: 100.00%, val:  73.75%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-52  lr=['0.0055254'], tr/val_loss:  0.001106/  2.385300, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-53  lr=['0.0053408'], tr/val_loss:  0.001097/  2.392002, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-54  lr=['0.0051567'], tr/val_loss:  0.001075/  2.382960, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-55  lr=['0.0049733'], tr/val_loss:  0.000977/  2.391532, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-56  lr=['0.0047909'], tr/val_loss:  0.000948/  2.398522, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-57  lr=['0.0046095'], tr/val_loss:  0.000896/  2.395079, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-58  lr=['0.0044294'], tr/val_loss:  0.000920/  2.399096, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-59  lr=['0.0042508'], tr/val_loss:  0.000847/  2.398285, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-60  lr=['0.0040738'], tr/val_loss:  0.000862/  2.403034, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-61  lr=['0.0038985'], tr/val_loss:  0.000845/  2.402835, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-62  lr=['0.0037253'], tr/val_loss:  0.000783/  2.409336, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-63  lr=['0.0035542'], tr/val_loss:  0.000797/  2.410628, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-64  lr=['0.0033854'], tr/val_loss:  0.000803/  2.415296, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-65  lr=['0.0032191'], tr/val_loss:  0.000764/  2.420634, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-66  lr=['0.0030554'], tr/val_loss:  0.000748/  2.427182, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-67  lr=['0.0028945'], tr/val_loss:  0.000758/  2.428890, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-68  lr=['0.0027366'], tr/val_loss:  0.000741/  2.424499, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-69  lr=['0.0025818'], tr/val_loss:  0.000725/  2.431726, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-70  lr=['0.0024303'], tr/val_loss:  0.000714/  2.442748, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-71  lr=['0.0022821'], tr/val_loss:  0.000718/  2.438627, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-72  lr=['0.0021376'], tr/val_loss:  0.000696/  2.438468, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-73  lr=['0.0019968'], tr/val_loss:  0.000690/  2.435776, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-74  lr=['0.0018598'], tr/val_loss:  0.000677/  2.439091, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-75  lr=['0.0017268'], tr/val_loss:  0.000657/  2.443451, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-76  lr=['0.0015979'], tr/val_loss:  0.000676/  2.442976, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-77  lr=['0.0014732'], tr/val_loss:  0.000689/  2.448623, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-78  lr=['0.0013530'], tr/val_loss:  0.000650/  2.445585, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-79  lr=['0.0012372'], tr/val_loss:  0.000653/  2.445920, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-80  lr=['0.0011260'], tr/val_loss:  0.000640/  2.448995, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-81  lr=['0.0010195'], tr/val_loss:  0.000642/  2.448852, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-82  lr=['0.0009178'], tr/val_loss:  0.000652/  2.451093, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-83  lr=['0.0008210'], tr/val_loss:  0.000637/  2.452789, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-84  lr=['0.0007292'], tr/val_loss:  0.000645/  2.454238, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-85  lr=['0.0006426'], tr/val_loss:  0.000635/  2.454928, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-86  lr=['0.0005611'], tr/val_loss:  0.000634/  2.454899, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-87  lr=['0.0004849'], tr/val_loss:  0.000639/  2.452788, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-88  lr=['0.0004140'], tr/val_loss:  0.000650/  2.452516, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-89  lr=['0.0003485'], tr/val_loss:  0.000631/  2.453031, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-90  lr=['0.0002886'], tr/val_loss:  0.000643/  2.451359, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-91  lr=['0.0002341'], tr/val_loss:  0.000651/  2.452024, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-92  lr=['0.0001852'], tr/val_loss:  0.000651/  2.452391, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-93  lr=['0.0001420'], tr/val_loss:  0.000643/  2.453466, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-94  lr=['0.0001044'], tr/val_loss:  0.000641/  2.452142, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-95  lr=['0.0000726'], tr/val_loss:  0.000654/  2.452711, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-96  lr=['0.0000465'], tr/val_loss:  0.000632/  2.452549, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-97  lr=['0.0000262'], tr/val_loss:  0.000655/  2.452569, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-98  lr=['0.0000116'], tr/val_loss:  0.000652/  2.452338, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-99  lr=['0.0000029'], tr/val_loss:  0.000629/  2.452339, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f9363e3d194e2f9d606f5f9abee459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▇▃▅▇▇▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▆▇▅▆█▅█▇▇▇█▇█▇██████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▆▆▆▇█▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▆▆▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▆▇▅▆█▅█▇▇▇█▇█▇██████████████████████</td></tr><tr><td>val_loss</td><td>▂▂▁▂▁▁▂▂▂▄▃▄▅▆▆▇▇▇▇█▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00063</td></tr><tr><td>val_acc_best</td><td>0.775</td></tr><tr><td>val_acc_now</td><td>0.75833</td></tr><tr><td>val_loss</td><td>2.45234</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lively-sweep-66</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lochvpea' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lochvpea</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_152008-lochvpea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u7r3z9p7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0051534668028067575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.7077669301393026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.6001763322082203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_152929-u7r3z9p7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u7r3z9p7' target=\"_blank\">lively-sweep-68</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u7r3z9p7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u7r3z9p7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0051535'], tr/val_loss:  1.739001/  1.451338, tr:  39.94%, val:  47.50%, val_best:  47.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-1   lr=['0.0051522'], tr/val_loss:  1.211000/  1.346483, tr:  57.51%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-2   lr=['0.0051484'], tr/val_loss:  1.018039/  1.181876, tr:  62.21%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-3   lr=['0.0051420'], tr/val_loss:  0.903194/  1.178837, tr:  69.77%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-4   lr=['0.0051331'], tr/val_loss:  0.853740/  1.172524, tr:  69.36%, val:  60.83%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-5   lr=['0.0051217'], tr/val_loss:  0.792014/  1.210596, tr:  74.46%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-6   lr=['0.0051078'], tr/val_loss:  0.710964/  1.205986, tr:  76.81%, val:  58.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-7   lr=['0.0050914'], tr/val_loss:  0.694276/  1.293663, tr:  76.00%, val:  62.08%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-8   lr=['0.0050725'], tr/val_loss:  0.635267/  1.150459, tr:  78.86%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-9   lr=['0.0050512'], tr/val_loss:  0.521015/  1.290145, tr:  84.27%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-10  lr=['0.0050274'], tr/val_loss:  0.462248/  1.303311, tr:  88.76%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-11  lr=['0.0050011'], tr/val_loss:  0.428408/  1.394463, tr:  90.30%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-12  lr=['0.0049725'], tr/val_loss:  0.392442/  1.363946, tr:  93.56%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-13  lr=['0.0049415'], tr/val_loss:  0.361125/  1.427808, tr:  92.24%, val:  67.08%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-14  lr=['0.0049082'], tr/val_loss:  0.283118/  1.399538, tr:  96.02%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-15  lr=['0.0048726'], tr/val_loss:  0.320796/  1.427033, tr:  93.36%, val:  71.67%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-16  lr=['0.0048347'], tr/val_loss:  0.272791/  1.574764, tr:  95.91%, val:  67.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-17  lr=['0.0047946'], tr/val_loss:  0.261396/  1.506073, tr:  95.91%, val:  69.58%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-18  lr=['0.0047523'], tr/val_loss:  0.260863/  1.505645, tr:  94.69%, val:  69.17%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-19  lr=['0.0047079'], tr/val_loss:  0.188435/  1.574640, tr:  98.77%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-20  lr=['0.0046614'], tr/val_loss:  0.174649/  1.567958, tr:  98.16%, val:  70.00%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-21  lr=['0.0046128'], tr/val_loss:  0.125338/  1.728084, tr:  99.69%, val:  69.58%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-22  lr=['0.0045621'], tr/val_loss:  0.130128/  1.681768, tr:  99.28%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-23  lr=['0.0045096'], tr/val_loss:  0.110231/  1.753018, tr:  99.28%, val:  70.42%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-24  lr=['0.0044551'], tr/val_loss:  0.089732/  1.810523, tr:  99.69%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-25  lr=['0.0043988'], tr/val_loss:  0.083932/  1.842995, tr:  99.80%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-26  lr=['0.0043406'], tr/val_loss:  0.077408/  1.811500, tr:  99.59%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-27  lr=['0.0042808'], tr/val_loss:  0.050902/  1.869328, tr: 100.00%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-28  lr=['0.0042192'], tr/val_loss:  0.039572/  1.907663, tr: 100.00%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-29  lr=['0.0041560'], tr/val_loss:  0.036078/  1.994832, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-30  lr=['0.0040913'], tr/val_loss:  0.029191/  2.001312, tr: 100.00%, val:  75.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-31  lr=['0.0040251'], tr/val_loss:  0.023345/  2.023175, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-32  lr=['0.0039574'], tr/val_loss:  0.018635/  2.070959, tr: 100.00%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-33  lr=['0.0038884'], tr/val_loss:  0.016264/  2.130250, tr: 100.00%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-34  lr=['0.0038181'], tr/val_loss:  0.014325/  2.147372, tr: 100.00%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-35  lr=['0.0037465'], tr/val_loss:  0.015135/  2.168425, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-36  lr=['0.0036739'], tr/val_loss:  0.010430/  2.191683, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-37  lr=['0.0036001'], tr/val_loss:  0.010066/  2.220170, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-38  lr=['0.0035253'], tr/val_loss:  0.013705/  2.237557, tr: 100.00%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-39  lr=['0.0034496'], tr/val_loss:  0.008437/  2.228127, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-40  lr=['0.0033730'], tr/val_loss:  0.007402/  2.249268, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-41  lr=['0.0032956'], tr/val_loss:  0.006709/  2.258963, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-42  lr=['0.0032175'], tr/val_loss:  0.005811/  2.280837, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-43  lr=['0.0031388'], tr/val_loss:  0.005095/  2.284275, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-44  lr=['0.0030596'], tr/val_loss:  0.005198/  2.280582, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-45  lr=['0.0029798'], tr/val_loss:  0.004619/  2.291031, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-46  lr=['0.0028997'], tr/val_loss:  0.004675/  2.292670, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-47  lr=['0.0028192'], tr/val_loss:  0.004034/  2.313175, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-48  lr=['0.0027385'], tr/val_loss:  0.003623/  2.327214, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-49  lr=['0.0026577'], tr/val_loss:  0.004016/  2.343713, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-50  lr=['0.0025767'], tr/val_loss:  0.003551/  2.332232, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-51  lr=['0.0024958'], tr/val_loss:  0.003334/  2.354393, tr: 100.00%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-52  lr=['0.0024149'], tr/val_loss:  0.003134/  2.358589, tr: 100.00%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-53  lr=['0.0023342'], tr/val_loss:  0.003068/  2.369748, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-54  lr=['0.0022538'], tr/val_loss:  0.002993/  2.374825, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-55  lr=['0.0021736'], tr/val_loss:  0.002852/  2.387184, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-56  lr=['0.0020939'], tr/val_loss:  0.002809/  2.373515, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-57  lr=['0.0020146'], tr/val_loss:  0.002952/  2.378147, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-58  lr=['0.0019359'], tr/val_loss:  0.002743/  2.381779, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-59  lr=['0.0018578'], tr/val_loss:  0.002991/  2.390469, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-60  lr=['0.0017805'], tr/val_loss:  0.002753/  2.398785, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-61  lr=['0.0017039'], tr/val_loss:  0.002936/  2.402436, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-62  lr=['0.0016282'], tr/val_loss:  0.002637/  2.401079, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-63  lr=['0.0015534'], tr/val_loss:  0.002534/  2.409811, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-64  lr=['0.0014796'], tr/val_loss:  0.002514/  2.408575, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-65  lr=['0.0014069'], tr/val_loss:  0.002499/  2.415584, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-66  lr=['0.0013354'], tr/val_loss:  0.002460/  2.416413, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-67  lr=['0.0012651'], tr/val_loss:  0.002343/  2.425516, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-68  lr=['0.0011961'], tr/val_loss:  0.002372/  2.424322, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-69  lr=['0.0011284'], tr/val_loss:  0.002375/  2.424830, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-70  lr=['0.0010622'], tr/val_loss:  0.002384/  2.430711, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-71  lr=['0.0009974'], tr/val_loss:  0.002229/  2.432455, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-72  lr=['0.0009343'], tr/val_loss:  0.002159/  2.434221, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-73  lr=['0.0008727'], tr/val_loss:  0.002191/  2.442269, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-74  lr=['0.0008128'], tr/val_loss:  0.002122/  2.433594, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-75  lr=['0.0007547'], tr/val_loss:  0.002089/  2.437330, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-76  lr=['0.0006984'], tr/val_loss:  0.002139/  2.440866, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-77  lr=['0.0006439'], tr/val_loss:  0.002026/  2.434117, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-78  lr=['0.0005913'], tr/val_loss:  0.002017/  2.439803, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-79  lr=['0.0005407'], tr/val_loss:  0.002059/  2.442660, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-80  lr=['0.0004921'], tr/val_loss:  0.002072/  2.444688, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-81  lr=['0.0004456'], tr/val_loss:  0.001987/  2.440162, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-82  lr=['0.0004011'], tr/val_loss:  0.002022/  2.437289, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-83  lr=['0.0003588'], tr/val_loss:  0.001996/  2.440325, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-84  lr=['0.0003187'], tr/val_loss:  0.001977/  2.446815, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-85  lr=['0.0002808'], tr/val_loss:  0.001998/  2.443657, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-86  lr=['0.0002452'], tr/val_loss:  0.001934/  2.445535, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-87  lr=['0.0002119'], tr/val_loss:  0.001934/  2.448750, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-88  lr=['0.0001809'], tr/val_loss:  0.001981/  2.449444, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-89  lr=['0.0001523'], tr/val_loss:  0.001925/  2.451592, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-90  lr=['0.0001261'], tr/val_loss:  0.001949/  2.451886, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-91  lr=['0.0001023'], tr/val_loss:  0.001957/  2.453386, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-92  lr=['0.0000810'], tr/val_loss:  0.001966/  2.454405, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-93  lr=['0.0000621'], tr/val_loss:  0.001950/  2.451943, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-94  lr=['0.0000456'], tr/val_loss:  0.001943/  2.453115, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-95  lr=['0.0000317'], tr/val_loss:  0.001955/  2.452923, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-96  lr=['0.0000203'], tr/val_loss:  0.001936/  2.452946, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-97  lr=['0.0000114'], tr/val_loss:  0.001901/  2.452495, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-98  lr=['0.0000051'], tr/val_loss:  0.001927/  2.452499, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-99  lr=['0.0000013'], tr/val_loss:  0.001897/  2.452499, tr: 100.00%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aca9362fb4849a388feda23e55596b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▃▂▅▇▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▄▆▆▇▆▇▆▇▇▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▄▆▆▇▆▇▆▇▇▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▂▂▂▂▃▃▄▄▄▅▆▆▇▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0019</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>2.4525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lively-sweep-68</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u7r3z9p7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u7r3z9p7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_152929-u7r3z9p7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gbd7reci with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.017741869899087104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.4118945661542584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.9170700471312188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_153849-gbd7reci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gbd7reci' target=\"_blank\">twilight-sweep-70</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gbd7reci' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gbd7reci</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0177419'], tr/val_loss:  2.178541/  1.719490, tr:  16.96%, val:  40.00%, val_best:  40.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-1   lr=['0.0177375'], tr/val_loss:  1.455603/  1.510692, tr:  48.93%, val:  49.58%, val_best:  49.58%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-2   lr=['0.0177244'], tr/val_loss:  1.196048/  1.214367, tr:  59.24%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-3   lr=['0.0177025'], tr/val_loss:  1.053924/  1.205141, tr:  65.47%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-4   lr=['0.0176719'], tr/val_loss:  0.983387/  1.296032, tr:  67.31%, val:  57.08%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-5   lr=['0.0176327'], tr/val_loss:  0.911919/  1.332249, tr:  68.64%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-6   lr=['0.0175847'], tr/val_loss:  0.837905/  1.323451, tr:  71.40%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-7   lr=['0.0175282'], tr/val_loss:  0.787379/  1.324467, tr:  73.54%, val:  62.08%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-8   lr=['0.0174632'], tr/val_loss:  0.688664/  1.236034, tr:  77.32%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-9   lr=['0.0173896'], tr/val_loss:  0.572679/  1.368970, tr:  79.88%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-10  lr=['0.0173077'], tr/val_loss:  0.546667/  1.453630, tr:  83.45%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-11  lr=['0.0172174'], tr/val_loss:  0.523554/  1.467664, tr:  82.84%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-12  lr=['0.0171189'], tr/val_loss:  0.456704/  1.393523, tr:  86.72%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-13  lr=['0.0170123'], tr/val_loss:  0.372348/  1.537512, tr:  91.93%, val:  67.50%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-14  lr=['0.0168976'], tr/val_loss:  0.326102/  1.442606, tr:  92.65%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-15  lr=['0.0167750'], tr/val_loss:  0.377942/  1.485451, tr:  89.99%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-16  lr=['0.0166446'], tr/val_loss:  0.322743/  1.952248, tr:  93.16%, val:  67.92%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-17  lr=['0.0165065'], tr/val_loss:  0.382502/  1.871244, tr:  91.73%, val:  57.92%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-18  lr=['0.0163609'], tr/val_loss:  0.313345/  1.589635, tr:  93.16%, val:  70.83%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-19  lr=['0.0162079'], tr/val_loss:  0.206257/  1.720150, tr:  96.94%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-20  lr=['0.0160477'], tr/val_loss:  0.171700/  1.771280, tr:  97.45%, val:  73.75%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-21  lr=['0.0158803'], tr/val_loss:  0.129495/  1.977330, tr:  99.18%, val:  71.25%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-22  lr=['0.0157061'], tr/val_loss:  0.134861/  1.873730, tr:  98.88%, val:  72.50%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-23  lr=['0.0155251'], tr/val_loss:  0.099436/  1.898860, tr:  99.28%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-24  lr=['0.0153376'], tr/val_loss:  0.171126/  1.932576, tr:  96.53%, val:  70.83%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-25  lr=['0.0151436'], tr/val_loss:  0.114768/  1.915895, tr:  99.49%, val:  72.50%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-26  lr=['0.0149435'], tr/val_loss:  0.106163/  1.914167, tr:  99.28%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-27  lr=['0.0147374'], tr/val_loss:  0.062942/  2.033172, tr:  99.80%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-28  lr=['0.0145255'], tr/val_loss:  0.041130/  2.093168, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-29  lr=['0.0143080'], tr/val_loss:  0.036431/  2.184872, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-30  lr=['0.0140851'], tr/val_loss:  0.038068/  2.199919, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-31  lr=['0.0138571'], tr/val_loss:  0.020088/  2.288702, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-32  lr=['0.0136242'], tr/val_loss:  0.017088/  2.324984, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-33  lr=['0.0133866'], tr/val_loss:  0.013061/  2.389056, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-34  lr=['0.0131445'], tr/val_loss:  0.009287/  2.419753, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-35  lr=['0.0128983'], tr/val_loss:  0.008994/  2.472296, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-36  lr=['0.0126480'], tr/val_loss:  0.010290/  2.484262, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-37  lr=['0.0123940'], tr/val_loss:  0.012947/  2.475045, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-38  lr=['0.0121365'], tr/val_loss:  0.009202/  2.509603, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-39  lr=['0.0118759'], tr/val_loss:  0.006645/  2.529762, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-40  lr=['0.0116122'], tr/val_loss:  0.005065/  2.564955, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-41  lr=['0.0113458'], tr/val_loss:  0.013955/  2.545777, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-42  lr=['0.0110770'], tr/val_loss:  0.004818/  2.588934, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-43  lr=['0.0108061'], tr/val_loss:  0.003359/  2.618503, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-44  lr=['0.0105332'], tr/val_loss:  0.003898/  2.615226, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-45  lr=['0.0102587'], tr/val_loss:  0.002437/  2.632259, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-46  lr=['0.0099828'], tr/val_loss:  0.002527/  2.640123, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-47  lr=['0.0097058'], tr/val_loss:  0.002213/  2.680451, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-48  lr=['0.0094279'], tr/val_loss:  0.001857/  2.682440, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-49  lr=['0.0091496'], tr/val_loss:  0.002052/  2.714040, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-50  lr=['0.0088709'], tr/val_loss:  0.001716/  2.695574, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-51  lr=['0.0085923'], tr/val_loss:  0.001736/  2.710058, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-52  lr=['0.0083139'], tr/val_loss:  0.001473/  2.725930, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-53  lr=['0.0080361'], tr/val_loss:  0.001384/  2.727399, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-54  lr=['0.0077591'], tr/val_loss:  0.001399/  2.734580, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-55  lr=['0.0074832'], tr/val_loss:  0.001324/  2.734573, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-56  lr=['0.0072087'], tr/val_loss:  0.001316/  2.758877, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-57  lr=['0.0069358'], tr/val_loss:  0.001238/  2.754266, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-58  lr=['0.0066648'], tr/val_loss:  0.001236/  2.767043, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-59  lr=['0.0063960'], tr/val_loss:  0.001224/  2.786847, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-60  lr=['0.0061297'], tr/val_loss:  0.001111/  2.788552, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-61  lr=['0.0058660'], tr/val_loss:  0.001130/  2.799033, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-62  lr=['0.0056053'], tr/val_loss:  0.001151/  2.807927, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-63  lr=['0.0053479'], tr/val_loss:  0.001105/  2.798380, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-64  lr=['0.0050939'], tr/val_loss:  0.001153/  2.806362, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-65  lr=['0.0048436'], tr/val_loss:  0.001011/  2.803777, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-66  lr=['0.0045973'], tr/val_loss:  0.001062/  2.811112, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-67  lr=['0.0043553'], tr/val_loss:  0.001063/  2.818809, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-68  lr=['0.0041177'], tr/val_loss:  0.001116/  2.819275, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-69  lr=['0.0038847'], tr/val_loss:  0.001058/  2.825210, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-70  lr=['0.0036567'], tr/val_loss:  0.000944/  2.828187, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-71  lr=['0.0034339'], tr/val_loss:  0.000932/  2.827850, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-72  lr=['0.0032164'], tr/val_loss:  0.000931/  2.835179, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-73  lr=['0.0030045'], tr/val_loss:  0.000982/  2.837729, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-74  lr=['0.0027984'], tr/val_loss:  0.000948/  2.839755, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-75  lr=['0.0025982'], tr/val_loss:  0.000908/  2.840319, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-76  lr=['0.0024043'], tr/val_loss:  0.000927/  2.836346, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-77  lr=['0.0022167'], tr/val_loss:  0.000933/  2.837292, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-78  lr=['0.0020358'], tr/val_loss:  0.000922/  2.844285, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-79  lr=['0.0018615'], tr/val_loss:  0.000926/  2.844836, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-80  lr=['0.0016942'], tr/val_loss:  0.000955/  2.849667, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-81  lr=['0.0015340'], tr/val_loss:  0.000903/  2.850412, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-82  lr=['0.0013810'], tr/val_loss:  0.000923/  2.855698, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-83  lr=['0.0012353'], tr/val_loss:  0.000907/  2.851583, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-84  lr=['0.0010973'], tr/val_loss:  0.000905/  2.853012, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-85  lr=['0.0009669'], tr/val_loss:  0.000903/  2.852286, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-86  lr=['0.0008443'], tr/val_loss:  0.000912/  2.848839, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-87  lr=['0.0007296'], tr/val_loss:  0.000917/  2.849441, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-88  lr=['0.0006229'], tr/val_loss:  0.000896/  2.851213, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-89  lr=['0.0005244'], tr/val_loss:  0.000898/  2.851996, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-90  lr=['0.0004342'], tr/val_loss:  0.000903/  2.852559, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-91  lr=['0.0003522'], tr/val_loss:  0.000920/  2.852587, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-92  lr=['0.0002787'], tr/val_loss:  0.000899/  2.851166, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-93  lr=['0.0002136'], tr/val_loss:  0.000908/  2.852508, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-94  lr=['0.0001571'], tr/val_loss:  0.000914/  2.852667, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-95  lr=['0.0001092'], tr/val_loss:  0.000908/  2.852743, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-96  lr=['0.0000699'], tr/val_loss:  0.000925/  2.853520, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-97  lr=['0.0000394'], tr/val_loss:  0.000900/  2.853579, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-98  lr=['0.0000175'], tr/val_loss:  0.000896/  2.853587, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-99  lr=['0.0000044'], tr/val_loss:  0.000878/  2.853587, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b914558e874c2bac8c40652ff7d19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▅▄▅▇▇████▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▄▅▅▇▇▄▇▇▇█████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▅▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▄▅▅▇▇▄▇▇▇█████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▁▂▂▂▄▃▄▄▄▅▆▆▆▇▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00088</td></tr><tr><td>val_acc_best</td><td>0.78333</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>2.85359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-70</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gbd7reci' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gbd7reci</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_153849-gbd7reci/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ex7ax8tx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.011835741393079378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.6706372402526548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.718241898052957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_154751-ex7ax8tx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ex7ax8tx' target=\"_blank\">resilient-sweep-72</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ex7ax8tx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ex7ax8tx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0118357'], tr/val_loss:  2.025768/  1.536905, tr:  25.13%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:04<00:00, 13.33it/s]\n",
      "epoch-1   lr=['0.0118328'], tr/val_loss:  1.338825/  1.430098, tr:  55.16%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-2   lr=['0.0118241'], tr/val_loss:  1.113976/  1.160542, tr:  60.98%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-3   lr=['0.0118095'], tr/val_loss:  0.963243/  1.248274, tr:  66.39%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-4   lr=['0.0117891'], tr/val_loss:  0.895923/  1.163021, tr:  70.07%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-5   lr=['0.0117629'], tr/val_loss:  0.806059/  1.343835, tr:  72.42%, val:  60.42%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-6   lr=['0.0117309'], tr/val_loss:  0.708409/  1.237900, tr:  75.38%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-7   lr=['0.0116932'], tr/val_loss:  0.672959/  1.475204, tr:  77.73%, val:  58.75%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-8   lr=['0.0116498'], tr/val_loss:  0.635235/  1.254322, tr:  78.65%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-9   lr=['0.0116008'], tr/val_loss:  0.474743/  1.360483, tr:  84.68%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-10  lr=['0.0115461'], tr/val_loss:  0.412355/  1.492246, tr:  88.36%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-11  lr=['0.0114859'], tr/val_loss:  0.377574/  1.602994, tr:  88.66%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-12  lr=['0.0114202'], tr/val_loss:  0.345064/  1.520350, tr:  92.13%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-13  lr=['0.0113490'], tr/val_loss:  0.291545/  1.517590, tr:  94.28%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-14  lr=['0.0112725'], tr/val_loss:  0.234777/  1.471167, tr:  95.40%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-15  lr=['0.0111907'], tr/val_loss:  0.258852/  1.695451, tr:  94.18%, val:  70.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-16  lr=['0.0111037'], tr/val_loss:  0.174806/  1.922086, tr:  97.96%, val:  72.08%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-17  lr=['0.0110116'], tr/val_loss:  0.197578/  1.710254, tr:  97.34%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-18  lr=['0.0109145'], tr/val_loss:  0.151138/  1.771691, tr:  98.37%, val:  72.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-19  lr=['0.0108124'], tr/val_loss:  0.095854/  1.863038, tr:  99.39%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-20  lr=['0.0107055'], tr/val_loss:  0.068795/  1.885971, tr:  99.39%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-21  lr=['0.0105939'], tr/val_loss:  0.042760/  1.950517, tr:  99.90%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-22  lr=['0.0104777'], tr/val_loss:  0.033229/  2.006864, tr:  99.90%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-23  lr=['0.0103569'], tr/val_loss:  0.025169/  2.017091, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-24  lr=['0.0102318'], tr/val_loss:  0.019711/  2.140046, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-25  lr=['0.0101024'], tr/val_loss:  0.010503/  2.167907, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-26  lr=['0.0099689'], tr/val_loss:  0.007063/  2.210559, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-27  lr=['0.0098314'], tr/val_loss:  0.008313/  2.240573, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-28  lr=['0.0096901'], tr/val_loss:  0.005983/  2.241022, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-29  lr=['0.0095450'], tr/val_loss:  0.003965/  2.336069, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-30  lr=['0.0093963'], tr/val_loss:  0.003245/  2.358437, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-31  lr=['0.0092442'], tr/val_loss:  0.003048/  2.389244, tr: 100.00%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-32  lr=['0.0090888'], tr/val_loss:  0.002548/  2.380144, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-33  lr=['0.0089303'], tr/val_loss:  0.002084/  2.416077, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-34  lr=['0.0087688'], tr/val_loss:  0.001743/  2.382875, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-35  lr=['0.0086045'], tr/val_loss:  0.001673/  2.387051, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-36  lr=['0.0084376'], tr/val_loss:  0.001564/  2.434452, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-37  lr=['0.0082681'], tr/val_loss:  0.001379/  2.450273, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-38  lr=['0.0080964'], tr/val_loss:  0.001274/  2.464681, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-39  lr=['0.0079225'], tr/val_loss:  0.001307/  2.445689, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-40  lr=['0.0077466'], tr/val_loss:  0.001278/  2.479646, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-41  lr=['0.0075689'], tr/val_loss:  0.001194/  2.474009, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-42  lr=['0.0073896'], tr/val_loss:  0.001068/  2.497966, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-43  lr=['0.0072088'], tr/val_loss:  0.001057/  2.500069, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-44  lr=['0.0070268'], tr/val_loss:  0.001032/  2.506745, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-45  lr=['0.0068436'], tr/val_loss:  0.000992/  2.510109, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-46  lr=['0.0066596'], tr/val_loss:  0.000902/  2.512567, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-47  lr=['0.0064748'], tr/val_loss:  0.000885/  2.519812, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-48  lr=['0.0062895'], tr/val_loss:  0.000950/  2.517204, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-49  lr=['0.0061038'], tr/val_loss:  0.000919/  2.531898, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-50  lr=['0.0059179'], tr/val_loss:  0.000883/  2.543155, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-51  lr=['0.0057320'], tr/val_loss:  0.000817/  2.533801, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-52  lr=['0.0055463'], tr/val_loss:  0.000790/  2.541590, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-53  lr=['0.0053609'], tr/val_loss:  0.000785/  2.547864, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-54  lr=['0.0051762'], tr/val_loss:  0.000824/  2.560709, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-55  lr=['0.0049921'], tr/val_loss:  0.000762/  2.552762, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-56  lr=['0.0048090'], tr/val_loss:  0.000748/  2.547023, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-57  lr=['0.0046269'], tr/val_loss:  0.000770/  2.553381, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-58  lr=['0.0044462'], tr/val_loss:  0.000722/  2.564059, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-59  lr=['0.0042668'], tr/val_loss:  0.000792/  2.561847, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-60  lr=['0.0040891'], tr/val_loss:  0.000710/  2.569024, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n",
      "epoch-61  lr=['0.0039133'], tr/val_loss:  0.000687/  2.576771, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-62  lr=['0.0037394'], tr/val_loss:  0.000667/  2.580752, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-63  lr=['0.0035676'], tr/val_loss:  0.000697/  2.585800, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-64  lr=['0.0033982'], tr/val_loss:  0.000674/  2.586960, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-65  lr=['0.0032312'], tr/val_loss:  0.000663/  2.589359, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-66  lr=['0.0030669'], tr/val_loss:  0.000640/  2.597599, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-67  lr=['0.0029054'], tr/val_loss:  0.000656/  2.595248, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-68  lr=['0.0027469'], tr/val_loss:  0.000658/  2.602346, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-69  lr=['0.0025915'], tr/val_loss:  0.000607/  2.604822, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-70  lr=['0.0024394'], tr/val_loss:  0.000588/  2.604900, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-71  lr=['0.0022908'], tr/val_loss:  0.000587/  2.607429, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-72  lr=['0.0021457'], tr/val_loss:  0.000589/  2.611379, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-73  lr=['0.0020043'], tr/val_loss:  0.000601/  2.617173, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-74  lr=['0.0018668'], tr/val_loss:  0.000591/  2.616826, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-75  lr=['0.0017333'], tr/val_loss:  0.000575/  2.618893, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-76  lr=['0.0016039'], tr/val_loss:  0.000568/  2.620089, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-77  lr=['0.0014788'], tr/val_loss:  0.000576/  2.610970, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-78  lr=['0.0013581'], tr/val_loss:  0.000559/  2.614378, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-79  lr=['0.0012418'], tr/val_loss:  0.000576/  2.607944, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-80  lr=['0.0011302'], tr/val_loss:  0.000576/  2.613464, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-81  lr=['0.0010233'], tr/val_loss:  0.000589/  2.611060, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-82  lr=['0.0009212'], tr/val_loss:  0.000576/  2.613413, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-83  lr=['0.0008241'], tr/val_loss:  0.000580/  2.611224, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-84  lr=['0.0007320'], tr/val_loss:  0.000576/  2.615979, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-85  lr=['0.0006450'], tr/val_loss:  0.000573/  2.615601, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-86  lr=['0.0005632'], tr/val_loss:  0.000570/  2.622795, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-87  lr=['0.0004867'], tr/val_loss:  0.000579/  2.618069, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-88  lr=['0.0004156'], tr/val_loss:  0.000578/  2.617841, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-89  lr=['0.0003499'], tr/val_loss:  0.000575/  2.620696, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-90  lr=['0.0002896'], tr/val_loss:  0.000573/  2.622036, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-91  lr=['0.0002350'], tr/val_loss:  0.000585/  2.620515, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-92  lr=['0.0001859'], tr/val_loss:  0.000568/  2.621188, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-93  lr=['0.0001425'], tr/val_loss:  0.000580/  2.622399, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-94  lr=['0.0001048'], tr/val_loss:  0.000583/  2.622623, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-95  lr=['0.0000729'], tr/val_loss:  0.000567/  2.622512, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-96  lr=['0.0000467'], tr/val_loss:  0.000565/  2.622393, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-97  lr=['0.0000263'], tr/val_loss:  0.000557/  2.622736, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-98  lr=['0.0000117'], tr/val_loss:  0.000566/  2.622984, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-99  lr=['0.0000029'], tr/val_loss:  0.000555/  2.622983, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b063f3f5bea24359926b316c1031543b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▃▅███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▃▆▆▇▆▇▇▇▇▇██▇████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▃▆▆▇▆▇▇▇▇▇██▇████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▃▂▃▂▄▄▅▆▆▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00056</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.62298</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resilient-sweep-72</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ex7ax8tx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ex7ax8tx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_154751-ex7ax8tx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2qkjo83k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011236249932367636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.4498087055317881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.2762110293751932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_155655-2qkjo83k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2qkjo83k' target=\"_blank\">hopeful-sweep-74</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2qkjo83k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2qkjo83k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0011236'], tr/val_loss:  2.304944/  2.302546, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.12it/s]\n",
      "epoch-1   lr=['0.0011233'], tr/val_loss:  2.304520/  2.300482, tr:   8.07%, val:  11.25%, val_best:  11.25%: 100%|██████████| 62/62 [00:04<00:00, 13.22it/s]\n",
      "epoch-2   lr=['0.0011225'], tr/val_loss:  2.281651/  2.233416, tr:  13.07%, val:  25.00%, val_best:  25.00%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-3   lr=['0.0011211'], tr/val_loss:  2.114351/  1.996240, tr:  28.70%, val:  36.25%, val_best:  36.25%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-4   lr=['0.0011192'], tr/val_loss:  1.806418/  1.752877, tr:  42.39%, val:  42.50%, val_best:  42.50%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-5   lr=['0.0011167'], tr/val_loss:  1.553693/  1.594193, tr:  51.17%, val:  45.42%, val_best:  45.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-6   lr=['0.0011137'], tr/val_loss:  1.409771/  1.533484, tr:  55.36%, val:  49.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-7   lr=['0.0011101'], tr/val_loss:  1.324518/  1.455663, tr:  60.16%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-8   lr=['0.0011060'], tr/val_loss:  1.245271/  1.394549, tr:  57.92%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-9   lr=['0.0011013'], tr/val_loss:  1.188129/  1.377279, tr:  64.66%, val:  54.17%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-10  lr=['0.0010961'], tr/val_loss:  1.155344/  1.334699, tr:  62.82%, val:  54.17%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-11  lr=['0.0010904'], tr/val_loss:  1.116857/  1.326860, tr:  65.07%, val:  55.42%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-12  lr=['0.0010842'], tr/val_loss:  1.087255/  1.279316, tr:  64.86%, val:  55.42%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-13  lr=['0.0010774'], tr/val_loss:  1.048430/  1.260579, tr:  66.19%, val:  57.08%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-14  lr=['0.0010702'], tr/val_loss:  1.034820/  1.248410, tr:  66.09%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-15  lr=['0.0010624'], tr/val_loss:  1.011584/  1.226922, tr:  67.72%, val:  57.50%, val_best:  59.17%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-16  lr=['0.0010541'], tr/val_loss:  0.990897/  1.231906, tr:  69.56%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-17  lr=['0.0010454'], tr/val_loss:  0.968177/  1.216560, tr:  71.81%, val:  57.08%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-18  lr=['0.0010362'], tr/val_loss:  0.950837/  1.194571, tr:  69.77%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-19  lr=['0.0010265'], tr/val_loss:  0.932445/  1.187803, tr:  71.60%, val:  60.42%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-20  lr=['0.0010163'], tr/val_loss:  0.904355/  1.193907, tr:  72.42%, val:  62.08%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-21  lr=['0.0010057'], tr/val_loss:  0.903918/  1.187435, tr:  73.65%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-22  lr=['0.0009947'], tr/val_loss:  0.879345/  1.161710, tr:  74.46%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-23  lr=['0.0009832'], tr/val_loss:  0.860897/  1.167269, tr:  75.08%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-24  lr=['0.0009714'], tr/val_loss:  0.853285/  1.198404, tr:  75.79%, val:  60.00%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-25  lr=['0.0009591'], tr/val_loss:  0.848701/  1.174376, tr:  74.87%, val:  63.33%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-26  lr=['0.0009464'], tr/val_loss:  0.826990/  1.159599, tr:  77.32%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-27  lr=['0.0009333'], tr/val_loss:  0.814279/  1.144987, tr:  77.94%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-28  lr=['0.0009199'], tr/val_loss:  0.805765/  1.164099, tr:  77.32%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-29  lr=['0.0009062'], tr/val_loss:  0.797549/  1.155598, tr:  78.55%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-30  lr=['0.0008920'], tr/val_loss:  0.776001/  1.152143, tr:  80.80%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-31  lr=['0.0008776'], tr/val_loss:  0.765845/  1.141033, tr:  80.59%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-32  lr=['0.0008628'], tr/val_loss:  0.766166/  1.163974, tr:  79.78%, val:  64.58%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-33  lr=['0.0008478'], tr/val_loss:  0.747639/  1.148504, tr:  81.92%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-34  lr=['0.0008325'], tr/val_loss:  0.745147/  1.147297, tr:  82.23%, val:  70.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-35  lr=['0.0008169'], tr/val_loss:  0.737671/  1.144530, tr:  84.07%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-36  lr=['0.0008010'], tr/val_loss:  0.732213/  1.156791, tr:  83.66%, val:  68.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-37  lr=['0.0007849'], tr/val_loss:  0.714972/  1.150661, tr:  81.51%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-38  lr=['0.0007686'], tr/val_loss:  0.701049/  1.178443, tr:  84.98%, val:  67.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n",
      "epoch-39  lr=['0.0007521'], tr/val_loss:  0.699877/  1.169013, tr:  85.19%, val:  65.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-40  lr=['0.0007354'], tr/val_loss:  0.689547/  1.152061, tr:  82.64%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-41  lr=['0.0007186'], tr/val_loss:  0.679583/  1.176118, tr:  85.70%, val:  68.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-42  lr=['0.0007015'], tr/val_loss:  0.663384/  1.171747, tr:  87.54%, val:  69.58%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-43  lr=['0.0006844'], tr/val_loss:  0.661162/  1.172863, tr:  88.25%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-44  lr=['0.0006671'], tr/val_loss:  0.654221/  1.167671, tr:  87.03%, val:  70.42%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-45  lr=['0.0006497'], tr/val_loss:  0.642711/  1.189472, tr:  88.46%, val:  67.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-46  lr=['0.0006322'], tr/val_loss:  0.641047/  1.188205, tr:  87.84%, val:  70.00%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-47  lr=['0.0006147'], tr/val_loss:  0.633677/  1.175078, tr:  89.38%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-48  lr=['0.0005971'], tr/val_loss:  0.629216/  1.182046, tr:  90.09%, val:  69.58%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-49  lr=['0.0005795'], tr/val_loss:  0.617242/  1.172882, tr:  89.68%, val:  69.58%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-50  lr=['0.0005618'], tr/val_loss:  0.615384/  1.180191, tr:  89.68%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-51  lr=['0.0005442'], tr/val_loss:  0.605607/  1.188341, tr:  91.42%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-52  lr=['0.0005265'], tr/val_loss:  0.598761/  1.203897, tr:  91.62%, val:  69.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-53  lr=['0.0005089'], tr/val_loss:  0.592580/  1.185408, tr:  92.03%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-54  lr=['0.0004914'], tr/val_loss:  0.586109/  1.189103, tr:  92.34%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-55  lr=['0.0004739'], tr/val_loss:  0.575833/  1.187139, tr:  93.26%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-56  lr=['0.0004565'], tr/val_loss:  0.576382/  1.201849, tr:  92.13%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-57  lr=['0.0004393'], tr/val_loss:  0.572113/  1.197710, tr:  91.01%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-58  lr=['0.0004221'], tr/val_loss:  0.560902/  1.204853, tr:  92.54%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-59  lr=['0.0004051'], tr/val_loss:  0.560425/  1.196474, tr:  93.16%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-60  lr=['0.0003882'], tr/val_loss:  0.556138/  1.207481, tr:  94.89%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-61  lr=['0.0003715'], tr/val_loss:  0.561594/  1.215105, tr:  94.59%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-62  lr=['0.0003550'], tr/val_loss:  0.547409/  1.207333, tr:  94.79%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-63  lr=['0.0003387'], tr/val_loss:  0.548729/  1.212945, tr:  94.99%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-64  lr=['0.0003226'], tr/val_loss:  0.537269/  1.219093, tr:  94.48%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-65  lr=['0.0003068'], tr/val_loss:  0.530781/  1.214572, tr:  95.61%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-66  lr=['0.0002912'], tr/val_loss:  0.529020/  1.217671, tr:  95.71%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-67  lr=['0.0002758'], tr/val_loss:  0.534839/  1.224458, tr:  94.59%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-68  lr=['0.0002608'], tr/val_loss:  0.525530/  1.231328, tr:  94.69%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-69  lr=['0.0002460'], tr/val_loss:  0.520036/  1.229584, tr:  95.20%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-70  lr=['0.0002316'], tr/val_loss:  0.515620/  1.223651, tr:  95.91%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-71  lr=['0.0002175'], tr/val_loss:  0.519343/  1.228135, tr:  96.53%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-72  lr=['0.0002037'], tr/val_loss:  0.510666/  1.228309, tr:  96.02%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-73  lr=['0.0001903'], tr/val_loss:  0.521371/  1.229001, tr:  96.32%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-74  lr=['0.0001772'], tr/val_loss:  0.506533/  1.233436, tr:  96.12%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-75  lr=['0.0001646'], tr/val_loss:  0.500321/  1.243339, tr:  97.04%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-76  lr=['0.0001523'], tr/val_loss:  0.505049/  1.231373, tr:  96.63%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-77  lr=['0.0001404'], tr/val_loss:  0.498904/  1.228246, tr:  97.24%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-78  lr=['0.0001289'], tr/val_loss:  0.498713/  1.236349, tr:  97.14%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-79  lr=['0.0001179'], tr/val_loss:  0.495733/  1.236591, tr:  96.73%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-80  lr=['0.0001073'], tr/val_loss:  0.491533/  1.242330, tr:  96.63%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-81  lr=['0.0000971'], tr/val_loss:  0.492925/  1.243683, tr:  96.94%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-82  lr=['0.0000875'], tr/val_loss:  0.495984/  1.245622, tr:  96.63%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-83  lr=['0.0000782'], tr/val_loss:  0.494503/  1.245851, tr:  97.04%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-84  lr=['0.0000695'], tr/val_loss:  0.488065/  1.240372, tr:  96.73%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-85  lr=['0.0000612'], tr/val_loss:  0.486355/  1.244142, tr:  97.24%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-86  lr=['0.0000535'], tr/val_loss:  0.487836/  1.243368, tr:  97.34%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-87  lr=['0.0000462'], tr/val_loss:  0.488840/  1.242252, tr:  97.34%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-88  lr=['0.0000395'], tr/val_loss:  0.487755/  1.245694, tr:  97.24%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-89  lr=['0.0000332'], tr/val_loss:  0.488791/  1.246449, tr:  97.55%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:08<00:00,  7.44it/s]\n",
      "epoch-90  lr=['0.0000275'], tr/val_loss:  0.488990/  1.243201, tr:  97.34%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-91  lr=['0.0000223'], tr/val_loss:  0.491899/  1.242068, tr:  97.45%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-92  lr=['0.0000177'], tr/val_loss:  0.486043/  1.241092, tr:  97.45%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-93  lr=['0.0000135'], tr/val_loss:  0.487918/  1.241439, tr:  97.45%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-94  lr=['0.0000100'], tr/val_loss:  0.493805/  1.243728, tr:  97.34%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-95  lr=['0.0000069'], tr/val_loss:  0.487379/  1.242185, tr:  97.45%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-96  lr=['0.0000044'], tr/val_loss:  0.482937/  1.242907, tr:  97.34%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-97  lr=['0.0000025'], tr/val_loss:  0.484477/  1.242749, tr:  97.45%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-98  lr=['0.0000011'], tr/val_loss:  0.489021/  1.242559, tr:  97.45%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-99  lr=['0.0000003'], tr/val_loss:  0.484344/  1.243009, tr:  97.45%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f12e3d0e4cb47368b8cf99b8fdba674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▅▅▆▆▅▆▇▇▆▆▆█▇▆▆███▆████▇████▇█▇███████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▆▆▆▆▇▇▆▇▇▇██▇▇██▇▇██████████████████</td></tr><tr><td>tr_acc</td><td>▁▁▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▆▆▆▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▆▆▆▆▇▇▆▇▇▇██▇▇██▇▇██████████████████</td></tr><tr><td>val_loss</td><td>██▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.97446</td></tr><tr><td>tr_epoch_loss</td><td>0.48434</td></tr><tr><td>val_acc_best</td><td>0.74167</td></tr><tr><td>val_acc_now</td><td>0.73333</td></tr><tr><td>val_loss</td><td>1.24301</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-sweep-74</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2qkjo83k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2qkjo83k</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_155655-2qkjo83k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 38vjkdok with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.013681616315671411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.4498778218074741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.90556606503759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_160600-38vjkdok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/38vjkdok' target=\"_blank\">worthy-sweep-76</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/38vjkdok' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/38vjkdok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0136816'], tr/val_loss:  2.218908/  1.838247, tr:  15.22%, val:  35.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-1   lr=['0.0136782'], tr/val_loss:  1.456859/  1.450395, tr:  48.62%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-2   lr=['0.0136681'], tr/val_loss:  1.202967/  1.213923, tr:  57.51%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-3   lr=['0.0136513'], tr/val_loss:  1.023791/  1.206973, tr:  65.88%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 13.06it/s]\n",
      "epoch-4   lr=['0.0136277'], tr/val_loss:  0.991260/  1.186244, tr:  66.60%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:04<00:00, 13.10it/s]\n",
      "epoch-5   lr=['0.0135974'], tr/val_loss:  0.922581/  1.344257, tr:  67.62%, val:  59.17%, val_best:  62.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-6   lr=['0.0135604'], tr/val_loss:  0.839302/  1.250219, tr:  69.77%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-7   lr=['0.0135169'], tr/val_loss:  0.769110/  1.311240, tr:  74.16%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-8   lr=['0.0134667'], tr/val_loss:  0.707167/  1.199346, tr:  76.71%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-9   lr=['0.0134100'], tr/val_loss:  0.609865/  1.357710, tr:  77.94%, val:  61.25%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-10  lr=['0.0133468'], tr/val_loss:  0.568523/  1.367779, tr:  82.12%, val:  66.67%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-11  lr=['0.0132772'], tr/val_loss:  0.525545/  1.398125, tr:  82.02%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-12  lr=['0.0132012'], tr/val_loss:  0.503167/  1.341595, tr:  86.21%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-13  lr=['0.0131190'], tr/val_loss:  0.407273/  1.414767, tr:  89.89%, val:  67.50%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-14  lr=['0.0130306'], tr/val_loss:  0.364113/  1.372893, tr:  91.73%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-15  lr=['0.0129360'], tr/val_loss:  0.385845/  1.436668, tr:  90.09%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-16  lr=['0.0128355'], tr/val_loss:  0.335184/  1.958421, tr:  92.95%, val:  67.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]\n",
      "epoch-17  lr=['0.0127290'], tr/val_loss:  0.460068/  1.615125, tr:  90.40%, val:  60.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-18  lr=['0.0126167'], tr/val_loss:  0.378028/  1.454428, tr:  90.91%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-19  lr=['0.0124987'], tr/val_loss:  0.275357/  1.507196, tr:  95.30%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-20  lr=['0.0123751'], tr/val_loss:  0.237267/  1.560143, tr:  96.22%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-21  lr=['0.0122461'], tr/val_loss:  0.174279/  1.751987, tr:  98.77%, val:  71.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.20it/s]\n",
      "epoch-22  lr=['0.0121117'], tr/val_loss:  0.192355/  1.653129, tr:  97.04%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-23  lr=['0.0119722'], tr/val_loss:  0.164887/  1.679926, tr:  97.34%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.06it/s]\n",
      "epoch-24  lr=['0.0118275'], tr/val_loss:  0.142423/  1.811932, tr:  98.77%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-25  lr=['0.0116780'], tr/val_loss:  0.111388/  1.819377, tr:  99.59%, val:  71.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-26  lr=['0.0115237'], tr/val_loss:  0.105894/  1.851207, tr:  99.49%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-27  lr=['0.0113647'], tr/val_loss:  0.073294/  1.890858, tr:  99.80%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-28  lr=['0.0112013'], tr/val_loss:  0.055434/  1.981129, tr:  99.90%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-29  lr=['0.0110336'], tr/val_loss:  0.048445/  2.056015, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-30  lr=['0.0108617'], tr/val_loss:  0.043145/  2.099902, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-31  lr=['0.0106859'], tr/val_loss:  0.035623/  2.158173, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-32  lr=['0.0105063'], tr/val_loss:  0.029697/  2.263687, tr:  99.90%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-33  lr=['0.0103231'], tr/val_loss:  0.024462/  2.264967, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-34  lr=['0.0101364'], tr/val_loss:  0.015756/  2.272677, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-35  lr=['0.0099465'], tr/val_loss:  0.012334/  2.338031, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-36  lr=['0.0097535'], tr/val_loss:  0.009297/  2.393170, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-37  lr=['0.0095576'], tr/val_loss:  0.007796/  2.415523, tr: 100.00%, val:  73.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-38  lr=['0.0093591'], tr/val_loss:  0.007996/  2.496594, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-39  lr=['0.0091580'], tr/val_loss:  0.006680/  2.500714, tr: 100.00%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-40  lr=['0.0089547'], tr/val_loss:  0.005714/  2.489647, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-41  lr=['0.0087493'], tr/val_loss:  0.005613/  2.534333, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-42  lr=['0.0085420'], tr/val_loss:  0.004861/  2.554743, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-43  lr=['0.0083331'], tr/val_loss:  0.004057/  2.535226, tr: 100.00%, val:  75.42%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.22it/s]\n",
      "epoch-44  lr=['0.0081226'], tr/val_loss:  0.003348/  2.564008, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-45  lr=['0.0079109'], tr/val_loss:  0.003791/  2.594425, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-46  lr=['0.0076982'], tr/val_loss:  0.003158/  2.592685, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-47  lr=['0.0074846'], tr/val_loss:  0.002899/  2.590547, tr: 100.00%, val:  75.00%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-48  lr=['0.0072703'], tr/val_loss:  0.002478/  2.621378, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-49  lr=['0.0070557'], tr/val_loss:  0.002449/  2.630790, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-50  lr=['0.0068408'], tr/val_loss:  0.002568/  2.635186, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-51  lr=['0.0066259'], tr/val_loss:  0.002547/  2.662466, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-52  lr=['0.0064113'], tr/val_loss:  0.002349/  2.646793, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-53  lr=['0.0061970'], tr/val_loss:  0.002065/  2.652582, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-54  lr=['0.0059834'], tr/val_loss:  0.002681/  2.680978, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-55  lr=['0.0057707'], tr/val_loss:  0.002209/  2.661772, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-56  lr=['0.0055590'], tr/val_loss:  0.002199/  2.674039, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-57  lr=['0.0053485'], tr/val_loss:  0.002002/  2.660120, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-58  lr=['0.0051396'], tr/val_loss:  0.001709/  2.680543, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-59  lr=['0.0049323'], tr/val_loss:  0.001963/  2.688760, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-60  lr=['0.0047269'], tr/val_loss:  0.001936/  2.686985, tr: 100.00%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-61  lr=['0.0045236'], tr/val_loss:  0.001659/  2.699635, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-62  lr=['0.0043225'], tr/val_loss:  0.001904/  2.708067, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-63  lr=['0.0041240'], tr/val_loss:  0.001699/  2.713085, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-64  lr=['0.0039281'], tr/val_loss:  0.001542/  2.707475, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-65  lr=['0.0037351'], tr/val_loss:  0.001570/  2.721596, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-66  lr=['0.0035452'], tr/val_loss:  0.001452/  2.719503, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-67  lr=['0.0033586'], tr/val_loss:  0.001435/  2.722500, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-68  lr=['0.0031753'], tr/val_loss:  0.001461/  2.717666, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-69  lr=['0.0029957'], tr/val_loss:  0.001392/  2.729581, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-70  lr=['0.0028199'], tr/val_loss:  0.001297/  2.719103, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-71  lr=['0.0026480'], tr/val_loss:  0.001312/  2.720810, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-72  lr=['0.0024803'], tr/val_loss:  0.001253/  2.725107, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-73  lr=['0.0023169'], tr/val_loss:  0.001518/  2.753504, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-74  lr=['0.0021580'], tr/val_loss:  0.001350/  2.743277, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-75  lr=['0.0020036'], tr/val_loss:  0.001240/  2.734341, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-76  lr=['0.0018541'], tr/val_loss:  0.001266/  2.739690, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-77  lr=['0.0017094'], tr/val_loss:  0.001272/  2.740918, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-78  lr=['0.0015699'], tr/val_loss:  0.001297/  2.744963, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.16it/s]\n",
      "epoch-79  lr=['0.0014355'], tr/val_loss:  0.001303/  2.757323, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-80  lr=['0.0013065'], tr/val_loss:  0.001254/  2.757806, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-81  lr=['0.0011829'], tr/val_loss:  0.001204/  2.759695, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-82  lr=['0.0010649'], tr/val_loss:  0.001191/  2.758698, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-83  lr=['0.0009526'], tr/val_loss:  0.001198/  2.749230, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-84  lr=['0.0008462'], tr/val_loss:  0.001200/  2.752276, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-85  lr=['0.0007456'], tr/val_loss:  0.001211/  2.747805, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-86  lr=['0.0006511'], tr/val_loss:  0.001205/  2.750338, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-87  lr=['0.0005626'], tr/val_loss:  0.001203/  2.749605, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-88  lr=['0.0004804'], tr/val_loss:  0.001234/  2.752622, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-89  lr=['0.0004044'], tr/val_loss:  0.001199/  2.746542, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-90  lr=['0.0003348'], tr/val_loss:  0.001201/  2.747759, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-91  lr=['0.0002716'], tr/val_loss:  0.001226/  2.749126, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-92  lr=['0.0002149'], tr/val_loss:  0.001186/  2.748755, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-93  lr=['0.0001647'], tr/val_loss:  0.001193/  2.746311, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-94  lr=['0.0001212'], tr/val_loss:  0.001207/  2.746542, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-95  lr=['0.0000842'], tr/val_loss:  0.001230/  2.744061, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-96  lr=['0.0000539'], tr/val_loss:  0.001173/  2.746562, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-97  lr=['0.0000304'], tr/val_loss:  0.001145/  2.746555, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-98  lr=['0.0000135'], tr/val_loss:  0.001188/  2.746562, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-99  lr=['0.0000034'], tr/val_loss:  0.001156/  2.746562, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c3214abdc24cc4b50fb8e75bb3a247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▅▃▅▆▇▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▅▇▇▅█▇▇▇███▇███▇████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▅▇▇▅█▇▇▇███▇███▇████████████████████</td></tr><tr><td>val_loss</td><td>▄▁▁▂▂▂▂▃▂▄▄▄▅▆▆▆▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00116</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>2.74656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-76</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/38vjkdok' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/38vjkdok</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_160600-38vjkdok/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vf5y7pgd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.021322993296360785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.8239855699325174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6952974275107229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_161445-vf5y7pgd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5y7pgd' target=\"_blank\">peach-sweep-78</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5y7pgd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5y7pgd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0213230'], tr/val_loss:  1.835143/  1.502764, tr:  33.71%, val:  46.25%, val_best:  46.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-1   lr=['0.0213177'], tr/val_loss:  1.322695/  1.355373, tr:  53.73%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-2   lr=['0.0213020'], tr/val_loss:  1.057217/  1.702772, tr:  63.84%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 13.09it/s]\n",
      "epoch-3   lr=['0.0212757'], tr/val_loss:  0.960312/  1.457647, tr:  67.52%, val:  51.67%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 13.42it/s]\n",
      "epoch-4   lr=['0.0212389'], tr/val_loss:  0.878476/  1.305660, tr:  68.64%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-5   lr=['0.0211917'], tr/val_loss:  0.834534/  1.459587, tr:  72.52%, val:  52.92%, val_best:  59.58%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-6   lr=['0.0211341'], tr/val_loss:  0.747919/  1.542235, tr:  73.75%, val:  58.75%, val_best:  59.58%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-7   lr=['0.0210662'], tr/val_loss:  0.775776/  1.551738, tr:  72.42%, val:  56.25%, val_best:  59.58%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-8   lr=['0.0209880'], tr/val_loss:  0.720833/  1.484577, tr:  74.36%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-9   lr=['0.0208997'], tr/val_loss:  0.554605/  1.387346, tr:  81.10%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-10  lr=['0.0208012'], tr/val_loss:  0.468556/  1.770922, tr:  86.21%, val:  61.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-11  lr=['0.0206927'], tr/val_loss:  0.465132/  1.475082, tr:  86.52%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-12  lr=['0.0205743'], tr/val_loss:  0.350136/  1.568491, tr:  91.01%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-13  lr=['0.0204461'], tr/val_loss:  0.299475/  1.654588, tr:  91.73%, val:  69.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-14  lr=['0.0203083'], tr/val_loss:  0.290005/  1.509971, tr:  93.67%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-15  lr=['0.0201610'], tr/val_loss:  0.275063/  1.693919, tr:  91.83%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-16  lr=['0.0200042'], tr/val_loss:  0.179272/  1.802640, tr:  96.83%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-17  lr=['0.0198383'], tr/val_loss:  0.194782/  1.657981, tr:  94.89%, val:  73.75%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-18  lr=['0.0196633'], tr/val_loss:  0.133575/  1.850981, tr:  98.06%, val:  74.17%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-19  lr=['0.0194794'], tr/val_loss:  0.099588/  1.928295, tr:  99.08%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-20  lr=['0.0192868'], tr/val_loss:  0.056884/  2.031290, tr:  99.90%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-21  lr=['0.0190857'], tr/val_loss:  0.021331/  2.103301, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-22  lr=['0.0188763'], tr/val_loss:  0.010272/  2.164154, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-23  lr=['0.0186588'], tr/val_loss:  0.009262/  2.224946, tr: 100.00%, val:  77.50%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-24  lr=['0.0184334'], tr/val_loss:  0.004668/  2.189561, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-25  lr=['0.0182003'], tr/val_loss:  0.003023/  2.275475, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-26  lr=['0.0179598'], tr/val_loss:  0.002161/  2.282706, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-27  lr=['0.0177121'], tr/val_loss:  0.001820/  2.286640, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-28  lr=['0.0174574'], tr/val_loss:  0.001816/  2.317220, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-29  lr=['0.0171960'], tr/val_loss:  0.001439/  2.348670, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-30  lr=['0.0169282'], tr/val_loss:  0.001032/  2.383318, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-31  lr=['0.0166541'], tr/val_loss:  0.000774/  2.379343, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-32  lr=['0.0163742'], tr/val_loss:  0.000758/  2.423887, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-33  lr=['0.0160886'], tr/val_loss:  0.000653/  2.409231, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-34  lr=['0.0157977'], tr/val_loss:  0.000594/  2.415125, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-35  lr=['0.0155017'], tr/val_loss:  0.000571/  2.428839, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-36  lr=['0.0152009'], tr/val_loss:  0.000524/  2.439523, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.03it/s]\n",
      "epoch-37  lr=['0.0148957'], tr/val_loss:  0.000519/  2.441087, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-38  lr=['0.0145863'], tr/val_loss:  0.000476/  2.443557, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-39  lr=['0.0142729'], tr/val_loss:  0.000440/  2.453794, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-40  lr=['0.0139561'], tr/val_loss:  0.000441/  2.457802, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-41  lr=['0.0136360'], tr/val_loss:  0.000405/  2.474885, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-42  lr=['0.0133129'], tr/val_loss:  0.000406/  2.464041, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-43  lr=['0.0129872'], tr/val_loss:  0.000376/  2.464501, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-44  lr=['0.0126593'], tr/val_loss:  0.000363/  2.475904, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-45  lr=['0.0123293'], tr/val_loss:  0.000363/  2.480078, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-46  lr=['0.0119977'], tr/val_loss:  0.000354/  2.490996, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-47  lr=['0.0116648'], tr/val_loss:  0.000351/  2.490214, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-48  lr=['0.0113309'], tr/val_loss:  0.000337/  2.498393, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-49  lr=['0.0109964'], tr/val_loss:  0.000320/  2.503045, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-50  lr=['0.0106615'], tr/val_loss:  0.000318/  2.513309, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-51  lr=['0.0103266'], tr/val_loss:  0.000324/  2.512026, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-52  lr=['0.0099921'], tr/val_loss:  0.000308/  2.520252, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-53  lr=['0.0096582'], tr/val_loss:  0.000299/  2.525596, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-54  lr=['0.0093253'], tr/val_loss:  0.000304/  2.522042, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-55  lr=['0.0089937'], tr/val_loss:  0.000293/  2.527725, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-56  lr=['0.0086637'], tr/val_loss:  0.000285/  2.534491, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-57  lr=['0.0083358'], tr/val_loss:  0.000285/  2.534571, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-58  lr=['0.0080101'], tr/val_loss:  0.000292/  2.533840, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-59  lr=['0.0076870'], tr/val_loss:  0.000287/  2.533629, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-60  lr=['0.0073669'], tr/val_loss:  0.000290/  2.535337, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-61  lr=['0.0070500'], tr/val_loss:  0.000285/  2.531613, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-62  lr=['0.0067367'], tr/val_loss:  0.000271/  2.544556, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-63  lr=['0.0064273'], tr/val_loss:  0.000273/  2.544147, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-64  lr=['0.0061221'], tr/val_loss:  0.000267/  2.551293, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-65  lr=['0.0058213'], tr/val_loss:  0.000257/  2.553262, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-66  lr=['0.0055253'], tr/val_loss:  0.000261/  2.548543, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-67  lr=['0.0052344'], tr/val_loss:  0.000253/  2.558187, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-68  lr=['0.0049488'], tr/val_loss:  0.000249/  2.559904, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-69  lr=['0.0046688'], tr/val_loss:  0.000248/  2.559712, tr: 100.00%, val:  78.33%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-70  lr=['0.0043948'], tr/val_loss:  0.000254/  2.559592, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-71  lr=['0.0041270'], tr/val_loss:  0.000255/  2.560625, tr: 100.00%, val:  78.33%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-72  lr=['0.0038656'], tr/val_loss:  0.000253/  2.562707, tr: 100.00%, val:  78.33%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-73  lr=['0.0036109'], tr/val_loss:  0.000259/  2.562039, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-74  lr=['0.0033632'], tr/val_loss:  0.000244/  2.560991, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-75  lr=['0.0031227'], tr/val_loss:  0.000241/  2.564002, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-76  lr=['0.0028896'], tr/val_loss:  0.000246/  2.565675, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-77  lr=['0.0026642'], tr/val_loss:  0.000249/  2.561299, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-78  lr=['0.0024467'], tr/val_loss:  0.000243/  2.562670, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-79  lr=['0.0022373'], tr/val_loss:  0.000235/  2.561450, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-80  lr=['0.0020362'], tr/val_loss:  0.000237/  2.562315, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-81  lr=['0.0018436'], tr/val_loss:  0.000230/  2.562591, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-82  lr=['0.0016597'], tr/val_loss:  0.000228/  2.559934, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-83  lr=['0.0014847'], tr/val_loss:  0.000228/  2.559445, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-84  lr=['0.0013188'], tr/val_loss:  0.000224/  2.561946, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-85  lr=['0.0011620'], tr/val_loss:  0.000225/  2.567439, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-86  lr=['0.0010147'], tr/val_loss:  0.000227/  2.566600, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-87  lr=['0.0008769'], tr/val_loss:  0.000226/  2.567257, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-88  lr=['0.0007487'], tr/val_loss:  0.000230/  2.569504, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-89  lr=['0.0006303'], tr/val_loss:  0.000227/  2.569244, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-90  lr=['0.0005218'], tr/val_loss:  0.000229/  2.571274, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-91  lr=['0.0004233'], tr/val_loss:  0.000229/  2.571595, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-92  lr=['0.0003350'], tr/val_loss:  0.000227/  2.572085, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-93  lr=['0.0002568'], tr/val_loss:  0.000233/  2.572251, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-94  lr=['0.0001888'], tr/val_loss:  0.000228/  2.572404, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-95  lr=['0.0001313'], tr/val_loss:  0.000227/  2.572113, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-96  lr=['0.0000841'], tr/val_loss:  0.000225/  2.572308, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-97  lr=['0.0000473'], tr/val_loss:  0.000221/  2.572316, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-98  lr=['0.0000210'], tr/val_loss:  0.000240/  2.573194, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-99  lr=['0.0000053'], tr/val_loss:  0.000221/  2.573195, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8e014fb968423695f10f538e9fee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▆▃▆▆▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▃▅▇▇▇▇████████████████████▇██████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▅▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▃▅▇▇▇▇████████████████████▇██████████</td></tr><tr><td>val_loss</td><td>▂▃▁▂▁▂▂▃▄▅▆▆▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00022</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.57319</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sweep-78</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5y7pgd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5y7pgd</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_161445-vf5y7pgd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jzthewj6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01191837059397274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.7579600044410252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.7451408481886974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_162343-jzthewj6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzthewj6' target=\"_blank\">earnest-sweep-80</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzthewj6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzthewj6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0119184'], tr/val_loss:  1.996589/  1.516866, tr:  26.25%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-1   lr=['0.0119154'], tr/val_loss:  1.328093/  1.437187, tr:  53.73%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-2   lr=['0.0119066'], tr/val_loss:  1.071100/  1.218737, tr:  63.53%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-3   lr=['0.0118919'], tr/val_loss:  0.931112/  1.246378, tr:  67.31%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.51it/s]\n",
      "epoch-4   lr=['0.0118714'], tr/val_loss:  0.832609/  1.189469, tr:  71.50%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 13.22it/s]\n",
      "epoch-5   lr=['0.0118450'], tr/val_loss:  0.743562/  1.224527, tr:  73.75%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:04<00:00, 13.56it/s]\n",
      "epoch-6   lr=['0.0118128'], tr/val_loss:  0.687107/  1.283816, tr:  74.87%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 13.33it/s]\n",
      "epoch-7   lr=['0.0117749'], tr/val_loss:  0.668616/  1.554872, tr:  76.71%, val:  55.42%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-8   lr=['0.0117312'], tr/val_loss:  0.642105/  1.259539, tr:  78.86%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-9   lr=['0.0116818'], tr/val_loss:  0.482435/  1.362605, tr:  85.60%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-10  lr=['0.0116267'], tr/val_loss:  0.391991/  1.480120, tr:  90.91%, val:  69.17%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-11  lr=['0.0115661'], tr/val_loss:  0.316527/  1.544023, tr:  92.95%, val:  67.92%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-12  lr=['0.0114999'], tr/val_loss:  0.295071/  1.517927, tr:  94.79%, val:  72.08%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-13  lr=['0.0114283'], tr/val_loss:  0.278362/  1.480713, tr:  92.75%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-14  lr=['0.0113512'], tr/val_loss:  0.191342/  1.524303, tr:  96.73%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-15  lr=['0.0112689'], tr/val_loss:  0.215895/  1.531711, tr:  95.10%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-16  lr=['0.0111813'], tr/val_loss:  0.115271/  1.682321, tr:  99.28%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-17  lr=['0.0110885'], tr/val_loss:  0.098912/  1.716641, tr:  99.28%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-18  lr=['0.0109907'], tr/val_loss:  0.117960/  1.732589, tr:  99.18%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-19  lr=['0.0108879'], tr/val_loss:  0.077551/  1.811256, tr:  99.49%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-20  lr=['0.0107803'], tr/val_loss:  0.054386/  1.863853, tr:  99.80%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-21  lr=['0.0106679'], tr/val_loss:  0.021155/  1.971043, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-22  lr=['0.0105508'], tr/val_loss:  0.010902/  2.052450, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-23  lr=['0.0104292'], tr/val_loss:  0.009532/  2.083093, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-24  lr=['0.0103032'], tr/val_loss:  0.005611/  2.126501, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-25  lr=['0.0101730'], tr/val_loss:  0.005108/  2.156666, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-26  lr=['0.0100385'], tr/val_loss:  0.005005/  2.197651, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-27  lr=['0.0099001'], tr/val_loss:  0.008464/  2.199769, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-28  lr=['0.0097577'], tr/val_loss:  0.005224/  2.238091, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-29  lr=['0.0096116'], tr/val_loss:  0.002427/  2.280449, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-30  lr=['0.0094619'], tr/val_loss:  0.001935/  2.308167, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-31  lr=['0.0093087'], tr/val_loss:  0.001631/  2.308152, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-32  lr=['0.0091523'], tr/val_loss:  0.001456/  2.324232, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-33  lr=['0.0089927'], tr/val_loss:  0.001369/  2.311671, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 13.12it/s]\n",
      "epoch-34  lr=['0.0088300'], tr/val_loss:  0.001256/  2.325722, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.97it/s]\n",
      "epoch-35  lr=['0.0086646'], tr/val_loss:  0.001097/  2.335448, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n",
      "epoch-36  lr=['0.0084965'], tr/val_loss:  0.001138/  2.366272, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-37  lr=['0.0083259'], tr/val_loss:  0.001022/  2.373328, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-38  lr=['0.0081529'], tr/val_loss:  0.000980/  2.367490, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-39  lr=['0.0079778'], tr/val_loss:  0.000901/  2.397269, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-40  lr=['0.0078007'], tr/val_loss:  0.000857/  2.402194, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-41  lr=['0.0076217'], tr/val_loss:  0.000848/  2.403510, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-42  lr=['0.0074412'], tr/val_loss:  0.000827/  2.410584, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-43  lr=['0.0072591'], tr/val_loss:  0.000750/  2.413297, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-44  lr=['0.0070758'], tr/val_loss:  0.000721/  2.413692, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-45  lr=['0.0068914'], tr/val_loss:  0.000716/  2.423426, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-46  lr=['0.0067061'], tr/val_loss:  0.000695/  2.410941, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-47  lr=['0.0065200'], tr/val_loss:  0.000679/  2.422072, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-48  lr=['0.0063334'], tr/val_loss:  0.000649/  2.427576, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-49  lr=['0.0061464'], tr/val_loss:  0.000659/  2.425085, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-50  lr=['0.0059592'], tr/val_loss:  0.000620/  2.433765, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-51  lr=['0.0057720'], tr/val_loss:  0.000589/  2.431759, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 13.12it/s]\n",
      "epoch-52  lr=['0.0055850'], tr/val_loss:  0.000604/  2.445471, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-53  lr=['0.0053984'], tr/val_loss:  0.000581/  2.452634, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-54  lr=['0.0052123'], tr/val_loss:  0.000561/  2.456029, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-55  lr=['0.0050270'], tr/val_loss:  0.000563/  2.457941, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-56  lr=['0.0048425'], tr/val_loss:  0.000554/  2.452397, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-57  lr=['0.0046592'], tr/val_loss:  0.000541/  2.455847, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-58  lr=['0.0044772'], tr/val_loss:  0.000513/  2.470612, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-59  lr=['0.0042966'], tr/val_loss:  0.000514/  2.470113, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-60  lr=['0.0041177'], tr/val_loss:  0.000507/  2.470989, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-61  lr=['0.0039406'], tr/val_loss:  0.000512/  2.477353, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-62  lr=['0.0037655'], tr/val_loss:  0.000490/  2.474230, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-63  lr=['0.0035925'], tr/val_loss:  0.000516/  2.488441, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-64  lr=['0.0034219'], tr/val_loss:  0.000494/  2.492664, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-65  lr=['0.0032538'], tr/val_loss:  0.000505/  2.494878, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-66  lr=['0.0030883'], tr/val_loss:  0.000489/  2.499587, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-67  lr=['0.0029257'], tr/val_loss:  0.000486/  2.498242, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-68  lr=['0.0027661'], tr/val_loss:  0.000479/  2.494514, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  8.34it/s]\n",
      "epoch-69  lr=['0.0026096'], tr/val_loss:  0.000467/  2.492878, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-70  lr=['0.0024565'], tr/val_loss:  0.000473/  2.498011, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-71  lr=['0.0023068'], tr/val_loss:  0.000459/  2.493739, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-72  lr=['0.0021607'], tr/val_loss:  0.000454/  2.494112, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-73  lr=['0.0020183'], tr/val_loss:  0.000477/  2.502517, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-74  lr=['0.0018798'], tr/val_loss:  0.000464/  2.500115, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-75  lr=['0.0017454'], tr/val_loss:  0.000459/  2.494921, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-76  lr=['0.0016151'], tr/val_loss:  0.000454/  2.502135, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-77  lr=['0.0014891'], tr/val_loss:  0.000448/  2.500618, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-78  lr=['0.0013676'], tr/val_loss:  0.000450/  2.504546, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-79  lr=['0.0012505'], tr/val_loss:  0.000438/  2.502518, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-80  lr=['0.0011381'], tr/val_loss:  0.000427/  2.503867, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-81  lr=['0.0010305'], tr/val_loss:  0.000433/  2.503982, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-82  lr=['0.0009277'], tr/val_loss:  0.000430/  2.507156, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-83  lr=['0.0008299'], tr/val_loss:  0.000420/  2.507490, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-84  lr=['0.0007371'], tr/val_loss:  0.000423/  2.507518, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-85  lr=['0.0006495'], tr/val_loss:  0.000418/  2.505109, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-86  lr=['0.0005672'], tr/val_loss:  0.000432/  2.503796, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-87  lr=['0.0004901'], tr/val_loss:  0.000433/  2.502031, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-88  lr=['0.0004185'], tr/val_loss:  0.000420/  2.504941, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-89  lr=['0.0003523'], tr/val_loss:  0.000421/  2.505328, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-90  lr=['0.0002917'], tr/val_loss:  0.000425/  2.506174, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-91  lr=['0.0002366'], tr/val_loss:  0.000422/  2.505888, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-92  lr=['0.0001872'], tr/val_loss:  0.000417/  2.506571, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-93  lr=['0.0001435'], tr/val_loss:  0.000427/  2.504111, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-94  lr=['0.0001056'], tr/val_loss:  0.000421/  2.504085, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-95  lr=['0.0000734'], tr/val_loss:  0.000422/  2.505555, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  8.71it/s]\n",
      "epoch-96  lr=['0.0000470'], tr/val_loss:  0.000419/  2.505766, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-97  lr=['0.0000264'], tr/val_loss:  0.000420/  2.505775, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-98  lr=['0.0000118'], tr/val_loss:  0.000426/  2.505778, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-99  lr=['0.0000029'], tr/val_loss:  0.000416/  2.505778, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53f5743b1634d5fbbc4550501abb53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▅▅▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▃▆▆▇▇████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▆▆▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▃▆▆▇▇████████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▃▂▃▃▄▄▅▆▆▇▇▇▇▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00042</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.50578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-80</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzthewj6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzthewj6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_162343-jzthewj6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zyuurhsy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07904799657544233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.0656333847161497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.328907845980712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_163250-zyuurhsy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyuurhsy' target=\"_blank\">earthy-sweep-82</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyuurhsy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyuurhsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0790480'], tr/val_loss:  1.943988/  1.786457, tr:  32.89%, val:  34.17%, val_best:  34.17%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-1   lr=['0.0790285'], tr/val_loss:  1.690748/  1.801358, tr:  39.94%, val:  40.00%, val_best:  40.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-2   lr=['0.0789700'], tr/val_loss:  1.598008/  2.432189, tr:  43.41%, val:  36.25%, val_best:  40.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-3   lr=['0.0788726'], tr/val_loss:  1.718197/  1.699650, tr:  40.45%, val:  40.42%, val_best:  40.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-4   lr=['0.0787363'], tr/val_loss:  2.049946/  2.679651, tr:  39.73%, val:  33.33%, val_best:  40.42%: 100%|██████████| 62/62 [00:04<00:00, 13.16it/s]\n",
      "epoch-5   lr=['0.0785614'], tr/val_loss:  2.280027/  2.632388, tr:  35.04%, val:  33.75%, val_best:  40.42%: 100%|██████████| 62/62 [00:04<00:00, 13.63it/s]\n",
      "epoch-6   lr=['0.0783479'], tr/val_loss:  2.228752/  2.602917, tr:  36.57%, val:  38.75%, val_best:  40.42%: 100%|██████████| 62/62 [00:04<00:00, 13.72it/s]\n",
      "epoch-7   lr=['0.0780961'], tr/val_loss:  2.044755/  2.204203, tr:  38.00%, val:  30.42%, val_best:  40.42%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-8   lr=['0.0778063'], tr/val_loss:  2.220287/  2.464638, tr:  35.24%, val:  32.92%, val_best:  40.42%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-9   lr=['0.0774786'], tr/val_loss:  2.449966/  2.667820, tr:  36.06%, val:  42.92%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-10  lr=['0.0771136'], tr/val_loss:  2.259788/  2.871297, tr:  35.55%, val:  26.67%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-11  lr=['0.0767114'], tr/val_loss:  2.398611/  3.127717, tr:  32.38%, val:  33.75%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-12  lr=['0.0762725'], tr/val_loss:  2.279193/  2.433868, tr:  35.85%, val:  31.67%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-13  lr=['0.0757973'], tr/val_loss:  2.643219/  2.769319, tr:  34.83%, val:  35.83%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-14  lr=['0.0752864'], tr/val_loss:  2.558618/  2.209878, tr:  33.81%, val:  35.83%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-15  lr=['0.0747401'], tr/val_loss:  2.463771/  3.109783, tr:  36.77%, val:  31.67%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-16  lr=['0.0741591'], tr/val_loss:  2.388635/  2.294410, tr:  35.55%, val:  42.08%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-17  lr=['0.0735440'], tr/val_loss:  2.668001/  2.247270, tr:  36.77%, val:  35.00%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-18  lr=['0.0728952'], tr/val_loss:  2.499933/  2.479351, tr:  40.45%, val:  38.33%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-19  lr=['0.0722135'], tr/val_loss:  2.254197/  3.777792, tr:  39.12%, val:  35.83%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-20  lr=['0.0714996'], tr/val_loss:  2.690909/  2.912745, tr:  31.97%, val:  41.25%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-21  lr=['0.0707541'], tr/val_loss:  2.268932/  2.552680, tr:  39.53%, val:  33.75%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-22  lr=['0.0699778'], tr/val_loss:  2.196959/  2.214933, tr:  40.04%, val:  36.25%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-23  lr=['0.0691714'], tr/val_loss:  2.328345/  1.837351, tr:  40.45%, val:  44.17%, val_best:  44.17%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-24  lr=['0.0683358'], tr/val_loss:  2.030703/  2.131700, tr:  44.43%, val:  41.67%, val_best:  44.17%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-25  lr=['0.0674717'], tr/val_loss:  1.855831/  2.298931, tr:  43.62%, val:  45.00%, val_best:  45.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-26  lr=['0.0665800'], tr/val_loss:  2.242468/  2.087157, tr:  43.11%, val:  42.08%, val_best:  45.00%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-27  lr=['0.0656617'], tr/val_loss:  2.140458/  2.563044, tr:  41.98%, val:  46.67%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-28  lr=['0.0647175'], tr/val_loss:  2.156347/  2.549565, tr:  46.58%, val:  40.42%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-29  lr=['0.0637485'], tr/val_loss:  2.501314/  2.034348, tr:  41.37%, val:  45.00%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-30  lr=['0.0627556'], tr/val_loss:  1.963392/  2.113538, tr:  48.01%, val:  44.17%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-31  lr=['0.0617398'], tr/val_loss:  1.822926/  2.273409, tr:  48.52%, val:  40.42%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-32  lr=['0.0607020'], tr/val_loss:  1.991261/  2.174675, tr:  47.09%, val:  38.33%, val_best:  46.67%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-33  lr=['0.0596434'], tr/val_loss:  1.890532/  2.003386, tr:  44.94%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-34  lr=['0.0585648'], tr/val_loss:  1.820050/  2.146084, tr:  44.54%, val:  38.75%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-35  lr=['0.0574675'], tr/val_loss:  1.837513/  2.366804, tr:  46.88%, val:  33.75%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-36  lr=['0.0563525'], tr/val_loss:  2.370131/  3.523319, tr:  44.74%, val:  31.67%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-37  lr=['0.0552209'], tr/val_loss:  2.446120/  2.583211, tr:  42.80%, val:  46.25%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-38  lr=['0.0540738'], tr/val_loss:  1.837196/  1.986197, tr:  48.62%, val:  42.08%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-39  lr=['0.0529123'], tr/val_loss:  1.591785/  2.204873, tr:  51.07%, val:  35.83%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-40  lr=['0.0517376'], tr/val_loss:  1.603508/  2.086319, tr:  51.17%, val:  39.58%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-41  lr=['0.0505508'], tr/val_loss:  1.619861/  2.640591, tr:  52.71%, val:  38.75%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-42  lr=['0.0493532'], tr/val_loss:  1.836446/  1.834785, tr:  46.58%, val:  44.17%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-43  lr=['0.0481459'], tr/val_loss:  1.619747/  1.694071, tr:  51.17%, val:  48.33%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-44  lr=['0.0469301'], tr/val_loss:  1.740843/  2.507884, tr:  51.48%, val:  45.83%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-45  lr=['0.0457069'], tr/val_loss:  1.592559/  2.199320, tr:  50.56%, val:  45.83%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-46  lr=['0.0444777'], tr/val_loss:  1.778496/  2.631303, tr:  50.46%, val:  35.83%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-47  lr=['0.0432435'], tr/val_loss:  1.733746/  2.299374, tr:  52.50%, val:  43.75%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-48  lr=['0.0420057'], tr/val_loss:  1.615984/  1.778163, tr:  53.73%, val:  45.42%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-49  lr=['0.0407655'], tr/val_loss:  1.609799/  2.229814, tr:  52.20%, val:  44.17%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-50  lr=['0.0395240'], tr/val_loss:  1.444779/  1.902186, tr:  56.79%, val:  38.33%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-51  lr=['0.0382825'], tr/val_loss:  1.486523/  1.788402, tr:  51.28%, val:  46.25%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-52  lr=['0.0370423'], tr/val_loss:  1.430192/  1.929590, tr:  57.81%, val:  41.67%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-53  lr=['0.0358045'], tr/val_loss:  1.294431/  1.737351, tr:  54.85%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-54  lr=['0.0345703'], tr/val_loss:  1.398771/  2.157577, tr:  56.28%, val:  45.00%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-55  lr=['0.0333411'], tr/val_loss:  1.412033/  2.261880, tr:  54.24%, val:  43.75%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-56  lr=['0.0321179'], tr/val_loss:  1.313581/  2.000251, tr:  55.36%, val:  42.08%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-57  lr=['0.0309021'], tr/val_loss:  1.311503/  1.762923, tr:  58.02%, val:  46.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-58  lr=['0.0296948'], tr/val_loss:  1.196485/  1.878387, tr:  57.51%, val:  43.75%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-59  lr=['0.0284972'], tr/val_loss:  1.254725/  1.606293, tr:  56.28%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-60  lr=['0.0273104'], tr/val_loss:  1.140059/  1.777602, tr:  60.06%, val:  46.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-61  lr=['0.0261357'], tr/val_loss:  1.352601/  1.898199, tr:  57.71%, val:  47.08%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-62  lr=['0.0249742'], tr/val_loss:  1.172710/  1.592396, tr:  58.02%, val:  46.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-63  lr=['0.0238271'], tr/val_loss:  1.203604/  1.559110, tr:  60.67%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-64  lr=['0.0226955'], tr/val_loss:  1.106122/  1.692938, tr:  62.61%, val:  47.92%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-65  lr=['0.0215805'], tr/val_loss:  1.121809/  1.810291, tr:  60.88%, val:  48.75%, val_best:  52.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-66  lr=['0.0204832'], tr/val_loss:  1.131777/  1.707316, tr:  59.96%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-67  lr=['0.0194046'], tr/val_loss:  1.099452/  1.550799, tr:  61.29%, val:  55.00%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-68  lr=['0.0183460'], tr/val_loss:  1.006937/  1.663369, tr:  61.80%, val:  55.42%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-69  lr=['0.0173082'], tr/val_loss:  0.949408/  1.570628, tr:  64.86%, val:  52.08%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-70  lr=['0.0162924'], tr/val_loss:  0.970447/  1.640609, tr:  61.70%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-71  lr=['0.0152995'], tr/val_loss:  0.941324/  1.597499, tr:  65.88%, val:  48.33%, val_best:  55.83%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-72  lr=['0.0143305'], tr/val_loss:  0.950514/  1.750084, tr:  64.66%, val:  52.08%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-73  lr=['0.0133863'], tr/val_loss:  0.939810/  1.559826, tr:  63.64%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-74  lr=['0.0124680'], tr/val_loss:  0.876707/  1.585288, tr:  64.04%, val:  54.58%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-75  lr=['0.0115763'], tr/val_loss:  0.892361/  1.562398, tr:  64.66%, val:  55.42%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-76  lr=['0.0107122'], tr/val_loss:  0.849705/  1.507901, tr:  67.82%, val:  56.67%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-77  lr=['0.0098766'], tr/val_loss:  0.880079/  1.534290, tr:  65.68%, val:  54.17%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-78  lr=['0.0090702'], tr/val_loss:  0.857376/  1.609468, tr:  64.45%, val:  53.75%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-79  lr=['0.0082939'], tr/val_loss:  0.831236/  1.521727, tr:  67.21%, val:  50.83%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-80  lr=['0.0075484'], tr/val_loss:  0.815960/  1.521894, tr:  67.52%, val:  54.58%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-81  lr=['0.0068345'], tr/val_loss:  0.816315/  1.511351, tr:  68.13%, val:  53.75%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-82  lr=['0.0061528'], tr/val_loss:  0.822277/  1.445634, tr:  65.37%, val:  57.08%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-83  lr=['0.0055040'], tr/val_loss:  0.815198/  1.478172, tr:  69.77%, val:  53.33%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-84  lr=['0.0048889'], tr/val_loss:  0.795698/  1.492705, tr:  68.74%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-85  lr=['0.0043079'], tr/val_loss:  0.783421/  1.488421, tr:  68.34%, val:  57.50%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-86  lr=['0.0037616'], tr/val_loss:  0.766742/  1.506674, tr:  68.44%, val:  54.58%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-87  lr=['0.0032507'], tr/val_loss:  0.763768/  1.480890, tr:  70.68%, val:  57.92%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-88  lr=['0.0027755'], tr/val_loss:  0.757070/  1.493499, tr:  69.56%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-89  lr=['0.0023366'], tr/val_loss:  0.757635/  1.487753, tr:  70.28%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-90  lr=['0.0019344'], tr/val_loss:  0.755216/  1.518676, tr:  71.60%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-91  lr=['0.0015694'], tr/val_loss:  0.751647/  1.489052, tr:  71.60%, val:  55.83%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-92  lr=['0.0012417'], tr/val_loss:  0.738560/  1.497630, tr:  72.52%, val:  58.33%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-93  lr=['0.0009519'], tr/val_loss:  0.736743/  1.494996, tr:  71.20%, val:  58.75%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-94  lr=['0.0007001'], tr/val_loss:  0.734199/  1.496605, tr:  74.16%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-95  lr=['0.0004866'], tr/val_loss:  0.735217/  1.494049, tr:  75.18%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-96  lr=['0.0003117'], tr/val_loss:  0.737156/  1.501659, tr:  74.57%, val:  60.42%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-97  lr=['0.0001754'], tr/val_loss:  0.727382/  1.498198, tr:  75.49%, val:  61.25%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-98  lr=['0.0000780'], tr/val_loss:  0.729352/  1.496289, tr:  76.51%, val:  60.42%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-99  lr=['0.0000195'], tr/val_loss:  0.726082/  1.497326, tr:  75.79%, val:  60.42%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37ce933905746d38a33e59c3a4997df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▂▂▂▁▃▂▄▅▂▄▄▄▄▄▂▄▆▁▃▄▅▅▄█▅▄▅▄▄▅▅▅▇▇▆▅▇</td></tr><tr><td>summary_val_acc</td><td>▂▂▂▁▄▁▂▂▂▂▃▄▄▃▂▄▂▄▄▄▄▃▄▅▆▅▅▆▆▆▆▆▅▇▇▇▇▇██</td></tr><tr><td>tr_acc</td><td>▁▃▂▂▂▁▁▂▂▂▃▃▂▃▃▃▄▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▅▄▆▆▇▇██▇▇▆▆▇▆▅▇▄▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc_now</td><td>▂▂▂▁▄▁▂▂▂▂▃▄▄▃▂▄▂▄▄▄▄▃▄▅▆▅▅▆▆▆▆▆▅▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>▂▄▅▃▅▄▃▃█▄▃▃▃▃▄▄▃▂▄▄▃▂▃▂▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.66667</td></tr><tr><td>tr_acc</td><td>0.75792</td></tr><tr><td>tr_epoch_loss</td><td>0.72608</td></tr><tr><td>val_acc_best</td><td>0.62917</td></tr><tr><td>val_acc_now</td><td>0.60417</td></tr><tr><td>val_loss</td><td>1.49733</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-82</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyuurhsy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zyuurhsy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_163250-zyuurhsy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sl1hhqki with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0020319670338139104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.1243037392107378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.9507861414656542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_164145-sl1hhqki</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sl1hhqki' target=\"_blank\">sandy-sweep-84</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sl1hhqki' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sl1hhqki</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0020320'], tr/val_loss:  2.006336/  1.617481, tr:  28.91%, val:  48.75%, val_best:  48.75%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-1   lr=['0.0020315'], tr/val_loss:  1.272354/  1.379456, tr:  57.81%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-2   lr=['0.0020300'], tr/val_loss:  1.062057/  1.182056, tr:  63.53%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-3   lr=['0.0020275'], tr/val_loss:  0.927691/  1.193568, tr:  68.74%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-4   lr=['0.0020240'], tr/val_loss:  0.874077/  1.152888, tr:  69.56%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-5   lr=['0.0020195'], tr/val_loss:  0.818654/  1.235214, tr:  73.85%, val:  64.58%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-6   lr=['0.0020140'], tr/val_loss:  0.731059/  1.126566, tr:  77.83%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-7   lr=['0.0020075'], tr/val_loss:  0.704720/  1.156056, tr:  78.96%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 13.30it/s]\n",
      "epoch-8   lr=['0.0020000'], tr/val_loss:  0.621310/  1.119731, tr:  79.67%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 13.42it/s]\n",
      "epoch-9   lr=['0.0019916'], tr/val_loss:  0.532277/  1.320980, tr:  86.31%, val:  64.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 13.40it/s]\n",
      "epoch-10  lr=['0.0019822'], tr/val_loss:  0.503926/  1.171988, tr:  88.05%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-11  lr=['0.0019719'], tr/val_loss:  0.436358/  1.267347, tr:  90.30%, val:  71.67%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-12  lr=['0.0019606'], tr/val_loss:  0.416284/  1.212388, tr:  91.22%, val:  75.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-13  lr=['0.0019484'], tr/val_loss:  0.369475/  1.343759, tr:  92.54%, val:  68.33%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-14  lr=['0.0019353'], tr/val_loss:  0.335578/  1.281295, tr:  93.36%, val:  73.33%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-15  lr=['0.0019212'], tr/val_loss:  0.324603/  1.287687, tr:  93.97%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-16  lr=['0.0019063'], tr/val_loss:  0.284094/  1.504474, tr:  96.32%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-17  lr=['0.0018905'], tr/val_loss:  0.265504/  1.492337, tr:  96.73%, val:  71.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-18  lr=['0.0018738'], tr/val_loss:  0.239777/  1.406780, tr:  97.14%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-19  lr=['0.0018563'], tr/val_loss:  0.190317/  1.454657, tr:  98.77%, val:  75.83%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-20  lr=['0.0018379'], tr/val_loss:  0.177772/  1.530386, tr:  98.98%, val:  75.42%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-21  lr=['0.0018188'], tr/val_loss:  0.139726/  1.620923, tr:  99.08%, val:  71.67%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-22  lr=['0.0017988'], tr/val_loss:  0.137293/  1.513023, tr:  99.28%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-23  lr=['0.0017781'], tr/val_loss:  0.113579/  1.601159, tr:  99.90%, val:  74.58%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-24  lr=['0.0017566'], tr/val_loss:  0.101412/  1.660535, tr:  99.69%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-25  lr=['0.0017344'], tr/val_loss:  0.084630/  1.639402, tr: 100.00%, val:  75.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-26  lr=['0.0017115'], tr/val_loss:  0.078166/  1.701230, tr:  99.90%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-27  lr=['0.0016879'], tr/val_loss:  0.063148/  1.712552, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-28  lr=['0.0016636'], tr/val_loss:  0.057388/  1.711136, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.97it/s]\n",
      "epoch-29  lr=['0.0016387'], tr/val_loss:  0.049909/  1.791523, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-30  lr=['0.0016132'], tr/val_loss:  0.055821/  1.778425, tr:  99.80%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-31  lr=['0.0015871'], tr/val_loss:  0.037869/  1.797640, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-32  lr=['0.0015604'], tr/val_loss:  0.035112/  1.843467, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-33  lr=['0.0015332'], tr/val_loss:  0.027859/  1.823169, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-34  lr=['0.0015054'], tr/val_loss:  0.024777/  1.831291, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-35  lr=['0.0014772'], tr/val_loss:  0.027675/  1.858509, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-36  lr=['0.0014486'], tr/val_loss:  0.021754/  1.892681, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-37  lr=['0.0014195'], tr/val_loss:  0.020375/  1.923142, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-38  lr=['0.0013900'], tr/val_loss:  0.018141/  1.901567, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-39  lr=['0.0013601'], tr/val_loss:  0.017998/  1.899024, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-40  lr=['0.0013299'], tr/val_loss:  0.015253/  1.937636, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-41  lr=['0.0012994'], tr/val_loss:  0.016453/  1.941910, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-42  lr=['0.0012686'], tr/val_loss:  0.014104/  1.947944, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-43  lr=['0.0012376'], tr/val_loss:  0.013169/  1.975621, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-44  lr=['0.0012064'], tr/val_loss:  0.012256/  1.993072, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-45  lr=['0.0011749'], tr/val_loss:  0.011572/  1.989083, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-46  lr=['0.0011433'], tr/val_loss:  0.010384/  2.005931, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-47  lr=['0.0011116'], tr/val_loss:  0.010343/  2.013537, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-48  lr=['0.0010798'], tr/val_loss:  0.009714/  2.027961, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-49  lr=['0.0010479'], tr/val_loss:  0.009189/  2.020477, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-50  lr=['0.0010160'], tr/val_loss:  0.008742/  2.032241, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-51  lr=['0.0009841'], tr/val_loss:  0.008432/  2.040916, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-52  lr=['0.0009522'], tr/val_loss:  0.008459/  2.040921, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-53  lr=['0.0009204'], tr/val_loss:  0.008034/  2.047288, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-54  lr=['0.0008886'], tr/val_loss:  0.007729/  2.043615, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-55  lr=['0.0008570'], tr/val_loss:  0.007315/  2.053030, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-56  lr=['0.0008256'], tr/val_loss:  0.006646/  2.052406, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-57  lr=['0.0007944'], tr/val_loss:  0.006639/  2.062466, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-58  lr=['0.0007633'], tr/val_loss:  0.006328/  2.075780, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-59  lr=['0.0007325'], tr/val_loss:  0.006399/  2.059490, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-60  lr=['0.0007020'], tr/val_loss:  0.006416/  2.080055, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-61  lr=['0.0006718'], tr/val_loss:  0.006040/  2.082601, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-62  lr=['0.0006420'], tr/val_loss:  0.006180/  2.075063, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-63  lr=['0.0006125'], tr/val_loss:  0.006117/  2.087160, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-64  lr=['0.0005834'], tr/val_loss:  0.005834/  2.089785, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-65  lr=['0.0005547'], tr/val_loss:  0.005780/  2.100268, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-66  lr=['0.0005265'], tr/val_loss:  0.005626/  2.092072, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-67  lr=['0.0004988'], tr/val_loss:  0.005647/  2.096706, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-68  lr=['0.0004716'], tr/val_loss:  0.005423/  2.116829, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-69  lr=['0.0004449'], tr/val_loss:  0.005417/  2.115178, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-70  lr=['0.0004188'], tr/val_loss:  0.005224/  2.103283, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-71  lr=['0.0003933'], tr/val_loss:  0.005187/  2.112830, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-72  lr=['0.0003684'], tr/val_loss:  0.005191/  2.111028, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-73  lr=['0.0003441'], tr/val_loss:  0.005356/  2.123802, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-74  lr=['0.0003205'], tr/val_loss:  0.005136/  2.113537, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-75  lr=['0.0002976'], tr/val_loss:  0.005115/  2.111670, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-76  lr=['0.0002754'], tr/val_loss:  0.004864/  2.121592, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-77  lr=['0.0002539'], tr/val_loss:  0.004946/  2.120654, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-78  lr=['0.0002332'], tr/val_loss:  0.004954/  2.114167, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-79  lr=['0.0002132'], tr/val_loss:  0.004904/  2.119878, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-80  lr=['0.0001940'], tr/val_loss:  0.004877/  2.116642, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-81  lr=['0.0001757'], tr/val_loss:  0.004778/  2.124877, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-82  lr=['0.0001582'], tr/val_loss:  0.004866/  2.123226, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-83  lr=['0.0001415'], tr/val_loss:  0.004810/  2.123314, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-84  lr=['0.0001257'], tr/val_loss:  0.004739/  2.131546, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-85  lr=['0.0001107'], tr/val_loss:  0.004695/  2.133977, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-86  lr=['0.0000967'], tr/val_loss:  0.004726/  2.131492, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-87  lr=['0.0000836'], tr/val_loss:  0.004747/  2.131564, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-88  lr=['0.0000713'], tr/val_loss:  0.004830/  2.127826, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-89  lr=['0.0000601'], tr/val_loss:  0.004747/  2.129006, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-90  lr=['0.0000497'], tr/val_loss:  0.004746/  2.127490, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-91  lr=['0.0000403'], tr/val_loss:  0.004783/  2.126551, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-92  lr=['0.0000319'], tr/val_loss:  0.004692/  2.127066, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-93  lr=['0.0000245'], tr/val_loss:  0.004757/  2.127233, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-94  lr=['0.0000180'], tr/val_loss:  0.004759/  2.128010, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-95  lr=['0.0000125'], tr/val_loss:  0.004757/  2.127854, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-96  lr=['0.0000080'], tr/val_loss:  0.004700/  2.127992, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-97  lr=['0.0000045'], tr/val_loss:  0.004675/  2.128668, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-98  lr=['0.0000020'], tr/val_loss:  0.004682/  2.128675, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-99  lr=['0.0000005'], tr/val_loss:  0.004634/  2.129061, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ca8e8041c541a5b73e7deb23f5152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▂▅█▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▅▇▇▆▇▆▇█▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▅▇▇▆▇▆▇█▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▄▁▁▁▂▁▂▃▃▄▅▅▆▆▆▇▆▇▇▇▇▇▇█▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00463</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>2.12906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-sweep-84</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sl1hhqki' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sl1hhqki</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_164145-sl1hhqki/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nyo18kkz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08374124624381347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.6927554451943952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.615239484299811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973d0f4e0a214f38bff39f6b44033fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114114791982703, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_165040-nyo18kkz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nyo18kkz' target=\"_blank\">apricot-sweep-86</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nyo18kkz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nyo18kkz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0837412'], tr/val_loss:  1.930723/  1.508365, tr:  32.38%, val:  42.92%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-1   lr=['0.0837206'], tr/val_loss:  1.568955/  1.733346, tr:  45.56%, val:  40.42%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-2   lr=['0.0836586'], tr/val_loss:  1.397707/  1.999139, tr:  50.87%, val:  40.00%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-3   lr=['0.0835554'], tr/val_loss:  1.411518/  1.656584, tr:  54.34%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-4   lr=['0.0834111'], tr/val_loss:  1.479708/  1.466600, tr:  53.22%, val:  48.75%, val_best:  50.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-5   lr=['0.0832257'], tr/val_loss:  1.598956/  2.179488, tr:  50.05%, val:  36.25%, val_best:  50.42%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-6   lr=['0.0829996'], tr/val_loss:  1.735117/  1.845020, tr:  46.99%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-7   lr=['0.0827329'], tr/val_loss:  1.659964/  3.155006, tr:  52.60%, val:  32.50%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.59it/s]\n",
      "epoch-8   lr=['0.0824258'], tr/val_loss:  2.139741/  1.812788, tr:  46.58%, val:  44.58%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.41it/s]\n",
      "epoch-9   lr=['0.0820787'], tr/val_loss:  1.953729/  2.075259, tr:  48.72%, val:  42.08%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.16it/s]\n",
      "epoch-10  lr=['0.0816920'], tr/val_loss:  1.834776/  2.920633, tr:  49.95%, val:  41.25%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-11  lr=['0.0812659'], tr/val_loss:  1.927162/  2.373359, tr:  45.76%, val:  33.33%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.17it/s]\n",
      "epoch-12  lr=['0.0808009'], tr/val_loss:  1.927120/  2.652252, tr:  49.13%, val:  34.17%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-13  lr=['0.0802976'], tr/val_loss:  1.969705/  1.928608, tr:  50.66%, val:  45.00%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-14  lr=['0.0797563'], tr/val_loss:  1.643803/  2.187211, tr:  50.77%, val:  40.83%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-15  lr=['0.0791776'], tr/val_loss:  2.115508/  2.622838, tr:  47.29%, val:  43.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-16  lr=['0.0785621'], tr/val_loss:  1.875214/  2.332043, tr:  52.20%, val:  48.33%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-17  lr=['0.0779104'], tr/val_loss:  1.907467/  2.133158, tr:  52.81%, val:  46.25%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-18  lr=['0.0772232'], tr/val_loss:  2.132720/  2.749854, tr:  52.50%, val:  36.67%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-19  lr=['0.0765010'], tr/val_loss:  1.684315/  2.899065, tr:  52.40%, val:  41.25%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-20  lr=['0.0757447'], tr/val_loss:  1.894937/  2.599470, tr:  53.83%, val:  45.42%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-21  lr=['0.0749549'], tr/val_loss:  1.720478/  2.603281, tr:  53.93%, val:  53.33%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-22  lr=['0.0741325'], tr/val_loss:  1.785854/  2.284293, tr:  54.34%, val:  50.42%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-23  lr=['0.0732782'], tr/val_loss:  1.788411/  2.046838, tr:  56.69%, val:  40.83%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-24  lr=['0.0723930'], tr/val_loss:  1.605495/  2.173972, tr:  56.38%, val:  40.00%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-25  lr=['0.0714776'], tr/val_loss:  1.511417/  2.489257, tr:  55.98%, val:  44.17%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-26  lr=['0.0705330'], tr/val_loss:  1.589170/  1.898155, tr:  55.26%, val:  49.58%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-27  lr=['0.0695602'], tr/val_loss:  1.567816/  2.337684, tr:  52.91%, val:  40.83%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-28  lr=['0.0685600'], tr/val_loss:  1.497639/  2.251536, tr:  57.20%, val:  45.83%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-29  lr=['0.0675334'], tr/val_loss:  1.449644/  1.976127, tr:  57.81%, val:  47.08%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-30  lr=['0.0664816'], tr/val_loss:  1.525657/  2.449630, tr:  58.32%, val:  50.00%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-31  lr=['0.0654054'], tr/val_loss:  1.436582/  1.758885, tr:  59.75%, val:  50.83%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-32  lr=['0.0643060'], tr/val_loss:  1.209076/  1.829531, tr:  61.70%, val:  50.42%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-33  lr=['0.0631845'], tr/val_loss:  1.184383/  1.627766, tr:  62.00%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-34  lr=['0.0620419'], tr/val_loss:  1.177296/  1.998323, tr:  64.04%, val:  53.33%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-35  lr=['0.0608795'], tr/val_loss:  1.208097/  1.909505, tr:  64.96%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 13.03it/s]\n",
      "epoch-36  lr=['0.0596983'], tr/val_loss:  1.228602/  1.771799, tr:  62.31%, val:  48.75%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-37  lr=['0.0584995'], tr/val_loss:  1.219887/  1.897694, tr:  65.37%, val:  55.00%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-38  lr=['0.0572842'], tr/val_loss:  1.173632/  2.212319, tr:  64.66%, val:  49.17%, val_best:  55.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-39  lr=['0.0560538'], tr/val_loss:  1.003866/  1.920585, tr:  68.54%, val:  53.75%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-40  lr=['0.0548094'], tr/val_loss:  1.124459/  1.892177, tr:  67.52%, val:  47.50%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-41  lr=['0.0535522'], tr/val_loss:  1.021785/  1.799420, tr:  67.93%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.97it/s]\n",
      "epoch-42  lr=['0.0522834'], tr/val_loss:  1.075925/  1.768906, tr:  65.07%, val:  48.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-43  lr=['0.0510044'], tr/val_loss:  1.027371/  2.000002, tr:  64.66%, val:  53.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-44  lr=['0.0497164'], tr/val_loss:  1.114659/  2.012268, tr:  59.24%, val:  52.92%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-45  lr=['0.0484206'], tr/val_loss:  1.023275/  1.752924, tr:  68.64%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-46  lr=['0.0471184'], tr/val_loss:  0.909202/  1.779135, tr:  68.03%, val:  57.92%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-47  lr=['0.0458110'], tr/val_loss:  0.994850/  1.874821, tr:  66.29%, val:  53.75%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-48  lr=['0.0444997'], tr/val_loss:  0.985401/  1.716569, tr:  67.31%, val:  56.25%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-49  lr=['0.0431858'], tr/val_loss:  0.978161/  1.642888, tr:  69.56%, val:  54.58%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-50  lr=['0.0418706'], tr/val_loss:  0.871811/  1.853443, tr:  70.28%, val:  50.83%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-51  lr=['0.0405554'], tr/val_loss:  0.817111/  1.660379, tr:  70.28%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-52  lr=['0.0392415'], tr/val_loss:  0.908166/  1.674883, tr:  70.99%, val:  57.92%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-53  lr=['0.0379302'], tr/val_loss:  0.799491/  1.912825, tr:  70.38%, val:  57.50%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-54  lr=['0.0366228'], tr/val_loss:  0.783490/  1.734707, tr:  72.73%, val:  57.08%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-55  lr=['0.0353206'], tr/val_loss:  0.728294/  1.977671, tr:  71.09%, val:  57.50%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-56  lr=['0.0340249'], tr/val_loss:  0.734796/  1.618559, tr:  73.44%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-57  lr=['0.0327368'], tr/val_loss:  0.735339/  1.745394, tr:  71.60%, val:  57.92%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-58  lr=['0.0314578'], tr/val_loss:  0.717220/  1.723942, tr:  70.58%, val:  57.92%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-59  lr=['0.0301891'], tr/val_loss:  0.679344/  1.588476, tr:  73.34%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-60  lr=['0.0289319'], tr/val_loss:  0.717671/  1.623528, tr:  71.81%, val:  62.50%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-61  lr=['0.0276875'], tr/val_loss:  0.697405/  1.754924, tr:  73.95%, val:  59.58%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-62  lr=['0.0264570'], tr/val_loss:  0.654209/  1.640678, tr:  73.44%, val:  57.08%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-63  lr=['0.0252418'], tr/val_loss:  0.657282/  1.688226, tr:  75.69%, val:  60.42%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-64  lr=['0.0240430'], tr/val_loss:  0.607129/  1.624351, tr:  74.97%, val:  60.83%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-65  lr=['0.0228618'], tr/val_loss:  0.602805/  1.675188, tr:  76.00%, val:  57.08%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-66  lr=['0.0216993'], tr/val_loss:  0.584015/  1.629290, tr:  74.46%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-67  lr=['0.0205567'], tr/val_loss:  0.586538/  1.580486, tr:  77.12%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-68  lr=['0.0194352'], tr/val_loss:  0.539784/  1.643211, tr:  76.71%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-69  lr=['0.0183358'], tr/val_loss:  0.531939/  1.707191, tr:  78.55%, val:  59.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-70  lr=['0.0172597'], tr/val_loss:  0.510286/  1.701588, tr:  78.24%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-71  lr=['0.0162078'], tr/val_loss:  0.535849/  1.727230, tr:  78.75%, val:  59.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-72  lr=['0.0151813'], tr/val_loss:  0.519453/  1.717196, tr:  76.92%, val:  58.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-73  lr=['0.0141811'], tr/val_loss:  0.522286/  1.665358, tr:  77.73%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-74  lr=['0.0132082'], tr/val_loss:  0.460619/  1.691003, tr:  80.59%, val:  64.58%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-75  lr=['0.0122636'], tr/val_loss:  0.457782/  1.675533, tr:  79.98%, val:  60.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-76  lr=['0.0113483'], tr/val_loss:  0.449269/  1.660562, tr:  80.69%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-77  lr=['0.0104630'], tr/val_loss:  0.462708/  1.670715, tr:  78.86%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-78  lr=['0.0096088'], tr/val_loss:  0.447278/  1.677710, tr:  82.33%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-79  lr=['0.0087863'], tr/val_loss:  0.431686/  1.699341, tr:  83.15%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-80  lr=['0.0079966'], tr/val_loss:  0.420640/  1.653672, tr:  83.86%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-81  lr=['0.0072402'], tr/val_loss:  0.416437/  1.690652, tr:  83.86%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-82  lr=['0.0065181'], tr/val_loss:  0.417205/  1.690871, tr:  85.09%, val:  64.58%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-83  lr=['0.0058308'], tr/val_loss:  0.396269/  1.706485, tr:  86.52%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-84  lr=['0.0051791'], tr/val_loss:  0.396860/  1.716581, tr:  86.21%, val:  63.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-85  lr=['0.0045636'], tr/val_loss:  0.401264/  1.721949, tr:  85.80%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-86  lr=['0.0039850'], tr/val_loss:  0.389658/  1.726534, tr:  86.82%, val:  62.92%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-87  lr=['0.0034437'], tr/val_loss:  0.387741/  1.712689, tr:  88.36%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-88  lr=['0.0029403'], tr/val_loss:  0.383449/  1.721910, tr:  88.76%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-89  lr=['0.0024754'], tr/val_loss:  0.380782/  1.712880, tr:  87.74%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-90  lr=['0.0020493'], tr/val_loss:  0.373874/  1.727931, tr:  90.40%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-91  lr=['0.0016625'], tr/val_loss:  0.377547/  1.722372, tr:  90.19%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-92  lr=['0.0013154'], tr/val_loss:  0.376708/  1.721336, tr:  90.81%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-93  lr=['0.0010084'], tr/val_loss:  0.368921/  1.719011, tr:  89.99%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-94  lr=['0.0007416'], tr/val_loss:  0.370298/  1.723826, tr:  90.70%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-95  lr=['0.0005155'], tr/val_loss:  0.366809/  1.718854, tr:  91.32%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-96  lr=['0.0003302'], tr/val_loss:  0.365028/  1.719887, tr:  91.11%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-97  lr=['0.0001858'], tr/val_loss:  0.364794/  1.722153, tr:  91.11%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-98  lr=['0.0000826'], tr/val_loss:  0.375447/  1.726431, tr:  91.52%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-99  lr=['0.0000207'], tr/val_loss:  0.365614/  1.725513, tr:  91.83%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27cbf0467234879997381d4cd6d2bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▃▂▂▂▁▅▆▃▅▅▄▅▃▃▄▂▇▅▃▃▅▅▄▅▇█▅▅▅▅▇▅▅█▇▇▄▇</td></tr><tr><td>summary_val_acc</td><td>▃▂▄▁▃▁▃▄▃▅▂▄▄▄▅▅▅▄▅▅▅▆▆▆▇▆▆▇▇▆▆▇▇▇▇█▇▇█▇</td></tr><tr><td>tr_acc</td><td>▁▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▆▇██▇█▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>val_acc_now</td><td>▃▂▄▁▃▁▃▄▃▅▂▄▄▄▅▅▅▄▅▅▅▆▆▆▇▆▆▇▇▆▆▇▇▇▇█▇▇█▇</td></tr><tr><td>val_loss</td><td>▁▃▁█▄▆▄▄▇▆▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.91828</td></tr><tr><td>tr_epoch_loss</td><td>0.36561</td></tr><tr><td>val_acc_best</td><td>0.69167</td></tr><tr><td>val_acc_now</td><td>0.65833</td></tr><tr><td>val_loss</td><td>1.72551</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-86</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nyo18kkz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nyo18kkz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_165040-nyo18kkz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67ww27cb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0020556105338171565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.40901372722486257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.7616613456390382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_165938-67ww27cb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/67ww27cb' target=\"_blank\">earthy-sweep-88</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/67ww27cb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/67ww27cb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0020556'], tr/val_loss:  2.306624/  2.302723, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-1   lr=['0.0020551'], tr/val_loss:  2.307049/  2.302790, tr:   7.35%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-2   lr=['0.0020536'], tr/val_loss:  2.304099/  2.289302, tr:  10.32%, val:  18.33%, val_best:  18.33%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-3   lr=['0.0020510'], tr/val_loss:  2.172239/  2.018016, tr:  24.62%, val:  32.92%, val_best:  32.92%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-4   lr=['0.0020475'], tr/val_loss:  1.779760/  1.706310, tr:  41.98%, val:  44.17%, val_best:  44.17%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-5   lr=['0.0020430'], tr/val_loss:  1.477169/  1.540541, tr:  51.38%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-6   lr=['0.0020374'], tr/val_loss:  1.342660/  1.462219, tr:  54.14%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-7   lr=['0.0020309'], tr/val_loss:  1.266426/  1.421298, tr:  58.73%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-8   lr=['0.0020233'], tr/val_loss:  1.197400/  1.353646, tr:  56.08%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-9   lr=['0.0020148'], tr/val_loss:  1.139225/  1.344700, tr:  62.92%, val:  55.00%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-10  lr=['0.0020053'], tr/val_loss:  1.107638/  1.304668, tr:  63.84%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 13.43it/s]\n",
      "epoch-11  lr=['0.0019948'], tr/val_loss:  1.078438/  1.281941, tr:  63.64%, val:  57.50%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 13.39it/s]\n",
      "epoch-12  lr=['0.0019834'], tr/val_loss:  1.043868/  1.219604, tr:  66.70%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.03it/s]\n",
      "epoch-13  lr=['0.0019711'], tr/val_loss:  0.998815/  1.231405, tr:  68.34%, val:  59.17%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-14  lr=['0.0019578'], tr/val_loss:  0.991393/  1.201512, tr:  66.39%, val:  60.00%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-15  lr=['0.0019436'], tr/val_loss:  0.962736/  1.181261, tr:  70.07%, val:  59.58%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-16  lr=['0.0019285'], tr/val_loss:  0.933985/  1.196301, tr:  72.73%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-17  lr=['0.0019125'], tr/val_loss:  0.919601/  1.169568, tr:  71.60%, val:  60.42%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-18  lr=['0.0018956'], tr/val_loss:  0.887547/  1.173195, tr:  71.91%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-19  lr=['0.0018779'], tr/val_loss:  0.867077/  1.169996, tr:  73.44%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-20  lr=['0.0018593'], tr/val_loss:  0.841771/  1.189393, tr:  73.85%, val:  65.00%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-21  lr=['0.0018399'], tr/val_loss:  0.835995/  1.199251, tr:  76.20%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-22  lr=['0.0018197'], tr/val_loss:  0.811156/  1.144588, tr:  76.81%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-23  lr=['0.0017988'], tr/val_loss:  0.792580/  1.176254, tr:  76.71%, val:  65.00%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-24  lr=['0.0017770'], tr/val_loss:  0.781559/  1.210906, tr:  77.43%, val:  64.58%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-25  lr=['0.0017546'], tr/val_loss:  0.781988/  1.187778, tr:  77.83%, val:  64.58%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-26  lr=['0.0017314'], tr/val_loss:  0.746796/  1.181319, tr:  80.49%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-27  lr=['0.0017075'], tr/val_loss:  0.741705/  1.180739, tr:  80.29%, val:  66.67%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-28  lr=['0.0016830'], tr/val_loss:  0.726875/  1.188310, tr:  79.37%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-29  lr=['0.0016578'], tr/val_loss:  0.719082/  1.183280, tr:  82.53%, val:  68.33%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-30  lr=['0.0016319'], tr/val_loss:  0.692903/  1.172473, tr:  83.86%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-31  lr=['0.0016055'], tr/val_loss:  0.674243/  1.195201, tr:  84.37%, val:  65.42%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-32  lr=['0.0015785'], tr/val_loss:  0.670386/  1.215071, tr:  81.41%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-33  lr=['0.0015510'], tr/val_loss:  0.658044/  1.177078, tr:  85.70%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-34  lr=['0.0015230'], tr/val_loss:  0.650101/  1.203060, tr:  84.88%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-35  lr=['0.0014944'], tr/val_loss:  0.641842/  1.190933, tr:  86.21%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-36  lr=['0.0014654'], tr/val_loss:  0.631582/  1.214465, tr:  87.03%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-37  lr=['0.0014360'], tr/val_loss:  0.615763/  1.214092, tr:  85.19%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-38  lr=['0.0014062'], tr/val_loss:  0.605547/  1.232973, tr:  88.25%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-39  lr=['0.0013760'], tr/val_loss:  0.591045/  1.223703, tr:  89.79%, val:  67.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-40  lr=['0.0013454'], tr/val_loss:  0.586806/  1.209883, tr:  87.13%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-41  lr=['0.0013146'], tr/val_loss:  0.576313/  1.243010, tr:  88.15%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-42  lr=['0.0012834'], tr/val_loss:  0.553817/  1.241395, tr:  91.73%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-43  lr=['0.0012520'], tr/val_loss:  0.550289/  1.242552, tr:  92.34%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-44  lr=['0.0012204'], tr/val_loss:  0.543511/  1.246283, tr:  91.83%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-45  lr=['0.0011886'], tr/val_loss:  0.536250/  1.291865, tr:  91.62%, val:  70.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-46  lr=['0.0011566'], tr/val_loss:  0.525451/  1.260047, tr:  92.75%, val:  73.75%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-47  lr=['0.0011245'], tr/val_loss:  0.510439/  1.270171, tr:  94.08%, val:  71.67%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-48  lr=['0.0010923'], tr/val_loss:  0.511830/  1.268361, tr:  93.36%, val:  75.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-49  lr=['0.0010601'], tr/val_loss:  0.504977/  1.266025, tr:  92.95%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-50  lr=['0.0010278'], tr/val_loss:  0.498359/  1.287145, tr:  94.48%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-51  lr=['0.0009955'], tr/val_loss:  0.484983/  1.289851, tr:  95.61%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-52  lr=['0.0009633'], tr/val_loss:  0.472485/  1.321406, tr:  95.40%, val:  70.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-53  lr=['0.0009311'], tr/val_loss:  0.467881/  1.306030, tr:  95.61%, val:  73.75%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-54  lr=['0.0008990'], tr/val_loss:  0.464911/  1.308205, tr:  95.71%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-55  lr=['0.0008670'], tr/val_loss:  0.448640/  1.305763, tr:  96.42%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-56  lr=['0.0008352'], tr/val_loss:  0.448266/  1.314353, tr:  96.83%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-57  lr=['0.0008036'], tr/val_loss:  0.441663/  1.334166, tr:  96.12%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-58  lr=['0.0007722'], tr/val_loss:  0.427357/  1.326535, tr:  96.42%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-59  lr=['0.0007411'], tr/val_loss:  0.426189/  1.308995, tr:  97.04%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-60  lr=['0.0007102'], tr/val_loss:  0.423766/  1.338095, tr:  97.45%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-61  lr=['0.0006796'], tr/val_loss:  0.421686/  1.361873, tr:  97.65%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-62  lr=['0.0006494'], tr/val_loss:  0.415672/  1.350008, tr:  97.55%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-63  lr=['0.0006196'], tr/val_loss:  0.411523/  1.354721, tr:  98.06%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-64  lr=['0.0005902'], tr/val_loss:  0.405753/  1.354452, tr:  98.16%, val:  75.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-65  lr=['0.0005612'], tr/val_loss:  0.403052/  1.363331, tr:  98.26%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-66  lr=['0.0005327'], tr/val_loss:  0.399032/  1.364279, tr:  98.06%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-67  lr=['0.0005046'], tr/val_loss:  0.398987/  1.358987, tr:  97.65%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-68  lr=['0.0004771'], tr/val_loss:  0.389239/  1.391051, tr:  98.16%, val:  73.33%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-69  lr=['0.0004501'], tr/val_loss:  0.383069/  1.381294, tr:  98.16%, val:  75.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-70  lr=['0.0004237'], tr/val_loss:  0.383754/  1.380211, tr:  98.57%, val:  73.33%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-71  lr=['0.0003979'], tr/val_loss:  0.384291/  1.382998, tr:  98.16%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-72  lr=['0.0003727'], tr/val_loss:  0.377381/  1.387740, tr:  98.67%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-73  lr=['0.0003481'], tr/val_loss:  0.389505/  1.366921, tr:  98.26%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-74  lr=['0.0003242'], tr/val_loss:  0.375017/  1.391483, tr:  98.57%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-75  lr=['0.0003010'], tr/val_loss:  0.372283/  1.398127, tr:  98.26%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-76  lr=['0.0002786'], tr/val_loss:  0.371031/  1.397930, tr:  98.88%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-77  lr=['0.0002568'], tr/val_loss:  0.366173/  1.385111, tr:  98.67%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-78  lr=['0.0002359'], tr/val_loss:  0.369313/  1.394318, tr:  98.88%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-79  lr=['0.0002157'], tr/val_loss:  0.362822/  1.397872, tr:  99.08%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-80  lr=['0.0001963'], tr/val_loss:  0.363034/  1.405107, tr:  98.98%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-81  lr=['0.0001777'], tr/val_loss:  0.361828/  1.413130, tr:  99.08%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-82  lr=['0.0001600'], tr/val_loss:  0.361336/  1.402112, tr:  98.77%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-83  lr=['0.0001431'], tr/val_loss:  0.357972/  1.408164, tr:  98.88%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-84  lr=['0.0001271'], tr/val_loss:  0.357819/  1.418118, tr:  99.08%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-85  lr=['0.0001120'], tr/val_loss:  0.356654/  1.408804, tr:  98.57%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-86  lr=['0.0000978'], tr/val_loss:  0.357261/  1.413305, tr:  99.08%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-87  lr=['0.0000845'], tr/val_loss:  0.359470/  1.416187, tr:  98.88%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-88  lr=['0.0000722'], tr/val_loss:  0.357594/  1.411734, tr:  98.67%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-89  lr=['0.0000608'], tr/val_loss:  0.357389/  1.410521, tr:  98.67%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-90  lr=['0.0000503'], tr/val_loss:  0.358109/  1.418280, tr:  98.88%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-91  lr=['0.0000408'], tr/val_loss:  0.359255/  1.411611, tr:  98.98%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-92  lr=['0.0000323'], tr/val_loss:  0.358108/  1.423902, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-93  lr=['0.0000248'], tr/val_loss:  0.356610/  1.419177, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-94  lr=['0.0000182'], tr/val_loss:  0.364000/  1.414375, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-95  lr=['0.0000127'], tr/val_loss:  0.356956/  1.417149, tr:  98.88%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-96  lr=['0.0000081'], tr/val_loss:  0.354036/  1.418240, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-97  lr=['0.0000046'], tr/val_loss:  0.353921/  1.416204, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-98  lr=['0.0000020'], tr/val_loss:  0.356009/  1.417404, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-99  lr=['0.0000005'], tr/val_loss:  0.354338/  1.417245, tr:  98.98%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1eabbd441444e996e35d72798a4296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▄▄▅▅▆▆▇▆▇▆▆█▇▇████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▅▆▆▆▆▇▇▇▇▇▇█▇▇▇█▇█▇██████████████████</td></tr><tr><td>tr_acc</td><td>▁▁▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▅▆▆▆▆▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▅▆▆▆▆▇▇▇▇▇▇█▇▇▇█▇█▇██████████████████</td></tr><tr><td>val_loss</td><td>██▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98979</td></tr><tr><td>tr_epoch_loss</td><td>0.35434</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>1.41725</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-88</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/67ww27cb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/67ww27cb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_165938-67ww27cb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4hgg1y1r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004991864731318275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.47403970529242967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.128840806716217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_170833-4hgg1y1r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hgg1y1r' target=\"_blank\">peach-sweep-90</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hgg1y1r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hgg1y1r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0049919'], tr/val_loss:  1.782781/  1.517478, tr:  36.26%, val:  45.00%, val_best:  45.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-1   lr=['0.0049906'], tr/val_loss:  1.332282/  1.476936, tr:  50.26%, val:  45.83%, val_best:  45.83%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-2   lr=['0.0049869'], tr/val_loss:  1.172433/  1.334694, tr:  56.79%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-3   lr=['0.0049808'], tr/val_loss:  1.139990/  1.248554, tr:  56.28%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-4   lr=['0.0049722'], tr/val_loss:  1.072132/  1.269974, tr:  58.84%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-5   lr=['0.0049611'], tr/val_loss:  1.001414/  1.387626, tr:  64.45%, val:  49.17%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-6   lr=['0.0049477'], tr/val_loss:  0.913381/  1.362298, tr:  66.39%, val:  49.58%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-7   lr=['0.0049318'], tr/val_loss:  0.904306/  1.322543, tr:  67.31%, val:  52.08%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-8   lr=['0.0049135'], tr/val_loss:  0.888568/  1.252559, tr:  69.05%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-9   lr=['0.0048928'], tr/val_loss:  0.727043/  1.588560, tr:  74.36%, val:  54.58%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-10  lr=['0.0048697'], tr/val_loss:  0.688385/  1.403357, tr:  76.10%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-11  lr=['0.0048443'], tr/val_loss:  0.681943/  1.429257, tr:  78.04%, val:  58.75%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.10it/s]\n",
      "epoch-12  lr=['0.0048166'], tr/val_loss:  0.612254/  1.261239, tr:  80.39%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 13.10it/s]\n",
      "epoch-13  lr=['0.0047866'], tr/val_loss:  0.580396/  1.463431, tr:  81.00%, val:  61.67%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 13.36it/s]\n",
      "epoch-14  lr=['0.0047543'], tr/val_loss:  0.538679/  1.398123, tr:  82.84%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 13.39it/s]\n",
      "epoch-15  lr=['0.0047198'], tr/val_loss:  0.487230/  1.402974, tr:  85.39%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-16  lr=['0.0046831'], tr/val_loss:  0.470792/  1.493931, tr:  88.05%, val:  62.92%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-17  lr=['0.0046443'], tr/val_loss:  0.455252/  1.658305, tr:  85.90%, val:  58.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-18  lr=['0.0046033'], tr/val_loss:  0.454424/  1.546837, tr:  85.80%, val:  62.92%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-19  lr=['0.0045603'], tr/val_loss:  0.395379/  1.620099, tr:  90.09%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-20  lr=['0.0045152'], tr/val_loss:  0.354052/  1.596399, tr:  90.60%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-21  lr=['0.0044681'], tr/val_loss:  0.327738/  1.629353, tr:  92.34%, val:  63.75%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-22  lr=['0.0044191'], tr/val_loss:  0.338742/  1.615659, tr:  92.85%, val:  65.42%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-23  lr=['0.0043682'], tr/val_loss:  0.292369/  1.696163, tr:  91.93%, val:  65.42%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-24  lr=['0.0043154'], tr/val_loss:  0.314948/  1.764325, tr:  91.93%, val:  64.17%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-25  lr=['0.0042608'], tr/val_loss:  0.277403/  1.759685, tr:  94.99%, val:  63.75%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-26  lr=['0.0042045'], tr/val_loss:  0.246030/  1.796637, tr:  94.69%, val:  65.83%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-27  lr=['0.0041465'], tr/val_loss:  0.236934/  1.803327, tr:  93.36%, val:  65.83%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-28  lr=['0.0040869'], tr/val_loss:  0.197165/  1.893368, tr:  96.73%, val:  65.00%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-29  lr=['0.0040257'], tr/val_loss:  0.181874/  2.020120, tr:  96.53%, val:  64.17%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-30  lr=['0.0039630'], tr/val_loss:  0.211681/  1.950160, tr:  97.55%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-31  lr=['0.0038989'], tr/val_loss:  0.155033/  2.042219, tr:  97.96%, val:  65.00%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-32  lr=['0.0038333'], tr/val_loss:  0.162275/  1.999262, tr:  97.04%, val:  66.67%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-33  lr=['0.0037665'], tr/val_loss:  0.144744/  2.016863, tr:  98.16%, val:  66.25%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-34  lr=['0.0036984'], tr/val_loss:  0.126300/  2.040242, tr:  99.18%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-35  lr=['0.0036291'], tr/val_loss:  0.116673/  2.110230, tr:  98.16%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-36  lr=['0.0035586'], tr/val_loss:  0.099366/  2.130618, tr:  99.69%, val:  64.58%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-37  lr=['0.0034872'], tr/val_loss:  0.118932/  2.130757, tr:  98.47%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-38  lr=['0.0034147'], tr/val_loss:  0.090178/  2.195597, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-39  lr=['0.0033414'], tr/val_loss:  0.077006/  2.195614, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-40  lr=['0.0032672'], tr/val_loss:  0.084094/  2.230211, tr:  99.80%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n",
      "epoch-41  lr=['0.0031923'], tr/val_loss:  0.089714/  2.245145, tr:  98.98%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-42  lr=['0.0031166'], tr/val_loss:  0.064485/  2.307945, tr:  99.90%, val:  65.42%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-43  lr=['0.0030404'], tr/val_loss:  0.059908/  2.287367, tr:  99.90%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-44  lr=['0.0029636'], tr/val_loss:  0.055058/  2.301977, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-45  lr=['0.0028864'], tr/val_loss:  0.054944/  2.347193, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-46  lr=['0.0028088'], tr/val_loss:  0.049286/  2.366809, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-47  lr=['0.0027308'], tr/val_loss:  0.044282/  2.382297, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-48  lr=['0.0026527'], tr/val_loss:  0.038781/  2.393492, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-49  lr=['0.0025743'], tr/val_loss:  0.039213/  2.425684, tr:  99.90%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-50  lr=['0.0024959'], tr/val_loss:  0.043719/  2.442935, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-51  lr=['0.0024175'], tr/val_loss:  0.030589/  2.490685, tr: 100.00%, val:  68.75%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-52  lr=['0.0023392'], tr/val_loss:  0.028513/  2.485123, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-53  lr=['0.0022610'], tr/val_loss:  0.027801/  2.508855, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-54  lr=['0.0021831'], tr/val_loss:  0.026010/  2.564664, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-55  lr=['0.0021055'], tr/val_loss:  0.026040/  2.553457, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-56  lr=['0.0020282'], tr/val_loss:  0.024441/  2.539603, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-57  lr=['0.0019515'], tr/val_loss:  0.021850/  2.554494, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-58  lr=['0.0018752'], tr/val_loss:  0.022150/  2.570284, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-59  lr=['0.0017996'], tr/val_loss:  0.020533/  2.605318, tr: 100.00%, val:  68.75%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-60  lr=['0.0017246'], tr/val_loss:  0.022033/  2.617256, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-61  lr=['0.0016505'], tr/val_loss:  0.018361/  2.599258, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-62  lr=['0.0015771'], tr/val_loss:  0.017746/  2.606276, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-63  lr=['0.0015047'], tr/val_loss:  0.017842/  2.633437, tr: 100.00%, val:  68.75%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-64  lr=['0.0014332'], tr/val_loss:  0.015892/  2.649579, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-65  lr=['0.0013628'], tr/val_loss:  0.014750/  2.644320, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-66  lr=['0.0012935'], tr/val_loss:  0.015645/  2.655729, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-67  lr=['0.0012254'], tr/val_loss:  0.015163/  2.659865, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-68  lr=['0.0011585'], tr/val_loss:  0.013923/  2.676429, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-69  lr=['0.0010930'], tr/val_loss:  0.013463/  2.683607, tr: 100.00%, val:  66.67%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-70  lr=['0.0010289'], tr/val_loss:  0.013114/  2.677970, tr: 100.00%, val:  66.67%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-71  lr=['0.0009662'], tr/val_loss:  0.012740/  2.686113, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-72  lr=['0.0009050'], tr/val_loss:  0.012499/  2.692322, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-73  lr=['0.0008453'], tr/val_loss:  0.013130/  2.714127, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-74  lr=['0.0007873'], tr/val_loss:  0.012079/  2.711015, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-75  lr=['0.0007310'], tr/val_loss:  0.011457/  2.715878, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-76  lr=['0.0006765'], tr/val_loss:  0.011511/  2.714624, tr: 100.00%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-77  lr=['0.0006237'], tr/val_loss:  0.011256/  2.704539, tr: 100.00%, val:  66.67%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-78  lr=['0.0005728'], tr/val_loss:  0.010722/  2.720843, tr: 100.00%, val:  66.67%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-79  lr=['0.0005238'], tr/val_loss:  0.010744/  2.716279, tr: 100.00%, val:  66.67%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-80  lr=['0.0004767'], tr/val_loss:  0.011192/  2.711767, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-81  lr=['0.0004316'], tr/val_loss:  0.010909/  2.717563, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-82  lr=['0.0003885'], tr/val_loss:  0.010555/  2.715659, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-83  lr=['0.0003476'], tr/val_loss:  0.010357/  2.718342, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-84  lr=['0.0003087'], tr/val_loss:  0.010130/  2.729035, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-85  lr=['0.0002720'], tr/val_loss:  0.010364/  2.713753, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-86  lr=['0.0002375'], tr/val_loss:  0.010244/  2.719462, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-87  lr=['0.0002053'], tr/val_loss:  0.010157/  2.725322, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-88  lr=['0.0001753'], tr/val_loss:  0.009856/  2.719307, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-89  lr=['0.0001476'], tr/val_loss:  0.010646/  2.717675, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-90  lr=['0.0001222'], tr/val_loss:  0.010176/  2.715851, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-91  lr=['0.0000991'], tr/val_loss:  0.009676/  2.718373, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-92  lr=['0.0000784'], tr/val_loss:  0.009855/  2.718480, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-93  lr=['0.0000601'], tr/val_loss:  0.009879/  2.722645, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-94  lr=['0.0000442'], tr/val_loss:  0.010076/  2.724360, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-95  lr=['0.0000307'], tr/val_loss:  0.009671/  2.724235, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-96  lr=['0.0000197'], tr/val_loss:  0.009545/  2.725654, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-97  lr=['0.0000111'], tr/val_loss:  0.009616/  2.726448, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-98  lr=['0.0000049'], tr/val_loss:  0.009732/  2.726023, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-99  lr=['0.0000012'], tr/val_loss:  0.009529/  2.726058, tr: 100.00%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd725edf5e54d8c814aa8e66c931de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▃▄▄▃▆▇██▆█▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▃▄▆▇▅▇▆▆▇▆▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▃▄▅▆▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▅▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▇▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▃▄▆▇▅▇▆▆▇▆▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▃▁▂▃▃▃▃▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00953</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.675</td></tr><tr><td>val_loss</td><td>2.72606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sweep-90</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hgg1y1r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hgg1y1r</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_170833-4hgg1y1r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jzeuerzl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0036021517786834025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.31013327299602356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.1040295953326091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_171727-jzeuerzl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzeuerzl' target=\"_blank\">flowing-sweep-92</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzeuerzl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzeuerzl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0036022'], tr/val_loss:  2.307851/  2.294594, tr:  10.21%, val:  12.92%, val_best:  12.92%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-1   lr=['0.0036013'], tr/val_loss:  2.162694/  1.941828, tr:  24.00%, val:  39.17%, val_best:  39.17%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-2   lr=['0.0035986'], tr/val_loss:  1.643233/  1.597050, tr:  46.27%, val:  48.75%, val_best:  48.75%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-3   lr=['0.0035942'], tr/val_loss:  1.353064/  1.473311, tr:  56.59%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-4   lr=['0.0035879'], tr/val_loss:  1.270507/  1.380692, tr:  56.69%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-5   lr=['0.0035800'], tr/val_loss:  1.177410/  1.345680, tr:  59.65%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-6   lr=['0.0035702'], tr/val_loss:  1.120476/  1.266299, tr:  63.13%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-7   lr=['0.0035588'], tr/val_loss:  1.078987/  1.316025, tr:  64.15%, val:  54.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-8   lr=['0.0035456'], tr/val_loss:  1.022560/  1.223670, tr:  64.25%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-9   lr=['0.0035306'], tr/val_loss:  0.975401/  1.273662, tr:  69.15%, val:  58.33%, val_best:  60.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-10  lr=['0.0035140'], tr/val_loss:  0.943567/  1.241205, tr:  70.07%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-11  lr=['0.0034957'], tr/val_loss:  0.932288/  1.215545, tr:  72.22%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-12  lr=['0.0034757'], tr/val_loss:  0.886019/  1.158224, tr:  74.36%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-13  lr=['0.0034540'], tr/val_loss:  0.871330/  1.191670, tr:  72.11%, val:  63.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-14  lr=['0.0034307'], tr/val_loss:  0.850679/  1.190717, tr:  73.95%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 13.12it/s]\n",
      "epoch-15  lr=['0.0034058'], tr/val_loss:  0.826999/  1.153424, tr:  74.77%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-16  lr=['0.0033794'], tr/val_loss:  0.802972/  1.195478, tr:  77.43%, val:  62.92%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 13.35it/s]\n",
      "epoch-17  lr=['0.0033513'], tr/val_loss:  0.789673/  1.175421, tr:  77.73%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 13.31it/s]\n",
      "epoch-18  lr=['0.0033218'], tr/val_loss:  0.768971/  1.170315, tr:  78.86%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 13.08it/s]\n",
      "epoch-19  lr=['0.0032907'], tr/val_loss:  0.732332/  1.204126, tr:  82.02%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-20  lr=['0.0032582'], tr/val_loss:  0.712539/  1.212058, tr:  82.02%, val:  70.42%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-21  lr=['0.0032242'], tr/val_loss:  0.692855/  1.250705, tr:  82.23%, val:  63.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:07<00:00,  8.50it/s]\n",
      "epoch-22  lr=['0.0031888'], tr/val_loss:  0.676343/  1.184036, tr:  84.78%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-23  lr=['0.0031521'], tr/val_loss:  0.660174/  1.279962, tr:  85.19%, val:  63.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-24  lr=['0.0031140'], tr/val_loss:  0.651784/  1.304974, tr:  83.35%, val:  62.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-25  lr=['0.0030746'], tr/val_loss:  0.644390/  1.244599, tr:  85.39%, val:  65.83%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-26  lr=['0.0030340'], tr/val_loss:  0.604214/  1.221737, tr:  89.27%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-27  lr=['0.0029921'], tr/val_loss:  0.605563/  1.292684, tr:  87.64%, val:  67.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-28  lr=['0.0029491'], tr/val_loss:  0.581972/  1.259852, tr:  88.56%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-29  lr=['0.0029050'], tr/val_loss:  0.570695/  1.323987, tr:  90.50%, val:  70.42%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-30  lr=['0.0028597'], tr/val_loss:  0.555028/  1.262366, tr:  90.40%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-31  lr=['0.0028134'], tr/val_loss:  0.520665/  1.304777, tr:  91.42%, val:  70.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-32  lr=['0.0027661'], tr/val_loss:  0.514047/  1.345225, tr:  91.32%, val:  68.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-33  lr=['0.0027179'], tr/val_loss:  0.494357/  1.342506, tr:  94.48%, val:  69.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-34  lr=['0.0026688'], tr/val_loss:  0.475480/  1.320126, tr:  94.38%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-35  lr=['0.0026187'], tr/val_loss:  0.479594/  1.357886, tr:  93.36%, val:  70.42%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-36  lr=['0.0025679'], tr/val_loss:  0.452420/  1.361848, tr:  95.30%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-37  lr=['0.0025164'], tr/val_loss:  0.450158/  1.407066, tr:  93.46%, val:  67.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-38  lr=['0.0024641'], tr/val_loss:  0.431613/  1.407384, tr:  96.22%, val:  70.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-39  lr=['0.0024112'], tr/val_loss:  0.417464/  1.431601, tr:  95.40%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-40  lr=['0.0023576'], tr/val_loss:  0.414923/  1.396532, tr:  96.53%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-41  lr=['0.0023036'], tr/val_loss:  0.403667/  1.440945, tr:  95.71%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-42  lr=['0.0022490'], tr/val_loss:  0.385224/  1.457868, tr:  97.14%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-43  lr=['0.0021940'], tr/val_loss:  0.373888/  1.474320, tr:  97.34%, val:  70.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-44  lr=['0.0021386'], tr/val_loss:  0.366974/  1.504927, tr:  98.16%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-45  lr=['0.0020828'], tr/val_loss:  0.360229/  1.528261, tr:  97.34%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-46  lr=['0.0020268'], tr/val_loss:  0.349772/  1.518351, tr:  98.88%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-47  lr=['0.0019706'], tr/val_loss:  0.341380/  1.551690, tr:  98.67%, val:  70.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-48  lr=['0.0019142'], tr/val_loss:  0.336567/  1.546715, tr:  98.57%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-49  lr=['0.0018576'], tr/val_loss:  0.329708/  1.558534, tr:  98.88%, val:  70.83%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-50  lr=['0.0018011'], tr/val_loss:  0.328928/  1.571175, tr:  98.06%, val:  70.83%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-51  lr=['0.0017445'], tr/val_loss:  0.315742/  1.595657, tr:  99.08%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-52  lr=['0.0016880'], tr/val_loss:  0.302944/  1.608403, tr:  99.59%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-53  lr=['0.0016316'], tr/val_loss:  0.302915/  1.625849, tr:  99.49%, val:  70.83%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-54  lr=['0.0015753'], tr/val_loss:  0.307207/  1.648663, tr:  99.08%, val:  69.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-55  lr=['0.0015193'], tr/val_loss:  0.282628/  1.652795, tr:  99.18%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-56  lr=['0.0014636'], tr/val_loss:  0.281609/  1.660389, tr:  98.77%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-57  lr=['0.0014082'], tr/val_loss:  0.267605/  1.691073, tr:  99.08%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-58  lr=['0.0013532'], tr/val_loss:  0.259630/  1.703789, tr:  99.49%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-59  lr=['0.0012986'], tr/val_loss:  0.258972/  1.729798, tr:  99.69%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-60  lr=['0.0012445'], tr/val_loss:  0.255602/  1.725437, tr:  99.39%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-61  lr=['0.0011910'], tr/val_loss:  0.252388/  1.757167, tr:  99.69%, val:  70.42%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-62  lr=['0.0011381'], tr/val_loss:  0.244441/  1.735047, tr:  99.59%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-63  lr=['0.0010858'], tr/val_loss:  0.247730/  1.741387, tr:  99.49%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-64  lr=['0.0010342'], tr/val_loss:  0.235152/  1.764859, tr:  99.69%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-65  lr=['0.0009834'], tr/val_loss:  0.231455/  1.773608, tr:  99.90%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-66  lr=['0.0009334'], tr/val_loss:  0.233096/  1.760047, tr:  99.80%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-67  lr=['0.0008843'], tr/val_loss:  0.230012/  1.775820, tr:  99.69%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-68  lr=['0.0008360'], tr/val_loss:  0.222669/  1.811305, tr:  99.69%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-69  lr=['0.0007887'], tr/val_loss:  0.218297/  1.825286, tr:  99.59%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-70  lr=['0.0007424'], tr/val_loss:  0.217899/  1.825182, tr:  99.80%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-71  lr=['0.0006972'], tr/val_loss:  0.219619/  1.806513, tr:  99.90%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-72  lr=['0.0006530'], tr/val_loss:  0.209921/  1.828590, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-73  lr=['0.0006100'], tr/val_loss:  0.214412/  1.815188, tr:  99.90%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-74  lr=['0.0005682'], tr/val_loss:  0.205258/  1.840124, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-75  lr=['0.0005275'], tr/val_loss:  0.205835/  1.830306, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-76  lr=['0.0004881'], tr/val_loss:  0.203864/  1.846857, tr:  99.90%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-77  lr=['0.0004501'], tr/val_loss:  0.201926/  1.848682, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-78  lr=['0.0004133'], tr/val_loss:  0.197861/  1.845446, tr:  99.80%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-79  lr=['0.0003779'], tr/val_loss:  0.198617/  1.849484, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-80  lr=['0.0003440'], tr/val_loss:  0.198623/  1.854926, tr: 100.00%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-81  lr=['0.0003114'], tr/val_loss:  0.194521/  1.853147, tr: 100.00%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-82  lr=['0.0002804'], tr/val_loss:  0.196764/  1.855543, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-83  lr=['0.0002508'], tr/val_loss:  0.190380/  1.870056, tr: 100.00%, val:  75.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-84  lr=['0.0002228'], tr/val_loss:  0.188880/  1.877748, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-85  lr=['0.0001963'], tr/val_loss:  0.187263/  1.871391, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-86  lr=['0.0001714'], tr/val_loss:  0.189327/  1.872132, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-87  lr=['0.0001481'], tr/val_loss:  0.190735/  1.873935, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-88  lr=['0.0001265'], tr/val_loss:  0.187644/  1.874154, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-89  lr=['0.0001065'], tr/val_loss:  0.187472/  1.867007, tr: 100.00%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-90  lr=['0.0000882'], tr/val_loss:  0.187392/  1.870981, tr: 100.00%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-91  lr=['0.0000715'], tr/val_loss:  0.189899/  1.874496, tr: 100.00%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-92  lr=['0.0000566'], tr/val_loss:  0.189529/  1.876212, tr: 100.00%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-93  lr=['0.0000434'], tr/val_loss:  0.187299/  1.877991, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-94  lr=['0.0000319'], tr/val_loss:  0.190043/  1.874808, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-95  lr=['0.0000222'], tr/val_loss:  0.187905/  1.877071, tr: 100.00%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-96  lr=['0.0000142'], tr/val_loss:  0.186239/  1.876227, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-97  lr=['0.0000080'], tr/val_loss:  0.185332/  1.876917, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-98  lr=['0.0000036'], tr/val_loss:  0.186448/  1.877836, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-99  lr=['0.0000009'], tr/val_loss:  0.186497/  1.877273, tr: 100.00%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1bc41cc29b46b0b0b2311221d390d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▄▅▅▅▆▇▇▇▆▆█▇▇█▇▇█▇███████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▇▇▇█▇▇█▇▇▇▇███▇██▇██▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▇▇▇█▇▇█▇▇▇▇███▇██▇██▇██████████████</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▁▁▁▁▂▂▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.1865</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>1.87727</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-sweep-92</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzeuerzl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jzeuerzl</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_171727-jzeuerzl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 99x1zr6a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.032831838712809217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.5694993160575861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.8558879178363168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_172625-99x1zr6a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/99x1zr6a' target=\"_blank\">zesty-sweep-94</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/99x1zr6a' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/99x1zr6a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0328318'], tr/val_loss:  1.902127/  1.717291, tr:  32.79%, val:  38.75%, val_best:  38.75%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-1   lr=['0.0328237'], tr/val_loss:  1.454853/  1.361942, tr:  52.20%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-2   lr=['0.0327994'], tr/val_loss:  1.125050/  1.805683, tr:  62.21%, val:  53.75%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-3   lr=['0.0327590'], tr/val_loss:  1.036145/  1.599099, tr:  66.60%, val:  50.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-4   lr=['0.0327024'], tr/val_loss:  1.043208/  1.365896, tr:  66.70%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-5   lr=['0.0326297'], tr/val_loss:  0.894124/  1.430121, tr:  70.68%, val:  58.75%, val_best:  60.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-6   lr=['0.0325411'], tr/val_loss:  0.801897/  1.487185, tr:  73.03%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-7   lr=['0.0324365'], tr/val_loss:  0.760444/  1.477635, tr:  74.97%, val:  60.00%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-8   lr=['0.0323161'], tr/val_loss:  0.639952/  1.382403, tr:  78.75%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-9   lr=['0.0321800'], tr/val_loss:  0.523068/  1.623553, tr:  83.86%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-10  lr=['0.0320284'], tr/val_loss:  0.451074/  1.728707, tr:  85.29%, val:  64.58%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-11  lr=['0.0318613'], tr/val_loss:  0.416154/  1.809587, tr:  85.90%, val:  64.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-12  lr=['0.0316791'], tr/val_loss:  0.376972/  1.739032, tr:  90.40%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-13  lr=['0.0314817'], tr/val_loss:  0.304347/  1.654772, tr:  92.34%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-14  lr=['0.0312695'], tr/val_loss:  0.225546/  1.724229, tr:  95.40%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-15  lr=['0.0310426'], tr/val_loss:  0.228107/  2.075944, tr:  94.18%, val:  71.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-16  lr=['0.0308013'], tr/val_loss:  0.149005/  1.974439, tr:  98.16%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-17  lr=['0.0305458'], tr/val_loss:  0.195704/  1.763394, tr:  96.22%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-18  lr=['0.0302763'], tr/val_loss:  0.150675/  1.782660, tr:  97.04%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.32it/s]\n",
      "epoch-19  lr=['0.0299932'], tr/val_loss:  0.092998/  1.998863, tr:  99.59%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.27it/s]\n",
      "epoch-20  lr=['0.0296967'], tr/val_loss:  0.050552/  2.055367, tr:  99.80%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.47it/s]\n",
      "epoch-21  lr=['0.0293870'], tr/val_loss:  0.017443/  2.336895, tr: 100.00%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.10it/s]\n",
      "epoch-22  lr=['0.0290646'], tr/val_loss:  0.011556/  2.322811, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-23  lr=['0.0287297'], tr/val_loss:  0.007507/  2.383920, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-24  lr=['0.0283826'], tr/val_loss:  0.003050/  2.436336, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-25  lr=['0.0280237'], tr/val_loss:  0.002167/  2.471017, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-26  lr=['0.0276534'], tr/val_loss:  0.001852/  2.506687, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-27  lr=['0.0272720'], tr/val_loss:  0.001095/  2.542669, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-28  lr=['0.0268798'], tr/val_loss:  0.000824/  2.566216, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-29  lr=['0.0264774'], tr/val_loss:  0.000732/  2.601558, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-30  lr=['0.0260650'], tr/val_loss:  0.000642/  2.611765, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-31  lr=['0.0256430'], tr/val_loss:  0.000562/  2.630610, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-32  lr=['0.0252120'], tr/val_loss:  0.000510/  2.621460, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-33  lr=['0.0247723'], tr/val_loss:  0.000465/  2.625465, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-34  lr=['0.0243243'], tr/val_loss:  0.000409/  2.644592, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-35  lr=['0.0238686'], tr/val_loss:  0.000419/  2.652063, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-36  lr=['0.0234055'], tr/val_loss:  0.000365/  2.664681, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-37  lr=['0.0229355'], tr/val_loss:  0.000328/  2.676049, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-38  lr=['0.0224590'], tr/val_loss:  0.000331/  2.687424, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n",
      "epoch-39  lr=['0.0219766'], tr/val_loss:  0.000314/  2.683931, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-40  lr=['0.0214887'], tr/val_loss:  0.000294/  2.685572, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-41  lr=['0.0209958'], tr/val_loss:  0.000290/  2.711638, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-42  lr=['0.0204984'], tr/val_loss:  0.000292/  2.722273, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-43  lr=['0.0199969'], tr/val_loss:  0.000296/  2.736644, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-44  lr=['0.0194920'], tr/val_loss:  0.000272/  2.742073, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-45  lr=['0.0189839'], tr/val_loss:  0.000279/  2.751116, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-46  lr=['0.0184734'], tr/val_loss:  0.000273/  2.757740, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-47  lr=['0.0179608'], tr/val_loss:  0.000263/  2.760236, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-48  lr=['0.0174467'], tr/val_loss:  0.000262/  2.770919, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-49  lr=['0.0169316'], tr/val_loss:  0.000249/  2.770565, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-50  lr=['0.0164159'], tr/val_loss:  0.000265/  2.763096, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-51  lr=['0.0159003'], tr/val_loss:  0.000243/  2.769405, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-52  lr=['0.0153852'], tr/val_loss:  0.000237/  2.765633, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-53  lr=['0.0148710'], tr/val_loss:  0.000236/  2.772327, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-54  lr=['0.0143585'], tr/val_loss:  0.000226/  2.777311, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-55  lr=['0.0138479'], tr/val_loss:  0.000221/  2.787588, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-56  lr=['0.0133399'], tr/val_loss:  0.000214/  2.779516, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-57  lr=['0.0128349'], tr/val_loss:  0.000251/  2.782750, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-58  lr=['0.0123334'], tr/val_loss:  0.000243/  2.780762, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-59  lr=['0.0118360'], tr/val_loss:  0.000220/  2.780278, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-60  lr=['0.0113431'], tr/val_loss:  0.000206/  2.785869, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-61  lr=['0.0108552'], tr/val_loss:  0.000205/  2.786949, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]\n",
      "epoch-62  lr=['0.0103728'], tr/val_loss:  0.000195/  2.793794, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-63  lr=['0.0098964'], tr/val_loss:  0.000205/  2.796248, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-64  lr=['0.0094264'], tr/val_loss:  0.000200/  2.796075, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-65  lr=['0.0089632'], tr/val_loss:  0.000195/  2.802131, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-66  lr=['0.0085075'], tr/val_loss:  0.000184/  2.808827, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-67  lr=['0.0080595'], tr/val_loss:  0.000194/  2.808777, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-68  lr=['0.0076198'], tr/val_loss:  0.000203/  2.815206, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-69  lr=['0.0071888'], tr/val_loss:  0.000200/  2.816361, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-70  lr=['0.0067669'], tr/val_loss:  0.000175/  2.820096, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-71  lr=['0.0063545'], tr/val_loss:  0.000188/  2.826138, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-72  lr=['0.0059520'], tr/val_loss:  0.000188/  2.829427, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-73  lr=['0.0055599'], tr/val_loss:  0.000197/  2.833303, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-74  lr=['0.0051784'], tr/val_loss:  0.000176/  2.842677, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-75  lr=['0.0048081'], tr/val_loss:  0.000174/  2.845492, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-76  lr=['0.0044492'], tr/val_loss:  0.000181/  2.846130, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-77  lr=['0.0041022'], tr/val_loss:  0.000171/  2.850559, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-78  lr=['0.0037672'], tr/val_loss:  0.000169/  2.851976, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-79  lr=['0.0034448'], tr/val_loss:  0.000183/  2.852527, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-80  lr=['0.0031352'], tr/val_loss:  0.000168/  2.851302, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-81  lr=['0.0028386'], tr/val_loss:  0.000169/  2.855086, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-82  lr=['0.0025555'], tr/val_loss:  0.000169/  2.855074, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-83  lr=['0.0022860'], tr/val_loss:  0.000167/  2.854419, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-84  lr=['0.0020305'], tr/val_loss:  0.000164/  2.858237, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-85  lr=['0.0017892'], tr/val_loss:  0.000162/  2.860051, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-86  lr=['0.0015624'], tr/val_loss:  0.000163/  2.857473, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-87  lr=['0.0013501'], tr/val_loss:  0.000165/  2.858339, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-88  lr=['0.0011528'], tr/val_loss:  0.000165/  2.859234, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-89  lr=['0.0009705'], tr/val_loss:  0.000166/  2.857129, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-90  lr=['0.0008035'], tr/val_loss:  0.000162/  2.859970, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-91  lr=['0.0006518'], tr/val_loss:  0.000171/  2.859314, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-92  lr=['0.0005157'], tr/val_loss:  0.000164/  2.859342, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-93  lr=['0.0003953'], tr/val_loss:  0.000164/  2.859418, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-94  lr=['0.0002908'], tr/val_loss:  0.000166/  2.859752, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-95  lr=['0.0002021'], tr/val_loss:  0.000164/  2.860554, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-96  lr=['0.0001294'], tr/val_loss:  0.000162/  2.860570, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-97  lr=['0.0000729'], tr/val_loss:  0.000164/  2.861814, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-98  lr=['0.0000324'], tr/val_loss:  0.000183/  2.861817, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-99  lr=['0.0000081'], tr/val_loss:  0.000160/  2.861816, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa34cce57814905ae75e32518e9ca59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▆▆▄█▆█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▅▅▆▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▆▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▅▅▆▇▇▇▇██████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▃▁▂▂▃▃▃▄▆▆▆▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00016</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.86182</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-94</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/99x1zr6a' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/99x1zr6a</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_172625-99x1zr6a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 53z2ybyw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07684136478972096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.092764972980634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.7194856709609685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_173517-53z2ybyw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53z2ybyw' target=\"_blank\">winter-sweep-96</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53z2ybyw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53z2ybyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0768414'], tr/val_loss:  1.926088/  1.753418, tr:  32.89%, val:  40.83%, val_best:  40.83%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-1   lr=['0.0768224'], tr/val_loss:  1.670161/  1.874067, tr:  41.88%, val:  46.67%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-2   lr=['0.0767656'], tr/val_loss:  1.578176/  1.890534, tr:  46.58%, val:  40.83%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 13.10it/s]\n",
      "epoch-3   lr=['0.0766709'], tr/val_loss:  1.435623/  1.438606, tr:  50.26%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-4   lr=['0.0765384'], tr/val_loss:  1.498105/  1.760965, tr:  51.38%, val:  45.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-5   lr=['0.0763683'], tr/val_loss:  1.439112/  1.850528, tr:  50.77%, val:  47.50%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-6   lr=['0.0761608'], tr/val_loss:  1.377018/  1.579835, tr:  54.44%, val:  48.75%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-7   lr=['0.0759161'], tr/val_loss:  1.386116/  1.716554, tr:  51.89%, val:  47.08%, val_best:  50.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-8   lr=['0.0756343'], tr/val_loss:  1.342061/  1.602610, tr:  56.59%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-9   lr=['0.0753158'], tr/val_loss:  1.195750/  1.768127, tr:  58.22%, val:  49.17%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-10  lr=['0.0749609'], tr/val_loss:  1.147615/  1.636732, tr:  60.88%, val:  53.75%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-11  lr=['0.0745700'], tr/val_loss:  1.238200/  1.581372, tr:  59.35%, val:  50.42%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-12  lr=['0.0741433'], tr/val_loss:  1.161772/  1.548087, tr:  59.24%, val:  51.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-13  lr=['0.0736814'], tr/val_loss:  1.109728/  1.580303, tr:  62.92%, val:  50.83%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-14  lr=['0.0731848'], tr/val_loss:  1.090304/  1.531054, tr:  60.37%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-15  lr=['0.0726538'], tr/val_loss:  1.180831/  1.496333, tr:  60.78%, val:  56.67%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-16  lr=['0.0720890'], tr/val_loss:  1.087509/  1.665692, tr:  64.25%, val:  57.08%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-17  lr=['0.0714910'], tr/val_loss:  1.207012/  1.702538, tr:  60.06%, val:  53.33%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-18  lr=['0.0708603'], tr/val_loss:  1.154797/  1.585260, tr:  61.18%, val:  48.75%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-19  lr=['0.0701977'], tr/val_loss:  1.029095/  1.455140, tr:  65.68%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 13.17it/s]\n",
      "epoch-20  lr=['0.0695037'], tr/val_loss:  0.957026/  1.386178, tr:  67.21%, val:  58.33%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-21  lr=['0.0687790'], tr/val_loss:  0.959106/  1.774896, tr:  66.91%, val:  50.83%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]\n",
      "epoch-22  lr=['0.0680243'], tr/val_loss:  0.988256/  1.293279, tr:  67.11%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-23  lr=['0.0672405'], tr/val_loss:  0.897736/  1.450324, tr:  69.87%, val:  57.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-24  lr=['0.0664282'], tr/val_loss:  0.918676/  1.513321, tr:  70.07%, val:  58.75%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-25  lr=['0.0655882'], tr/val_loss:  0.856328/  1.456823, tr:  73.24%, val:  53.33%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-26  lr=['0.0647214'], tr/val_loss:  0.851994/  1.555982, tr:  70.48%, val:  56.25%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-27  lr=['0.0638287'], tr/val_loss:  0.845870/  1.388484, tr:  71.40%, val:  63.33%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-28  lr=['0.0629109'], tr/val_loss:  0.804589/  1.393846, tr:  72.73%, val:  62.50%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-29  lr=['0.0619690'], tr/val_loss:  0.774575/  1.605229, tr:  72.93%, val:  58.75%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-30  lr=['0.0610038'], tr/val_loss:  0.820567/  1.464134, tr:  71.91%, val:  63.75%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-31  lr=['0.0600163'], tr/val_loss:  0.748957/  1.605184, tr:  73.44%, val:  58.75%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-32  lr=['0.0590075'], tr/val_loss:  0.766067/  1.631663, tr:  72.73%, val:  58.75%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-33  lr=['0.0579784'], tr/val_loss:  0.758424/  1.616762, tr:  70.79%, val:  59.17%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-34  lr=['0.0569300'], tr/val_loss:  0.690316/  1.574174, tr:  74.87%, val:  60.83%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-35  lr=['0.0558633'], tr/val_loss:  0.681924/  1.627349, tr:  73.44%, val:  59.58%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-36  lr=['0.0547794'], tr/val_loss:  0.693902/  1.689869, tr:  76.40%, val:  59.58%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-37  lr=['0.0536794'], tr/val_loss:  0.710754/  1.544073, tr:  75.69%, val:  62.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-38  lr=['0.0525643'], tr/val_loss:  0.665694/  1.554807, tr:  74.46%, val:  67.08%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-39  lr=['0.0514352'], tr/val_loss:  0.620896/  1.646376, tr:  78.35%, val:  58.33%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-40  lr=['0.0502933'], tr/val_loss:  0.653154/  1.502123, tr:  74.57%, val:  62.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-41  lr=['0.0491397'], tr/val_loss:  0.604778/  1.591054, tr:  78.04%, val:  65.42%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-42  lr=['0.0479755'], tr/val_loss:  0.586824/  1.761264, tr:  79.37%, val:  61.67%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-43  lr=['0.0468019'], tr/val_loss:  0.561926/  1.626562, tr:  80.90%, val:  62.50%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-44  lr=['0.0456200'], tr/val_loss:  0.571971/  1.665525, tr:  80.29%, val:  65.83%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-45  lr=['0.0444310'], tr/val_loss:  0.580030/  1.552593, tr:  78.14%, val:  64.58%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-46  lr=['0.0432361'], tr/val_loss:  0.520144/  1.841534, tr:  80.59%, val:  62.08%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-47  lr=['0.0420364'], tr/val_loss:  0.565526/  1.614166, tr:  80.39%, val:  65.83%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-48  lr=['0.0408331'], tr/val_loss:  0.562251/  1.718221, tr:  79.98%, val:  63.75%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-49  lr=['0.0396275'], tr/val_loss:  0.525878/  1.617487, tr:  82.02%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-50  lr=['0.0384207'], tr/val_loss:  0.493862/  1.739088, tr:  84.47%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-51  lr=['0.0372139'], tr/val_loss:  0.490918/  1.597919, tr:  85.60%, val:  64.58%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-52  lr=['0.0360082'], tr/val_loss:  0.459869/  1.711944, tr:  85.09%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-53  lr=['0.0348050'], tr/val_loss:  0.455693/  1.841600, tr:  86.93%, val:  62.50%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-54  lr=['0.0336053'], tr/val_loss:  0.472770/  1.677494, tr:  86.31%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-55  lr=['0.0324104'], tr/val_loss:  0.417707/  1.736981, tr:  88.87%, val:  64.58%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-56  lr=['0.0312214'], tr/val_loss:  0.379726/  1.714837, tr:  89.99%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-57  lr=['0.0300395'], tr/val_loss:  0.384183/  1.777413, tr:  90.91%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-58  lr=['0.0288658'], tr/val_loss:  0.356619/  1.733553, tr:  92.75%, val:  70.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-59  lr=['0.0277017'], tr/val_loss:  0.325152/  1.842014, tr:  93.46%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-60  lr=['0.0265480'], tr/val_loss:  0.324021/  1.757032, tr:  93.26%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-61  lr=['0.0254061'], tr/val_loss:  0.301647/  1.878928, tr:  94.08%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-62  lr=['0.0242771'], tr/val_loss:  0.284602/  1.833756, tr:  96.53%, val:  69.58%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-63  lr=['0.0231620'], tr/val_loss:  0.315960/  1.841418, tr:  94.59%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-64  lr=['0.0220620'], tr/val_loss:  0.276625/  1.889101, tr:  95.51%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-65  lr=['0.0209781'], tr/val_loss:  0.256710/  1.932937, tr:  97.65%, val:  70.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-66  lr=['0.0199114'], tr/val_loss:  0.244554/  1.890312, tr:  96.73%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-67  lr=['0.0188630'], tr/val_loss:  0.227892/  1.914205, tr:  97.24%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-68  lr=['0.0178339'], tr/val_loss:  0.225410/  1.970732, tr:  97.34%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-69  lr=['0.0168251'], tr/val_loss:  0.228520/  2.004776, tr:  97.04%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-70  lr=['0.0158376'], tr/val_loss:  0.213964/  1.994975, tr:  97.24%, val:  68.33%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-71  lr=['0.0148724'], tr/val_loss:  0.198738/  1.946515, tr:  98.26%, val:  70.83%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-72  lr=['0.0139304'], tr/val_loss:  0.187195/  1.974406, tr:  98.37%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-73  lr=['0.0130126'], tr/val_loss:  0.200156/  2.026263, tr:  98.77%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-74  lr=['0.0121199'], tr/val_loss:  0.181950/  2.037928, tr:  99.08%, val:  70.83%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-75  lr=['0.0112532'], tr/val_loss:  0.169175/  2.022714, tr:  99.08%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-76  lr=['0.0104132'], tr/val_loss:  0.160550/  2.068079, tr:  98.77%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-77  lr=['0.0096009'], tr/val_loss:  0.160034/  2.068340, tr:  99.28%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-78  lr=['0.0088170'], tr/val_loss:  0.148541/  2.070894, tr:  99.28%, val:  73.75%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-79  lr=['0.0080624'], tr/val_loss:  0.143326/  2.060385, tr:  99.28%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-80  lr=['0.0073377'], tr/val_loss:  0.144564/  2.092858, tr:  99.08%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-81  lr=['0.0066437'], tr/val_loss:  0.137231/  2.113085, tr:  99.49%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-82  lr=['0.0059810'], tr/val_loss:  0.136097/  2.098297, tr:  99.49%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-83  lr=['0.0053504'], tr/val_loss:  0.137752/  2.134702, tr:  99.49%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-84  lr=['0.0047524'], tr/val_loss:  0.129152/  2.113472, tr:  99.69%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-85  lr=['0.0041876'], tr/val_loss:  0.128391/  2.122841, tr:  99.49%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-86  lr=['0.0036566'], tr/val_loss:  0.127024/  2.140415, tr:  99.80%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-87  lr=['0.0031599'], tr/val_loss:  0.123943/  2.136019, tr:  99.59%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-88  lr=['0.0026980'], tr/val_loss:  0.125049/  2.131541, tr:  99.49%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-89  lr=['0.0022714'], tr/val_loss:  0.121156/  2.140573, tr:  99.90%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-90  lr=['0.0018804'], tr/val_loss:  0.121869/  2.132955, tr:  99.49%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-91  lr=['0.0015255'], tr/val_loss:  0.124549/  2.126578, tr:  99.59%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-92  lr=['0.0012071'], tr/val_loss:  0.122197/  2.123396, tr:  99.59%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-93  lr=['0.0009253'], tr/val_loss:  0.124020/  2.120323, tr:  99.39%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-94  lr=['0.0006805'], tr/val_loss:  0.119796/  2.119979, tr:  99.59%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-95  lr=['0.0004730'], tr/val_loss:  0.120216/  2.127306, tr:  99.59%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-96  lr=['0.0003030'], tr/val_loss:  0.117785/  2.125975, tr:  99.69%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-97  lr=['0.0001705'], tr/val_loss:  0.120019/  2.125174, tr:  99.69%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-98  lr=['0.0000758'], tr/val_loss:  0.123693/  2.125134, tr:  99.69%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-99  lr=['0.0000190'], tr/val_loss:  0.118612/  2.124364, tr:  99.69%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93d5edd04134736aa78abfc1733dba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▃▄▄▃▄▃▅▇▅▆▃▅▅▃▆▇▅▇▇▅▇█▇████████▇█████▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▂▃▃▄▄▅▃▅▄▅▅▅▅▄▅▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>tr_acc</td><td>▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▂▃▃▄▄▅▃▅▄▅▅▅▅▄▅▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>val_loss</td><td>▄▅▄▄▄▂▂▄▁▄▂▂▃▃▃▂▃▄▃▃▃▄▃▄▅▅▆▆▇▆▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99694</td></tr><tr><td>tr_epoch_loss</td><td>0.11861</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>2.12436</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-sweep-96</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53z2ybyw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/53z2ybyw</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_173517-53z2ybyw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x2b8uw8q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.012058953871422789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.2997718169962316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.7128644540750035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_174415-x2b8uw8q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x2b8uw8q' target=\"_blank\">summer-sweep-98</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x2b8uw8q' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x2b8uw8q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0120590'], tr/val_loss:  2.022365/  1.467528, tr:  25.43%, val:  42.50%, val_best:  42.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-1   lr=['0.0120560'], tr/val_loss:  1.321527/  1.419282, tr:  54.65%, val:  51.25%, val_best:  51.25%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-2   lr=['0.0120471'], tr/val_loss:  1.097791/  1.293262, tr:  60.88%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-3   lr=['0.0120322'], tr/val_loss:  0.975187/  1.364878, tr:  66.80%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-4   lr=['0.0120114'], tr/val_loss:  0.945206/  1.184062, tr:  67.31%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-5   lr=['0.0119847'], tr/val_loss:  0.834653/  1.376556, tr:  70.48%, val:  55.83%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-6   lr=['0.0119522'], tr/val_loss:  0.804459/  1.326016, tr:  70.38%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-7   lr=['0.0119137'], tr/val_loss:  0.756441/  1.435270, tr:  73.14%, val:  62.50%, val_best:  63.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-8   lr=['0.0118695'], tr/val_loss:  0.659997/  1.358154, tr:  76.20%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-9   lr=['0.0118195'], tr/val_loss:  0.610007/  1.515455, tr:  77.63%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-10  lr=['0.0117639'], tr/val_loss:  0.509434/  1.603291, tr:  84.88%, val:  64.17%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-11  lr=['0.0117025'], tr/val_loss:  0.481606/  1.561039, tr:  84.78%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-12  lr=['0.0116355'], tr/val_loss:  0.517972/  1.369925, tr:  84.98%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-13  lr=['0.0115631'], tr/val_loss:  0.438379/  1.475937, tr:  86.82%, val:  68.75%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-14  lr=['0.0114851'], tr/val_loss:  0.430715/  1.526192, tr:  89.48%, val:  66.25%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-15  lr=['0.0114018'], tr/val_loss:  0.479675/  1.526404, tr:  87.13%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-16  lr=['0.0113131'], tr/val_loss:  0.331459/  1.862152, tr:  93.56%, val:  66.67%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-17  lr=['0.0112193'], tr/val_loss:  0.407912/  1.395267, tr:  88.66%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-18  lr=['0.0111203'], tr/val_loss:  0.339423/  1.583127, tr:  91.73%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-19  lr=['0.0110163'], tr/val_loss:  0.249985/  1.569939, tr:  97.45%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-20  lr=['0.0109074'], tr/val_loss:  0.202804/  1.595064, tr:  96.53%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.12it/s]\n",
      "epoch-21  lr=['0.0107937'], tr/val_loss:  0.126812/  1.953283, tr:  99.28%, val:  70.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-22  lr=['0.0106753'], tr/val_loss:  0.124113/  1.813017, tr:  98.98%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.24it/s]\n",
      "epoch-23  lr=['0.0105523'], tr/val_loss:  0.109901/  1.773654, tr:  98.77%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.44it/s]\n",
      "epoch-24  lr=['0.0104248'], tr/val_loss:  0.068890/  1.919054, tr:  99.80%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-25  lr=['0.0102930'], tr/val_loss:  0.055444/  1.989687, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-26  lr=['0.0101569'], tr/val_loss:  0.035416/  2.039987, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-27  lr=['0.0100168'], tr/val_loss:  0.015674/  2.037116, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-28  lr=['0.0098728'], tr/val_loss:  0.009429/  2.051688, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-29  lr=['0.0097250'], tr/val_loss:  0.006855/  2.139484, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-30  lr=['0.0095735'], tr/val_loss:  0.004185/  2.160777, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-31  lr=['0.0094185'], tr/val_loss:  0.003074/  2.148945, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-32  lr=['0.0092602'], tr/val_loss:  0.002462/  2.193243, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-33  lr=['0.0090987'], tr/val_loss:  0.001736/  2.215487, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-34  lr=['0.0089342'], tr/val_loss:  0.001638/  2.241041, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-35  lr=['0.0087668'], tr/val_loss:  0.001361/  2.233291, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-36  lr=['0.0085967'], tr/val_loss:  0.001205/  2.254459, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-37  lr=['0.0084241'], tr/val_loss:  0.001173/  2.284992, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-38  lr=['0.0082491'], tr/val_loss:  0.001089/  2.297730, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-39  lr=['0.0080719'], tr/val_loss:  0.001178/  2.286289, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-40  lr=['0.0078927'], tr/val_loss:  0.000887/  2.320496, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-41  lr=['0.0077116'], tr/val_loss:  0.000858/  2.324199, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-42  lr=['0.0075289'], tr/val_loss:  0.000836/  2.320660, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-43  lr=['0.0073448'], tr/val_loss:  0.000748/  2.321857, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-44  lr=['0.0071593'], tr/val_loss:  0.000674/  2.336365, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-45  lr=['0.0069727'], tr/val_loss:  0.000674/  2.343723, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-46  lr=['0.0067852'], tr/val_loss:  0.000634/  2.338922, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-47  lr=['0.0065969'], tr/val_loss:  0.000647/  2.351527, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-48  lr=['0.0064081'], tr/val_loss:  0.000642/  2.357311, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-49  lr=['0.0062189'], tr/val_loss:  0.000574/  2.356960, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-50  lr=['0.0060295'], tr/val_loss:  0.000576/  2.366043, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-51  lr=['0.0058401'], tr/val_loss:  0.000547/  2.367490, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-52  lr=['0.0056509'], tr/val_loss:  0.000525/  2.367941, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-53  lr=['0.0054621'], tr/val_loss:  0.000509/  2.373149, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-54  lr=['0.0052738'], tr/val_loss:  0.000506/  2.377031, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-55  lr=['0.0050863'], tr/val_loss:  0.000491/  2.377477, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-56  lr=['0.0048997'], tr/val_loss:  0.000484/  2.384815, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-57  lr=['0.0047142'], tr/val_loss:  0.000462/  2.391078, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-58  lr=['0.0045300'], tr/val_loss:  0.000456/  2.379997, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-59  lr=['0.0043473'], tr/val_loss:  0.000447/  2.377702, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-60  lr=['0.0041663'], tr/val_loss:  0.000455/  2.386015, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-61  lr=['0.0039871'], tr/val_loss:  0.000450/  2.387228, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-62  lr=['0.0038099'], tr/val_loss:  0.000441/  2.391899, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-63  lr=['0.0036349'], tr/val_loss:  0.000463/  2.379336, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-64  lr=['0.0034623'], tr/val_loss:  0.000445/  2.377318, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-65  lr=['0.0032922'], tr/val_loss:  0.000438/  2.377986, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-66  lr=['0.0031248'], tr/val_loss:  0.000431/  2.380477, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-67  lr=['0.0029602'], tr/val_loss:  0.000428/  2.379183, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-68  lr=['0.0027987'], tr/val_loss:  0.000430/  2.388294, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-69  lr=['0.0026404'], tr/val_loss:  0.000429/  2.388939, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-70  lr=['0.0024854'], tr/val_loss:  0.000420/  2.383352, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-71  lr=['0.0023340'], tr/val_loss:  0.000414/  2.384899, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-72  lr=['0.0021861'], tr/val_loss:  0.000409/  2.384256, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-73  lr=['0.0020421'], tr/val_loss:  0.000422/  2.387696, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-74  lr=['0.0019020'], tr/val_loss:  0.000409/  2.390312, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-75  lr=['0.0017660'], tr/val_loss:  0.000413/  2.389009, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-76  lr=['0.0016342'], tr/val_loss:  0.000419/  2.390938, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-77  lr=['0.0015067'], tr/val_loss:  0.000403/  2.389154, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-78  lr=['0.0013837'], tr/val_loss:  0.000404/  2.388352, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-79  lr=['0.0012653'], tr/val_loss:  0.000397/  2.390105, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-80  lr=['0.0011515'], tr/val_loss:  0.000403/  2.394347, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-81  lr=['0.0010426'], tr/val_loss:  0.000402/  2.395429, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-82  lr=['0.0009386'], tr/val_loss:  0.000400/  2.395079, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-83  lr=['0.0008397'], tr/val_loss:  0.000392/  2.394907, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-84  lr=['0.0007458'], tr/val_loss:  0.000387/  2.395458, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-85  lr=['0.0006572'], tr/val_loss:  0.000392/  2.397830, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-86  lr=['0.0005738'], tr/val_loss:  0.000387/  2.397981, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-87  lr=['0.0004959'], tr/val_loss:  0.000387/  2.395777, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-88  lr=['0.0004234'], tr/val_loss:  0.000395/  2.395489, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-89  lr=['0.0003565'], tr/val_loss:  0.000384/  2.395732, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-90  lr=['0.0002951'], tr/val_loss:  0.000378/  2.398781, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-91  lr=['0.0002394'], tr/val_loss:  0.000406/  2.399311, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-92  lr=['0.0001894'], tr/val_loss:  0.000384/  2.399520, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-93  lr=['0.0001452'], tr/val_loss:  0.000387/  2.399587, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-94  lr=['0.0001068'], tr/val_loss:  0.000385/  2.399324, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-95  lr=['0.0000742'], tr/val_loss:  0.000388/  2.400403, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-96  lr=['0.0000475'], tr/val_loss:  0.000385/  2.399357, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-97  lr=['0.0000268'], tr/val_loss:  0.000384/  2.399365, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-98  lr=['0.0000119'], tr/val_loss:  0.000395/  2.399556, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-99  lr=['0.0000030'], tr/val_loss:  0.000380/  2.400430, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e557353806e34e848672639ba2d8e6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▆▄▅▆▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▅▅▇▅▆▇▆██████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▅▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▅▅▇▅▆▇▆██████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▂▃▂▃▂▃▅▅▆▆▇▇▇▇███████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00038</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.40043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-98</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x2b8uw8q' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x2b8uw8q</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_174415-x2b8uw8q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 87t0uvcy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009687149722953342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.8558116309507504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6014679405734136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_175322-87t0uvcy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/87t0uvcy' target=\"_blank\">peach-sweep-100</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/87t0uvcy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/87t0uvcy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0096871'], tr/val_loss:  2.317081/  2.315732, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-1   lr=['0.0096848'], tr/val_loss:  1.961347/  1.583780, tr:  29.01%, val:  48.75%, val_best:  48.75%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-2   lr=['0.0096776'], tr/val_loss:  1.269793/  1.459801, tr:  53.32%, val:  43.75%, val_best:  48.75%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-3   lr=['0.0096657'], tr/val_loss:  1.126667/  1.402333, tr:  61.39%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-4   lr=['0.0096490'], tr/val_loss:  1.128826/  1.319725, tr:  61.18%, val:  51.25%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-5   lr=['0.0096275'], tr/val_loss:  0.989347/  1.525853, tr:  64.35%, val:  49.58%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-6   lr=['0.0096014'], tr/val_loss:  0.942037/  1.444201, tr:  64.96%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-7   lr=['0.0095705'], tr/val_loss:  0.909799/  1.431638, tr:  68.03%, val:  55.42%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-8   lr=['0.0095350'], tr/val_loss:  0.839035/  1.323225, tr:  70.99%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-9   lr=['0.0094948'], tr/val_loss:  0.658389/  1.337229, tr:  75.08%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-10  lr=['0.0094501'], tr/val_loss:  0.653247/  1.303677, tr:  77.12%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-11  lr=['0.0094008'], tr/val_loss:  0.598731/  1.464615, tr:  78.86%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-12  lr=['0.0093470'], tr/val_loss:  0.627238/  1.235845, tr:  76.92%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-13  lr=['0.0092888'], tr/val_loss:  0.572507/  1.536279, tr:  80.29%, val:  58.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-14  lr=['0.0092262'], tr/val_loss:  0.544568/  1.445864, tr:  82.64%, val:  64.17%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-15  lr=['0.0091592'], tr/val_loss:  0.550849/  1.335039, tr:  79.16%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-16  lr=['0.0090880'], tr/val_loss:  0.444102/  1.516880, tr:  86.11%, val:  66.67%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-17  lr=['0.0090126'], tr/val_loss:  0.484385/  1.421591, tr:  84.58%, val:  65.42%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-18  lr=['0.0089331'], tr/val_loss:  0.398568/  1.406425, tr:  87.74%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-19  lr=['0.0088496'], tr/val_loss:  0.353230/  1.435667, tr:  90.81%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-20  lr=['0.0087621'], tr/val_loss:  0.298769/  1.422068, tr:  93.05%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.10it/s]\n",
      "epoch-21  lr=['0.0086707'], tr/val_loss:  0.267638/  1.655052, tr:  93.77%, val:  62.92%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.31it/s]\n",
      "epoch-22  lr=['0.0085756'], tr/val_loss:  0.307002/  1.537379, tr:  91.93%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.49it/s]\n",
      "epoch-23  lr=['0.0084768'], tr/val_loss:  0.282805/  1.567215, tr:  94.38%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.41it/s]\n",
      "epoch-24  lr=['0.0083744'], tr/val_loss:  0.275175/  1.742755, tr:  96.42%, val:  69.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-25  lr=['0.0082685'], tr/val_loss:  0.229966/  1.562783, tr:  96.63%, val:  75.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-26  lr=['0.0081592'], tr/val_loss:  0.160922/  1.731022, tr:  99.08%, val:  72.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-27  lr=['0.0080467'], tr/val_loss:  0.135435/  1.662364, tr:  99.08%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-28  lr=['0.0079310'], tr/val_loss:  0.103757/  1.697436, tr:  99.59%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-29  lr=['0.0078122'], tr/val_loss:  0.107110/  2.004375, tr:  99.59%, val:  68.33%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-30  lr=['0.0076906'], tr/val_loss:  0.086536/  1.861104, tr:  99.59%, val:  72.92%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-31  lr=['0.0075661'], tr/val_loss:  0.079296/  1.918790, tr:  99.80%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-32  lr=['0.0074389'], tr/val_loss:  0.045754/  1.909394, tr:  99.90%, val:  72.08%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-33  lr=['0.0073092'], tr/val_loss:  0.028413/  2.008596, tr: 100.00%, val:  73.33%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-34  lr=['0.0071770'], tr/val_loss:  0.025776/  2.039636, tr: 100.00%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-35  lr=['0.0070425'], tr/val_loss:  0.014612/  1.986827, tr: 100.00%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-36  lr=['0.0069059'], tr/val_loss:  0.009665/  2.030418, tr: 100.00%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-37  lr=['0.0067672'], tr/val_loss:  0.006372/  2.062261, tr: 100.00%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-38  lr=['0.0066266'], tr/val_loss:  0.004017/  2.075547, tr: 100.00%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-39  lr=['0.0064843'], tr/val_loss:  0.003283/  2.063202, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-40  lr=['0.0063403'], tr/val_loss:  0.002680/  2.069771, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-41  lr=['0.0061949'], tr/val_loss:  0.002451/  2.089447, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-42  lr=['0.0060481'], tr/val_loss:  0.002242/  2.105923, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-43  lr=['0.0059002'], tr/val_loss:  0.001903/  2.100897, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-44  lr=['0.0057512'], tr/val_loss:  0.001770/  2.110367, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-45  lr=['0.0056013'], tr/val_loss:  0.001710/  2.121972, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-46  lr=['0.0054506'], tr/val_loss:  0.001618/  2.125934, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-47  lr=['0.0052994'], tr/val_loss:  0.001508/  2.140106, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-48  lr=['0.0051477'], tr/val_loss:  0.001446/  2.145039, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-49  lr=['0.0049957'], tr/val_loss:  0.001449/  2.156003, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-50  lr=['0.0048436'], tr/val_loss:  0.001329/  2.163193, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-51  lr=['0.0046914'], tr/val_loss:  0.001288/  2.172878, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-52  lr=['0.0045394'], tr/val_loss:  0.001234/  2.161761, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-53  lr=['0.0043878'], tr/val_loss:  0.001197/  2.163329, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-54  lr=['0.0042365'], tr/val_loss:  0.001156/  2.175696, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-55  lr=['0.0040859'], tr/val_loss:  0.001142/  2.185674, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-56  lr=['0.0039360'], tr/val_loss:  0.001104/  2.183405, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-57  lr=['0.0037870'], tr/val_loss:  0.001081/  2.195347, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-58  lr=['0.0036390'], tr/val_loss:  0.001027/  2.190464, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-59  lr=['0.0034923'], tr/val_loss:  0.001021/  2.195307, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-60  lr=['0.0033468'], tr/val_loss:  0.001027/  2.205453, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-61  lr=['0.0032029'], tr/val_loss:  0.001005/  2.217645, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-62  lr=['0.0030605'], tr/val_loss:  0.001010/  2.206775, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-63  lr=['0.0029200'], tr/val_loss:  0.000970/  2.206094, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-64  lr=['0.0027813'], tr/val_loss:  0.000944/  2.216297, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-65  lr=['0.0026446'], tr/val_loss:  0.000930/  2.215763, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-66  lr=['0.0025102'], tr/val_loss:  0.000947/  2.196098, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-67  lr=['0.0023780'], tr/val_loss:  0.000928/  2.210296, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-68  lr=['0.0022483'], tr/val_loss:  0.000916/  2.204191, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-69  lr=['0.0021211'], tr/val_loss:  0.000894/  2.206775, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-70  lr=['0.0019966'], tr/val_loss:  0.000875/  2.219186, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-71  lr=['0.0018749'], tr/val_loss:  0.000866/  2.224440, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-72  lr=['0.0017562'], tr/val_loss:  0.000830/  2.218061, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-73  lr=['0.0016405'], tr/val_loss:  0.000854/  2.223717, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-74  lr=['0.0015279'], tr/val_loss:  0.000834/  2.226285, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-75  lr=['0.0014187'], tr/val_loss:  0.000847/  2.228494, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-76  lr=['0.0013128'], tr/val_loss:  0.000821/  2.227409, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-77  lr=['0.0012104'], tr/val_loss:  0.000820/  2.232570, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-78  lr=['0.0011115'], tr/val_loss:  0.000821/  2.233916, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-79  lr=['0.0010164'], tr/val_loss:  0.000850/  2.229374, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-80  lr=['0.0009250'], tr/val_loss:  0.000831/  2.234572, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-81  lr=['0.0008375'], tr/val_loss:  0.000837/  2.229628, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-82  lr=['0.0007540'], tr/val_loss:  0.000813/  2.232941, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-83  lr=['0.0006745'], tr/val_loss:  0.000811/  2.232472, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-84  lr=['0.0005991'], tr/val_loss:  0.000834/  2.233728, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-85  lr=['0.0005279'], tr/val_loss:  0.000821/  2.232728, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-86  lr=['0.0004610'], tr/val_loss:  0.000803/  2.235247, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-87  lr=['0.0003984'], tr/val_loss:  0.000791/  2.235960, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-88  lr=['0.0003401'], tr/val_loss:  0.000790/  2.234004, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-89  lr=['0.0002863'], tr/val_loss:  0.000789/  2.233101, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-90  lr=['0.0002371'], tr/val_loss:  0.000793/  2.234632, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-91  lr=['0.0001923'], tr/val_loss:  0.000808/  2.231897, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-92  lr=['0.0001522'], tr/val_loss:  0.000786/  2.230390, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-93  lr=['0.0001166'], tr/val_loss:  0.000785/  2.230105, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-94  lr=['0.0000858'], tr/val_loss:  0.000793/  2.230255, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-95  lr=['0.0000596'], tr/val_loss:  0.000787/  2.230388, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-96  lr=['0.0000382'], tr/val_loss:  0.000786/  2.228979, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-97  lr=['0.0000215'], tr/val_loss:  0.000779/  2.228992, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-98  lr=['0.0000096'], tr/val_loss:  0.000812/  2.228997, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-99  lr=['0.0000024'], tr/val_loss:  0.000774/  2.228997, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b85982901e545e0bb2dcc26893566bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▄▅▆▇▇▇██▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▇▆▇▇▆▇▇▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▇▆▇▇▆▇▇▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▁▂▂▂▄▄▄▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00077</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>2.229</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sweep-100</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/87t0uvcy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/87t0uvcy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_175322-87t0uvcy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y1g89i1k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004721141874399294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.4695768564479621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6765555287257072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_180223-y1g89i1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y1g89i1k' target=\"_blank\">crimson-sweep-102</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y1g89i1k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y1g89i1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0047211'], tr/val_loss:  2.310491/  2.302474, tr:   9.19%, val:  11.25%, val_best:  11.25%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-1   lr=['0.0047200'], tr/val_loss:  2.013991/  1.680460, tr:  28.91%, val:  45.00%, val_best:  45.00%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-2   lr=['0.0047165'], tr/val_loss:  1.376021/  1.445330, tr:  53.73%, val:  49.58%, val_best:  49.58%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-3   lr=['0.0047107'], tr/val_loss:  1.206887/  1.363238, tr:  59.04%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-4   lr=['0.0047025'], tr/val_loss:  1.162864/  1.281499, tr:  60.67%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-5   lr=['0.0046921'], tr/val_loss:  1.071648/  1.269714, tr:  63.13%, val:  57.50%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-6   lr=['0.0046793'], tr/val_loss:  0.982274/  1.174105, tr:  68.44%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-7   lr=['0.0046643'], tr/val_loss:  0.936214/  1.187400, tr:  68.34%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-8   lr=['0.0046470'], tr/val_loss:  0.867901/  1.139082, tr:  69.77%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-9   lr=['0.0046274'], tr/val_loss:  0.809742/  1.297724, tr:  74.26%, val:  57.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-10  lr=['0.0046056'], tr/val_loss:  0.789892/  1.159891, tr:  75.49%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-11  lr=['0.0045816'], tr/val_loss:  0.738172/  1.173498, tr:  77.32%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-12  lr=['0.0045554'], tr/val_loss:  0.694701/  1.124300, tr:  81.41%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-13  lr=['0.0045270'], tr/val_loss:  0.671088/  1.191012, tr:  80.18%, val:  62.50%, val_best:  72.08%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-14  lr=['0.0044965'], tr/val_loss:  0.628206/  1.151481, tr:  81.41%, val:  69.17%, val_best:  72.08%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-15  lr=['0.0044639'], tr/val_loss:  0.612628/  1.179025, tr:  83.45%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-16  lr=['0.0044292'], tr/val_loss:  0.587627/  1.253056, tr:  84.88%, val:  70.00%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-17  lr=['0.0043924'], tr/val_loss:  0.571828/  1.266934, tr:  84.88%, val:  67.50%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-18  lr=['0.0043537'], tr/val_loss:  0.546908/  1.229134, tr:  86.11%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-19  lr=['0.0043130'], tr/val_loss:  0.490146/  1.262618, tr:  91.22%, val:  70.00%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-20  lr=['0.0042703'], tr/val_loss:  0.465878/  1.339196, tr:  89.27%, val:  67.92%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-21  lr=['0.0042258'], tr/val_loss:  0.417794/  1.325339, tr:  93.16%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 13.56it/s]\n",
      "epoch-22  lr=['0.0041794'], tr/val_loss:  0.411278/  1.342542, tr:  92.85%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 13.21it/s]\n",
      "epoch-23  lr=['0.0041313'], tr/val_loss:  0.387541/  1.433859, tr:  92.65%, val:  68.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 13.27it/s]\n",
      "epoch-24  lr=['0.0040814'], tr/val_loss:  0.403200/  1.487545, tr:  92.65%, val:  69.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-25  lr=['0.0040297'], tr/val_loss:  0.338465/  1.461594, tr:  96.73%, val:  72.50%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-26  lr=['0.0039765'], tr/val_loss:  0.325198/  1.440084, tr:  95.61%, val:  72.08%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-27  lr=['0.0039216'], tr/val_loss:  0.298766/  1.498229, tr:  95.81%, val:  72.50%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-28  lr=['0.0038653'], tr/val_loss:  0.271640/  1.525599, tr:  98.06%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-29  lr=['0.0038074'], tr/val_loss:  0.286667/  1.654567, tr:  97.14%, val:  69.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-30  lr=['0.0037481'], tr/val_loss:  0.279828/  1.525725, tr:  98.06%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-31  lr=['0.0036874'], tr/val_loss:  0.227755/  1.621627, tr:  98.47%, val:  73.75%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-32  lr=['0.0036254'], tr/val_loss:  0.240405/  1.669758, tr:  98.47%, val:  72.50%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-33  lr=['0.0035622'], tr/val_loss:  0.210198/  1.679116, tr:  99.59%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-34  lr=['0.0034978'], tr/val_loss:  0.189574/  1.695802, tr:  99.08%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-35  lr=['0.0034322'], tr/val_loss:  0.182430/  1.684544, tr:  99.18%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-36  lr=['0.0033657'], tr/val_loss:  0.161869/  1.782310, tr:  99.90%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-37  lr=['0.0032981'], tr/val_loss:  0.179149/  1.786039, tr:  99.28%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-38  lr=['0.0032296'], tr/val_loss:  0.148855/  1.823768, tr:  99.69%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-39  lr=['0.0031602'], tr/val_loss:  0.136179/  1.858634, tr:  99.80%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-40  lr=['0.0030900'], tr/val_loss:  0.143965/  1.849177, tr:  99.80%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-41  lr=['0.0030191'], tr/val_loss:  0.129731/  1.906915, tr:  99.49%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-42  lr=['0.0029476'], tr/val_loss:  0.115850/  1.925020, tr:  99.90%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-43  lr=['0.0028755'], tr/val_loss:  0.110832/  1.965849, tr: 100.00%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-44  lr=['0.0028029'], tr/val_loss:  0.115064/  1.987600, tr:  99.80%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-45  lr=['0.0027298'], tr/val_loss:  0.112663/  1.988622, tr:  99.80%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-46  lr=['0.0026564'], tr/val_loss:  0.101155/  2.045461, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-47  lr=['0.0025827'], tr/val_loss:  0.096993/  2.062572, tr: 100.00%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-48  lr=['0.0025088'], tr/val_loss:  0.087217/  2.035978, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-49  lr=['0.0024347'], tr/val_loss:  0.084096/  2.069200, tr:  99.90%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-50  lr=['0.0023606'], tr/val_loss:  0.085334/  2.092992, tr: 100.00%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-51  lr=['0.0022864'], tr/val_loss:  0.072477/  2.094204, tr: 100.00%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-52  lr=['0.0022123'], tr/val_loss:  0.072076/  2.129793, tr: 100.00%, val:  74.17%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-53  lr=['0.0021384'], tr/val_loss:  0.066888/  2.162344, tr: 100.00%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-54  lr=['0.0020647'], tr/val_loss:  0.062424/  2.215560, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-55  lr=['0.0019913'], tr/val_loss:  0.059855/  2.185058, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-56  lr=['0.0019182'], tr/val_loss:  0.054103/  2.190351, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-57  lr=['0.0018456'], tr/val_loss:  0.052400/  2.228296, tr: 100.00%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-58  lr=['0.0017735'], tr/val_loss:  0.051521/  2.244509, tr: 100.00%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-59  lr=['0.0017020'], tr/val_loss:  0.048835/  2.267151, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-60  lr=['0.0016311'], tr/val_loss:  0.048025/  2.298864, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-61  lr=['0.0015610'], tr/val_loss:  0.046541/  2.294311, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-62  lr=['0.0014916'], tr/val_loss:  0.041168/  2.322120, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-63  lr=['0.0014231'], tr/val_loss:  0.042400/  2.319698, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-64  lr=['0.0013555'], tr/val_loss:  0.039650/  2.336724, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-65  lr=['0.0012889'], tr/val_loss:  0.035544/  2.360686, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-66  lr=['0.0012234'], tr/val_loss:  0.036387/  2.351353, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-67  lr=['0.0011589'], tr/val_loss:  0.037605/  2.362697, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-68  lr=['0.0010957'], tr/val_loss:  0.031425/  2.373262, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-69  lr=['0.0010337'], tr/val_loss:  0.031561/  2.410284, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-70  lr=['0.0009731'], tr/val_loss:  0.032065/  2.405211, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-71  lr=['0.0009138'], tr/val_loss:  0.032050/  2.399901, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-72  lr=['0.0008559'], tr/val_loss:  0.030243/  2.412587, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-73  lr=['0.0007995'], tr/val_loss:  0.031230/  2.401658, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-74  lr=['0.0007446'], tr/val_loss:  0.029169/  2.418028, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-75  lr=['0.0006914'], tr/val_loss:  0.028156/  2.429818, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-76  lr=['0.0006398'], tr/val_loss:  0.027914/  2.436760, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-77  lr=['0.0005899'], tr/val_loss:  0.029680/  2.427668, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-78  lr=['0.0005417'], tr/val_loss:  0.027543/  2.437548, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-79  lr=['0.0004954'], tr/val_loss:  0.025582/  2.442758, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-80  lr=['0.0004508'], tr/val_loss:  0.025065/  2.448683, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-81  lr=['0.0004082'], tr/val_loss:  0.024562/  2.452959, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-82  lr=['0.0003675'], tr/val_loss:  0.025344/  2.444514, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-83  lr=['0.0003287'], tr/val_loss:  0.024768/  2.456616, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-84  lr=['0.0002920'], tr/val_loss:  0.024900/  2.463092, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-85  lr=['0.0002573'], tr/val_loss:  0.024733/  2.456409, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-86  lr=['0.0002247'], tr/val_loss:  0.023690/  2.467290, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-87  lr=['0.0001941'], tr/val_loss:  0.023518/  2.469935, tr: 100.00%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-88  lr=['0.0001658'], tr/val_loss:  0.024433/  2.473187, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-89  lr=['0.0001396'], tr/val_loss:  0.023973/  2.474842, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-90  lr=['0.0001155'], tr/val_loss:  0.023032/  2.471622, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-91  lr=['0.0000937'], tr/val_loss:  0.023485/  2.468307, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-92  lr=['0.0000742'], tr/val_loss:  0.023947/  2.478494, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-93  lr=['0.0000569'], tr/val_loss:  0.022807/  2.478056, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-94  lr=['0.0000418'], tr/val_loss:  0.022789/  2.480028, tr: 100.00%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-95  lr=['0.0000291'], tr/val_loss:  0.022749/  2.475532, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-96  lr=['0.0000186'], tr/val_loss:  0.022499/  2.475276, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-97  lr=['0.0000105'], tr/val_loss:  0.022521/  2.474980, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-98  lr=['0.0000047'], tr/val_loss:  0.022570/  2.475426, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-99  lr=['0.0000012'], tr/val_loss:  0.022372/  2.475178, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab00ad4b96c4a35a6f1e3fd14dc70c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▆▆▇▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▇▇▇▇█▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▇▇▇▇█▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▇▃▂▁▂▁▁▂▂▂▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02237</td></tr><tr><td>val_acc_best</td><td>0.775</td></tr><tr><td>val_acc_now</td><td>0.75417</td></tr><tr><td>val_loss</td><td>2.47518</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-102</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y1g89i1k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y1g89i1k</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_180223-y1g89i1k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4diwln9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.020559853023331815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.0725866542164006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.3111370630541943\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_181124-z4diwln9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4diwln9' target=\"_blank\">atomic-sweep-104</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4diwln9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4diwln9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0205599'], tr/val_loss:  1.772142/  1.480535, tr:  37.90%, val:  44.17%, val_best:  44.17%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-1   lr=['0.0205548'], tr/val_loss:  1.328735/  1.376939, tr:  52.50%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-2   lr=['0.0205396'], tr/val_loss:  1.125010/  1.873898, tr:  57.71%, val:  46.67%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-3   lr=['0.0205142'], tr/val_loss:  1.061581/  1.493159, tr:  65.37%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-4   lr=['0.0204788'], tr/val_loss:  1.050057/  1.454071, tr:  64.56%, val:  51.25%, val_best:  51.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-5   lr=['0.0204333'], tr/val_loss:  0.913290/  1.657658, tr:  67.93%, val:  47.50%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-6   lr=['0.0203778'], tr/val_loss:  0.817180/  1.493106, tr:  70.28%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-7   lr=['0.0203123'], tr/val_loss:  0.850959/  1.537691, tr:  68.03%, val:  55.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-8   lr=['0.0202369'], tr/val_loss:  0.759026/  1.421054, tr:  72.32%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-9   lr=['0.0201517'], tr/val_loss:  0.678774/  1.560735, tr:  74.16%, val:  63.75%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-10  lr=['0.0200567'], tr/val_loss:  0.629660/  1.697672, tr:  80.90%, val:  59.17%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-11  lr=['0.0199521'], tr/val_loss:  0.635752/  1.627566, tr:  78.55%, val:  59.17%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-12  lr=['0.0198380'], tr/val_loss:  0.615040/  1.407013, tr:  80.18%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-13  lr=['0.0197144'], tr/val_loss:  0.453389/  1.404149, tr:  85.80%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-14  lr=['0.0195815'], tr/val_loss:  0.431482/  1.416970, tr:  90.09%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-15  lr=['0.0194394'], tr/val_loss:  0.451225/  1.500396, tr:  86.21%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-16  lr=['0.0192883'], tr/val_loss:  0.342872/  2.080363, tr:  92.34%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-17  lr=['0.0191283'], tr/val_loss:  0.548689/  1.358542, tr:  85.50%, val:  67.08%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-18  lr=['0.0189596'], tr/val_loss:  0.404025/  1.524288, tr:  89.68%, val:  66.67%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-19  lr=['0.0187823'], tr/val_loss:  0.367753/  1.522324, tr:  89.79%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 13.21it/s]\n",
      "epoch-20  lr=['0.0185966'], tr/val_loss:  0.299655/  1.544481, tr:  92.95%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.32it/s]\n",
      "epoch-21  lr=['0.0184027'], tr/val_loss:  0.210171/  1.711349, tr:  96.83%, val:  72.92%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.50it/s]\n",
      "epoch-22  lr=['0.0182007'], tr/val_loss:  0.200066/  1.510729, tr:  98.26%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 13.54it/s]\n",
      "epoch-23  lr=['0.0179910'], tr/val_loss:  0.196266/  1.699425, tr:  96.94%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 13.22it/s]\n",
      "epoch-24  lr=['0.0177737'], tr/val_loss:  0.178997/  1.675907, tr:  96.94%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-25  lr=['0.0175489'], tr/val_loss:  0.167391/  1.877239, tr:  97.55%, val:  72.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-26  lr=['0.0173170'], tr/val_loss:  0.117757/  1.790713, tr:  98.98%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-27  lr=['0.0170782'], tr/val_loss:  0.072707/  1.875275, tr:  99.80%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-28  lr=['0.0168326'], tr/val_loss:  0.075942/  1.841517, tr:  99.69%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-29  lr=['0.0165806'], tr/val_loss:  0.045734/  2.025225, tr: 100.00%, val:  75.00%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.09it/s]\n",
      "epoch-30  lr=['0.0163223'], tr/val_loss:  0.045261/  1.959532, tr:  99.90%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-31  lr=['0.0160581'], tr/val_loss:  0.020761/  2.075359, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-32  lr=['0.0157882'], tr/val_loss:  0.018055/  2.208446, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-33  lr=['0.0155128'], tr/val_loss:  0.013445/  2.166701, tr: 100.00%, val:  78.33%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-34  lr=['0.0152323'], tr/val_loss:  0.006919/  2.229822, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-35  lr=['0.0149469'], tr/val_loss:  0.007335/  2.251868, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-36  lr=['0.0146569'], tr/val_loss:  0.003796/  2.249873, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-37  lr=['0.0143626'], tr/val_loss:  0.003262/  2.301639, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-38  lr=['0.0140642'], tr/val_loss:  0.002949/  2.289772, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-39  lr=['0.0137621'], tr/val_loss:  0.001538/  2.367069, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-40  lr=['0.0134566'], tr/val_loss:  0.001297/  2.368134, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-41  lr=['0.0131479'], tr/val_loss:  0.001053/  2.365555, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-42  lr=['0.0128364'], tr/val_loss:  0.001007/  2.378418, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-43  lr=['0.0125224'], tr/val_loss:  0.000958/  2.379301, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-44  lr=['0.0122062'], tr/val_loss:  0.000888/  2.406271, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-45  lr=['0.0118881'], tr/val_loss:  0.000786/  2.426357, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-46  lr=['0.0115683'], tr/val_loss:  0.000742/  2.435424, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-47  lr=['0.0112474'], tr/val_loss:  0.000722/  2.442340, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-48  lr=['0.0109254'], tr/val_loss:  0.000672/  2.447469, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-49  lr=['0.0106028'], tr/val_loss:  0.000610/  2.446357, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-50  lr=['0.0102799'], tr/val_loss:  0.000634/  2.446721, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-51  lr=['0.0099570'], tr/val_loss:  0.000595/  2.459516, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-52  lr=['0.0096344'], tr/val_loss:  0.000568/  2.453347, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-53  lr=['0.0093125'], tr/val_loss:  0.000558/  2.459244, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-54  lr=['0.0089915'], tr/val_loss:  0.000554/  2.442807, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-55  lr=['0.0086718'], tr/val_loss:  0.000558/  2.460762, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-56  lr=['0.0083537'], tr/val_loss:  0.000522/  2.468559, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-57  lr=['0.0080374'], tr/val_loss:  0.000508/  2.457384, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-58  lr=['0.0077234'], tr/val_loss:  0.000487/  2.466427, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-59  lr=['0.0074119'], tr/val_loss:  0.000471/  2.472428, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-60  lr=['0.0071033'], tr/val_loss:  0.000476/  2.474049, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-61  lr=['0.0067977'], tr/val_loss:  0.000470/  2.473624, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-62  lr=['0.0064956'], tr/val_loss:  0.000462/  2.474332, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-63  lr=['0.0061973'], tr/val_loss:  0.000480/  2.474912, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-64  lr=['0.0059029'], tr/val_loss:  0.000447/  2.474286, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-65  lr=['0.0056129'], tr/val_loss:  0.000426/  2.475846, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-66  lr=['0.0053275'], tr/val_loss:  0.000435/  2.478608, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-67  lr=['0.0050470'], tr/val_loss:  0.000423/  2.486409, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-68  lr=['0.0047717'], tr/val_loss:  0.000406/  2.484863, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-69  lr=['0.0045018'], tr/val_loss:  0.000411/  2.496248, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-70  lr=['0.0042375'], tr/val_loss:  0.000390/  2.495127, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-71  lr=['0.0039793'], tr/val_loss:  0.000382/  2.494795, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-72  lr=['0.0037273'], tr/val_loss:  0.000377/  2.499002, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-73  lr=['0.0034817'], tr/val_loss:  0.000384/  2.501115, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-74  lr=['0.0032428'], tr/val_loss:  0.000378/  2.495342, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-75  lr=['0.0030109'], tr/val_loss:  0.000368/  2.492848, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-76  lr=['0.0027862'], tr/val_loss:  0.000368/  2.492858, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-77  lr=['0.0025688'], tr/val_loss:  0.000374/  2.492992, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-78  lr=['0.0023591'], tr/val_loss:  0.000363/  2.494745, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-79  lr=['0.0021572'], tr/val_loss:  0.000358/  2.498899, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-80  lr=['0.0019633'], tr/val_loss:  0.000363/  2.501451, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-81  lr=['0.0017776'], tr/val_loss:  0.000383/  2.505825, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-82  lr=['0.0016003'], tr/val_loss:  0.000375/  2.505054, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-83  lr=['0.0014316'], tr/val_loss:  0.000361/  2.503696, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-84  lr=['0.0012716'], tr/val_loss:  0.000357/  2.503545, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-85  lr=['0.0011204'], tr/val_loss:  0.000363/  2.506143, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-86  lr=['0.0009784'], tr/val_loss:  0.000362/  2.504336, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-87  lr=['0.0008455'], tr/val_loss:  0.000358/  2.504443, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-88  lr=['0.0007219'], tr/val_loss:  0.000355/  2.505790, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-89  lr=['0.0006077'], tr/val_loss:  0.000362/  2.505405, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-90  lr=['0.0005031'], tr/val_loss:  0.000366/  2.504858, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-91  lr=['0.0004082'], tr/val_loss:  0.000363/  2.504530, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-92  lr=['0.0003230'], tr/val_loss:  0.000357/  2.502776, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-93  lr=['0.0002476'], tr/val_loss:  0.000355/  2.502573, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-94  lr=['0.0001821'], tr/val_loss:  0.000360/  2.503094, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-95  lr=['0.0001266'], tr/val_loss:  0.000356/  2.502298, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-96  lr=['0.0000811'], tr/val_loss:  0.000358/  2.502318, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-97  lr=['0.0000456'], tr/val_loss:  0.000351/  2.502196, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-98  lr=['0.0000203'], tr/val_loss:  0.000368/  2.502200, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-99  lr=['0.0000051'], tr/val_loss:  0.000352/  2.502200, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d1af4debaf4af899b4159fc17758a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▅▅▅▆▇█▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▃▅▅▅▅▇▆▇▇▇█▇█▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▄▅▆▇▆▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▄▅▅▅▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▃▅▅▅▅▇▆▇▇▇█▇█▇███████████████████████</td></tr><tr><td>val_loss</td><td>▂▄▂▂▂▁▁▁▂▃▃▄▅▆▆▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00035</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>2.5022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-sweep-104</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4diwln9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4diwln9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_181124-z4diwln9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v11oh73o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.032749943541375226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.305045604096402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6930511561890655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_182018-v11oh73o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v11oh73o' target=\"_blank\">lemon-sweep-106</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v11oh73o' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v11oh73o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0327499'], tr/val_loss:  2.088138/  1.623740, tr:  21.65%, val:  47.08%, val_best:  47.08%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-1   lr=['0.0327419'], tr/val_loss:  1.508171/  1.478595, tr:  50.66%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-2   lr=['0.0327176'], tr/val_loss:  1.214413/  1.483511, tr:  58.84%, val:  57.50%, val_best:  57.50%: 100%|██████████| 62/62 [00:04<00:00, 13.30it/s]\n",
      "epoch-3   lr=['0.0326773'], tr/val_loss:  1.119760/  1.313689, tr:  62.10%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-4   lr=['0.0326208'], tr/val_loss:  1.046017/  1.556519, tr:  66.70%, val:  47.08%, val_best:  62.50%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-5   lr=['0.0325483'], tr/val_loss:  0.939431/  1.353919, tr:  67.42%, val:  58.33%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-6   lr=['0.0324599'], tr/val_loss:  0.885559/  1.343285, tr:  70.07%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-7   lr=['0.0323556'], tr/val_loss:  0.840718/  1.519757, tr:  71.50%, val:  56.25%, val_best:  63.75%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-8   lr=['0.0322355'], tr/val_loss:  0.778326/  1.407300, tr:  75.89%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-9   lr=['0.0320998'], tr/val_loss:  0.621802/  1.591670, tr:  80.29%, val:  62.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-10  lr=['0.0319485'], tr/val_loss:  0.572053/  1.557756, tr:  83.86%, val:  63.33%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-11  lr=['0.0317819'], tr/val_loss:  0.558926/  1.602056, tr:  83.86%, val:  64.17%, val_best:  67.92%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-12  lr=['0.0316000'], tr/val_loss:  0.515170/  1.451240, tr:  84.37%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-13  lr=['0.0314032'], tr/val_loss:  0.381986/  1.523747, tr:  91.11%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-14  lr=['0.0311915'], tr/val_loss:  0.326581/  1.465662, tr:  91.83%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-15  lr=['0.0309652'], tr/val_loss:  0.327168/  1.772118, tr:  92.13%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-16  lr=['0.0307245'], tr/val_loss:  0.270923/  2.235543, tr:  95.20%, val:  62.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-17  lr=['0.0304696'], tr/val_loss:  0.408037/  1.674495, tr:  91.01%, val:  60.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-18  lr=['0.0302008'], tr/val_loss:  0.264507/  1.788167, tr:  93.56%, val:  67.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-19  lr=['0.0299184'], tr/val_loss:  0.200031/  1.837311, tr:  97.65%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-20  lr=['0.0296226'], tr/val_loss:  0.120016/  1.864356, tr:  99.69%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-21  lr=['0.0293137'], tr/val_loss:  0.092643/  1.986522, tr:  99.69%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-22  lr=['0.0289921'], tr/val_loss:  0.077168/  2.054145, tr:  99.59%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 13.13it/s]\n",
      "epoch-23  lr=['0.0286580'], tr/val_loss:  0.055686/  2.145937, tr: 100.00%, val:  74.17%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 13.23it/s]\n",
      "epoch-24  lr=['0.0283118'], tr/val_loss:  0.083954/  2.087025, tr:  99.49%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.33it/s]\n",
      "epoch-25  lr=['0.0279538'], tr/val_loss:  0.049414/  2.126483, tr: 100.00%, val:  75.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.30it/s]\n",
      "epoch-26  lr=['0.0275844'], tr/val_loss:  0.034659/  2.255240, tr: 100.00%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.33it/s]\n",
      "epoch-27  lr=['0.0272039'], tr/val_loss:  0.022935/  2.231549, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.36it/s]\n",
      "epoch-28  lr=['0.0268128'], tr/val_loss:  0.018216/  2.392363, tr: 100.00%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 13.18it/s]\n",
      "epoch-29  lr=['0.0264113'], tr/val_loss:  0.012741/  2.439085, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-30  lr=['0.0259999'], tr/val_loss:  0.009021/  2.434990, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-31  lr=['0.0255791'], tr/val_loss:  0.007463/  2.547753, tr: 100.00%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-32  lr=['0.0251491'], tr/val_loss:  0.009033/  2.549013, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-33  lr=['0.0247105'], tr/val_loss:  0.007139/  2.569791, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-34  lr=['0.0242637'], tr/val_loss:  0.003573/  2.581891, tr: 100.00%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-35  lr=['0.0238091'], tr/val_loss:  0.003501/  2.645385, tr: 100.00%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-36  lr=['0.0233471'], tr/val_loss:  0.002586/  2.652807, tr: 100.00%, val:  75.42%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-37  lr=['0.0228783'], tr/val_loss:  0.002211/  2.692639, tr: 100.00%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-38  lr=['0.0224030'], tr/val_loss:  0.003059/  2.711059, tr: 100.00%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-39  lr=['0.0219218'], tr/val_loss:  0.002174/  2.737424, tr: 100.00%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-40  lr=['0.0214351'], tr/val_loss:  0.002313/  2.749938, tr: 100.00%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-41  lr=['0.0209434'], tr/val_loss:  0.001558/  2.769506, tr: 100.00%, val:  76.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-42  lr=['0.0204473'], tr/val_loss:  0.001561/  2.739398, tr: 100.00%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-43  lr=['0.0199471'], tr/val_loss:  0.001369/  2.773518, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-44  lr=['0.0194433'], tr/val_loss:  0.002038/  2.784226, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-45  lr=['0.0189366'], tr/val_loss:  0.001930/  2.783920, tr: 100.00%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-46  lr=['0.0184273'], tr/val_loss:  0.001573/  2.788477, tr: 100.00%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-47  lr=['0.0179160'], tr/val_loss:  0.001157/  2.793027, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-48  lr=['0.0174032'], tr/val_loss:  0.001071/  2.814367, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-49  lr=['0.0168893'], tr/val_loss:  0.001102/  2.820075, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-50  lr=['0.0163750'], tr/val_loss:  0.000975/  2.832301, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-51  lr=['0.0158606'], tr/val_loss:  0.000928/  2.838056, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-52  lr=['0.0153468'], tr/val_loss:  0.001051/  2.857251, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-53  lr=['0.0148340'], tr/val_loss:  0.001163/  2.879519, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-54  lr=['0.0143226'], tr/val_loss:  0.000991/  2.834399, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-55  lr=['0.0138134'], tr/val_loss:  0.000947/  2.874831, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-56  lr=['0.0133066'], tr/val_loss:  0.000936/  2.879490, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-57  lr=['0.0128029'], tr/val_loss:  0.000823/  2.894048, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-58  lr=['0.0123027'], tr/val_loss:  0.000790/  2.901128, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-59  lr=['0.0118065'], tr/val_loss:  0.000743/  2.907033, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-60  lr=['0.0113148'], tr/val_loss:  0.000688/  2.919762, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-61  lr=['0.0108281'], tr/val_loss:  0.000716/  2.932476, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-62  lr=['0.0103469'], tr/val_loss:  0.000683/  2.937020, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-63  lr=['0.0098717'], tr/val_loss:  0.000682/  2.930684, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-64  lr=['0.0094028'], tr/val_loss:  0.000642/  2.937966, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-65  lr=['0.0089409'], tr/val_loss:  0.000652/  2.945468, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-66  lr=['0.0084863'], tr/val_loss:  0.000610/  2.934370, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-67  lr=['0.0080394'], tr/val_loss:  0.000585/  2.932765, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-68  lr=['0.0076008'], tr/val_loss:  0.000575/  2.936908, tr: 100.00%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-69  lr=['0.0071709'], tr/val_loss:  0.000564/  2.932619, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-70  lr=['0.0067500'], tr/val_loss:  0.000554/  2.937556, tr: 100.00%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-71  lr=['0.0063386'], tr/val_loss:  0.000547/  2.936685, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-72  lr=['0.0059372'], tr/val_loss:  0.000538/  2.931663, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.28it/s]\n",
      "epoch-73  lr=['0.0055460'], tr/val_loss:  0.000554/  2.930975, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.63it/s]\n",
      "epoch-74  lr=['0.0051655'], tr/val_loss:  0.000514/  2.935684, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-75  lr=['0.0047961'], tr/val_loss:  0.000536/  2.933359, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-76  lr=['0.0044381'], tr/val_loss:  0.000536/  2.934188, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-77  lr=['0.0040919'], tr/val_loss:  0.000514/  2.932293, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-78  lr=['0.0037578'], tr/val_loss:  0.000549/  2.938573, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-79  lr=['0.0034362'], tr/val_loss:  0.000541/  2.942223, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.13it/s]\n",
      "epoch-80  lr=['0.0031273'], tr/val_loss:  0.000532/  2.943270, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-81  lr=['0.0028316'], tr/val_loss:  0.000498/  2.940712, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.30it/s]\n",
      "epoch-82  lr=['0.0025491'], tr/val_loss:  0.000523/  2.937951, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-83  lr=['0.0022803'], tr/val_loss:  0.000538/  2.942945, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-84  lr=['0.0020255'], tr/val_loss:  0.000509/  2.934466, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-85  lr=['0.0017848'], tr/val_loss:  0.000527/  2.939797, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.06it/s]\n",
      "epoch-86  lr=['0.0015585'], tr/val_loss:  0.000498/  2.938879, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]\n",
      "epoch-87  lr=['0.0013468'], tr/val_loss:  0.000500/  2.938791, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-88  lr=['0.0011499'], tr/val_loss:  0.000538/  2.937333, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-89  lr=['0.0009681'], tr/val_loss:  0.000501/  2.938586, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.19it/s]\n",
      "epoch-90  lr=['0.0008014'], tr/val_loss:  0.000508/  2.936622, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.36it/s]\n",
      "epoch-91  lr=['0.0006502'], tr/val_loss:  0.000514/  2.935572, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.61it/s]\n",
      "epoch-92  lr=['0.0005144'], tr/val_loss:  0.000511/  2.936400, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-93  lr=['0.0003944'], tr/val_loss:  0.000507/  2.935869, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.56it/s]\n",
      "epoch-94  lr=['0.0002900'], tr/val_loss:  0.000512/  2.935937, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-95  lr=['0.0002016'], tr/val_loss:  0.000505/  2.935979, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-96  lr=['0.0001291'], tr/val_loss:  0.000487/  2.936406, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.34it/s]\n",
      "epoch-97  lr=['0.0000727'], tr/val_loss:  0.000491/  2.936421, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-98  lr=['0.0000323'], tr/val_loss:  0.000497/  2.936427, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-99  lr=['0.0000081'], tr/val_loss:  0.000493/  2.936428, tr: 100.00%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492c16925c247e09898cbb9b0ef3093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▃▄▄▅▆█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▁▃▅▆▇▄▇██▇██▇▇████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▆▆▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▁▃▅▆▇▄▇██▇██▇▇████████████████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▁▁▂▃▄▄▅▆▆▇▇▇▇▇▇▇█▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00049</td></tr><tr><td>val_acc_best</td><td>0.775</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>2.93643</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-106</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v11oh73o' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v11oh73o</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_182018-v11oh73o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sx8xj7ki with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08698728598356298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.768581102430335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.8709479254367685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_182909-sx8xj7ki</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sx8xj7ki' target=\"_blank\">spring-sweep-108</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sx8xj7ki' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sx8xj7ki</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0869873'], tr/val_loss:  2.051527/  1.724890, tr:  30.95%, val:  35.42%, val_best:  35.42%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-1   lr=['0.0869658'], tr/val_loss:  1.818400/  1.779898, tr:  38.51%, val:  35.83%, val_best:  35.83%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-2   lr=['0.0869015'], tr/val_loss:  1.998292/  2.443592, tr:  37.90%, val:  41.25%, val_best:  41.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-3   lr=['0.0867943'], tr/val_loss:  2.007859/  2.033780, tr:  38.00%, val:  40.00%, val_best:  41.25%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-4   lr=['0.0866443'], tr/val_loss:  2.158474/  2.872122, tr:  35.75%, val:  29.17%, val_best:  41.25%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-5   lr=['0.0864518'], tr/val_loss:  1.939499/  2.444465, tr:  36.26%, val:  27.92%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-6   lr=['0.0862169'], tr/val_loss:  1.975394/  3.252649, tr:  37.18%, val:  31.25%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-7   lr=['0.0859398'], tr/val_loss:  2.083156/  2.279742, tr:  36.47%, val:  36.67%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-8   lr=['0.0856209'], tr/val_loss:  2.269614/  2.422867, tr:  33.09%, val:  36.25%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-9   lr=['0.0852603'], tr/val_loss:  2.132107/  2.187881, tr:  34.42%, val:  39.58%, val_best:  41.25%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-10  lr=['0.0848586'], tr/val_loss:  1.856947/  2.474405, tr:  39.94%, val:  34.58%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-11  lr=['0.0844160'], tr/val_loss:  1.816282/  2.462483, tr:  40.25%, val:  35.42%, val_best:  41.25%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-12  lr=['0.0839330'], tr/val_loss:  2.019414/  1.992025, tr:  38.00%, val:  42.92%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-13  lr=['0.0834101'], tr/val_loss:  1.840449/  2.119760, tr:  42.80%, val:  34.17%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-14  lr=['0.0828479'], tr/val_loss:  1.823189/  1.823353, tr:  36.47%, val:  33.33%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-15  lr=['0.0822468'], tr/val_loss:  1.916546/  2.024083, tr:  38.61%, val:  37.50%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-16  lr=['0.0816074'], tr/val_loss:  1.815139/  1.945237, tr:  39.12%, val:  40.42%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-17  lr=['0.0809304'], tr/val_loss:  2.033700/  2.635987, tr:  37.59%, val:  24.17%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-18  lr=['0.0802165'], tr/val_loss:  1.961361/  2.488835, tr:  39.33%, val:  31.25%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-19  lr=['0.0794664'], tr/val_loss:  1.855527/  2.032632, tr:  37.18%, val:  41.67%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-20  lr=['0.0786807'], tr/val_loss:  1.780136/  1.937966, tr:  42.70%, val:  42.50%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-21  lr=['0.0778604'], tr/val_loss:  1.753220/  2.294611, tr:  40.25%, val:  37.50%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-22  lr=['0.0770061'], tr/val_loss:  1.835288/  2.000411, tr:  40.14%, val:  35.83%, val_best:  42.92%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-23  lr=['0.0761187'], tr/val_loss:  1.692684/  2.051512, tr:  39.53%, val:  40.42%, val_best:  42.92%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-24  lr=['0.0751991'], tr/val_loss:  1.696905/  1.741834, tr:  41.37%, val:  43.75%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-25  lr=['0.0742483'], tr/val_loss:  1.662006/  2.013113, tr:  44.02%, val:  36.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-26  lr=['0.0732671'], tr/val_loss:  1.677094/  1.863101, tr:  41.47%, val:  37.92%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-27  lr=['0.0722565'], tr/val_loss:  1.636350/  1.799285, tr:  42.80%, val:  42.50%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-28  lr=['0.0712175'], tr/val_loss:  1.674942/  2.040708, tr:  44.23%, val:  40.83%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-29  lr=['0.0701512'], tr/val_loss:  1.691576/  1.926411, tr:  43.82%, val:  37.50%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-30  lr=['0.0690586'], tr/val_loss:  1.652337/  2.133189, tr:  43.62%, val:  36.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-31  lr=['0.0679407'], tr/val_loss:  1.581501/  1.908526, tr:  42.70%, val:  43.75%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-32  lr=['0.0667987'], tr/val_loss:  1.531797/  1.987067, tr:  45.66%, val:  36.25%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-33  lr=['0.0656337'], tr/val_loss:  1.603879/  1.806770, tr:  42.80%, val:  37.08%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-34  lr=['0.0644469'], tr/val_loss:  1.539864/  1.906188, tr:  44.54%, val:  45.42%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-35  lr=['0.0632393'], tr/val_loss:  1.531934/  2.031371, tr:  42.90%, val:  40.83%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-36  lr=['0.0620123'], tr/val_loss:  1.686385/  1.821832, tr:  39.53%, val:  45.00%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-37  lr=['0.0607671'], tr/val_loss:  1.643598/  2.078779, tr:  42.08%, val:  38.33%, val_best:  45.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-38  lr=['0.0595047'], tr/val_loss:  1.543557/  1.840657, tr:  44.84%, val:  42.08%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-39  lr=['0.0582266'], tr/val_loss:  1.481721/  1.875607, tr:  47.19%, val:  41.67%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-40  lr=['0.0569339'], tr/val_loss:  1.391252/  1.901028, tr:  47.19%, val:  36.67%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-41  lr=['0.0556280'], tr/val_loss:  1.418289/  1.914007, tr:  48.93%, val:  42.92%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-42  lr=['0.0543101'], tr/val_loss:  1.338173/  1.768216, tr:  51.48%, val:  38.75%, val_best:  45.42%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-43  lr=['0.0529815'], tr/val_loss:  1.280058/  1.976319, tr:  53.52%, val:  39.17%, val_best:  45.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-44  lr=['0.0516435'], tr/val_loss:  1.379627/  2.060831, tr:  52.50%, val:  35.00%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-45  lr=['0.0502975'], tr/val_loss:  1.393019/  1.831192, tr:  51.07%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-46  lr=['0.0489448'], tr/val_loss:  1.376440/  1.629213, tr:  51.89%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-47  lr=['0.0475868'], tr/val_loss:  1.310910/  2.014228, tr:  53.42%, val:  35.83%, val_best:  50.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-48  lr=['0.0462246'], tr/val_loss:  1.350410/  1.629272, tr:  54.95%, val:  48.75%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-49  lr=['0.0448598'], tr/val_loss:  1.307725/  1.613527, tr:  55.57%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-50  lr=['0.0434936'], tr/val_loss:  1.323414/  1.801562, tr:  57.20%, val:  47.50%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-51  lr=['0.0421275'], tr/val_loss:  1.328539/  1.682517, tr:  54.44%, val:  48.33%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-52  lr=['0.0407627'], tr/val_loss:  1.297822/  1.655336, tr:  59.35%, val:  51.25%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-53  lr=['0.0394005'], tr/val_loss:  1.264328/  1.742159, tr:  56.38%, val:  50.83%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-54  lr=['0.0380424'], tr/val_loss:  1.125171/  1.709184, tr:  60.78%, val:  48.33%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-55  lr=['0.0366897'], tr/val_loss:  1.142093/  1.851598, tr:  60.37%, val:  47.92%, val_best:  51.67%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-56  lr=['0.0353437'], tr/val_loss:  1.179275/  1.515805, tr:  59.86%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-57  lr=['0.0340058'], tr/val_loss:  1.113405/  1.665110, tr:  58.73%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:04<00:00, 13.22it/s]\n",
      "epoch-58  lr=['0.0326772'], tr/val_loss:  1.061560/  1.681687, tr:  63.13%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.26it/s]\n",
      "epoch-59  lr=['0.0313593'], tr/val_loss:  1.093877/  1.744545, tr:  60.16%, val:  51.25%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 13.43it/s]\n",
      "epoch-60  lr=['0.0300534'], tr/val_loss:  1.097776/  1.706710, tr:  60.06%, val:  50.42%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-61  lr=['0.0287607'], tr/val_loss:  1.122614/  1.668893, tr:  63.13%, val:  52.50%, val_best:  53.75%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-62  lr=['0.0274826'], tr/val_loss:  1.030264/  1.646114, tr:  61.18%, val:  48.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-63  lr=['0.0262202'], tr/val_loss:  1.032725/  1.525192, tr:  62.72%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-64  lr=['0.0249750'], tr/val_loss:  0.931836/  1.639042, tr:  64.76%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:12<00:00,  4.94it/s]\n",
      "epoch-65  lr=['0.0237479'], tr/val_loss:  0.959362/  1.711008, tr:  63.64%, val:  49.58%, val_best:  55.00%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-66  lr=['0.0225404'], tr/val_loss:  0.897920/  1.585603, tr:  66.80%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-67  lr=['0.0213536'], tr/val_loss:  0.953187/  1.612452, tr:  63.74%, val:  51.67%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-68  lr=['0.0201886'], tr/val_loss:  0.885279/  1.712603, tr:  66.60%, val:  52.08%, val_best:  55.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-69  lr=['0.0190466'], tr/val_loss:  0.848591/  1.584444, tr:  67.93%, val:  55.00%, val_best:  55.42%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-70  lr=['0.0179287'], tr/val_loss:  0.835884/  1.551178, tr:  65.37%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-71  lr=['0.0168361'], tr/val_loss:  0.854647/  1.690301, tr:  67.52%, val:  51.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-72  lr=['0.0157698'], tr/val_loss:  0.817622/  1.662432, tr:  65.58%, val:  50.83%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-73  lr=['0.0147308'], tr/val_loss:  0.828061/  1.729421, tr:  65.88%, val:  54.58%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-74  lr=['0.0137202'], tr/val_loss:  0.785943/  1.624820, tr:  67.62%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-75  lr=['0.0127390'], tr/val_loss:  0.765563/  1.653876, tr:  67.52%, val:  55.00%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-76  lr=['0.0117881'], tr/val_loss:  0.746158/  1.628707, tr:  69.56%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-77  lr=['0.0108686'], tr/val_loss:  0.740083/  1.617515, tr:  68.03%, val:  55.83%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-78  lr=['0.0099812'], tr/val_loss:  0.741268/  1.798886, tr:  68.13%, val:  51.67%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-79  lr=['0.0091269'], tr/val_loss:  0.711181/  1.726911, tr:  70.58%, val:  50.00%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-80  lr=['0.0083065'], tr/val_loss:  0.694651/  1.674798, tr:  70.17%, val:  55.42%, val_best:  56.25%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-81  lr=['0.0075209'], tr/val_loss:  0.688607/  1.689604, tr:  70.68%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-82  lr=['0.0067707'], tr/val_loss:  0.669985/  1.753449, tr:  70.38%, val:  55.83%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-83  lr=['0.0060568'], tr/val_loss:  0.666881/  1.715437, tr:  72.11%, val:  55.00%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-84  lr=['0.0053799'], tr/val_loss:  0.653743/  1.792123, tr:  71.81%, val:  51.67%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-85  lr=['0.0047405'], tr/val_loss:  0.650584/  1.763053, tr:  70.99%, val:  53.75%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-86  lr=['0.0041394'], tr/val_loss:  0.633144/  1.751592, tr:  74.26%, val:  54.58%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-87  lr=['0.0035772'], tr/val_loss:  0.629606/  1.764475, tr:  72.52%, val:  52.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-88  lr=['0.0030543'], tr/val_loss:  0.624848/  1.747859, tr:  72.32%, val:  55.42%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n",
      "epoch-89  lr=['0.0025713'], tr/val_loss:  0.625644/  1.768006, tr:  72.73%, val:  54.17%, val_best:  57.08%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-90  lr=['0.0021287'], tr/val_loss:  0.630249/  1.738054, tr:  72.83%, val:  55.42%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-91  lr=['0.0017270'], tr/val_loss:  0.618755/  1.744922, tr:  73.95%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-92  lr=['0.0013664'], tr/val_loss:  0.611646/  1.772386, tr:  73.95%, val:  53.75%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-93  lr=['0.0010475'], tr/val_loss:  0.608907/  1.762208, tr:  73.03%, val:  56.25%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-94  lr=['0.0007704'], tr/val_loss:  0.604176/  1.771995, tr:  74.87%, val:  55.83%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-95  lr=['0.0005355'], tr/val_loss:  0.603204/  1.766404, tr:  74.26%, val:  54.17%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-96  lr=['0.0003430'], tr/val_loss:  0.614018/  1.773957, tr:  75.38%, val:  56.67%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-97  lr=['0.0001930'], tr/val_loss:  0.602271/  1.772135, tr:  76.81%, val:  54.58%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-98  lr=['0.0000858'], tr/val_loss:  0.608261/  1.774009, tr:  76.81%, val:  54.58%, val_best:  57.92%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-99  lr=['0.0000215'], tr/val_loss:  0.596832/  1.773295, tr:  76.71%, val:  54.58%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48b1e0fdb6f43fc9292f3d0004c5bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▄▂▂▁▂▂▂▄▂▂▂▂▂▂▃▂▃▂▂▂▄▅▄▂█▆▅▄▆█▅▆▅▄▆▄█▅</td></tr><tr><td>summary_val_acc</td><td>▃▅▂▄▄▅▃▁▅▄▅▄▄▄▅▄▅▄▃▄▇▇▆▇▇▇▇▇█▇██▇█▇▇█▇██</td></tr><tr><td>tr_acc</td><td>▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>█▇███▇▆▇▇▆▆▆▆▅▅▆▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>val_acc_now</td><td>▃▅▂▄▄▅▃▁▅▄▅▄▄▄▅▄▅▄▃▄▇▇▆▇▇▇▇▇█▇██▇█▇▇█▇██</td></tr><tr><td>val_loss</td><td>▂▆█▅▄▃▂▇▄▅▂▃▃▃▄▄▃▂▄▃▁▂▂▂▂▂▂▁▁▂▂▁▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.76711</td></tr><tr><td>tr_epoch_loss</td><td>0.59683</td></tr><tr><td>val_acc_best</td><td>0.57917</td></tr><tr><td>val_acc_now</td><td>0.54583</td></tr><tr><td>val_loss</td><td>1.77329</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-108</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sx8xj7ki' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sx8xj7ki</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_182909-sx8xj7ki/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 75ir3oeh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015895192123688928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.5319447587810149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.0834193831502279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_183818-75ir3oeh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75ir3oeh' target=\"_blank\">floral-sweep-110</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75ir3oeh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75ir3oeh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0015895'], tr/val_loss:  1.933827/  1.640847, tr:  35.34%, val:  45.42%, val_best:  45.42%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-1   lr=['0.0015891'], tr/val_loss:  1.307061/  1.475630, tr:  53.63%, val:  47.50%, val_best:  47.50%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-2   lr=['0.0015880'], tr/val_loss:  1.168496/  1.321694, tr:  60.16%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-3   lr=['0.0015860'], tr/val_loss:  1.100765/  1.296769, tr:  62.21%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-4   lr=['0.0015833'], tr/val_loss:  1.077704/  1.277023, tr:  62.21%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-5   lr=['0.0015797'], tr/val_loss:  1.056433/  1.375106, tr:  62.10%, val:  54.17%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-6   lr=['0.0015754'], tr/val_loss:  1.046491/  1.315457, tr:  64.45%, val:  55.83%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-7   lr=['0.0015704'], tr/val_loss:  1.043020/  1.255041, tr:  65.07%, val:  53.75%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-8   lr=['0.0015646'], tr/val_loss:  0.981554/  1.203680, tr:  66.60%, val:  60.00%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-9   lr=['0.0015580'], tr/val_loss:  0.928388/  1.423046, tr:  68.95%, val:  48.75%, val_best:  60.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-10  lr=['0.0015506'], tr/val_loss:  0.936775/  1.259326, tr:  69.15%, val:  57.50%, val_best:  60.42%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-11  lr=['0.0015425'], tr/val_loss:  0.903031/  1.220122, tr:  71.71%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:04<00:00, 13.06it/s]\n",
      "epoch-12  lr=['0.0015337'], tr/val_loss:  0.856616/  1.149746, tr:  73.24%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-13  lr=['0.0015242'], tr/val_loss:  0.845508/  1.264115, tr:  73.85%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-14  lr=['0.0015139'], tr/val_loss:  0.814528/  1.212020, tr:  71.50%, val:  57.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-15  lr=['0.0015029'], tr/val_loss:  0.809077/  1.174924, tr:  73.95%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-16  lr=['0.0014912'], tr/val_loss:  0.761658/  1.245251, tr:  77.73%, val:  55.42%, val_best:  65.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-17  lr=['0.0014788'], tr/val_loss:  0.758408/  1.171880, tr:  75.59%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-18  lr=['0.0014658'], tr/val_loss:  0.750073/  1.163678, tr:  76.92%, val:  63.75%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-19  lr=['0.0014521'], tr/val_loss:  0.708954/  1.200968, tr:  79.16%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-20  lr=['0.0014377'], tr/val_loss:  0.678122/  1.217008, tr:  78.65%, val:  64.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-21  lr=['0.0014227'], tr/val_loss:  0.664903/  1.268397, tr:  79.98%, val:  59.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-22  lr=['0.0014071'], tr/val_loss:  0.638506/  1.225605, tr:  81.51%, val:  63.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-23  lr=['0.0013909'], tr/val_loss:  0.608031/  1.245631, tr:  82.94%, val:  63.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-24  lr=['0.0013741'], tr/val_loss:  0.598527/  1.313983, tr:  84.47%, val:  59.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-25  lr=['0.0013567'], tr/val_loss:  0.603308/  1.234499, tr:  82.84%, val:  62.08%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-26  lr=['0.0013388'], tr/val_loss:  0.562661/  1.263322, tr:  86.93%, val:  65.42%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-27  lr=['0.0013203'], tr/val_loss:  0.552275/  1.285478, tr:  85.90%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-28  lr=['0.0013014'], tr/val_loss:  0.543718/  1.262692, tr:  86.62%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-29  lr=['0.0012819'], tr/val_loss:  0.528522/  1.276598, tr:  87.13%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-30  lr=['0.0012619'], tr/val_loss:  0.507819/  1.244877, tr:  86.82%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-31  lr=['0.0012415'], tr/val_loss:  0.466939/  1.293388, tr:  89.58%, val:  64.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-32  lr=['0.0012206'], tr/val_loss:  0.472709/  1.340822, tr:  87.13%, val:  60.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-33  lr=['0.0011993'], tr/val_loss:  0.439204/  1.295360, tr:  91.32%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-34  lr=['0.0011776'], tr/val_loss:  0.442040/  1.317270, tr:  89.99%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-35  lr=['0.0011556'], tr/val_loss:  0.415946/  1.337905, tr:  92.24%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-36  lr=['0.0011332'], tr/val_loss:  0.406517/  1.368295, tr:  91.83%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-37  lr=['0.0011104'], tr/val_loss:  0.402638/  1.472454, tr:  91.01%, val:  62.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-38  lr=['0.0010873'], tr/val_loss:  0.380872/  1.379076, tr:  93.67%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-39  lr=['0.0010640'], tr/val_loss:  0.365713/  1.369274, tr:  93.67%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-40  lr=['0.0010404'], tr/val_loss:  0.362465/  1.376333, tr:  92.95%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-41  lr=['0.0010165'], tr/val_loss:  0.351857/  1.426475, tr:  92.54%, val:  67.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-42  lr=['0.0009924'], tr/val_loss:  0.326110/  1.461599, tr:  94.48%, val:  67.50%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-43  lr=['0.0009681'], tr/val_loss:  0.319559/  1.435108, tr:  95.30%, val:  65.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-44  lr=['0.0009437'], tr/val_loss:  0.314927/  1.469104, tr:  95.30%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-45  lr=['0.0009191'], tr/val_loss:  0.306046/  1.480587, tr:  95.61%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-46  lr=['0.0008944'], tr/val_loss:  0.298381/  1.481909, tr:  95.20%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-47  lr=['0.0008696'], tr/val_loss:  0.283888/  1.528057, tr:  96.63%, val:  65.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-48  lr=['0.0008447'], tr/val_loss:  0.274985/  1.513799, tr:  97.45%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-49  lr=['0.0008197'], tr/val_loss:  0.273204/  1.545890, tr:  96.22%, val:  66.25%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-50  lr=['0.0007948'], tr/val_loss:  0.272593/  1.550176, tr:  97.34%, val:  65.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-51  lr=['0.0007698'], tr/val_loss:  0.261567/  1.530101, tr:  97.55%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-52  lr=['0.0007449'], tr/val_loss:  0.254999/  1.570673, tr:  97.96%, val:  65.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-53  lr=['0.0007200'], tr/val_loss:  0.238914/  1.549102, tr:  98.16%, val:  70.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-54  lr=['0.0006951'], tr/val_loss:  0.246422/  1.572575, tr:  96.94%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-55  lr=['0.0006704'], tr/val_loss:  0.237997/  1.601632, tr:  97.04%, val:  66.25%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-56  lr=['0.0006458'], tr/val_loss:  0.233277/  1.573984, tr:  98.16%, val:  66.25%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-57  lr=['0.0006214'], tr/val_loss:  0.230201/  1.612282, tr:  97.34%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-58  lr=['0.0005971'], tr/val_loss:  0.218993/  1.608764, tr:  98.57%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-59  lr=['0.0005730'], tr/val_loss:  0.215861/  1.622227, tr:  98.37%, val:  67.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-60  lr=['0.0005492'], tr/val_loss:  0.213920/  1.637978, tr:  98.47%, val:  65.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-61  lr=['0.0005255'], tr/val_loss:  0.211906/  1.640408, tr:  98.67%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 13.03it/s]\n",
      "epoch-62  lr=['0.0005022'], tr/val_loss:  0.201668/  1.636956, tr:  99.08%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-63  lr=['0.0004791'], tr/val_loss:  0.208941/  1.654971, tr:  98.77%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-64  lr=['0.0004564'], tr/val_loss:  0.194227/  1.678041, tr:  99.18%, val:  70.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-65  lr=['0.0004339'], tr/val_loss:  0.196446/  1.691655, tr:  99.18%, val:  65.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-66  lr=['0.0004119'], tr/val_loss:  0.193644/  1.682798, tr:  99.28%, val:  65.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-67  lr=['0.0003902'], tr/val_loss:  0.190463/  1.677363, tr:  99.18%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-68  lr=['0.0003689'], tr/val_loss:  0.185090/  1.702906, tr:  99.28%, val:  67.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-69  lr=['0.0003480'], tr/val_loss:  0.182896/  1.696655, tr:  98.98%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-70  lr=['0.0003276'], tr/val_loss:  0.180940/  1.710943, tr:  99.69%, val:  67.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-71  lr=['0.0003076'], tr/val_loss:  0.177177/  1.715203, tr:  99.59%, val:  66.25%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-72  lr=['0.0002882'], tr/val_loss:  0.173793/  1.701985, tr:  99.69%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-73  lr=['0.0002692'], tr/val_loss:  0.180064/  1.721285, tr:  99.59%, val:  65.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-74  lr=['0.0002507'], tr/val_loss:  0.168687/  1.705940, tr:  99.80%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-75  lr=['0.0002328'], tr/val_loss:  0.168421/  1.721305, tr:  99.69%, val:  67.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-76  lr=['0.0002154'], tr/val_loss:  0.167881/  1.731936, tr:  99.69%, val:  65.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-77  lr=['0.0001986'], tr/val_loss:  0.167392/  1.719554, tr:  99.69%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-78  lr=['0.0001824'], tr/val_loss:  0.164663/  1.733272, tr:  99.80%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-79  lr=['0.0001668'], tr/val_loss:  0.165357/  1.731181, tr:  99.80%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-80  lr=['0.0001518'], tr/val_loss:  0.162303/  1.728339, tr:  99.69%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-81  lr=['0.0001374'], tr/val_loss:  0.161344/  1.725510, tr: 100.00%, val:  66.25%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-82  lr=['0.0001237'], tr/val_loss:  0.164498/  1.734517, tr:  99.69%, val:  66.25%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-83  lr=['0.0001107'], tr/val_loss:  0.159302/  1.740954, tr:  99.90%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-84  lr=['0.0000983'], tr/val_loss:  0.156517/  1.731136, tr:  99.90%, val:  65.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-85  lr=['0.0000866'], tr/val_loss:  0.156979/  1.723321, tr:  99.90%, val:  67.92%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-86  lr=['0.0000756'], tr/val_loss:  0.157248/  1.733116, tr:  99.90%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-87  lr=['0.0000654'], tr/val_loss:  0.156288/  1.727789, tr:  99.80%, val:  67.50%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-88  lr=['0.0000558'], tr/val_loss:  0.154716/  1.735071, tr:  99.80%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-89  lr=['0.0000470'], tr/val_loss:  0.154079/  1.738904, tr: 100.00%, val:  67.50%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-90  lr=['0.0000389'], tr/val_loss:  0.154893/  1.745012, tr: 100.00%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-91  lr=['0.0000316'], tr/val_loss:  0.157135/  1.742084, tr:  99.90%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-92  lr=['0.0000250'], tr/val_loss:  0.155546/  1.738817, tr: 100.00%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-93  lr=['0.0000191'], tr/val_loss:  0.153226/  1.742886, tr:  99.90%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]\n",
      "epoch-94  lr=['0.0000141'], tr/val_loss:  0.152645/  1.737634, tr:  99.90%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-95  lr=['0.0000098'], tr/val_loss:  0.153067/  1.740230, tr:  99.80%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-96  lr=['0.0000063'], tr/val_loss:  0.152123/  1.741729, tr:  99.80%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-97  lr=['0.0000035'], tr/val_loss:  0.152531/  1.741873, tr: 100.00%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-98  lr=['0.0000016'], tr/val_loss:  0.154057/  1.741531, tr:  99.90%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-99  lr=['0.0000004'], tr/val_loss:  0.152287/  1.742020, tr:  99.90%, val:  67.08%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f149ca01d8944a186a48611034117cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▁▁▄▃▂▄▅▆▅▅▅▅▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▃▂▇▅▇▇▅▅▇▆▆▇▆██▇▇▇▇▇██▇▇▇█▇█▇▇▇▇██▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▃▂▇▅▇▇▅▅▇▆▆▇▆██▇▇▇▇▇██▇▇▇█▇█▇▇▇▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▇▃▃▂▄▁▂▁▂▂▃▂▂▃▃▅▄▅▅▅▆▆▆▆▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99898</td></tr><tr><td>tr_epoch_loss</td><td>0.15229</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.67083</td></tr><tr><td>val_loss</td><td>1.74202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-sweep-110</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75ir3oeh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/75ir3oeh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_183818-75ir3oeh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wiu08b29 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0030709520156929626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1.2034380387181984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.3387508097917828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_184724-wiu08b29</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wiu08b29' target=\"_blank\">hardy-sweep-112</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wiu08b29' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wiu08b29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0030710'], tr/val_loss:  2.099082/  1.704577, tr:  22.78%, val:  43.75%, val_best:  43.75%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-1   lr=['0.0030702'], tr/val_loss:  1.311160/  1.394556, tr:  55.36%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-2   lr=['0.0030679'], tr/val_loss:  1.088210/  1.162571, tr:  62.10%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-3   lr=['0.0030641'], tr/val_loss:  0.938300/  1.161419, tr:  67.21%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-4   lr=['0.0030588'], tr/val_loss:  0.872848/  1.222957, tr:  68.74%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-5   lr=['0.0030520'], tr/val_loss:  0.821260/  1.232283, tr:  73.44%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-6   lr=['0.0030438'], tr/val_loss:  0.705787/  1.199109, tr:  76.30%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-7   lr=['0.0030340'], tr/val_loss:  0.692630/  1.277693, tr:  77.32%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-8   lr=['0.0030227'], tr/val_loss:  0.614475/  1.153601, tr:  79.88%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-9   lr=['0.0030100'], tr/val_loss:  0.510950/  1.342145, tr:  84.88%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-10  lr=['0.0029958'], tr/val_loss:  0.455969/  1.286867, tr:  88.56%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-11  lr=['0.0029802'], tr/val_loss:  0.399530/  1.390484, tr:  89.58%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-12  lr=['0.0029631'], tr/val_loss:  0.364332/  1.333503, tr:  90.91%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-13  lr=['0.0029447'], tr/val_loss:  0.311275/  1.398818, tr:  93.87%, val:  72.50%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-14  lr=['0.0029248'], tr/val_loss:  0.265543/  1.421398, tr:  96.12%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-15  lr=['0.0029036'], tr/val_loss:  0.258380/  1.438395, tr:  95.61%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-16  lr=['0.0028810'], tr/val_loss:  0.220003/  1.738810, tr:  97.65%, val:  70.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-17  lr=['0.0028571'], tr/val_loss:  0.229900/  1.597377, tr:  96.94%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-18  lr=['0.0028319'], tr/val_loss:  0.202839/  1.679364, tr:  96.32%, val:  71.25%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-19  lr=['0.0028054'], tr/val_loss:  0.159356/  1.569600, tr:  98.37%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-20  lr=['0.0027777'], tr/val_loss:  0.102761/  1.649307, tr:  99.80%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-21  lr=['0.0027487'], tr/val_loss:  0.080939/  1.787724, tr:  99.90%, val:  73.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-22  lr=['0.0027186'], tr/val_loss:  0.075136/  1.727871, tr:  99.90%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]\n",
      "epoch-23  lr=['0.0026873'], tr/val_loss:  0.065481/  1.862710, tr:  99.90%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-24  lr=['0.0026548'], tr/val_loss:  0.066599/  1.826766, tr:  99.90%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-25  lr=['0.0026212'], tr/val_loss:  0.047143/  1.848623, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-26  lr=['0.0025866'], tr/val_loss:  0.033173/  1.905695, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-27  lr=['0.0025509'], tr/val_loss:  0.027461/  1.941307, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-28  lr=['0.0025142'], tr/val_loss:  0.027981/  1.910420, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-29  lr=['0.0024766'], tr/val_loss:  0.016560/  1.964330, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 13.11it/s]\n",
      "epoch-30  lr=['0.0024380'], tr/val_loss:  0.014601/  1.988491, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-31  lr=['0.0023985'], tr/val_loss:  0.012175/  1.996806, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-32  lr=['0.0023582'], tr/val_loss:  0.011133/  2.045867, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-33  lr=['0.0023171'], tr/val_loss:  0.009824/  2.039598, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-34  lr=['0.0022752'], tr/val_loss:  0.008323/  2.039173, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-35  lr=['0.0022326'], tr/val_loss:  0.007441/  2.075495, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-36  lr=['0.0021892'], tr/val_loss:  0.006858/  2.076591, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-37  lr=['0.0021453'], tr/val_loss:  0.006159/  2.111332, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-38  lr=['0.0021007'], tr/val_loss:  0.005616/  2.123593, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-39  lr=['0.0020556'], tr/val_loss:  0.005589/  2.132547, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-40  lr=['0.0020100'], tr/val_loss:  0.005217/  2.146551, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-41  lr=['0.0019639'], tr/val_loss:  0.004921/  2.157400, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-42  lr=['0.0019173'], tr/val_loss:  0.004438/  2.161105, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-43  lr=['0.0018704'], tr/val_loss:  0.004367/  2.166029, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-44  lr=['0.0018232'], tr/val_loss:  0.004307/  2.151250, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-45  lr=['0.0017757'], tr/val_loss:  0.003967/  2.146881, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-46  lr=['0.0017279'], tr/val_loss:  0.003861/  2.171814, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-47  lr=['0.0016800'], tr/val_loss:  0.003747/  2.183041, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-48  lr=['0.0016319'], tr/val_loss:  0.003352/  2.186727, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-49  lr=['0.0015837'], tr/val_loss:  0.003612/  2.192192, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-50  lr=['0.0015355'], tr/val_loss:  0.003605/  2.200759, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-51  lr=['0.0014872'], tr/val_loss:  0.003465/  2.186608, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-52  lr=['0.0014391'], tr/val_loss:  0.003286/  2.200076, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-53  lr=['0.0013910'], tr/val_loss:  0.003234/  2.204206, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-54  lr=['0.0013430'], tr/val_loss:  0.002984/  2.223385, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-55  lr=['0.0012953'], tr/val_loss:  0.002947/  2.215071, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-56  lr=['0.0012478'], tr/val_loss:  0.002833/  2.209124, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-57  lr=['0.0012005'], tr/val_loss:  0.002711/  2.216207, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-58  lr=['0.0011536'], tr/val_loss:  0.002716/  2.231236, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-59  lr=['0.0011071'], tr/val_loss:  0.002849/  2.213320, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-60  lr=['0.0010610'], tr/val_loss:  0.002630/  2.219347, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-61  lr=['0.0010154'], tr/val_loss:  0.002607/  2.232615, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-62  lr=['0.0009702'], tr/val_loss:  0.002497/  2.228334, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.35it/s]\n",
      "epoch-63  lr=['0.0009257'], tr/val_loss:  0.002556/  2.234736, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.22it/s]\n",
      "epoch-64  lr=['0.0008817'], tr/val_loss:  0.002370/  2.234095, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.77it/s]\n",
      "epoch-65  lr=['0.0008384'], tr/val_loss:  0.002533/  2.226037, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-66  lr=['0.0007958'], tr/val_loss:  0.002433/  2.232101, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-67  lr=['0.0007539'], tr/val_loss:  0.002382/  2.224555, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-68  lr=['0.0007127'], tr/val_loss:  0.002348/  2.219183, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-69  lr=['0.0006724'], tr/val_loss:  0.002274/  2.241776, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-70  lr=['0.0006329'], tr/val_loss:  0.002295/  2.243125, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-71  lr=['0.0005944'], tr/val_loss:  0.002209/  2.245342, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-72  lr=['0.0005567'], tr/val_loss:  0.002205/  2.239696, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-73  lr=['0.0005200'], tr/val_loss:  0.002357/  2.238862, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-74  lr=['0.0004844'], tr/val_loss:  0.002268/  2.239048, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-75  lr=['0.0004497'], tr/val_loss:  0.002320/  2.238180, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-76  lr=['0.0004162'], tr/val_loss:  0.002221/  2.238428, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-77  lr=['0.0003837'], tr/val_loss:  0.002197/  2.236567, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-78  lr=['0.0003524'], tr/val_loss:  0.002165/  2.241796, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-79  lr=['0.0003222'], tr/val_loss:  0.002187/  2.244579, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-80  lr=['0.0002932'], tr/val_loss:  0.002130/  2.245216, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-81  lr=['0.0002655'], tr/val_loss:  0.002169/  2.243664, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-82  lr=['0.0002390'], tr/val_loss:  0.002170/  2.249010, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-83  lr=['0.0002138'], tr/val_loss:  0.002100/  2.248287, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-84  lr=['0.0001899'], tr/val_loss:  0.002076/  2.247988, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-85  lr=['0.0001674'], tr/val_loss:  0.002082/  2.248769, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-86  lr=['0.0001461'], tr/val_loss:  0.002088/  2.255991, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-87  lr=['0.0001263'], tr/val_loss:  0.002069/  2.253992, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-88  lr=['0.0001078'], tr/val_loss:  0.002042/  2.254265, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-89  lr=['0.0000908'], tr/val_loss:  0.002044/  2.256015, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-90  lr=['0.0000752'], tr/val_loss:  0.002080/  2.256115, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-91  lr=['0.0000610'], tr/val_loss:  0.002041/  2.254685, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-92  lr=['0.0000482'], tr/val_loss:  0.002039/  2.257525, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-93  lr=['0.0000370'], tr/val_loss:  0.002040/  2.259317, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-94  lr=['0.0000272'], tr/val_loss:  0.002036/  2.258049, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-95  lr=['0.0000189'], tr/val_loss:  0.002023/  2.258056, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-96  lr=['0.0000121'], tr/val_loss:  0.002027/  2.257096, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-97  lr=['0.0000068'], tr/val_loss:  0.001995/  2.257819, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-98  lr=['0.0000030'], tr/val_loss:  0.002023/  2.257824, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-99  lr=['0.0000008'], tr/val_loss:  0.002000/  2.257823, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.00it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd75eeed00242399ec1e492a613348b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.965 MB of 3.965 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▂▅█▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▆▇▇▇█▇██████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▇▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▆▇▇▇█▇██████████████████████████████</td></tr><tr><td>val_loss</td><td>▄▁▁▂▂▂▃▄▄▅▅▆▆▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.002</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.25782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-112</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wiu08b29' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wiu08b29</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240827_184724-wiu08b29/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vs1wsjsm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022801940335219196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.4153097129756968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.1151037758633182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240827_185619-vs1wsjsm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vs1wsjsm' target=\"_blank\">hearty-sweep-114</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yp7c5ffh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vs1wsjsm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vs1wsjsm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 4da85ad412939ff9a09fdbbef53276cf\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0228019'], tr/val_loss:  1.794612/  1.817935, tr:  37.90%, val:  35.00%, val_best:  35.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-1   lr=['0.0227963'], tr/val_loss:  1.409721/  1.838685, tr:  48.52%, val:  42.50%, val_best:  42.50%: 100%|██████████| 62/62 [00:04<00:00, 12.96it/s]\n",
      "epoch-2   lr=['0.0227794'], tr/val_loss:  1.161960/  1.987912, tr:  59.14%, val:  46.67%, val_best:  46.67%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-3   lr=['0.0227513'], tr/val_loss:  1.062164/  1.835220, tr:  63.33%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-4   lr=['0.0227120'], tr/val_loss:  0.910015/  1.478693, tr:  69.25%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-5   lr=['0.0226616'], tr/val_loss:  0.829171/  1.456457, tr:  72.83%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-6   lr=['0.0226000'], tr/val_loss:  0.762326/  1.495894, tr:  74.87%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-7   lr=['0.0225274'], tr/val_loss:  0.782329/  1.718269, tr:  73.24%, val:  52.50%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-8   lr=['0.0224438'], tr/val_loss:  0.672881/  1.658731, tr:  79.26%, val:  60.42%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-9   lr=['0.0223492'], tr/val_loss:  0.486151/  1.797755, tr:  84.47%, val:  59.58%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-10  lr=['0.0222439'], tr/val_loss:  0.457545/  2.011772, tr:  88.36%, val:  59.17%, val_best:  61.25%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]\n",
      "epoch-11  lr=['0.0221279'], tr/val_loss:  0.403966/  1.731154, tr:  89.27%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-12  lr=['0.0220013'], tr/val_loss:  0.318573/  1.647005, tr:  94.59%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-13  lr=['0.0218643'], tr/val_loss:  0.281592/  1.798149, tr:  94.89%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-14  lr=['0.0217169'], tr/val_loss:  0.186357/  1.831698, tr:  98.37%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-15  lr=['0.0215593'], tr/val_loss:  0.256623/  2.178509, tr:  93.87%, val:  63.75%, val_best:  69.58%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-16  lr=['0.0213917'], tr/val_loss:  0.148474/  1.962778, tr:  98.26%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-17  lr=['0.0212143'], tr/val_loss:  0.161210/  1.872730, tr:  97.45%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-18  lr=['0.0210271'], tr/val_loss:  0.106408/  2.071905, tr:  99.49%, val:  68.33%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-19  lr=['0.0208305'], tr/val_loss:  0.073317/  2.139457, tr:  99.59%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-20  lr=['0.0206245'], tr/val_loss:  0.059932/  2.129664, tr:  99.69%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-21  lr=['0.0204095'], tr/val_loss:  0.027129/  2.272475, tr: 100.00%, val:  71.25%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-22  lr=['0.0201856'], tr/val_loss:  0.019403/  2.489963, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]\n",
      "epoch-23  lr=['0.0199530'], tr/val_loss:  0.020337/  2.428543, tr: 100.00%, val:  70.83%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-24  lr=['0.0197119'], tr/val_loss:  0.008832/  2.363371, tr: 100.00%, val:  72.08%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-25  lr=['0.0194627'], tr/val_loss:  0.006587/  2.477242, tr: 100.00%, val:  71.67%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-26  lr=['0.0192055'], tr/val_loss:  0.004767/  2.499491, tr: 100.00%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-27  lr=['0.0189406'], tr/val_loss:  0.003629/  2.538684, tr: 100.00%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-28  lr=['0.0186682'], tr/val_loss:  0.003202/  2.649533, tr: 100.00%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-29  lr=['0.0183887'], tr/val_loss:  0.002443/  2.647915, tr: 100.00%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-30  lr=['0.0181023'], tr/val_loss:  0.001772/  2.675723, tr: 100.00%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-31  lr=['0.0178093'], tr/val_loss:  0.001754/  2.648687, tr: 100.00%, val:  70.42%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-32  lr=['0.0175099'], tr/val_loss:  0.001728/  2.705084, tr: 100.00%, val:  71.25%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]\n",
      "epoch-33  lr=['0.0172045'], tr/val_loss:  0.001433/  2.697896, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-34  lr=['0.0168934'], tr/val_loss:  0.001504/  2.733614, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-35  lr=['0.0165769'], tr/val_loss:  0.001230/  2.733720, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-36  lr=['0.0162553'], tr/val_loss:  0.001106/  2.735546, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-37  lr=['0.0159288'], tr/val_loss:  0.001123/  2.749453, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-38  lr=['0.0155979'], tr/val_loss:  0.001021/  2.773331, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-39  lr=['0.0152629'], tr/val_loss:  0.000937/  2.763276, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-40  lr=['0.0149241'], tr/val_loss:  0.000850/  2.758588, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-41  lr=['0.0145817'], tr/val_loss:  0.001100/  2.740552, tr: 100.00%, val:  70.83%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-42  lr=['0.0142363'], tr/val_loss:  0.000923/  2.755313, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-43  lr=['0.0138880'], tr/val_loss:  0.000793/  2.756787, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-44  lr=['0.0135373'], tr/val_loss:  0.000852/  2.764663, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-45  lr=['0.0131845'], tr/val_loss:  0.000816/  2.778679, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]\n",
      "epoch-46  lr=['0.0128299'], tr/val_loss:  0.000738/  2.786314, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-47  lr=['0.0124739'], tr/val_loss:  0.000711/  2.795863, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-48  lr=['0.0121168'], tr/val_loss:  0.000652/  2.792511, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-49  lr=['0.0117591'], tr/val_loss:  0.000599/  2.796910, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-50  lr=['0.0114010'], tr/val_loss:  0.000611/  2.805268, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-51  lr=['0.0110429'], tr/val_loss:  0.000613/  2.817390, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-52  lr=['0.0106851'], tr/val_loss:  0.000608/  2.815590, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-53  lr=['0.0103280'], tr/val_loss:  0.000586/  2.824318, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-54  lr=['0.0099720'], tr/val_loss:  0.000560/  2.821482, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-55  lr=['0.0096175'], tr/val_loss:  0.000586/  2.815970, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-56  lr=['0.0092646'], tr/val_loss:  0.000563/  2.814685, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-57  lr=['0.0089139'], tr/val_loss:  0.000562/  2.824857, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-58  lr=['0.0085657'], tr/val_loss:  0.000531/  2.826345, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-59  lr=['0.0082202'], tr/val_loss:  0.000534/  2.830265, tr: 100.00%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-60  lr=['0.0078779'], tr/val_loss:  0.000517/  2.830308, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-61  lr=['0.0075390'], tr/val_loss:  0.000517/  2.829825, tr: 100.00%, val:  68.33%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-62  lr=['0.0072040'], tr/val_loss:  0.000504/  2.828686, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]\n",
      "epoch-63  lr=['0.0068731'], tr/val_loss:  0.000508/  2.828866, tr: 100.00%, val:  68.33%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-64  lr=['0.0065467'], tr/val_loss:  0.000494/  2.833838, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-65  lr=['0.0062250'], tr/val_loss:  0.000481/  2.834292, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]\n",
      "epoch-66  lr=['0.0059085'], tr/val_loss:  0.000489/  2.837296, tr: 100.00%, val:  68.75%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 13.32it/s]\n",
      "epoch-67  lr=['0.0055974'], tr/val_loss:  0.000485/  2.842938, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-68  lr=['0.0052920'], tr/val_loss:  0.000491/  2.842545, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-69  lr=['0.0049927'], tr/val_loss:  0.000470/  2.845378, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-70  lr=['0.0046996'], tr/val_loss:  0.000461/  2.853415, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-71  lr=['0.0044132'], tr/val_loss:  0.000452/  2.851120, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-72  lr=['0.0041337'], tr/val_loss:  0.000463/  2.855995, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-73  lr=['0.0038614'], tr/val_loss:  0.000463/  2.857212, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-74  lr=['0.0035965'], tr/val_loss:  0.000447/  2.859277, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-75  lr=['0.0033393'], tr/val_loss:  0.000445/  2.863398, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-76  lr=['0.0030900'], tr/val_loss:  0.000449/  2.860131, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-77  lr=['0.0028490'], tr/val_loss:  0.000461/  2.862442, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-78  lr=['0.0026164'], tr/val_loss:  0.000445/  2.867215, tr: 100.00%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-79  lr=['0.0023924'], tr/val_loss:  0.000455/  2.867629, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-80  lr=['0.0021774'], tr/val_loss:  0.000442/  2.865545, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-81  lr=['0.0019714'], tr/val_loss:  0.000442/  2.867012, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-82  lr=['0.0017748'], tr/val_loss:  0.000462/  2.868095, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-83  lr=['0.0015877'], tr/val_loss:  0.000442/  2.873540, tr: 100.00%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-84  iter_acc: 100.00%, lr=['0.0014102'], iter_loss:  0.000564, val_best:  72.92%:   2%|▏         | 1/62 [00:00<00:09,  6.37it/s]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")} denoise false',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"min\": 0.001, \"max\": 0.1}, #0.00936191669529645\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"decay\": {\"values\": [0.25]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"epoch_num\": {\"values\": [100]},\n",
    "        \"dvs_duration\": {\"values\": [100_000]},\n",
    "        \"dvs_clipping\": {\"values\": [2]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "        \"const2\": {\"values\": [False]},\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "        \"e_transport_swap\": {\"values\": [0]},\n",
    "        \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "        \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [0]},\n",
    "        \"lif_layer_sg_width\": {\"min\": 0.3, \"max\": 6.0},\n",
    "        \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "        \"lif_layer_v_threshold\": {\"min\": 0.0, \"max\": 2.0},\n",
    "        \"scheduler_name\": {\"values\": ['CosineAnnealingLR']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "        \"denoise_on\": {\"values\": [False]}, \n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    which_data  =  wandb.config.which_data\n",
    "    OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "    const2  =  wandb.config.const2\n",
    "    surrogate  =  wandb.config.surrogate\n",
    "    DFA_on  =  wandb.config.DFA_on\n",
    "    OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "    cfg  =  wandb.config.cfg\n",
    "    e_transport_swap  =  wandb.config.e_transport_swap\n",
    "    e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "    drop_rate  =  wandb.config.drop_rate\n",
    "    exclude_class  =  wandb.config.exclude_class\n",
    "    merge_polarities  =  wandb.config.merge_polarities\n",
    "    lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "    lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "    e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "    lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "    scheduler_name  =  wandb.config.scheduler_name\n",
    "    denoise_on  =  wandb.config.denoise_on\n",
    "    if const2 == True:\n",
    "        const2 = decay\n",
    "    else:\n",
    "        const2 = 0.0\n",
    "\n",
    "    my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = which_data,\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = cfg,\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "                drop_rate = drop_rate,\n",
    "\n",
    "                exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = denoise_on,\n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
