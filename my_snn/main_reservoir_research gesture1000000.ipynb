{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH:256\n",
    "# batch_size:256\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.7834769413661389\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:32\n",
    "# learning_rate:0.007176761798504128\n",
    "# pre_spike_weight:5.165214142219577\n",
    "# rate_coding:true\n",
    "# TIME_STEP:9\n",
    "# time_step:9\n",
    "# v_decay:0.7834769413661389\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"CIFAR10\"\n",
    "\n",
    "\n",
    "# BATCH:256\n",
    "# batch_size:256\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.38993471232202725\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:28\n",
    "# learning_rate:0.06285718352377828\n",
    "# pre_spike_weight:6.21970124592063\n",
    "# rate_coding:true\n",
    "# TIME_STEP:16\n",
    "# time_step:16\n",
    "# v_decay:0.38993471232202725\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"MNIST\"\n",
    "\n",
    "# BATCH:64\n",
    "# batch_size:64\n",
    "# data_path:\"/data2\"\n",
    "# decay:0.9266077968579136\n",
    "# EPOCH:20\n",
    "# hard_reset:true\n",
    "# IMAGE_SIZE:28\n",
    "# learning_rate:0.07732456724854177\n",
    "# pre_spike_weight:1.5377416716615555\n",
    "# rate_coding:true\n",
    "# TIME_STEP:7\n",
    "# time_step:7\n",
    "# v_decay:0.9266077968579136\n",
    "# v_reset:0\n",
    "# v_threshold:1\n",
    "# which_data:\"FASHION_MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from snntorch import spikegen\n",
    "\n",
    " \n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAIhCAYAAACfVbSSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA75UlEQVR4nO3deXhU5f3//9ckkAlLEtaEICHErUZQg4kLmz9ESaWAWBcQlUXAgmERQhVSrChUImiRVgRFNpFFpICgIppKFVQoMSK4oKggCUqMLBJASMjM+f1ByfczJGAyztyHmXk+rutcl7lz5j7vmYK++zr3ucdhWZYlAAAA+F2Y3QUAAACEChovAAAAQ2i8AAAADKHxAgAAMITGCwAAwBAaLwAAAENovAAAAAyh8QIAADCExgsAAMAQGi/AC/Pnz5fD4Sg/atSoofj4eN155536+uuvbavr0UcflcPhsO36p8vLy9PQoUN12WWXKSoqSnFxcbrxxhu1bt26Cuf279/f4zOtU6eOWrRooZtvvlnz5s1TSUlJta+fmZkph8Ohbt26+eLtAMBvRuMF/Abz5s3Txo0b9e9//1vDhg3T6tWr1b59ex08eNDu0s4JS5Ys0ebNmzVgwACtWrVKs2fPltPp1A033KAFCxZUOL9WrVrauHGjNm7cqNdff10TJkxQnTp1dN999yk1NVV79uyp8rVPnDihhQsXSpLWrl2r77//3mfvCwC8ZgGotnnz5lmSrNzcXI/xxx57zJJkzZ0715a6xo8fb51Lf61//PHHCmNlZWXW5Zdfbl1wwQUe4/369bPq1KlT6TxvvfWWVbNmTeuaa66p8rWXLVtmSbK6du1qSbIef/zxKr2utLTUOnHiRKW/O3r0aJWvDwCVIfECfCgtLU2S9OOPP5aPHT9+XKNHj1ZKSopiYmLUoEEDtWnTRqtWrarweofDoWHDhumll15ScnKyateurSuuuEKvv/56hXPfeOMNpaSkyOl0KikpSU899VSlNR0/flxZWVlKSkpSRESEzjvvPA0dOlQ///yzx3ktWrRQt27d9Prrr6t169aqVauWkpOTy689f/58JScnq06dOrr66qv10Ucf/ernERsbW2EsPDxcqampKigo+NXXn5Kenq777rtP//3vf7V+/foqvWbOnDmKiIjQvHnzlJCQoHnz5smyLI9z3n33XTkcDr300ksaPXq0zjvvPDmdTn3zzTfq37+/6tatq08//VTp6emKiorSDTfcIEnKyclRjx491KxZM0VGRurCCy/U4MGDtW/fvvK5N2zYIIfDoSVLllSobcGCBXI4HMrNza3yZwAgONB4AT60a9cuSdLFF19cPlZSUqIDBw7oz3/+s1599VUtWbJE7du316233lrp7bY33nhD06dP14QJE7R8+XI1aNBAf/zjH7Vz587yc9555x316NFDUVFRevnll/Xkk0/qlVde0bx58zzmsixLt9xyi5566in16dNHb7zxhjIzM/Xiiy+qU6dOFdZNbd26VVlZWRozZoxWrFihmJgY3XrrrRo/frxmz56tSZMmadGiRTp06JC6deumY8eOVfszKisr04YNG9SyZctqve7mm2+WpCo1Xnv27NHbb7+tHj16qHHjxurXr5+++eabM742KytL+fn5eu655/Taa6+VN4ylpaW6+eab1alTJ61atUqPPfaYJOnbb79VmzZtNHPmTL399tt65JFH9N///lft27fXiRMnJEkdOnRQ69at9eyzz1a43vTp03XVVVfpqquuqtZnACAI2B25AYHo1K3GTZs2WSdOnLAOHz5srV271mrSpIl13XXXnfFWlWWdvNV24sQJa+DAgVbr1q09fifJiouLs4qLi8vHCgsLrbCwMCs7O7t87JprrrGaNm1qHTt2rHysuLjYatCggcetxrVr11qSrClTpnhcZ+nSpZYka9asWeVjiYmJVq1ataw9e/aUj33yySeWJCs+Pt7jNturr75qSbJWr15dlY/Lw7hx4yxJ1quvvuoxfrZbjZZlWdu3b7ckWffff/+vXmPChAmWJGvt2rWWZVnWzp07LYfDYfXp08fjvP/85z+WJOu6666rMEe/fv2qdNvY7XZbJ06csHbv3m1JslatWlX+u1N/TrZs2VI+tnnzZkuS9eKLL/7q+wAQfEi8gN/g2muvVc2aNRUVFaWbbrpJ9evX16pVq1SjRg2P85YtW6Z27dqpbt26qlGjhmrWrKk5c+Zo+/btFea8/vrrFRUVVf5zXFycYmNjtXv3bknS0aNHlZubq1tvvVWRkZHl50VFRal79+4ec516erB///4e43fccYfq1Kmjd955x2M8JSVF5513XvnPycnJkqSOHTuqdu3aFcZP1VRVs2fP1uOPP67Ro0erR48e1XqtddptwrOdd+r2YufOnSVJSUlJ6tixo5YvX67i4uIKr7ntttvOOF9lvysqKtKQIUOUkJBQ/r9nYmKiJHn8b9q7d2/FxsZ6pF7PPPOMGjdurF69elXp/QAILjRewG+wYMEC5ebmat26dRo8eLC2b9+u3r17e5yzYsUK9ezZU+edd54WLlyojRs3Kjc3VwMGDNDx48crzNmwYcMKY06ns/y23sGDB+V2u9WkSZMK550+tn//ftWoUUONGzf2GHc4HGrSpIn279/vMd6gQQOPnyMiIs46Xln9ZzJv3jwNHjxYf/rTn/Tkk09W+XWnnGrymjZtetbz1q1bp127dumOO+5QcXGxfv75Z/3888/q2bOnfvnll0rXXMXHx1c6V+3atRUdHe0x5na7lZ6erhUrVuihhx7SO++8o82bN2vTpk2S5HH71el0avDgwVq8eLF+/vln/fTTT3rllVc0aNAgOZ3Oar1/AMGhxq+fAuBMkpOTyxfUX3/99XK5XJo9e7b+9a9/6fbbb5ckLVy4UElJSVq6dKnHHlve7EslSfXr15fD4VBhYWGF350+1rBhQ5WVlemnn37yaL4sy1JhYaGxNUbz5s3ToEGD1K9fPz333HNe7TW2evVqSSfTt7OZM2eOJGnq1KmaOnVqpb8fPHiwx9iZ6qls/LPPPtPWrVs1f/589evXr3z8m2++qXSO+++/X0888YTmzp2r48ePq6ysTEOGDDnrewAQvEi8AB+aMmWK6tevr0ceeURut1vSyf94R0REePxHvLCwsNKnGqvi1FOFK1as8EicDh8+rNdee83j3FNP4Z3az+qU5cuX6+jRo+W/96f58+dr0KBBuueeezR79myvmq6cnBzNnj1bbdu2Vfv27c943sGDB7Vy5Uq1a9dO//nPfyocd999t3Jzc/XZZ595/X5O1X96YvX8889Xen58fLzuuOMOzZgxQ88995y6d++u5s2be319AIGNxAvwofr16ysrK0sPPfSQFi9erHvuuUfdunXTihUrlJGRodtvv10FBQWaOHGi4uPjvd7lfuLEibrpppvUuXNnjR49Wi6XS5MnT1adOnV04MCB8vM6d+6s3//+9xozZoyKi4vVrl07bdu2TePHj1fr1q3Vp08fX731Si1btkwDBw5USkqKBg8erM2bN3v8vnXr1h4NjNvtLr9lV1JSovz8fL355pt65ZVXlJycrFdeeeWs11u0aJGOHz+uESNGVJqMNWzYUIsWLdKcOXP09NNPe/WeLrnkEl1wwQUaO3asLMtSgwYN9NprryknJ+eMr3nggQd0zTXXSFKFJ08BhBh71/YDgelMG6halmUdO3bMat68uXXRRRdZZWVllmVZ1hNPPGG1aNHCcjqdVnJysvXCCy9UutmpJGvo0KEV5kxMTLT69evnMbZ69Wrr8ssvtyIiIqzmzZtbTzzxRKVzHjt2zBozZoyVmJho1axZ04qPj7fuv/9+6+DBgxWu0bVr1wrXrqymXbt2WZKsJ5988oyfkWX9vycDz3Ts2rXrjOfWqlXLat68udW9e3dr7ty5VklJyVmvZVmWlZKSYsXGxp713GuvvdZq1KiRVVJSUv5U47Jlyyqt/UxPWX7xxRdW586draioKKt+/frWHXfcYeXn51uSrPHjx1f6mhYtWljJycm/+h4ABDeHZVXxUSEAgFe2bdumK664Qs8++6wyMjLsLgeAjWi8AMBPvv32W+3evVt/+ctflJ+fr2+++cZjWw4AoYfF9QDgJxMnTlTnzp115MgRLVu2jKYLAIkXAACAKSReAAAAhtB4AQAAGELjBQAAYEhAb6Dqdrv1ww8/KCoqyqvdsAEACCWWZenw4cNq2rSpwsLMZy/Hjx9XaWmpX+aOiIhQZGSkX+b2pYBuvH744QclJCTYXQYAAAGloKBAzZo1M3rN48ePKymxrgqLXH6Zv0mTJtq1a9c533wFdOMVFRUlSbpozgMKr+38lbPPLU3qHra7BK+MSXzT7hK89sg3PewuwSsPnf+W3SV45cFV/v06In+6+Orddpfgle0FTewuwSsX/Gmr3SV4rST9SrtLqJaysuPKXZdd/t9Pk0pLS1VY5NLuvBaKjvJt2lZ82K3E1O9UWlpK4+VPp24vhtd2BlzjVaOOf6JWf6vj478sJtWoE1h/Rk6pHRVudwleCTvH/+V3NjXrRNhdglfCagXmZ17DUdPuErzmqhmYn7mdy3PqRjlUN8q313crcJYbBXTjBQAAAovLcsvl4x1EXZbbtxP6UeDGFwAAAAGGxAsAABjjliW3fBt5+Xo+fyLxAgAAMITECwAAGOOWW75ekeX7Gf2HxAsAAMAQEi8AAGCMy7Lksny7JsvX8/kTiRcAAIAhJF4AAMCYUH+qkcYLAAAY45YlVwg3XtxqBAAAMITECwAAGBPqtxpJvAAAAAwh8QIAAMawnQQAAACMIPECAADGuP93+HrOQGF74jVjxgwlJSUpMjJSqamp2rBhg90lAQAA+IWtjdfSpUs1cuRIjRs3Tlu2bFGHDh3UpUsX5efn21kWAADwE9f/9vHy9REobG28pk6dqoEDB2rQoEFKTk7WtGnTlJCQoJkzZ9pZFgAA8BOX5Z8jUNjWeJWWliovL0/p6eke4+np6frwww8rfU1JSYmKi4s9DgAAgEBhW+O1b98+uVwuxcXFeYzHxcWpsLCw0tdkZ2crJiam/EhISDBRKgAA8BG3n45AYfvieofD4fGzZVkVxk7JysrSoUOHyo+CggITJQIAAPiEbdtJNGrUSOHh4RXSraKiogop2ClOp1NOp9NEeQAAwA/ccsilygOW3zJnoLAt8YqIiFBqaqpycnI8xnNyctS2bVubqgIAAPAfWzdQzczMVJ8+fZSWlqY2bdpo1qxZys/P15AhQ+wsCwAA+InbOnn4es5AYWvj1atXL+3fv18TJkzQ3r171apVK61Zs0aJiYl2lgUAAOAXtn9lUEZGhjIyMuwuAwAAGODywxovX8/nT7Y3XgAAIHSEeuNl+3YSAAAAoYLECwAAGOO2HHJbPt5Owsfz+ROJFwAAgCEkXgAAwBjWeAEAAMAIEi8AAGCMS2Fy+Tj3cfl0Nv8i8QIAADCExAsAABhj+eGpRiuAnmqk8QIAAMawuB4AAABGkHgBAABjXFaYXJaPF9dbPp3Or0i8AAAADCHxAgAAxrjlkNvHuY9bgRN5kXgBAAAYEhSJV4emOxVRt6bdZVTL6x+k2l2CVyYNvMXuErz2/V8a2l2CVzLfH2h3CV65/861dpfgtcwGO+0uwSs33ZBmdwleqfdBA7tL8NpnP/5idwnV4vqlRHrb5hp4qhEAAAAmBEXiBQAAAoN/nmoMnDVeNF4AAMCYk4vrfXtr0Nfz+RO3GgEAAAwh8QIAAMa4FSYX20kAAADA30i8AACAMaG+uJ7ECwAAwBASLwAAYIxbYXxlEAAAAPyPxAsAABjjshxyWT7+yiAfz+dPNF4AAMAYlx+2k3BxqxEAAACnI/ECAADGuK0wuX28nYSb7SQAAABwOhIvAABgDGu8AAAAYASJFwAAMMYt32//4PbpbP5F4gUAAGAIiRcAADDGP18ZFDg5Eo0XAAAwxmWFyeXj7SR8PZ8/BU6lAAAAAY7ECwAAGOOWQ275enF94HxXI4kXAACAISReAADAGNZ4AQAAwAgSLwAAYIx/vjIocHKkwKkUAAAgwJF4AQAAY9yWQ25ff2WQj+fzJxIvAAAAQ0i8AACAMW4/rPHiK4MAAAAq4bbC5Pbx9g++ns+fAqdSAACAAEfjBQAAjHHJ4ZfDGzNmzFBSUpIiIyOVmpqqDRs2nPX8RYsW6YorrlDt2rUVHx+ve++9V/v376/WNWm8AABAyFm6dKlGjhypcePGacuWLerQoYO6dOmi/Pz8Ss9///331bdvXw0cOFCff/65li1bptzcXA0aNKha16XxAgAAxpxa4+Xro7qmTp2qgQMHatCgQUpOTta0adOUkJCgmTNnVnr+pk2b1KJFC40YMUJJSUlq3769Bg8erI8++qha16XxAgAAQaG4uNjjKCkpqfS80tJS5eXlKT093WM8PT1dH374YaWvadu2rfbs2aM1a9bIsiz9+OOP+te//qWuXbtWq0YaLwAAYIxL/ljndVJCQoJiYmLKj+zs7Epr2Ldvn1wul+Li4jzG4+LiVFhYWOlr2rZtq0WLFqlXr16KiIhQkyZNVK9ePT3zzDPVev80XgAAICgUFBTo0KFD5UdWVtZZz3c4PBflW5ZVYeyUL774QiNGjNAjjzyivLw8rV27Vrt27dKQIUOqVSP7eAEAAGP8uY9XdHS0oqOjf/X8Ro0aKTw8vEK6VVRUVCEFOyU7O1vt2rXTgw8+KEm6/PLLVadOHXXo0EF/+9vfFB8fX6VaSbwAAIAxLivML0d1REREKDU1VTk5OR7jOTk5atu2baWv+eWXXxQW5nmd8PBwSSeTsqqi8QIAACEnMzNTs2fP1ty5c7V9+3aNGjVK+fn55bcOs7Ky1Ldv3/Lzu3fvrhUrVmjmzJnauXOnPvjgA40YMUJXX321mjZtWuXrcqsRAAAYY8kht5cbnp5tzurq1auX9u/frwkTJmjv3r1q1aqV1qxZo8TEREnS3r17Pfb06t+/vw4fPqzp06dr9OjRqlevnjp16qTJkydX67o0XgAAICRlZGQoIyOj0t/Nnz+/wtjw4cM1fPjw33RNGi8AAGCMN2uyqjJnoAicSgEAAAJcUCReU+I/VnRUYPWQXz1wwu4SvLL9mWvsLsFrET8G1p+RU6J3ue0uwSvPf97e7hK89tKGm+wuwSulD9ldgXfubPgvu0vw2qGMyrceOFeVudzaYXMNbssht+XbNV6+ns+fAvO/RAAAAAEoKBIvAAAQGFwKk8vHuY+v5/MnGi8AAGAMtxoBAABgBIkXAAAwxq0wuX2c+/h6Pn8KnEoBAAACHIkXAAAwxmU55PLxmixfz+dPJF4AAACGkHgBAABjeKoRAAAARpB4AQAAYywrTG4ff6m1FUBfkk3jBQAAjHHJIZd8vLjex/P5U+C0iAAAAAGOxAsAABjjtny/GN5t+XQ6vyLxAgAAMITECwAAGOP2w+J6X8/nT4FTKQAAQIAj8QIAAMa45ZDbx08h+no+f7I18crOztZVV12lqKgoxcbG6pZbbtFXX31lZ0kAAAB+Y2vj9d5772no0KHatGmTcnJyVFZWpvT0dB09etTOsgAAgJ+c+pJsXx+BwtZbjWvXrvX4ed68eYqNjVVeXp6uu+46m6oCAAD+EuqL68+pNV6HDh2SJDVo0KDS35eUlKikpKT85+LiYiN1AQAA+MI50yJalqXMzEy1b99erVq1qvSc7OxsxcTElB8JCQmGqwQAAL+FWw65LR8fLK6vvmHDhmnbtm1asmTJGc/JysrSoUOHyo+CggKDFQIAAPw258StxuHDh2v16tVav369mjVrdsbznE6nnE6nwcoAAIAvWX7YTsIKoMTL1sbLsiwNHz5cK1eu1LvvvqukpCQ7ywEAAPArWxuvoUOHavHixVq1apWioqJUWFgoSYqJiVGtWrXsLA0AAPjBqXVZvp4zUNi6xmvmzJk6dOiQOnbsqPj4+PJj6dKldpYFAADgF7bfagQAAKGDfbwAAAAM4VYjAAAAjCDxAgAAxrj9sJ0EG6gCAACgAhIvAABgDGu8AAAAYASJFwAAMIbECwAAAEaQeAEAAGNCPfGi8QIAAMaEeuPFrUYAAABDSLwAAIAxlny/4WkgffMziRcAAIAhJF4AAMAY1ngBAADACBIvAABgTKgnXkHRePX46ibVqOO0u4xqcb5bZncJXvnswmfsLsFrqS+MtLsEr/z+ofV2l+CV5Mgf7C7Ba/9fmwK7S/BKxwUP2l2CVx5bd4vdJXity+xtdpdQLaVHSqWOdlcR2oKi8QIAAIGBxAsAAMCQUG+8WFwPAABgCIkXAAAwxrIcsnycUPl6Pn8i8QIAADCExAsAABjjlsPnXxnk6/n8icQLAADAEBIvAABgDE81AgAAwAgSLwAAYAxPNQIAAMAIEi8AAGBMqK/xovECAADGcKsRAAAARpB4AQAAYyw/3Gok8QIAAEAFJF4AAMAYS5Jl+X7OQEHiBQAAYAiJFwAAMMYthxx8STYAAAD8jcQLAAAYE+r7eNF4AQAAY9yWQ44Q3rmeW40AAACGkHgBAABjLMsP20kE0H4SJF4AAACGkHgBAABjQn1xPYkXAACAISReAADAGBIvAAAAGEHiBQAAjAn1fbxovAAAgDFsJwEAAAAjSLwAAIAxJxMvXy+u9+l0fkXiBQAAYAiJFwAAMIbtJAAAAGAEjRcAADDG8tPhjRkzZigpKUmRkZFKTU3Vhg0bznp+SUmJxo0bp8TERDmdTl1wwQWaO3duta7JrUYAABByli5dqpEjR2rGjBlq166dnn/+eXXp0kVffPGFmjdvXulrevbsqR9//FFz5szRhRdeqKKiIpWVlVXrujReAADAmHNljdfUqVM1cOBADRo0SJI0bdo0vfXWW5o5c6ays7MrnL927Vq999572rlzpxo0aCBJatGiRbWvy61GAABgjh/vNRYXF3scJSUllZZQWlqqvLw8paene4ynp6frww8/rPQ1q1evVlpamqZMmaLzzjtPF198sf785z/r2LFj1Xr7JF4AACAoJCQkePw8fvx4PfrooxXO27dvn1wul+Li4jzG4+LiVFhYWOncO3fu1Pvvv6/IyEitXLlS+/btU0ZGhg4cOFCtdV40XgAAwBw/3GrU/+YrKChQdHR0+bDT6TzryxwOzzosy6owdorb7ZbD4dCiRYsUExMj6eTtyttvv13PPvusatWqVaVSudUIAACCQnR0tMdxpsarUaNGCg8Pr5BuFRUVVUjBTomPj9d5551X3nRJUnJysizL0p49e6pcI40XAAAw5tSXZPv6qI6IiAilpqYqJyfHYzwnJ0dt27at9DXt2rXTDz/8oCNHjpSP7dixQ2FhYWrWrFmVr03jBQAAQk5mZqZmz56tuXPnavv27Ro1apTy8/M1ZMgQSVJWVpb69u1bfv5dd92lhg0b6t5779UXX3yh9evX68EHH9SAAQOqfJtRCpI1XiXPN5GrZqTdZVTLzY+/ZXcJXrl8yQN2l+C1i149aHcJXrmg9492l+CVRz6+2e4SvFZWVPV/iZ5LWqw/YXcJXnH+eNTuErz25YqWdpdQLWVlx+0u4ZzZTqJXr17av3+/JkyYoL1796pVq1Zas2aNEhMTJUl79+5Vfn5++fl169ZVTk6Ohg8frrS0NDVs2FA9e/bU3/72t2pdNygaLwAAgOrKyMhQRkZGpb+bP39+hbFLLrmkwu3J6qLxAgAA5liO8qcQfTpngKDxAgAAxnizGL4qcwYKFtcDAAAYQuIFAADM+T9f8ePTOQMEiRcAAIAhJF4AAMCYc2U7CbuQeAEAABhC4gUAAMwKoDVZvkbiBQAAYAiJFwAAMCbU13jReAEAAHPYTgIAAAAmkHgBAACDHP87fD1nYCDxAgAAMITECwAAmMMaLwAAAJhA4gUAAMwh8QIAAIAJ50zjlZ2dLYfDoZEjR9pdCgAA8BfL4Z8jQJwTtxpzc3M1a9YsXX755XaXAgAA/MiyTh6+njNQ2J54HTlyRHfffbdeeOEF1a9f3+5yAAAA/Mb2xmvo0KHq2rWrbrzxxl89t6SkRMXFxR4HAAAIIJafjgBh663Gl19+WR9//LFyc3OrdH52drYee+wxP1cFAADgH7YlXgUFBXrggQe0cOFCRUZGVuk1WVlZOnToUPlRUFDg5yoBAIBPsbjeHnl5eSoqKlJqamr5mMvl0vr16zV9+nSVlJQoPDzc4zVOp1NOp9N0qQAAAD5hW+N1ww036NNPP/UYu/fee3XJJZdozJgxFZouAAAQ+BzWycPXcwYK2xqvqKgotWrVymOsTp06atiwYYVxAACAYFDtNV4vvvii3njjjfKfH3roIdWrV09t27bV7t27fVocAAAIMiH+VGO1G69JkyapVq1akqSNGzdq+vTpmjJliho1aqRRo0b9pmLeffddTZs27TfNAQAAzmEsrq+egoICXXjhhZKkV199Vbfffrv+9Kc/qV27durYsaOv6wMAAAga1U686tatq/3790uS3n777fKNTyMjI3Xs2DHfVgcAAIJLiN9qrHbi1blzZw0aNEitW7fWjh071LVrV0nS559/rhYtWvi6PgAAgKBR7cTr2WefVZs2bfTTTz9p+fLlatiwoaST+3L17t3b5wUCAIAgQuJVPfXq1dP06dMrjPNVPgAAAGdXpcZr27ZtatWqlcLCwrRt27aznnv55Zf7pDAAABCE/JFQBVvilZKSosLCQsXGxiolJUUOh0OW9f/e5amfHQ6HXC6X34oFAAAIZFVqvHbt2qXGjRuX/zMAAIBX/LHvVrDt45WYmFjpP5/u/6ZgAAAA8FTtpxr79OmjI0eOVBj/7rvvdN111/mkKAAAEJxOfUm2r49AUe3G64svvtBll12mDz74oHzsxRdf1BVXXKG4uDifFgcAAIIM20lUz3//+189/PDD6tSpk0aPHq2vv/5aa9eu1T/+8Q8NGDDAHzUCAAAEhWo3XjVq1NATTzwhp9OpiRMnqkaNGnrvvffUpk0bf9QHAAAQNKp9q/HEiRMaPXq0Jk+erKysLLVp00Z//OMftWbNGn/UBwAAEDSqnXilpaXpl19+0bvvvqtrr71WlmVpypQpuvXWWzVgwADNmDHDH3UCAIAg4JDvF8MHzmYSXjZe//znP1WnTh1JJzdPHTNmjH7/+9/rnnvu8XmBVVF27wFZdZy2XNtbb153gd0leMUaF0ArGE9z8LIYu0vwyst7r7a7BK+4CmvZXYLXki77we4SvJLeabvdJXjl5ec7212C1+r1+N7uEqrFOloi/cfuKkJbtRuvOXPmVDqekpKivLy831wQAAAIYmyg6r1jx47pxIkTHmNOZ2AlTwAAAKZUe3H90aNHNWzYMMXGxqpu3bqqX7++xwEAAHBGIb6PV7Ubr4ceekjr1q3TjBkz5HQ6NXv2bD322GNq2rSpFixY4I8aAQBAsAjxxqvatxpfe+01LViwQB07dtSAAQPUoUMHXXjhhUpMTNSiRYt09913+6NOAACAgFftxOvAgQNKSkqSJEVHR+vAgQOSpPbt22v9+vW+rQ4AAAQVvquxms4//3x99913kqRLL71Ur7zyiqSTSVi9evV8WRsAAEBQqXbjde+992rr1q2SpKysrPK1XqNGjdKDDz7o8wIBAEAQYY1X9YwaNar8n6+//np9+eWX+uijj3TBBRfoiiuu8GlxAAAAweQ37eMlSc2bN1fz5s19UQsAAAh2/kioAijxqvatRgAAAHjnNydeAAAAVeWPpxCD8qnGPXv2+LMOAAAQCk59V6OvjwBR5carVatWeumll/xZCwAAQFCrcuM1adIkDR06VLfddpv279/vz5oAAECwCvHtJKrceGVkZGjr1q06ePCgWrZsqdWrV/uzLgAAgKBTrcX1SUlJWrdunaZPn67bbrtNycnJqlHDc4qPP/7YpwUCAIDgEeqL66v9VOPu3bu1fPlyNWjQQD169KjQeAEAAKBy1eqaXnjhBY0ePVo33nijPvvsMzVu3NhfdQEAgGAU4huoVrnxuummm7R582ZNnz5dffv29WdNAAAAQanKjZfL5dK2bdvUrFkzf9YDAACCmR/WeAVl4pWTk+PPOgAAQCgI8VuNfFcjAACAITySCAAAzCHxAgAAgAkkXgAAwJhQ30CVxAsAAMAQGi8AAABDaLwAAAAMYY0XAAAwJ8SfaqTxAgAAxrC4HgAAAEaQeAEAALMCKKHyNRIvAAAAQ0i8AACAOSG+uJ7ECwAAwBASLwAAYAxPNQIAAMAIEi8AAGBOiK/xovECAADGcKsRAAAgBM2YMUNJSUmKjIxUamqqNmzYUKXXffDBB6pRo4ZSUlKqfU0aLwAAYI7lp6Oali5dqpEjR2rcuHHasmWLOnTooC5duig/P/+srzt06JD69u2rG264ofoXFY0XAAAIQVOnTtXAgQM1aNAgJScna9q0aUpISNDMmTPP+rrBgwfrrrvuUps2bby6Lo0XAAAwx4+JV3FxscdRUlJSaQmlpaXKy8tTenq6x3h6ero+/PDDM5Y+b948ffvttxo/frw371wSjRcAAAgSCQkJiomJKT+ys7MrPW/fvn1yuVyKi4vzGI+Li1NhYWGlr/n66681duxYLVq0SDVqeP9sIk81AgAAY/z5VGNBQYGio6PLx51O59lf53B4/GxZVoUxSXK5XLrrrrv02GOP6eKLL/5NtQZF4zU86T+qHRVudxnVMum2u+0uwSvnveeyuwSv/dIosP6MnOLoG5jBtPPpI3aX4LV3Ll1tdwle6dR/kN0leOXmJ9+zuwSvbf25md0lVMuJE6V2l+BX0dHRHo3XmTRq1Ejh4eEV0q2ioqIKKZgkHT58WB999JG2bNmiYcOGSZLcbrcsy1KNGjX09ttvq1OnTlWqMSgaLwAAECDOgQ1UIyIilJqaqpycHP3xj38sH8/JyVGPHj0qnB8dHa1PP/3UY2zGjBlat26d/vWvfykpKanK16bxAgAA5pwDjZckZWZmqk+fPkpLS1ObNm00a9Ys5efna8iQIZKkrKwsff/991qwYIHCwsLUqlUrj9fHxsYqMjKywvivofECAAAhp1evXtq/f78mTJigvXv3qlWrVlqzZo0SExMlSXv37v3VPb28QeMFAACMOZe+MigjI0MZGRmV/m7+/Plnfe2jjz6qRx99tNrXDMxVuwAAAAGIxAsAAJhzjqzxsguJFwAAgCEkXgAAwJhzaY2XHUi8AAAADCHxAgAA5oT4Gi8aLwAAYE6IN17cagQAADCExAsAABjj+N/h6zkDBYkXAACAISReAADAHNZ4AQAAwAQSLwAAYAwbqAIAAMAI2xuv77//Xvfcc48aNmyo2rVrKyUlRXl5eXaXBQAA/MHy0xEgbL3VePDgQbVr107XX3+93nzzTcXGxurbb79VvXr17CwLAAD4UwA1Sr5ma+M1efJkJSQkaN68eeVjLVq0sK8gAAAAP7L1VuPq1auVlpamO+64Q7GxsWrdurVeeOGFM55fUlKi4uJijwMAAASOU4vrfX0EClsbr507d2rmzJm66KKL9NZbb2nIkCEaMWKEFixYUOn52dnZiomJKT8SEhIMVwwAAOA9Wxsvt9utK6+8UpMmTVLr1q01ePBg3XfffZo5c2al52dlZenQoUPlR0FBgeGKAQDAbxLii+ttbbzi4+N16aWXeowlJycrPz+/0vOdTqeio6M9DgAAgEBh6+L6du3a6auvvvIY27FjhxITE22qCAAA+BMbqNpo1KhR2rRpkyZNmqRvvvlGixcv1qxZszR06FA7ywIAAPALWxuvq666SitXrtSSJUvUqlUrTZw4UdOmTdPdd99tZ1kAAMBfQnyNl+3f1ditWzd169bN7jIAAAD8zvbGCwAAhI5QX+NF4wUAAMzxx63BAGq8bP+SbAAAgFBB4gUAAMwh8QIAAIAJJF4AAMCYUF9cT+IFAABgCIkXAAAwhzVeAAAAMIHECwAAGOOwLDks30ZUvp7Pn2i8AACAOdxqBAAAgAkkXgAAwBi2kwAAAIARJF4AAMAc1ngBAADAhKBIvHKPJsnpqGl3GdUSu/mQ3SV4x+22uwKvvfjP2XaX4JUhczvYXYJXzqvvsLsEr+04cdTuEryyp2Ng/XvwlNyeyXaX4DUrMrA+8zJXid0lsMbL7gIAAABCRVAkXgAAIECE+BovGi8AAGAMtxoBAABgBIkXAAAwJ8RvNZJ4AQAAGELiBQAAjAqkNVm+RuIFAABgCIkXAAAwx7JOHr6eM0CQeAEAABhC4gUAAIwJ9X28aLwAAIA5bCcBAAAAE0i8AACAMQ73ycPXcwYKEi8AAABDSLwAAIA5rPECAACACSReAADAmFDfToLECwAAwBASLwAAYE6If2UQjRcAADCGW40AAAAwgsQLAACYw3YSAAAAMIHECwAAGMMaLwAAABhB4gUAAMwJ8e0kSLwAAAAMIfECAADGhPoaLxovAABgDttJAAAAwAQSLwAAYEyo32ok8QIAADCExAsAAJjjtk4evp4zQJB4AQAAGELiBQAAzOGpRgAAAJhA4gUAAIxxyA9PNfp2Or+i8QIAAObwXY0AAAAwgcQLAAAYwwaqAAAAMILGCwAAmGP56fDCjBkzlJSUpMjISKWmpmrDhg1nPHfFihXq3LmzGjdurOjoaLVp00ZvvfVWta9J4wUAAELO0qVLNXLkSI0bN05btmxRhw4d1KVLF+Xn51d6/vr169W5c2etWbNGeXl5uv7669W9e3dt2bKlWtdljRcAADDGYVly+PgpRG/mmzp1qgYOHKhBgwZJkqZNm6a33npLM2fOVHZ2doXzp02b5vHzpEmTtGrVKr322mtq3bp1la8bFI3X2MabFR0VWOHdQy847S7BKxtfvNLuErzWf2im3SV4pfj+wPxrWm9Kqd0leG3yY7+3uwSvbO/3rN0leOVPna6zuwSvFd5Rz+4SqiXMXWJ3CX5VXFzs8bPT6ZTTWfG/t6WlpcrLy9PYsWM9xtPT0/Xhhx9W6Vput1uHDx9WgwYNqlVjYHUrAAAgsLn9dEhKSEhQTExM+VFZciVJ+/btk8vlUlxcnMd4XFycCgsLq/Q2/v73v+vo0aPq2bNnVd+5pCBJvAAAQGDw563GgoICRUdHl49XlnZ5vM7huee9ZVkVxiqzZMkSPfroo1q1apViY2OrVSuNFwAACArR0dEejdeZNGrUSOHh4RXSraKiogop2OmWLl2qgQMHatmyZbrxxhurXSO3GgEAgDnnwHYSERERSk1NVU5Ojsd4Tk6O2rZte8bXLVmyRP3799fixYvVtWvX6l30f0i8AABAyMnMzFSfPn2UlpamNm3aaNasWcrPz9eQIUMkSVlZWfr++++1YMECSSebrr59++of//iHrr322vK0rFatWoqJianydWm8AACAOefIl2T36tVL+/fv14QJE7R37161atVKa9asUWJioiRp7969Hnt6Pf/88yorK9PQoUM1dOjQ8vF+/fpp/vz5Vb4ujRcAAAhJGRkZysjIqPR3pzdT7777rk+uSeMFAACM4UuyAQAAYASJFwAAMOccWeNlFxIvAAAAQ0i8AACAMQ73ycPXcwYKGi8AAGAOtxoBAABgAokXAAAwx4uv+KnSnAGCxAsAAMAQEi8AAGCMw7Lk8PGaLF/P508kXgAAAIaQeAEAAHN4qtE+ZWVlevjhh5WUlKRatWrp/PPP14QJE+R2B9CGHAAAAFVka+I1efJkPffcc3rxxRfVsmVLffTRR7r33nsVExOjBx54wM7SAACAP1iSfJ2vBE7gZW/jtXHjRvXo0UNdu3aVJLVo0UJLlizRRx99VOn5JSUlKikpKf+5uLjYSJ0AAMA3WFxvo/bt2+udd97Rjh07JElbt27V+++/rz/84Q+Vnp+dna2YmJjyIyEhwWS5AAAAv4mtideYMWN06NAhXXLJJQoPD5fL5dLjjz+u3r17V3p+VlaWMjMzy38uLi6m+QIAIJBY8sPiet9O50+2Nl5Lly7VwoULtXjxYrVs2VKffPKJRo4cqaZNm6pfv34Vznc6nXI6nTZUCgAA8NvZ2ng9+OCDGjt2rO68805J0mWXXabdu3crOzu70sYLAAAEOLaTsM8vv/yisDDPEsLDw9lOAgAABCVbE6/u3bvr8ccfV/PmzdWyZUtt2bJFU6dO1YABA+wsCwAA+ItbksMPcwYIWxuvZ555Rn/961+VkZGhoqIiNW3aVIMHD9YjjzxiZ1kAAAB+YWvjFRUVpWnTpmnatGl2lgEAAAwJ9X28+K5GAABgDovrAQAAYAKJFwAAMIfECwAAACaQeAEAAHNIvAAAAGACiRcAADAnxDdQJfECAAAwhMQLAAAYwwaqAAAAprC4HgAAACaQeAEAAHPcluTwcULlJvECAADAaUi8AACAOazxAgAAgAkkXgAAwCA/JF4KnMQrKBqvQpdLR1yB86FL0ti4f9tdgld6HUixuwSv1fn6gN0leOXChwvtLsEr+WMusrsErzWrddDuErzS/YrOdpfglcK5jewuwWsHs2LsLqFa3MeOS5l2VxHagqLxAgAAASLE13jReAEAAHPclnx+a5DtJAAAAHA6Ei8AAGCO5T55+HrOAEHiBQAAYAiJFwAAMCfEF9eTeAEAABhC4gUAAMzhqUYAAACYQOIFAADMCfE1XjReAADAHEt+aLx8O50/casRAADAEBIvAABgTojfaiTxAgAAMITECwAAmON2S/LxV/y4+cogAAAAnIbECwAAmMMaLwAAAJhA4gUAAMwJ8cSLxgsAAJjDdzUCAADABBIvAABgjGW5ZVm+3f7B1/P5E4kXAACAISReAADAHMvy/ZqsAFpcT+IFAABgCIkXAAAwx/LDU40kXgAAADgdiRcAADDH7ZYcPn4KMYCeaqTxAgAA5nCrEQAAACaQeAEAAGMst1uWj281soEqAAAAKiDxAgAA5rDGCwAAACaQeAEAAHPcluQg8QIAAICfkXgBAABzLEuSrzdQJfECAADAaUi8AACAMZbbkuXjNV5WACVeNF4AAMAcyy3f32pkA1UAAACchsQLAAAYE+q3Gkm8AAAADCHxAgAA5oT4Gq+AbrxORYtHjgTOB37KCV/v2muI68Rxu0vwWpmrxO4SvFJ6pNTuErxSVha4f1ZKjpywuwSvlLkD88+K65fA/LspSe5jgfXn3H38ZL123por0wmff1VjmQLn76zDCqQbo6fZs2ePEhIS7C4DAICAUlBQoGbNmhm95vHjx5WUlKTCwkK/zN+kSRPt2rVLkZGRfpnfVwK68XK73frhhx8UFRUlh8Ph07mLi4uVkJCggoICRUdH+3RuVI7P3Cw+b7P4vM3jM6/IsiwdPnxYTZs2VViY+WXex48fV2mpf5LZiIiIc77pkgL8VmNYWJjfO/bo6Gj+whrGZ24Wn7dZfN7m8Zl7iomJse3akZGRAdEc+RNPNQIAABhC4wUAAGAIjdcZOJ1OjR8/Xk6n0+5SQgafuVl83mbxeZvHZ45zUUAvrgcAAAgkJF4AAACG0HgBAAAYQuMFAABgCI0XAACAITReZzBjxgwlJSUpMjJSqamp2rBhg90lBaXs7GxdddVVioqKUmxsrG655RZ99dVXdpcVMrKzs+VwODRy5Ei7Swlq33//ve655x41bNhQtWvXVkpKivLy8uwuKyiVlZXp4YcfVlJSkmrVqqXzzz9fEyZMkNsdeN/pi+BE41WJpUuXauTIkRo3bpy2bNmiDh06qEuXLsrPz7e7tKDz3nvvaejQodq0aZNycnJUVlam9PR0HT161O7Sgl5ubq5mzZqlyy+/3O5SgtrBgwfVrl071axZU2+++aa++OIL/f3vf1e9evXsLi0oTZ48Wc8995ymT5+u7du3a8qUKXryySf1zDPP2F0aIIntJCp1zTXX6Morr9TMmTPLx5KTk3XLLbcoOzvbxsqC308//aTY2Fi99957uu666+wuJ2gdOXJEV155pWbMmKG//e1vSklJ0bRp0+wuKyiNHTtWH3zwAam5Id26dVNcXJzmzJlTPnbbbbepdu3aeumll2ysDDiJxOs0paWlysvLU3p6usd4enq6PvzwQ5uqCh2HDh2SJDVo0MDmSoLb0KFD1bVrV9144412lxL0Vq9erbS0NN1xxx2KjY1V69at9cILL9hdVtBq37693nnnHe3YsUOStHXrVr3//vv6wx/+YHNlwEkB/SXZ/rBv3z65XC7FxcV5jMfFxamwsNCmqkKDZVnKzMxU+/bt1apVK7vLCVovv/yyPv74Y+Xm5tpdSkjYuXOnZs6cqczMTP3lL3/R5s2bNWLECDmdTvXt29fu8oLOmDFjdOjQIV1yySUKDw+Xy+XS448/rt69e9tdGiCJxuuMHA6Hx8+WZVUYg28NGzZM27Zt0/vvv293KUGroKBADzzwgN5++21FRkbaXU5IcLvdSktL06RJkyRJrVu31ueff66ZM2fSePnB0qVLtXDhQi1evFgtW7bUJ598opEjR6pp06bq16+f3eUBNF6na9SokcLDwyukW0VFRRVSMPjO8OHDtXr1aq1fv17NmjWzu5yglZeXp6KiIqWmppaPuVwurV+/XtOnT1dJSYnCw8NtrDD4xMfH69JLL/UYS05O1vLly22qKLg9+OCDGjt2rO68805J0mWXXabdu3crOzubxgvnBNZ4nSYiIkKpqanKycnxGM/JyVHbtm1tqip4WZalYcOGacWKFVq3bp2SkpLsLimo3XDDDfr000/1ySeflB9paWm6++679cknn9B0+UG7du0qbJGyY8cOJSYm2lRRcPvll18UFub5n7bw8HC2k8A5g8SrEpmZmerTp4/S0tLUpk0bzZo1S/n5+RoyZIjdpQWdoUOHavHixVq1apWioqLKk8aYmBjVqlXL5uqCT1RUVIX1c3Xq1FHDhg1ZV+cno0aNUtu2bTVp0iT17NlTmzdv1qxZszRr1iy7SwtK3bt31+OPP67mzZurZcuW2rJli6ZOnaoBAwbYXRogie0kzmjGjBmaMmWK9u7dq1atWunpp59mewM/ONO6uXnz5ql///5miwlRHTt2ZDsJP3v99deVlZWlr7/+WklJScrMzNR9991nd1lB6fDhw/rrX/+qlStXqqioSE2bNlXv3r31yCOPKCIiwu7yABovAAAAU1jjBQAAYAiNFwAAgCE0XgAAAIbQeAEAABhC4wUAAGAIjRcAAIAhNF4AAACG0HgBAAAYQuMFwHYOh0Ovvvqq3WUAgN/ReAGQy+VS27Ztddttt3mMHzp0SAkJCXr44Yf9ev29e/eqS5cufr0GAJwL+MogAJKkr7/+WikpKZo1a5buvvtuSVLfvn21detW5ebm8j13AOADJF4AJEkXXXSRsrOzNXz4cP3www9atWqVXn75Zb344otnbboWLlyotLQ0RUVFqUmTJrrrrrtUVFRU/vsJEyaoadOm2r9/f/nYzTffrOuuu05ut1uS563G0tJSDRs2TPHx8YqMjFSLFi2UnZ3tnzcNAIaReAEoZ1mWOnXqpPDwcH366acaPnz4r95mnDt3ruLj4/W73/1ORUVFGjVqlOrXr681a9ZIOnkbs0OHDoqLi9PKlSv13HPPaezYsdq6dasSExMlnWy8Vq5cqVtuuUVPPfWU/vnPf2rRokVq3ry5CgoKVFBQoN69e/v9/QOAv9F4AfDw5ZdfKjk5WZdddpk+/vhj1ahRo1qvz83N1dVXX63Dhw+rbt26kqSdO3cqJSVFGRkZeuaZZzxuZ0qejdeIESP0+eef69///rccDodP3xsA2I1bjQA8zJ07V7Vr19auXbu0Z8+eXz1/y5Yt6tGjhxITExUVFaWOHTtKkvLz88vPOf/88/XUU09p8uTJ6t69u0fTdbr+/fvrk08+0e9+9zuNGDFCb7/99m9+TwBwrqDxAlBu48aNevrpp7Vq1Sq1adNGAwcO1NlC8aNHjyo9PV1169bVwoULlZubq5UrV0o6uVbr/1q/fr3Cw8P13Xffqays7IxzXnnlldq1a5cmTpyoY8eOqWfPnrr99tt98wYBwGY0XgAkSceOHVO/fv00ePBg3XjjjZo9e7Zyc3P1/PPPn/E1X375pfbt26cnnnhCHTp00CWXXOKxsP6UpUuXasWKFXr33XdVUFCgiRMnnrWW6Oho9erVSy+88IKWLl2q5cuX68CBA7/5PQKA3Wi8AEiSxo4dK7fbrcmTJ0uSmjdvrr///e968MEH9d1331X6mubNmysiIkLPPPOMdu7cqdWrV1doqvbs2aP7779fkydPVvv27TV//nxlZ2dr06ZNlc759NNP6+WXX9aXX36pHTt2aNmyZWrSpInq1avny7cLALag8QKg9957T88++6zmz5+vOnXqlI/fd999atu27RlvOTZu3Fjz58/XsmXLdOmll+qJJ57QU089Vf57y7LUv39/XX311Ro2bJgkqXPnzho2bJjuueceHTlypMKcdevW1eTJk5WWlqarrrpK3333ndasWaOwMP51BSDw8VQjAACAIfxfSAAAAENovAAAAAyh8QIAADCExgsAAMAQGi8AAABDaLwAAAAMofECAAAwhMYLAADAEBovAAAAQ2i8AAAADKHxAgAAMOT/ByTRH5yycd7+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class RESERVOIR(nn.Module):\n",
    "    def __init__ (self, TIME_STEP=8, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1):\n",
    "        super(RESERVOIR, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.in_spike_size = in_spike_size\n",
    "        self.in_channel = in_channel\n",
    "        self.receptive_size = receptive_size #3\n",
    "        self.v_init = v_init\n",
    "        self.v_decay = v_decay\n",
    "        self.v_threshold = v_threshold\n",
    "        self.v_reset = v_reset\n",
    "        self.hard_reset = hard_reset\n",
    "        self.pre_spike_weight = pre_spike_weight\n",
    "\n",
    "        self.out_channel = 1\n",
    "\n",
    "        # 파라미터 \n",
    "        self.conv_depthwise = nn.Conv2d(in_channels=self.in_channel, out_channels=self.in_channel, \n",
    "                                        kernel_size=self.receptive_size, \n",
    "                                        stride=1, padding=1, groups=self.in_channel)\n",
    "\n",
    "        # kaiming 초기화\n",
    "        nn.init.kaiming_normal_(self.conv_depthwise.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.conv_depthwise.bias, 0)\n",
    "\n",
    "        # membrane potential 초기화\n",
    "        self.v = torch.full((self.in_channel, self.in_spike_size, self.in_spike_size), fill_value=self.v_init, requires_grad=False)\n",
    "\n",
    "        \n",
    "    def forward(self, pre_spike):    \n",
    "        # pre_spike [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        v = torch.full_like(pre_spike[0], fill_value=self.v_init, requires_grad=False)\n",
    "        post_spike = torch.zeros_like(pre_spike[0], requires_grad=False)\n",
    "        # v [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "        # recurrent [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        # timestep 안 맞으면 종료\n",
    "        assert pre_spike.size(0) == self.TIME_STEP, f\"Time step mismatch: {pre_spike.size(0)} vs {self.TIME_STEP}\"\n",
    "\n",
    "        output = []\n",
    "        for t in range (self.TIME_STEP):\n",
    "            # pre_spike[t] [batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "            input_current = self.pre_spike_weight * pre_spike[t]\n",
    "            recurrent_current = self.conv_depthwise(post_spike)\n",
    "            current = input_current + recurrent_current\n",
    "            # current [batch_size, in_channel, in_spike_size, in_spike_size] # kernel size 3이니까 사이즈 유지\n",
    "            \n",
    "            # decay and itegrate\n",
    "            v = v*self.v_decay + current\n",
    "\n",
    "            # post spike\n",
    "            post_spike = (v >= self.v_threshold).float()\n",
    "\n",
    "            output.append(post_spike)\n",
    "            \n",
    "            #reset\n",
    "            if self.hard_reset: # hard reset\n",
    "                v = (1 - post_spike)*v + post_spike*self.v_reset \n",
    "            else: # soft reset\n",
    "                v = v - post_spike*self.v_threshold\n",
    "\n",
    "        output = torch.stack(output, dim=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NO_RESERVOIR_NET(nn.Module):\n",
    "    def __init__(self, TIME_STEP=8, CLASS_NUM=10, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1):\n",
    "        super(NO_RESERVOIR_NET, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.reservoir = RESERVOIR(TIME_STEP = self.TIME_STEP, in_spike_size=in_spike_size, in_channel=in_channel, receptive_size=receptive_size, v_init=v_init, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "        self.linear = nn.Linear(in_features=in_channel*in_spike_size*in_spike_size, out_features=CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x size [batch_size, TIME_STEP, in_channel, in_spike_size, in_spike_size]\n",
    "        x = x.permute(1,0,2,3,4)\n",
    "        # x size [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     x = self.reservoir(x) # reservoir weight는 학습 안함\n",
    "\n",
    "        T, B, *spatial_dims = x.shape\n",
    "        x = x.reshape(T * B, -1) # time,batch 축은 합쳐서 FC에 삽입\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        x = x.view(T , B, -1).contiguous() \n",
    "        \n",
    "        x = x.mean(dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESERVOIR_NET(nn.Module):\n",
    "    def __init__(self, TIME_STEP=8, CLASS_NUM=10, in_spike_size=28, in_channel=1, receptive_size=3, v_init=0, v_decay=0.6, v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1):\n",
    "        super(RESERVOIR_NET, self).__init__()\n",
    "        self.TIME_STEP = TIME_STEP\n",
    "        self.reservoir = RESERVOIR(TIME_STEP = self.TIME_STEP, in_spike_size=in_spike_size, in_channel=in_channel, receptive_size=receptive_size, v_init=v_init, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "        self.linear = nn.Linear(in_features=in_channel*in_spike_size*in_spike_size, out_features=CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x size [batch_size, TIME_STEP, in_channel, in_spike_size, in_spike_size]\n",
    "        x = x.permute(1,0,2,3,4)\n",
    "        # x size [TIME_STEP, batch_size, in_channel, in_spike_size, in_spike_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.reservoir(x) # reservoir weight는 학습 안함\n",
    "\n",
    "        T, B, *spatial_dims = x.shape\n",
    "        x = x.reshape(T * B, -1) # time,batch 축은 합쳐서 FC에 삽입\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        x = x.view(T , B, -1).contiguous() \n",
    "        \n",
    "        x = x.mean(dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(which_data, data_path, rate_coding, BATCH, IMAGE_SIZE, TIME, dvs_duration, dvs_clipping):\n",
    "    if which_data == 'MNIST':\n",
    "        if rate_coding :\n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0,), (1,))])\n",
    "        else : \n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,),(0.5))])\n",
    "\n",
    "        trainset = torchvision.datasets.MNIST(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.MNIST(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        synapse_conv_in_channels = 1\n",
    "        CLASS_NUM = 10\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    elif (which_data == 'CIFAR10'):\n",
    "\n",
    "        if rate_coding :\n",
    "            # transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.RandomHorizontalFlip(),\n",
    "            #                                     transforms.ToTensor()])\n",
    "\n",
    "            # transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.ToTensor()])\n",
    "            \n",
    "            transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor()])\n",
    "                                            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                                transforms.ToTensor()])\n",
    "        \n",
    "        else :\n",
    "            # transform_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.RandomHorizontalFlip(),\n",
    "            #                                     transforms.ToTensor(),\n",
    "            #                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "            #                                 # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "            # transform_test = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            #                                     transforms.ToTensor(),\n",
    "            #                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),])\n",
    "            #                                 # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            \n",
    "            # assert IMAGE_SIZE == 32, 'OTTT랑 맞짱뜰 때는 32로 ㄱ'\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(IMAGE_SIZE, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "\n",
    "        trainset = torchvision.datasets.CIFAR10(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.CIFAR10(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform_test)\n",
    "        \n",
    "        \n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        \n",
    "        synapse_conv_in_channels = 3\n",
    "        CLASS_NUM = 10\n",
    "        '''\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "                'dog', 'frog', 'horse', 'ship', 'truck') \n",
    "        '''\n",
    "\n",
    "\n",
    "    elif (which_data == 'FASHION_MNIST'):\n",
    "\n",
    "        if rate_coding :\n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor()])\n",
    "        else : \n",
    "            transform = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,),(0.5))])\n",
    "\n",
    "        trainset = torchvision.datasets.FashionMNIST(root=data_path,\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "\n",
    "        testset = torchvision.datasets.FashionMNIST(root=data_path,\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(trainset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = True,\n",
    "                                num_workers =2)\n",
    "        test_loader = DataLoader(testset,\n",
    "                                batch_size =BATCH,\n",
    "                                shuffle = False,\n",
    "                                num_workers =2)\n",
    "        synapse_conv_in_channels = 1\n",
    "        CLASS_NUM = 10\n",
    "    elif (which_data == 'DVS_GESTURE'):\n",
    "        data_dir = data_path + '/gesture'\n",
    "        transform = None\n",
    "\n",
    "        # # spikingjelly.datasets.dvs128_gesture.DVS128Gesture(root: str, train: bool, use_frame=True, frames_num=10, split_by='number', normalization='max')\n",
    "       \n",
    "        #https://spikingjelly.readthedocs.io/zh-cn/latest/activation_based_en/neuromorphic_datasets.html\n",
    "        # 10ms마다 1개의 timestep하고 싶으면 위의 주소 참고. 근데 timestep이 각각 좀 다를 거임.\n",
    "\n",
    "        \n",
    "        if dvs_duration > 0:\n",
    "            resize_shape = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "            train_data = CustomDVS128Gesture(\n",
    "                data_dir, train=True, data_type='frame',  split_by='time',  duration=dvs_duration, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "            test_data = CustomDVS128Gesture(\n",
    "                data_dir, train=False, data_type='frame',  split_by='time',  duration=dvs_duration, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "\n",
    "        else:\n",
    "            train_data = CustomDVS128Gesture(\n",
    "                data_dir, train=True, data_type='frame', split_by='number', frames_number=TIME, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "            test_data = CustomDVS128Gesture(data_dir, train=False,\n",
    "                                            data_type='frame', split_by='number', frames_number=TIME, resize_shape=resize_shape, dvs_clipping=dvs_clipping, dvs_duration_copy=dvs_duration, TIME=TIME)\n",
    "        \n",
    "        exclude_class = 10\n",
    "        train_indices = [i for i, (_, target) in enumerate(train_data) if target != exclude_class]\n",
    "        test_indices = [i for i, (_, target) in enumerate(test_data) if target != exclude_class]\n",
    "    \n",
    "        # SubsetRandomSampler 생성\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        test_sampler = SequentialSampler(test_indices)\n",
    "\n",
    "        # ([B, T, 2, 128, 128]) \n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH, num_workers=2, sampler=train_sampler, collate_fn=pad_sequence_collate)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH, num_workers=2, sampler=test_sampler, collate_fn=pad_sequence_collate)\n",
    "        synapse_conv_in_channels = 2\n",
    "        CLASS_NUM = 10\n",
    "        # mapping = { 0 :'Hand Clapping'  1 :'Right Hand Wave'2 :'Left Hand Wave' 3 :'Right Arm CW'   4 :'Right Arm CCW'  5 :'Left Arm CW'    6 :'Left Arm CCW'   7 :'Arm Roll'       8 :'Air Drums'      9 :'Air Guitar'     10:'Other'}\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert False, 'wrong dataset name'\n",
    "\n",
    "\n",
    "    \n",
    "    return train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, rate_coding, TIME_STEP, which_data):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterator = enumerate(train_loader, 0)\n",
    "    for i, data in iterator:\n",
    "    # for i, (inputs, labels) in enumerate(train_loader):\n",
    "        if len(data) == 2:\n",
    "            inputs, labels = data\n",
    "            # 처리 로직 작성\n",
    "        elif len(data) == 3:\n",
    "            inputs, labels, x_len = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # if rate_coding == True:\n",
    "        #     inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "        # else:\n",
    "        #     inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "        \n",
    "\n",
    "        ###########################################################################################################################        \n",
    "        if (which_data == 'n_tidigits'):\n",
    "            inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "            labels = labels[:, 0, :]\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "        elif (which_data == 'heidelberg'):\n",
    "            inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "            print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "        # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "        # print(labels)\n",
    "            \n",
    "        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        elif rate_coding == True :\n",
    "            inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "        else :\n",
    "            inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "        ####################################################################################################################### \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        iter_correct = (predicted == labels).sum().item()\n",
    "        correct += iter_correct\n",
    "        # if i % 100 == 99:\n",
    "        # print(f\"[{i+1}] loss: {running_loss / 100:.3f}\")\n",
    "        # running_loss = 0.0\n",
    "        iter_accuracy = 100 * iter_correct / labels.size(0)\n",
    "        wandb.log({\"iter_accuracy\": iter_accuracy})\n",
    "    tr_accuracy = 100 * correct / total         \n",
    "    wandb.log({\"tr_accuracy\": tr_accuracy})\n",
    "    print(f\"Train Accuracy: {tr_accuracy:.2f}%\")\n",
    "    \n",
    "def test(model, test_loader, criterion, device, rate_coding, TIME_STEP, which_data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    iterator = enumerate(test_loader, 0)\n",
    "    with torch.no_grad():\n",
    "        for i, data in iterator:\n",
    "        # for inputs, labels in test_loader:\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # if rate_coding == True:\n",
    "            #     inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "            # else:\n",
    "            #     inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "\n",
    "        \n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME_STEP)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME_STEP, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = 100 * correct / total\n",
    "    wandb.log({\"val_accuracy\": val_accuracy})\n",
    "    print(f\"Test loss: {test_loss / len(test_loader):.3f}, Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path='/data2', which_data='MNIST', gpu = '3',learning_rate = 0.0001, BATCH=5, IMAGE_SIZE=28, TIME_STEP=8, EPOCH=10, rate_coding=True, v_decay= 0.6,\n",
    "v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "    # run = wandb.init(project=f'reservoir')\n",
    "\n",
    "    hyperparameters = locals()\n",
    "\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{which_data}_sweeprun_epoch{EPOCH}'\n",
    "    wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "\n",
    "    train_loader, test_loader, in_channel, CLASS_NUM = data_loader(\n",
    "        which_data=which_data, data_path=data_path, rate_coding=rate_coding, BATCH=BATCH, IMAGE_SIZE=IMAGE_SIZE, TIME=TIME_STEP, dvs_duration=dvs_duration, dvs_clipping=dvs_clipping)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if no_reservoir == True:\n",
    "        net = NO_RESERVOIR_NET(TIME_STEP=TIME_STEP, CLASS_NUM=CLASS_NUM, in_spike_size=IMAGE_SIZE, in_channel=in_channel, receptive_size=3, v_init=0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "    else:\n",
    "        net = RESERVOIR_NET(TIME_STEP=TIME_STEP, CLASS_NUM=CLASS_NUM, in_spike_size=IMAGE_SIZE, in_channel=in_channel, receptive_size=3, v_init=0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight)\n",
    "    net = net.to(device)\n",
    "    wandb.watch(net, log=\"all\", log_freq = 1) #gradient, parameter logging해줌\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        train(net, train_loader, criterion, optimizer, device, rate_coding, TIME_STEP, which_data)\n",
    "        test(net, test_loader, criterion, device, rate_coding, TIME_STEP, which_data)\n",
    "        # torch.save(net.state_dict(), 'net_save/reservoir_net.pth')\n",
    "        # artifact = wandb.Artifact('model', type='model')\n",
    "        # artifact.add_file('net_save/reservoir_net.pth')\n",
    "        # run.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하기 싫을 때\n",
    "# wandb.init(project=f'reservoir')\n",
    "# main(data_path='/data2', which_data='CIFAR10', gpu = '3', learning_rate = 0.0072, BATCH=256, IMAGE_SIZE=32, TIME_STEP=9, EPOCH=50, rate_coding=True, v_decay= 0.78,\n",
    "# v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=5.0, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "404 response executing GraphQL.\n",
      "{\"errors\":[{\"message\":\"could not find project bhkim003-seoul-national-university/uncategorized during createAgent\",\"path\":[\"createAgent\"]}],\"data\":{\"createAgent\":null}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: could not find project bhkim003-seoul-national-university/uncategorized during createAgent (<Response [404]>)\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "could not find project bhkim003-seoul-national-university/uncategorized during createAgent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/sdk/lib/retry.py:131\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Only print resolved attempts once every minute\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py:345\u001b[0m, in \u001b[0;36mApi.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:52\u001b[0m, in \u001b[0;36mClient.execute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(document)\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:60\u001b[0m, in \u001b[0;36mClient._get_result\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m last_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/sdk/lib/gql_request.py:59\u001b[0m, in \u001b[0;36mGraphQLSession.execute\u001b[0;34m(self, document, variable_values, timeout)\u001b[0m\n\u001b[1;32m     58\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpost_args)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m result \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.wandb.ai/graphql",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 51\u001b[0m\n\u001b[1;32m     28\u001b[0m sweep_configuration \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbayes\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: which_data_hyper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m      }\n\u001b[1;32m     48\u001b[0m }\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'reservoir')\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0j0aowy8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msweep_cover\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/wandb_agent.py:568\u001b[0m, in \u001b[0;36magent\u001b[0;34m(sweep_id, function, entity, project, count)\u001b[0m\n\u001b[1;32m    566\u001b[0m wandb_sdk\u001b[38;5;241m.\u001b[39mwandb_login\u001b[38;5;241m.\u001b[39m_login(_silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m function:\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyagent\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m in_jupyter \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mwandb_sdk\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mipython\u001b[38;5;241m.\u001b[39m_get_python_type() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_agent(\n\u001b[1;32m    571\u001b[0m     sweep_id,\n\u001b[1;32m    572\u001b[0m     function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     count\u001b[38;5;241m=\u001b[39mcount,\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/agents/pyagent.py:357\u001b[0m, in \u001b[0;36mpyagent\u001b[0;34m(sweep_id, function, entity, project, count)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction parameter must be callable!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    350\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m    351\u001b[0m     sweep_id,\n\u001b[1;32m    352\u001b[0m     function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     count\u001b[38;5;241m=\u001b[39mcount,\n\u001b[1;32m    356\u001b[0m )\n\u001b[0;32m--> 357\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/agents/pyagent.py:328\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    323\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting sweep agent: entity=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, project=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, count=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count\n\u001b[1;32m    326\u001b[0m         )\n\u001b[1;32m    327\u001b[0m     )\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# self._main_thread = threading.Thread(target=self._run_jobs_from_queue)\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_heartbeat_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_heartbeat)\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/agents/pyagent.py:136\u001b[0m, in \u001b[0;36mAgent._setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sweep_id:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweep_id \u001b[38;5;241m=\u001b[39m sweep_id\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/agents/pyagent.py:113\u001b[0m, in \u001b[0;36mAgent._register\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_register\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    112\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent._register()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgethostname\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msweep_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sweep_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_id \u001b[38;5;241m=\u001b[39m agent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    115\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_id = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agent_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/apis/internal.py:154\u001b[0m, in \u001b[0;36mApi.register_agent\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_agent\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/apis/normalize.py:73\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err\u001b[38;5;241m.\u001b[39mlast_exception)\u001b[38;5;241m.\u001b[39mwith_traceback(\n\u001b[1;32m     70\u001b[0m             sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# gql raises server errors with dict's as strings...\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(err\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/apis/normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhoa, you found a bug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     43\u001b[0m     errors \u001b[38;5;241m=\u001b[39m parse_backend_error_messages(error\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py:2959\u001b[0m, in \u001b[0;36mApi.register_agent\u001b[0;34m(self, host, sweep_id, project_name, entity)\u001b[0m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2957\u001b[0m     project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2959\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   2962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2963\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentityName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojectName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msweep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msweep_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_retry_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_retry_4xx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2969\u001b[0m result: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreateAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py:317\u001b[0m, in \u001b[0;36mApi.gql\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgql\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 317\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_gql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_cancel_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcancel_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/sdk/lib/retry.py:147\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retryable_exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# if the secondary check fails, re-raise\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     retry_timedelta_triggered \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_retry_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m retry_timedelta_triggered:\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aedat2/lib/python3.8/site-packages/wandb/util.py:881\u001b[0m, in \u001b[0;36mno_retry_4xx\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    880\u001b[0m body \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m--> 881\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UsageError(body[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mUsageError\u001b[0m: could not find project bhkim003-seoul-national-university/uncategorized during createAgent"
     ]
    }
   ],
   "source": [
    "# sweep하고싶을 때\n",
    "def sweep_cover(data_path='/data2', which_data='CIFAR10', gpu = '3', learning_rate = 0.0001, BATCH=5, IMAGE_SIZE=28, TIME_STEP=8, EPOCH=3, rate_coding=True, v_decay= 0.6,\n",
    "v_threshold=1, v_reset=0, hard_reset=True, pre_spike_weight=1, dvs_duration=1000000, dvs_clipping=True, no_reservoir = False):\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.batch_size\n",
    "    TIME_STEP  =  wandb.config.time_step\n",
    "    v_decay  =  wandb.config.decay\n",
    "    pre_spike_weight  =  wandb.config.pre_spike_weight\n",
    "    which_data  =  wandb.config.which_data\n",
    "    data_path  =  wandb.config.data_path\n",
    "    rate_coding  =  wandb.config.rate_coding\n",
    "    EPOCH  =  wandb.config.EPOCH\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    no_reservoir  =  wandb.config.no_reservoir\n",
    "    main(data_path=data_path, which_data=which_data, gpu = gpu, learning_rate = learning_rate, BATCH=BATCH, IMAGE_SIZE=IMAGE_SIZE, TIME_STEP=TIME_STEP, EPOCH=EPOCH, rate_coding=rate_coding, v_decay= v_decay,\n",
    "v_threshold=v_threshold, v_reset=v_reset, hard_reset=hard_reset, pre_spike_weight=pre_spike_weight, dvs_duration=dvs_duration, dvs_clipping=dvs_clipping, no_reservoir = no_reservoir)\n",
    "\n",
    "\n",
    "\n",
    "which_data_hyper = 'DVS_GESTURE' # 'MNIST', 'CIFAR10' ', 'FASHION_MNIST', 'DVS_GESTURE'\n",
    "data_path_hyper = '/data2'\n",
    "\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': which_data_hyper,\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"min\": 0.00001, \"max\": 0.1},\n",
    "        \"batch_size\": {\"values\": [16, 32, 64, 128, 256]},\n",
    "        \"time_step\": {\"values\": [4,5,6,7,8]},\n",
    "        \"decay\": {\"min\": 0.25, \"max\": 1.0},\n",
    "        \"pre_spike_weight\": {\"min\": 0.5, \"max\": 10.0},\n",
    "        \"which_data\": {\"values\": [which_data_hyper]},\n",
    "        \"data_path\": {\"values\": [data_path_hyper]},\n",
    "        \"rate_coding\": {\"values\": [True, False]},\n",
    "        \"EPOCH\": {\"values\": [50]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [16,32,48,128]},\n",
    "        \"dvs_duration\": {\"values\": [1000000]},\n",
    "        \"dvs_clipping\": {\"values\": [True]},\n",
    "        \"no_reservoir\": {\"values\": [True, False]},\n",
    "     }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'reservoir')\n",
    "wandb.agent('0j0aowy8', function=sweep_cover, count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE하기\n",
    "\n",
    "# # Import\n",
    "# import wandb\n",
    "# # Save your model.\n",
    "# torch.save(model.state_dict(), 'save/to/path/model.pth')\n",
    "# # Save as artifact for version control.\n",
    "# run = wandb.init(project='your-project-name')\n",
    "# artifact = wandb.Artifact('model', type='model')\n",
    "# artifact.add_file('save/to/path/model.pth')\n",
    "# run.log_artifact(artifact)\n",
    "# run.finish()\n",
    "\n",
    "\n",
    "# # LOAD 하기\n",
    "\n",
    "# import wandb\n",
    "# run = wandb.init()\n",
    "\n",
    "\n",
    "# artifact = run.use_artifact('entity/your-project-name/model:v0', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "\n",
    "# run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
