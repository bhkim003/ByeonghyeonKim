{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35000/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                no_val_best_growth_count = 0\n",
    "                DFA_current = not DFA_current\n",
    "                DFA_toggle = True\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                no_tr_best_growth_count = 0\n",
    "                DFA_current = not DFA_current\n",
    "                DFA_toggle = True\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "                        \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                loss /= TIME\n",
    "            tr_epoch_loss_temp += loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                val_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter/last_val_loss:{loss:10.6f}/{val_loss:10.6f}, last tr:{100 * tr_acc:7.2f}%, last val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"3\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.0002, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = 1000,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 2, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                \n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (NMNIST) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"4\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 34, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'NMNIST_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.009, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 10_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                \n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jncgk9ur with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.23996719260520796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_144719-jncgk9ur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jncgk9ur' target=\"_blank\">laced-sweep-6</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jncgk9ur' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jncgk9ur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.798632/  1.471797, tr:  37.59%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:07<00:00,  8.78it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.147267/  1.265025, tr:  62.72%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.994640/  1.145420, tr:  65.27%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:11<00:00,  5.49it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.884797/  1.114705, tr:  69.46%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:54<00:00,  1.13it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.831747/  1.174153, tr:  70.48%, val:  62.92%, val_best:  65.00%: 100%|██████████| 62/62 [00:55<00:00,  1.12it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.804560/  1.303019, tr:  70.07%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:48<00:00,  1.28it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.710803/  1.172710, tr:  74.26%, val:  62.08%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.662129/  1.233053, tr:  76.10%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.628416/  1.124813, tr:  77.32%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.485036/  1.257027, tr:  83.35%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.469861/  1.281134, tr:  84.78%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.464611/  1.323327, tr:  83.04%, val:  69.58%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.463567/  1.229168, tr:  85.50%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.392968/  1.348947, tr:  91.01%, val:  72.50%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.337209/  1.302196, tr:  92.13%, val:  74.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.352343/  1.349430, tr:  90.19%, val:  70.42%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.268760/  1.504374, tr:  94.99%, val:  72.50%, val_best:  74.58%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.244744/  1.370758, tr:  95.30%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.253434/  1.354646, tr:  93.87%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.170572/  1.470976, tr:  97.85%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.140353/  1.569666, tr:  99.08%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.106676/  1.678877, tr:  99.69%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.111697/  1.677293, tr:  99.18%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.098203/  1.664249, tr:  99.80%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.072952/  1.819401, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.063814/  1.790033, tr:  99.80%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.047030/  1.833658, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.042138/  1.874585, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.039913/  1.928172, tr: 100.00%, val:  80.00%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.029871/  1.931685, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.025259/  1.940434, tr: 100.00%, val:  81.67%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.022293/  1.957614, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.020382/  1.977409, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.014932/  2.005982, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.012069/  2.039949, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010946/  2.074241, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010716/  2.051721, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009152/  2.093782, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007965/  2.105626, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007438/  2.107742, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006615/  2.113617, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.005838/  2.127543, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005703/  2.122962, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006013/  2.121449, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005272/  2.141198, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.004926/  2.135955, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005030/  2.156284, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004610/  2.157245, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004890/  2.154991, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004540/  2.161591, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:07<00:00,  8.36it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004319/  2.165584, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.31it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004551/  2.162192, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:17<00:00,  3.47it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004436/  2.167775, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:19<00:00,  3.19it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004395/  2.167319, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.35it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004517/  2.166817, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.38it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004606/  2.168899, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:08<00:00,  7.24it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004456/  2.167226, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004306/  2.167844, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004275/  2.168235, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004405/  2.168280, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabef1df1a564805ac186888135025b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.943 MB of 4.943 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▆▅▆▇▆▇▇█▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0044</td></tr><tr><td>val_acc_best</td><td>0.83333</td></tr><tr><td>val_acc_now</td><td>0.82083</td></tr><tr><td>val_loss</td><td>2.16828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-6</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jncgk9ur' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jncgk9ur</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_144719-jncgk9ur/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jitsw52y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.22412966237514917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "error: short read while indexing my_snn/result_save/tr_acc_array_main.npy\n",
      "error: my_snn/result_save/tr_acc_array_main.npy: failed to insert into database\n",
      "fatal: cannot hash my_snn/result_save/tr_acc_array_main.npy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_145726-jitsw52y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jitsw52y' target=\"_blank\">fresh-sweep-11</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jitsw52y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jitsw52y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.804120/  1.466604, tr:  36.98%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.140633/  1.280132, tr:  63.13%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.989614/  1.147918, tr:  65.99%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.885682/  1.133698, tr:  69.87%, val:  63.33%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.843145/  1.189997, tr:  69.87%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.817397/  1.283739, tr:  69.87%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.701909/  1.172398, tr:  74.36%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.674376/  1.236500, tr:  75.28%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.640151/  1.118313, tr:  76.92%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.485378/  1.222973, tr:  83.55%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.481464/  1.249433, tr:  84.98%, val:  67.92%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.469222/  1.215787, tr:  83.35%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.451366/  1.243293, tr:  86.31%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.409285/  1.312064, tr:  88.76%, val:  71.25%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.327109/  1.314865, tr:  92.44%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.345140/  1.343417, tr:  91.42%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.272841/  1.475177, tr:  94.89%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.248065/  1.330542, tr:  96.42%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.232108/  1.372533, tr:  96.22%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.176049/  1.468081, tr:  98.16%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.128689/  1.588852, tr:  99.28%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.101472/  1.725951, tr:  99.90%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.116635/  1.661052, tr:  98.77%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.102326/  1.647912, tr:  99.59%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.066874/  1.784986, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.061217/  1.790974, tr:  99.90%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.044854/  1.797166, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.047849/  1.876024, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.069251/  1.872622, tr:  99.80%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.036594/  1.899119, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.031303/  1.932680, tr:  99.90%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.027232/  1.938407, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.027952/  1.982048, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015378/  2.017472, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013350/  2.003339, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011390/  2.040823, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009957/  2.041863, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008758/  2.057624, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008068/  2.080728, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007613/  2.089077, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007401/  2.077924, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006074/  2.105644, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006627/  2.112909, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005528/  2.111130, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005356/  2.131201, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005186/  2.121835, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005055/  2.124070, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005087/  2.120761, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004987/  2.130258, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004921/  2.128671, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004610/  2.133399, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004596/  2.134522, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004461/  2.142713, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004498/  2.143742, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004374/  2.140711, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004336/  2.139956, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004355/  2.139160, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004407/  2.138306, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004294/  2.140253, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004387/  2.138976, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce94024525894eca94122f707f99e1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▆▅▅▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00439</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.13898</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-11</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jitsw52y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jitsw52y</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_145726-jitsw52y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: obrh79ry with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.1773731656661035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_150330-obrh79ry</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obrh79ry' target=\"_blank\">crimson-sweep-13</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obrh79ry' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obrh79ry</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.817841/  1.484928, tr:  37.49%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.151183/  1.269968, tr:  62.41%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.996894/  1.147753, tr:  65.07%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.892471/  1.138638, tr:  69.46%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.856007/  1.186539, tr:  69.66%, val:  63.33%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.826348/  1.270522, tr:  69.36%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.714659/  1.171485, tr:  75.08%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.683741/  1.272811, tr:  76.20%, val:  61.25%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.664420/  1.084824, tr:  76.10%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.502972/  1.252233, tr:  82.23%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.485962/  1.214496, tr:  84.58%, val:  67.92%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.470239/  1.221153, tr:  83.25%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.470777/  1.302776, tr:  86.11%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.398922/  1.262094, tr:  89.99%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.323292/  1.278235, tr:  93.16%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.308291/  1.334265, tr:  93.87%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.271575/  1.523491, tr:  94.38%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.252103/  1.403261, tr:  95.30%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.240798/  1.406743, tr:  94.89%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.175054/  1.479259, tr:  97.96%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.159333/  1.613758, tr:  98.98%, val:  74.58%, val_best:  78.75%: 100%|██████████| 62/62 [00:11<00:00,  5.56it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.118932/  1.700351, tr:  99.90%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.107847/  1.681339, tr:  98.77%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.084622/  1.748001, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:11<00:00,  5.25it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.065428/  1.817364, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.063190/  1.857713, tr:  99.59%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.049269/  1.809813, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038206/  1.878699, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.04it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.043772/  1.971840, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  5.92it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.033703/  1.977960, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.033865/  1.970865, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.024384/  2.002367, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.019818/  2.053127, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.013611/  2.093822, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013051/  2.070077, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010724/  2.121746, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009881/  2.124283, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008912/  2.122527, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008040/  2.154500, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007181/  2.172772, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006928/  2.177614, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006552/  2.192427, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006115/  2.202425, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005597/  2.206732, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005578/  2.210750, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005013/  2.222686, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005101/  2.221440, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005000/  2.222896, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004840/  2.221685, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004808/  2.222081, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004823/  2.233307, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004797/  2.233880, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004697/  2.244714, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004535/  2.248230, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004457/  2.251215, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004276/  2.247992, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004356/  2.248745, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004279/  2.249380, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004318/  2.248707, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004423/  2.248712, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7095def872f54a2ab4aa7f2937a4ee97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.947 MB of 4.947 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▆▅▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00442</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>2.24871</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-13</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obrh79ry' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obrh79ry</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_150330-obrh79ry/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b682tqd9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.164580985240743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa4c2cc2ebb4d18a85b16d7cea1f80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0111137298349705, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_150950-b682tqd9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b682tqd9' target=\"_blank\">ancient-sweep-15</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b682tqd9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b682tqd9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.821234/  1.484609, tr:  37.59%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.149458/  1.276239, tr:  62.61%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.992699/  1.135316, tr:  65.68%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.893447/  1.138850, tr:  69.77%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.859111/  1.206672, tr:  70.28%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.833670/  1.267432, tr:  68.54%, val:  63.33%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.714512/  1.159544, tr:  74.67%, val:  63.75%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.673333/  1.279619, tr:  75.69%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.669753/  1.095292, tr:  76.71%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.498776/  1.276893, tr:  83.66%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:07<00:00,  8.56it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.487525/  1.198476, tr:  84.37%, val:  67.50%, val_best:  69.58%: 100%|██████████| 62/62 [00:08<00:00,  7.63it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.470258/  1.306285, tr:  84.07%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.475548/  1.207592, tr:  84.98%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.410645/  1.348726, tr:  89.79%, val:  70.83%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.330941/  1.336520, tr:  92.34%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:12<00:00,  5.06it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.347606/  1.380910, tr:  92.44%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.278676/  1.472786, tr:  94.79%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.242851/  1.364167, tr:  95.71%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.256500/  1.319958, tr:  94.38%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:08<00:00,  7.62it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.188337/  1.468685, tr:  97.75%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:10<00:00,  6.07it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.142665/  1.637348, tr:  99.18%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.111209/  1.651848, tr:  99.90%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.115773/  1.609805, tr:  98.26%, val:  77.08%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.093358/  1.648667, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.079250/  1.782157, tr:  99.80%, val:  76.67%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.064377/  1.787763, tr:  99.80%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.044901/  1.775495, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.042063/  1.877673, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.040708/  1.890824, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.031917/  1.943484, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.025717/  1.934491, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.019859/  1.966646, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.015885/  1.986065, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012926/  2.003094, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.90it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.012274/  2.018628, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010767/  2.030346, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009690/  2.041165, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009148/  2.046427, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007940/  2.069685, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007408/  2.086759, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007640/  2.102081, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006478/  2.113167, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006767/  2.105736, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006085/  2.108148, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005499/  2.115939, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005485/  2.105082, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005101/  2.120359, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005088/  2.126434, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004860/  2.132179, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004929/  2.138548, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004932/  2.142424, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004677/  2.147138, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004431/  2.142408, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004481/  2.144284, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004415/  2.148143, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004318/  2.147057, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004413/  2.149183, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004192/  2.146311, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004221/  2.145540, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004252/  2.146028, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313c952b13fc474497ae5049785e8ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.961 MB of 7.961 MB uploaded (2.363 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 29.2%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▅▇▆▆██▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00425</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.14603</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-15</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b682tqd9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b682tqd9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_150950-b682tqd9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qbxb1ddk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.16259131660381115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_151545-qbxb1ddk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qbxb1ddk' target=\"_blank\">cerulean-sweep-16</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qbxb1ddk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qbxb1ddk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.821681/  1.483422, tr:  36.98%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.150109/  1.267476, tr:  63.02%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.999317/  1.146396, tr:  65.99%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.903974/  1.133620, tr:  69.15%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.861806/  1.220467, tr:  70.17%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.833990/  1.299313, tr:  69.05%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.718752/  1.183524, tr:  74.26%, val:  62.92%, val_best:  65.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.674241/  1.289339, tr:  76.10%, val:  60.83%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.665653/  1.093987, tr:  76.92%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.500464/  1.265941, tr:  82.23%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.494122/  1.187806, tr:  84.37%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.459723/  1.268259, tr:  84.58%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.461168/  1.209354, tr:  84.78%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.397675/  1.278100, tr:  90.30%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.326097/  1.332109, tr:  91.83%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.312758/  1.336211, tr:  94.08%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.272650/  1.558689, tr:  93.77%, val:  69.58%, val_best:  77.08%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.254867/  1.394732, tr:  95.81%, val:  75.42%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.233279/  1.444561, tr:  95.51%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.180335/  1.495667, tr:  97.85%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.146044/  1.627814, tr:  98.98%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.104264/  1.673643, tr:  99.90%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.117085/  1.650897, tr:  98.16%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.095753/  1.687455, tr:  99.69%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.069408/  1.807303, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.053670/  1.842598, tr:  99.90%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.039911/  1.842826, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.035458/  1.899125, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.038434/  1.911852, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.042218/  1.965652, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.027490/  1.990092, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.020379/  2.039342, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.017889/  2.067065, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012222/  2.100748, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011007/  2.122659, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010634/  2.145643, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009298/  2.150026, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008534/  2.138971, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007926/  2.181147, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007324/  2.215951, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006542/  2.225928, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006233/  2.221929, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005975/  2.225626, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005827/  2.233401, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005414/  2.246575, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005170/  2.238542, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005027/  2.252833, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004996/  2.253597, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005222/  2.260297, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004777/  2.265342, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004693/  2.262475, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004744/  2.267631, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004821/  2.274307, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004448/  2.275823, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004461/  2.279242, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004315/  2.279616, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004520/  2.279364, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004513/  2.277182, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004333/  2.278237, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004477/  2.278252, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62455aac24dd472b84b169fe93d6373b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.944 MB of 5.944 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▅▅▆▇▆▇██▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▄▅▅▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00448</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.27825</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-16</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qbxb1ddk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qbxb1ddk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_151545-qbxb1ddk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v8u5abad with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.2907194703244136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_152111-v8u5abad</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v8u5abad' target=\"_blank\">trim-sweep-17</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v8u5abad' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v8u5abad</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.780947/  1.457433, tr:  38.61%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.138269/  1.244638, tr:  63.23%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.977931/  1.149737, tr:  66.39%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.880688/  1.114710, tr:  68.64%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.815024/  1.181609, tr:  71.20%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.805083/  1.324985, tr:  69.25%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.699808/  1.145247, tr:  74.77%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.657294/  1.220568, tr:  76.30%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.623251/  1.084376, tr:  77.83%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.472606/  1.288071, tr:  82.53%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.476102/  1.216991, tr:  83.86%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.455068/  1.317591, tr:  84.07%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.468554/  1.232645, tr:  82.74%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.385833/  1.296730, tr:  89.89%, val:  70.42%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.316562/  1.326085, tr:  92.54%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.330449/  1.329412, tr:  91.52%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.253242/  1.483317, tr:  94.79%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.254157/  1.384060, tr:  94.79%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.271409/  1.352863, tr:  93.67%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.181929/  1.424609, tr:  97.75%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.141808/  1.597568, tr:  99.18%, val:  76.67%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.118302/  1.595230, tr:  99.39%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.121125/  1.542202, tr:  98.06%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.121591/  1.521194, tr:  99.39%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.074573/  1.706022, tr: 100.00%, val:  77.92%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.066275/  1.750672, tr:  99.80%, val:  77.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.051882/  1.697183, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.039798/  1.757768, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.040630/  1.829950, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.042392/  1.801575, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.035084/  1.831810, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.024671/  1.867617, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.16it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.026796/  1.882639, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017802/  1.873594, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.06it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013594/  1.917021, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010433/  1.905721, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009097/  1.917418, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008425/  1.924022, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007089/  1.969795, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006755/  1.946007, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.75it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006444/  1.964860, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.005849/  1.973634, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.13it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005951/  1.974219, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.56it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005719/  1.972992, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.36it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005092/  1.974198, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.38it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005248/  1.983494, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.37it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005188/  1.983765, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004800/  1.990783, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005005/  2.001511, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004400/  2.006211, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.15it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004332/  2.001866, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004537/  2.005875, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004278/  2.003613, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004168/  2.001620, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004397/  2.001861, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004173/  1.997208, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004314/  2.000335, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004160/  2.001243, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004285/  2.001286, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 13.30it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004376/  2.001297, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb83b59f87ab452c882b756626a7ebc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.944 MB of 5.944 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▇▅▅▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▆▅▅▅▆▅▆▆▆▆▇▆▆▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00438</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.0013</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-17</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v8u5abad' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v8u5abad</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_152111-v8u5abad/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: grx0a528 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.06779564227501837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_152635-grx0a528</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/grx0a528' target=\"_blank\">ruby-sweep-18</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/grx0a528' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/grx0a528</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.846166/  1.501060, tr:  36.98%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.169744/  1.299217, tr:  62.21%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.019884/  1.161396, tr:  65.47%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.00it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.921235/  1.125522, tr:  68.74%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:08<00:00,  7.21it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.872366/  1.216740, tr:  69.97%, val:  63.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:09<00:00,  6.44it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.841046/  1.286881, tr:  68.44%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:09<00:00,  6.58it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.739937/  1.203436, tr:  73.24%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:09<00:00,  6.73it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.691997/  1.231257, tr:  75.89%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.682587/  1.120794, tr:  77.22%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:07<00:00,  8.42it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.525767/  1.272582, tr:  82.23%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.509823/  1.183165, tr:  84.37%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.490574/  1.283029, tr:  83.55%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.488550/  1.206690, tr:  83.86%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.436893/  1.268587, tr:  88.87%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.357210/  1.280874, tr:  90.50%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.348766/  1.334399, tr:  92.13%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.290597/  1.535504, tr:  93.56%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.269354/  1.449085, tr:  95.71%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.256702/  1.408258, tr:  95.81%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:07<00:00,  8.55it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.220669/  1.508528, tr:  98.26%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:07<00:00,  8.03it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.162646/  1.660880, tr:  99.28%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:07<00:00,  7.79it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.126718/  1.753624, tr:  99.59%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:10<00:00,  5.70it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.125040/  1.679002, tr:  98.37%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:10<00:00,  5.85it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.107902/  1.734734, tr:  99.90%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:09<00:00,  6.57it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.076389/  1.917522, tr:  99.90%, val:  75.00%, val_best:  78.75%: 100%|██████████| 62/62 [00:09<00:00,  6.79it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.073221/  1.880971, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.051216/  1.904626, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.041227/  1.958407, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:11<00:00,  5.53it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.036788/  2.008053, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.032016/  2.020213, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.025584/  2.052197, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.023324/  2.096598, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.30it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.015756/  2.145451, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:09<00:00,  6.86it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.013799/  2.149120, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:10<00:00,  6.15it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011947/  2.165160, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:08<00:00,  7.23it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011176/  2.211217, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009815/  2.238462, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009471/  2.233983, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008587/  2.266942, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007583/  2.271186, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007175/  2.282387, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006756/  2.296632, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006267/  2.297102, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005960/  2.300342, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005359/  2.304228, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005201/  2.314657, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005020/  2.307329, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005050/  2.318685, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005079/  2.313099, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:11<00:00,  5.20it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004811/  2.324546, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:10<00:00,  6.12it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004994/  2.326646, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:11<00:00,  5.48it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004866/  2.335283, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  8.19it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004843/  2.334625, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004401/  2.334550, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004514/  2.335041, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004425/  2.335078, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004485/  2.332965, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  7.77it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004413/  2.334170, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:10<00:00,  5.81it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004441/  2.334790, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:09<00:00,  6.60it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004499/  2.334528, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:10<00:00,  5.77it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d446e348ec9a4c738348135bc030baff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.945 MB of 5.945 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▆▅▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▇▇▇▇▇██▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▇▇▇▇▇██▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▅▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0045</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>2.33453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-sweep-18</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/grx0a528' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/grx0a528</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_152635-grx0a528/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7yveq073 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.01730621186611243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_153432-7yveq073</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7yveq073' target=\"_blank\">stellar-sweep-21</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7yveq073' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7yveq073</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.857090/  1.504361, tr:  36.47%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.181062/  1.318221, tr:  62.41%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.020479/  1.156615, tr:  65.47%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.920989/  1.153341, tr:  68.13%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:08<00:00,  6.94it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.888994/  1.218885, tr:  70.28%, val:  64.58%, val_best:  65.00%: 100%|██████████| 62/62 [00:09<00:00,  6.54it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.840004/  1.327281, tr:  69.66%, val:  62.08%, val_best:  65.00%: 100%|██████████| 62/62 [00:10<00:00,  5.97it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.761738/  1.172729, tr:  73.03%, val:  64.17%, val_best:  65.00%: 100%|██████████| 62/62 [00:09<00:00,  6.29it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.716868/  1.291637, tr:  74.97%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:08<00:00,  7.57it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.704262/  1.137583, tr:  76.30%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:10<00:00,  5.82it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.539664/  1.311637, tr:  81.82%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:10<00:00,  5.82it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.526271/  1.221114, tr:  83.76%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:09<00:00,  6.69it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.524065/  1.257476, tr:  81.41%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:08<00:00,  7.28it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.508252/  1.228931, tr:  83.96%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:10<00:00,  5.99it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.453114/  1.289103, tr:  88.76%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:10<00:00,  5.98it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.384469/  1.329307, tr:  89.17%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:10<00:00,  5.93it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.363530/  1.380787, tr:  93.16%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:10<00:00,  5.91it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.318359/  1.575617, tr:  92.65%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:11<00:00,  5.59it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.301013/  1.455641, tr:  94.79%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:10<00:00,  6.00it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.288917/  1.438210, tr:  94.08%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:10<00:00,  6.05it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.241334/  1.580666, tr:  96.63%, val:  75.00%, val_best:  75.42%: 100%|██████████| 62/62 [00:11<00:00,  5.23it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.184005/  1.714192, tr:  98.77%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:09<00:00,  6.62it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.136819/  1.795471, tr:  99.80%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:10<00:00,  5.85it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.148193/  1.741268, tr:  97.45%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:10<00:00,  5.65it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.139701/  1.788291, tr:  99.39%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:09<00:00,  6.54it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.103737/  1.978298, tr:  99.90%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:09<00:00,  6.34it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.086455/  1.902832, tr:  99.69%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:09<00:00,  6.82it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.056136/  1.968688, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:12<00:00,  5.05it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.047289/  2.018705, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.042034/  2.068170, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.044504/  2.067888, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.039656/  2.093375, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.033034/  2.150190, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:09<00:00,  6.80it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.025003/  2.212630, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:08<00:00,  7.06it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.019442/  2.219705, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:09<00:00,  6.27it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.016751/  2.253827, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:09<00:00,  6.75it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.014400/  2.285299, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:10<00:00,  5.74it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.013910/  2.313798, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:10<00:00,  5.89it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.011966/  2.310353, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:11<00:00,  5.22it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.010048/  2.347965, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:10<00:00,  5.73it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.009738/  2.359054, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:11<00:00,  5.48it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.009025/  2.351595, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:08<00:00,  6.93it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007830/  2.373964, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:11<00:00,  5.29it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.007437/  2.376276, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:07<00:00,  8.47it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006918/  2.377541, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006377/  2.399059, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.06it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006103/  2.398199, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005970/  2.405268, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005738/  2.404358, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005791/  2.409990, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:08<00:00,  7.28it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005479/  2.417449, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:07<00:00,  8.06it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005888/  2.418380, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:10<00:00,  5.67it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005722/  2.417060, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:11<00:00,  5.41it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005569/  2.422369, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:09<00:00,  6.56it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.005319/  2.424291, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005409/  2.426717, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.005266/  2.430830, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.005196/  2.430148, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.005155/  2.430900, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:10<00:00,  5.68it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.005085/  2.430738, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:09<00:00,  6.60it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.005208/  2.430963, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:11<00:00,  5.17it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06e090b5a47494da38820b89d5b83d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.068 MB of 5.068 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▆▅▄▅▆▇▆▆█▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00521</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.43096</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-21</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7yveq073' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7yveq073</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_153432-7yveq073/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2bq9prb0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.025602888526958575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_154400-2bq9prb0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2bq9prb0' target=\"_blank\">dark-sweep-24</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2bq9prb0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2bq9prb0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.855556/  1.498349, tr:  36.77%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.178512/  1.303664, tr:  62.31%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.026772/  1.157925, tr:  64.96%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.932087/  1.143975, tr:  68.13%, val:  64.17%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.883765/  1.197060, tr:  69.77%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.838104/  1.339088, tr:  69.77%, val:  61.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.765502/  1.212349, tr:  72.42%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.708701/  1.312483, tr:  75.59%, val:  60.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.693893/  1.111140, tr:  76.92%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:09<00:00,  6.85it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.538131/  1.287110, tr:  82.53%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:08<00:00,  7.24it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.520342/  1.207844, tr:  83.76%, val:  69.17%, val_best:  69.58%: 100%|██████████| 62/62 [00:08<00:00,  6.89it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.520801/  1.273560, tr:  82.74%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:07<00:00,  7.82it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.498323/  1.202291, tr:  84.58%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:08<00:00,  7.19it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.437163/  1.298818, tr:  89.48%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:09<00:00,  6.34it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.371813/  1.365986, tr:  91.01%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:09<00:00,  6.87it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.363347/  1.336870, tr:  91.73%, val:  70.42%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.56it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.313104/  1.604837, tr:  93.56%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.311323/  1.431350, tr:  94.18%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.270233/  1.458516, tr:  95.10%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.223005/  1.584725, tr:  97.34%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.167280/  1.682150, tr:  99.08%, val:  75.00%, val_best:  77.50%: 100%|██████████| 62/62 [00:07<00:00,  8.29it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.136282/  1.765392, tr:  99.80%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:09<00:00,  6.83it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.159612/  1.686698, tr:  97.45%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:11<00:00,  5.38it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.127791/  1.763560, tr:  99.49%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:09<00:00,  6.29it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.093830/  1.927356, tr:  99.80%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:08<00:00,  7.14it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.081136/  1.929550, tr:  99.90%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:09<00:00,  6.88it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.057299/  1.973338, tr: 100.00%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.048940/  2.044811, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.041893/  2.083720, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.037308/  2.086998, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.16it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.033272/  2.093835, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.48it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.031793/  2.136845, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  6.01it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.022764/  2.228401, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.35it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017624/  2.184046, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  6.97it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.015765/  2.194476, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.27it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.013337/  2.255995, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  6.17it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.012307/  2.271281, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.48it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.011681/  2.314155, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.80it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.009951/  2.325186, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.20it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.009571/  2.343750, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.71it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008137/  2.350576, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.34it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.008270/  2.374270, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.20it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006994/  2.386510, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  5.79it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006905/  2.379040, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.12it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006526/  2.390390, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.24it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006235/  2.377644, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:11<00:00,  5.50it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.006230/  2.397935, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  6.14it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005861/  2.402898, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.18it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.006144/  2.410851, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.28it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005624/  2.414650, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:11<00:00,  5.31it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005694/  2.411456, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.57it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005653/  2.412340, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.23it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005334/  2.414668, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  6.97it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.005255/  2.412429, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005603/  2.418422, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.005184/  2.417515, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.005342/  2.417519, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.005240/  2.420336, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  7.85it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.005240/  2.420392, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.27it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.005346/  2.420682, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.59it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b572d1ab944d34b73797bbb8b9bcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.945 MB of 4.945 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▆▅▅▆▆▆▆▇▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇█▇▇████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇█▇▇████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▅▄▅▅▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00535</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.42068</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-24</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2bq9prb0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2bq9prb0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_154400-2bq9prb0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qii6t9r7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.31183754239840417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_155238-qii6t9r7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qii6t9r7' target=\"_blank\">azure-sweep-27</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qii6t9r7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qii6t9r7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.774948/  1.453524, tr:  38.51%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:10<00:00,  5.89it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.135761/  1.251142, tr:  63.33%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:09<00:00,  6.71it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.979284/  1.125892, tr:  66.91%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:15<00:00,  3.97it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.868877/  1.116976, tr:  68.34%, val:  64.17%, val_best:  66.67%: 100%|██████████| 62/62 [00:09<00:00,  6.42it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.833040/  1.159698, tr:  70.79%, val:  62.08%, val_best:  66.67%: 100%|██████████| 62/62 [00:08<00:00,  7.46it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.822660/  1.251530, tr:  68.85%, val:  60.42%, val_best:  66.67%: 100%|██████████| 62/62 [00:08<00:00,  7.03it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.679979/  1.153331, tr:  74.77%, val:  62.92%, val_best:  66.67%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.658874/  1.215662, tr:  75.28%, val:  61.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.623985/  1.107621, tr:  77.22%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.486323/  1.364788, tr:  82.64%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:07<00:00,  8.06it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.481458/  1.178025, tr:  84.17%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:10<00:00,  5.81it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.443229/  1.317379, tr:  83.86%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:10<00:00,  6.07it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.446496/  1.237401, tr:  86.11%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:08<00:00,  7.00it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.390975/  1.322248, tr:  89.68%, val:  67.08%, val_best:  72.50%: 100%|██████████| 62/62 [00:08<00:00,  7.21it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.315089/  1.282791, tr:  91.83%, val:  71.67%, val_best:  72.50%: 100%|██████████| 62/62 [00:09<00:00,  6.34it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.359725/  1.337760, tr:  91.22%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.271629/  1.479930, tr:  94.48%, val:  70.83%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.257020/  1.365550, tr:  94.69%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.231291/  1.345732, tr:  96.02%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.172345/  1.489707, tr:  97.85%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.146726/  1.547752, tr:  98.88%, val:  74.58%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.102281/  1.579014, tr:  99.90%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.113753/  1.524811, tr:  98.67%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.087347/  1.592166, tr:  99.69%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.069929/  1.717895, tr: 100.00%, val:  75.42%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.064288/  1.706945, tr:  99.69%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.046109/  1.685247, tr:  99.90%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038094/  1.757539, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.034581/  1.786811, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.032136/  1.851708, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.027176/  1.872307, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.018712/  1.892446, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.017905/  1.910281, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012821/  1.915693, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.012875/  1.945626, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010847/  1.960614, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009736/  1.987323, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.007822/  1.966756, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007267/  2.015551, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007288/  2.018395, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006361/  2.008442, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006119/  2.008696, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005349/  2.012181, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005107/  2.035050, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005162/  2.028045, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.004469/  2.039063, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004272/  2.048862, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004434/  2.039186, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004404/  2.040399, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004090/  2.044801, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004235/  2.048420, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.003980/  2.047339, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004157/  2.046964, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004082/  2.043105, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004046/  2.044669, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.003954/  2.045044, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003902/  2.046727, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003868/  2.047541, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003796/  2.049830, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.003990/  2.049774, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c951f195fbf8450e87be2b6d0c1b1dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.942 MB of 4.942 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▇▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇██▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇██▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▆▅▅▅▆▆▆▆▆▆▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00399</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.04977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-sweep-27</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qii6t9r7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qii6t9r7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_155238-qii6t9r7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lei694wi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.1821546794796643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_155921-lei694wi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lei694wi' target=\"_blank\">fine-sweep-29</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lei694wi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lei694wi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.815317/  1.486226, tr:  37.28%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.149165/  1.271012, tr:  63.33%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.994869/  1.134982, tr:  65.78%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.895973/  1.131052, tr:  68.85%, val:  62.50%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.854710/  1.209977, tr:  69.97%, val:  61.25%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.831043/  1.291661, tr:  69.36%, val:  61.67%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.713704/  1.195023, tr:  74.57%, val:  62.92%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.682643/  1.280354, tr:  75.38%, val:  57.92%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.665092/  1.110923, tr:  77.12%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.496629/  1.221898, tr:  81.92%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.488428/  1.184163, tr:  85.09%, val:  67.08%, val_best:  70.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.452114/  1.243006, tr:  83.66%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.458037/  1.212490, tr:  85.09%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.402789/  1.267992, tr:  89.99%, val:  70.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.322374/  1.260311, tr:  92.24%, val:  72.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.310098/  1.322080, tr:  94.18%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.264888/  1.609596, tr:  95.10%, val:  70.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.261644/  1.421389, tr:  94.69%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.255743/  1.362348, tr:  94.08%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.184827/  1.467894, tr:  97.75%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.142415/  1.589830, tr:  99.28%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.109933/  1.689464, tr:  99.90%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.105888/  1.658948, tr:  98.88%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.102549/  1.682230, tr:  99.69%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.068550/  1.802779, tr: 100.00%, val:  77.08%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.060455/  1.802346, tr:  99.90%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.044991/  1.782398, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.036565/  1.847553, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.037154/  1.899164, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.027529/  1.939543, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.022953/  1.979762, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.020467/  1.985330, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.014233/  2.038523, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012301/  2.056410, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011424/  2.052014, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010049/  2.107177, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.008477/  2.104093, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.007770/  2.127747, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008342/  2.152647, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006570/  2.155581, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006485/  2.150594, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006124/  2.167625, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005450/  2.172611, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005142/  2.175043, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005369/  2.172874, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005018/  2.183126, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004542/  2.187579, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004758/  2.195552, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004804/  2.197141, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004547/  2.198495, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004552/  2.205322, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004572/  2.203861, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004480/  2.210432, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004251/  2.212152, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004345/  2.216655, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004201/  2.215372, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004289/  2.217399, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004182/  2.217226, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004182/  2.218086, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004259/  2.217918, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853ce191c5e6448cbb988b422a22a740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.496 MB of 7.496 MB uploaded (2.363 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 31.0%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆▄▅▇▆▆█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▆▇▇▇█▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▆▇▇▇█▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00426</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.21792</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-29</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lei694wi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lei694wi</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_155921-lei694wi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l88x3gd0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.08646512241322593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_160528-l88x3gd0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l88x3gd0' target=\"_blank\">drawn-sweep-31</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l88x3gd0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l88x3gd0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.841034/  1.501484, tr:  36.57%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.166797/  1.277058, tr:  62.00%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.014748/  1.151431, tr:  65.37%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.915123/  1.144477, tr:  69.15%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.871633/  1.201623, tr:  69.97%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.849319/  1.280051, tr:  68.03%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.726265/  1.138262, tr:  73.24%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.685511/  1.259271, tr:  75.59%, val:  61.25%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.680173/  1.112911, tr:  76.71%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.528767/  1.256085, tr:  82.02%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.500633/  1.198146, tr:  83.96%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.480161/  1.297255, tr:  83.04%, val:  70.42%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.496699/  1.210564, tr:  82.94%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.432661/  1.279857, tr:  88.97%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.350588/  1.271534, tr:  91.73%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.342831/  1.319894, tr:  92.65%, val:  73.75%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.306731/  1.550206, tr:  93.36%, val:  73.75%, val_best:  74.58%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.282083/  1.430934, tr:  94.79%, val:  74.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.261753/  1.422633, tr:  94.18%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.207178/  1.468504, tr:  97.65%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.162084/  1.677849, tr:  99.28%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.123406/  1.716100, tr:  99.90%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.119564/  1.721200, tr:  98.98%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.108319/  1.694621, tr:  99.80%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.079730/  1.898677, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.072309/  1.855585, tr:  99.80%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.049038/  1.909684, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.039821/  1.966631, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.040223/  1.984442, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.031363/  2.026668, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.027807/  2.065714, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.022864/  2.119103, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.021009/  2.122060, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015501/  2.166358, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.012398/  2.160847, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011662/  2.203825, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.011013/  2.226102, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009289/  2.222868, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008429/  2.261613, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007722/  2.263505, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007689/  2.271762, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006794/  2.280031, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006418/  2.287519, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005816/  2.280569, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005436/  2.296504, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005505/  2.288504, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005288/  2.305428, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005199/  2.309727, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005071/  2.313469, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004691/  2.316437, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004613/  2.322874, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004759/  2.321239, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004604/  2.319181, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004445/  2.320453, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004406/  2.323953, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004389/  2.324554, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004487/  2.326468, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004361/  2.327457, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004381/  2.327226, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004347/  2.325078, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceea4608c60444c9b7b7b1ec83694d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.982 MB of 4.982 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▆▅▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▄▄▅▄▄▅▅▅▅▆▅▅▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00435</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.32508</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-31</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l88x3gd0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l88x3gd0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_160528-l88x3gd0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hm3chqxi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.030401725681328307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_161129-hm3chqxi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hm3chqxi' target=\"_blank\">woven-sweep-33</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hm3chqxi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hm3chqxi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.855834/  1.506246, tr:  36.36%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.175348/  1.307638, tr:  62.61%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.022132/  1.168614, tr:  65.47%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.922225/  1.169635, tr:  69.05%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.885966/  1.194621, tr:  69.66%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.834496/  1.306788, tr:  70.68%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.751313/  1.184063, tr:  73.34%, val:  63.75%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.710971/  1.279928, tr:  75.38%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.706880/  1.105565, tr:  77.63%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.536577/  1.289743, tr:  81.92%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.523385/  1.184080, tr:  83.66%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.517163/  1.286255, tr:  82.64%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.497924/  1.215237, tr:  84.27%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.446417/  1.266752, tr:  89.17%, val:  71.67%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.380101/  1.319437, tr:  89.89%, val:  73.33%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.352078/  1.369106, tr:  92.34%, val:  72.08%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.318550/  1.567084, tr:  92.34%, val:  71.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.290434/  1.468957, tr:  94.79%, val:  71.67%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.275204/  1.436390, tr:  94.48%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.218132/  1.581195, tr:  97.24%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.181741/  1.661326, tr:  98.37%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.135572/  1.743667, tr:  99.80%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.148277/  1.702200, tr:  97.14%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.129617/  1.749007, tr:  99.59%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.113921/  1.891604, tr:  99.69%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.088276/  1.848504, tr:  99.90%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.060377/  1.885265, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.055629/  1.998900, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.046775/  1.982264, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.040464/  2.041119, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.034544/  2.055825, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.029300/  2.108392, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.024730/  2.150267, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017603/  2.169891, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.016836/  2.185790, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.014643/  2.211218, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.012744/  2.221653, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.011284/  2.257547, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.009909/  2.270937, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.008807/  2.293876, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008993/  2.312054, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.008033/  2.314273, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.007324/  2.325154, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006786/  2.335345, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006569/  2.340906, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006385/  2.339008, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005995/  2.346951, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.006089/  2.352516, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005759/  2.355194, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005625/  2.363728, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005842/  2.364767, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005737/  2.364737, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005563/  2.369478, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.005245/  2.367706, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005526/  2.369572, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.005150/  2.366808, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.005221/  2.367203, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.005239/  2.368090, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.005198/  2.367996, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.005139/  2.368527, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10de12f0e1143739eb3dc78deff131d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.947 MB of 4.947 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▆▇▆▆█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▆▇▇▇█▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▆▇▇▇█▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▄▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00514</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>2.36853</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-33</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hm3chqxi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hm3chqxi</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_161129-hm3chqxi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vnkfk0n3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.23089869965921905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_161745-vnkfk0n3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vnkfk0n3' target=\"_blank\">lucky-sweep-35</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vnkfk0n3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vnkfk0n3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.801868/  1.473549, tr:  37.28%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.142358/  1.271241, tr:  63.23%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.991682/  1.142410, tr:  65.99%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.887441/  1.113599, tr:  69.05%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.833200/  1.195403, tr:  70.89%, val:  61.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.819609/  1.293983, tr:  68.85%, val:  62.08%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.699397/  1.167002, tr:  74.46%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.666771/  1.233110, tr:  76.40%, val:  61.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.635714/  1.131192, tr:  77.02%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.494862/  1.261756, tr:  82.02%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.483096/  1.216716, tr:  84.68%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.449251/  1.274056, tr:  83.96%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.465131/  1.191584, tr:  85.29%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.382359/  1.353457, tr:  89.89%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.323460/  1.329929, tr:  92.44%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.336691/  1.381501, tr:  91.42%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.275538/  1.470502, tr:  93.67%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.247719/  1.417570, tr:  95.51%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.230080/  1.390883, tr:  95.61%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.196809/  1.482318, tr:  98.37%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.147742/  1.649130, tr:  99.08%, val:  75.42%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.114686/  1.674762, tr:  99.39%, val:  75.83%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.110999/  1.665015, tr:  98.77%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.083852/  1.716386, tr:  99.90%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.070568/  1.744845, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.059358/  1.839521, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.044646/  1.802686, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.036198/  1.903746, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.033306/  1.877025, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.026657/  1.959966, tr: 100.00%, val:  78.33%, val_best:  82.08%: 100%|██████████| 62/62 [00:09<00:00,  6.32it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.022768/  1.945087, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.018093/  1.996305, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.018050/  2.020811, tr: 100.00%, val:  78.33%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012846/  2.040130, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.010809/  2.049415, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011053/  2.094513, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010171/  2.084195, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009446/  2.101398, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007640/  2.133299, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006730/  2.113428, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006350/  2.119313, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006227/  2.140980, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005786/  2.140090, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005464/  2.151831, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005380/  2.150509, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005053/  2.153352, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004920/  2.164435, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004988/  2.158312, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004702/  2.164160, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004672/  2.164447, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004575/  2.172042, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004495/  2.177231, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004292/  2.180326, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004158/  2.182224, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004144/  2.186355, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004040/  2.185744, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003971/  2.185725, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003919/  2.186189, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003949/  2.185260, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.003923/  2.185474, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df9632df11d4940badb502b3f18b7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.445 MB of 7.445 MB uploaded (2.363 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 31.2%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▆▅▅▇▆▇██▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00392</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>2.18547</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-35</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vnkfk0n3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vnkfk0n3</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_161745-vnkfk0n3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zkx91vjx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3877457702402045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_162402-zkx91vjx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zkx91vjx' target=\"_blank\">clear-sweep-37</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zkx91vjx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zkx91vjx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.747110/  1.425003, tr:  39.94%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.121837/  1.237536, tr:  63.43%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.963836/  1.121071, tr:  66.39%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.862760/  1.102475, tr:  69.46%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.812993/  1.114162, tr:  69.87%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.777297/  1.359232, tr:  71.71%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.677073/  1.148069, tr:  74.57%, val:  63.75%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.642312/  1.261489, tr:  75.89%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.617784/  1.107383, tr:  76.51%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.474284/  1.457188, tr:  83.45%, val:  63.33%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.474045/  1.235756, tr:  84.07%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.431790/  1.324040, tr:  84.17%, val:  67.08%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.425325/  1.252645, tr:  86.01%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.364642/  1.379592, tr:  91.32%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.328161/  1.293210, tr:  91.22%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.291701/  1.382724, tr:  93.46%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.254169/  1.478404, tr:  94.99%, val:  70.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.241514/  1.355663, tr:  94.99%, val:  75.00%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.246633/  1.419538, tr:  95.20%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.183424/  1.466066, tr:  97.45%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.158492/  1.489915, tr:  97.85%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.115920/  1.623082, tr:  99.59%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.119882/  1.547704, tr:  98.37%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.110888/  1.628854, tr:  99.80%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.078462/  1.711498, tr:  99.69%, val:  74.17%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.064952/  1.712223, tr:  99.69%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.048942/  1.744228, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.044817/  1.816684, tr:  99.90%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.038149/  1.812527, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.032807/  1.831049, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.023036/  1.880478, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.021506/  1.888141, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.022077/  1.888105, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.016400/  1.914709, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.016650/  1.945005, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.012450/  1.940696, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010941/  1.955889, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009850/  1.974159, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007992/  1.999178, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007649/  1.968744, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007456/  2.001337, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006699/  2.024264, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.007265/  2.006996, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005739/  2.013204, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005891/  2.020088, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005363/  2.025870, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005166/  2.032228, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004988/  2.029367, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005241/  2.018418, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004768/  2.028660, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004235/  2.027304, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004335/  2.024656, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004397/  2.029910, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004139/  2.027702, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004213/  2.026279, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004039/  2.025425, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003976/  2.026763, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003993/  2.027959, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003993/  2.028540, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004096/  2.028588, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7587d7888d604e1c95c59c467ec1e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆▄▅▆▅▆█▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▇▇▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▇▇▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▆▅▅▆▆▅▅▆▆▆▆▆▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0041</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>2.02859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-sweep-37</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zkx91vjx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zkx91vjx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_162402-zkx91vjx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8q3s7qzz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3188065031143914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_163014-8q3s7qzz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8q3s7qzz' target=\"_blank\">giddy-sweep-39</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8q3s7qzz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8q3s7qzz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.772963/  1.449253, tr:  39.22%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.134193/  1.240703, tr:  63.43%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.969216/  1.121080, tr:  66.19%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.866176/  1.107482, tr:  68.85%, val:  64.58%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.819346/  1.143985, tr:  71.40%, val:  65.00%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.812599/  1.335912, tr:  69.87%, val:  58.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.699625/  1.147223, tr:  74.87%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.648553/  1.210209, tr:  76.61%, val:  60.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.605424/  1.124512, tr:  77.83%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.476948/  1.315525, tr:  82.74%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.462108/  1.225958, tr:  84.68%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.444152/  1.302288, tr:  84.37%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.445018/  1.210278, tr:  85.60%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.385873/  1.295018, tr:  89.79%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.309697/  1.325552, tr:  92.95%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.306951/  1.394002, tr:  93.26%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.249128/  1.494423, tr:  95.20%, val:  72.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.248863/  1.476628, tr:  95.51%, val:  73.33%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.273305/  1.324501, tr:  92.03%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.171532/  1.519167, tr:  98.67%, val:  75.42%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.142776/  1.618238, tr:  98.88%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.113368/  1.733782, tr:  99.59%, val:  76.67%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.115920/  1.655484, tr:  98.47%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.102357/  1.609065, tr:  99.90%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.070625/  1.734326, tr:  99.90%, val:  77.08%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.060671/  1.780616, tr:  99.80%, val:  78.33%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.051885/  1.775687, tr:  99.90%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.042113/  1.845489, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.040471/  1.847560, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.041959/  1.863546, tr:  99.90%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.046019/  1.845246, tr:  99.80%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.024702/  1.891149, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.020991/  1.882964, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017493/  1.914367, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.015102/  1.959411, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.013100/  1.968474, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.011032/  1.999201, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.010954/  1.980642, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.011248/  1.992851, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.008290/  1.999508, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008054/  1.999210, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007024/  2.016833, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006834/  2.025199, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006220/  2.025080, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005916/  2.032846, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005783/  2.042184, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005267/  2.047534, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004977/  2.042082, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005179/  2.047639, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004926/  2.050992, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004770/  2.059975, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004363/  2.061723, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004429/  2.063448, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004327/  2.058737, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004324/  2.062308, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004234/  2.065459, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004237/  2.063370, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004285/  2.066429, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004180/  2.066256, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004528/  2.066849, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eb170e94604d6dac2fbe0007c8ad3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.957 MB of 4.957 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▇▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▆▅▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00453</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>2.06685</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-39</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8q3s7qzz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8q3s7qzz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_163014-8q3s7qzz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g0pb0l5x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.26953043936861637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_163630-g0pb0l5x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g0pb0l5x' target=\"_blank\">amber-sweep-41</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g0pb0l5x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g0pb0l5x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.788037/  1.452570, tr:  37.69%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.140537/  1.267459, tr:  62.82%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:08<00:00,  7.42it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.988296/  1.125524, tr:  66.70%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.874086/  1.120332, tr:  69.05%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.832327/  1.176716, tr:  70.28%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.806640/  1.268433, tr:  69.77%, val:  62.50%, val_best:  66.25%: 100%|██████████| 62/62 [00:08<00:00,  6.89it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.689394/  1.137023, tr:  74.06%, val:  63.33%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.655844/  1.227936, tr:  76.81%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.622463/  1.099643, tr:  77.63%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:07<00:00,  7.79it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.480787/  1.288027, tr:  83.15%, val:  68.75%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.479981/  1.202673, tr:  84.17%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:08<00:00,  6.90it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.452287/  1.267447, tr:  83.35%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.461215/  1.212241, tr:  84.68%, val:  72.50%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.384835/  1.356116, tr:  89.79%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.317413/  1.298505, tr:  92.95%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.315517/  1.384872, tr:  92.75%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.250759/  1.445560, tr:  95.71%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.249042/  1.392828, tr:  94.79%, val:  72.08%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.265480/  1.330060, tr:  93.36%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.178199/  1.502728, tr:  98.06%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.141325/  1.586888, tr:  99.08%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.104441/  1.601150, tr:  99.80%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.107747/  1.647314, tr:  98.98%, val:  76.67%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.088358/  1.716829, tr:  99.69%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.070516/  1.831771, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.054681/  1.770676, tr: 100.00%, val:  76.67%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.047195/  1.807696, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.041762/  1.886950, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.035443/  1.877537, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.028961/  1.924957, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.024426/  1.952758, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.017878/  2.002682, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.016414/  2.035208, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.013470/  2.030156, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011924/  2.102360, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010780/  2.098478, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.008935/  2.091778, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008712/  2.069091, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007599/  2.088712, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006937/  2.094051, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007116/  2.105380, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.005675/  2.119990, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005319/  2.130877, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005245/  2.134573, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.004785/  2.134262, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.004880/  2.130695, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004491/  2.136522, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004499/  2.138709, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004435/  2.145473, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004177/  2.149155, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.003936/  2.155669, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.003900/  2.157220, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.003985/  2.152658, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.003810/  2.153265, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.003805/  2.154269, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.003777/  2.156101, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003660/  2.155009, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003726/  2.155646, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003709/  2.155571, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.003718/  2.156275, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f23f92320e846c184b40bd25763a86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.957 MB of 4.957 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▇▅▇▅▆▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇█▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇█▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00372</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.15627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-sweep-41</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g0pb0l5x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g0pb0l5x</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_163630-g0pb0l5x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: udkgimze with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.260806686605049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_164302-udkgimze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/udkgimze' target=\"_blank\">prime-sweep-43</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/udkgimze' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/udkgimze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.792790/  1.458847, tr:  37.79%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.137891/  1.268713, tr:  63.43%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.992233/  1.143777, tr:  65.37%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.882625/  1.116683, tr:  68.54%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.826656/  1.164938, tr:  70.28%, val:  63.75%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.802905/  1.304302, tr:  70.28%, val:  60.00%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.690826/  1.139580, tr:  74.67%, val:  63.75%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.654688/  1.253762, tr:  75.79%, val:  62.92%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.634189/  1.086964, tr:  76.81%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.478364/  1.256142, tr:  83.25%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.468827/  1.215557, tr:  84.78%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.454874/  1.360370, tr:  84.17%, val:  70.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.452817/  1.250040, tr:  85.39%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.387016/  1.350672, tr:  89.99%, val:  70.83%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.315360/  1.297006, tr:  92.65%, val:  72.08%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.317849/  1.368676, tr:  93.05%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.252182/  1.522739, tr:  95.40%, val:  72.50%, val_best:  74.58%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.250149/  1.397808, tr:  94.99%, val:  73.33%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.259074/  1.357375, tr:  93.97%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.174111/  1.482267, tr:  98.37%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.142834/  1.526544, tr:  99.28%, val:  77.08%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.102491/  1.645569, tr:  99.80%, val:  75.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.103912/  1.667387, tr:  99.28%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.091672/  1.643880, tr:  99.90%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.065785/  1.806188, tr: 100.00%, val:  76.25%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.055419/  1.766843, tr:  99.90%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.040419/  1.767400, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 13.01it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.036119/  1.835516, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.032166/  1.853343, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.031333/  1.949596, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.031994/  1.950817, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.024405/  2.006083, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.035842/  1.952076, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.016996/  1.971605, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013254/  1.992849, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010642/  2.028858, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009344/  2.040880, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008456/  2.043893, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007469/  2.065370, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007117/  2.083810, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007022/  2.097973, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006273/  2.082692, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006120/  2.098733, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005458/  2.123219, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005477/  2.125329, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005247/  2.120755, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004982/  2.127441, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005011/  2.150584, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005207/  2.130418, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005283/  2.136901, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004777/  2.143109, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004659/  2.145902, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004377/  2.145753, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004390/  2.150228, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004346/  2.153893, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004417/  2.152298, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004442/  2.153303, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004277/  2.153133, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004261/  2.153590, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004497/  2.153605, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c18ae876936483c89646a793e345ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆▅▅▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0045</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.1536</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-sweep-43</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/udkgimze' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/udkgimze</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_164302-udkgimze/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j12fogw6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.20793429619811732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_164919-j12fogw6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j12fogw6' target=\"_blank\">sweepy-sweep-45</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j12fogw6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j12fogw6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.809663/  1.481388, tr:  37.18%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.144408/  1.285210, tr:  63.23%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.994837/  1.136042, tr:  65.47%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.882122/  1.111690, tr:  69.77%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.847023/  1.188715, tr:  69.97%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.823742/  1.291831, tr:  69.36%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.701437/  1.180827, tr:  75.89%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.679355/  1.226536, tr:  74.97%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.653761/  1.109723, tr:  76.61%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.493556/  1.276551, tr:  82.43%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.488161/  1.234903, tr:  84.78%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.466406/  1.239500, tr:  83.86%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.475367/  1.239388, tr:  83.76%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.388838/  1.253028, tr:  89.58%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.323291/  1.329917, tr:  92.95%, val:  69.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.323730/  1.324590, tr:  93.46%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.263453/  1.468103, tr:  95.61%, val:  74.17%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.244481/  1.342863, tr:  95.71%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.244254/  1.316475, tr:  95.51%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.255305/  1.534566, tr:  97.75%, val:  75.42%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.175237/  1.493276, tr:  98.77%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.114491/  1.682232, tr:  99.90%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.118150/  1.576161, tr:  98.67%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.091518/  1.634406, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.067069/  1.737512, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.058073/  1.800229, tr:  99.90%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.043064/  1.771981, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038392/  1.835953, tr:  99.90%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.032759/  1.887490, tr: 100.00%, val:  76.67%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.028823/  1.909950, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.029628/  1.915077, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.021494/  1.963140, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.016193/  1.987441, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012701/  1.998876, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011285/  2.014313, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010251/  2.033979, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009041/  2.076570, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008270/  2.076721, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007005/  2.079270, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006644/  2.090559, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006570/  2.107507, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.005996/  2.120739, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005395/  2.130103, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005066/  2.143363, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.004884/  2.155127, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005011/  2.147129, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004581/  2.157789, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004530/  2.160502, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004255/  2.156176, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004285/  2.154337, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004178/  2.155299, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004182/  2.166251, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004075/  2.160680, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004064/  2.163615, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.003954/  2.166483, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004003/  2.167612, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003945/  2.169243, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003929/  2.170604, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003864/  2.171433, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.003868/  2.171446, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5577b5b8bb154391bcd5f86bc7b2ef30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.957 MB of 4.957 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▆▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00387</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>2.17145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweepy-sweep-45</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j12fogw6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j12fogw6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_164919-j12fogw6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qb7s9jtp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.35764775872334914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_165535-qb7s9jtp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qb7s9jtp' target=\"_blank\">electric-sweep-47</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qb7s9jtp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qb7s9jtp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.760034/  1.430698, tr:  39.33%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.121512/  1.246173, tr:  64.45%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.968741/  1.104921, tr:  66.39%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.859450/  1.098180, tr:  69.56%, val:  63.75%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.820212/  1.130205, tr:  70.48%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.788980/  1.330671, tr:  69.46%, val:  62.08%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.683518/  1.148397, tr:  75.49%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.652753/  1.241609, tr:  76.40%, val:  60.42%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.611373/  1.149219, tr:  77.02%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.474264/  1.329724, tr:  82.33%, val:  65.83%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.467359/  1.232459, tr:  84.37%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.425823/  1.334986, tr:  84.17%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.444223/  1.271026, tr:  83.86%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.361111/  1.371752, tr:  90.50%, val:  65.83%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.320530/  1.291094, tr:  91.93%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.315522/  1.403649, tr:  92.03%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.273269/  1.590181, tr:  93.77%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.265387/  1.415088, tr:  94.79%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.286425/  1.331789, tr:  92.95%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.228152/  1.539102, tr:  98.16%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.157390/  1.541108, tr:  98.16%, val:  74.17%, val_best:  77.08%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.120995/  1.564063, tr:  99.59%, val:  76.25%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.113971/  1.539413, tr:  98.77%, val:  76.25%, val_best:  77.08%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.099003/  1.546132, tr:  99.80%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.073493/  1.702429, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.067551/  1.695319, tr:  99.90%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.050084/  1.714998, tr: 100.00%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038221/  1.801602, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.038774/  1.812341, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.040473/  1.792220, tr: 100.00%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.040407/  1.825606, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:07<00:00,  8.69it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.025871/  1.807444, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.027138/  1.857390, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015449/  1.857963, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.015667/  1.874310, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.012167/  1.889044, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010108/  1.944519, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009657/  1.939478, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007703/  1.951238, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007160/  1.970877, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007072/  1.982886, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006904/  1.981659, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005751/  1.978335, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005716/  1.975844, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005702/  1.988623, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005095/  1.986494, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005325/  2.000111, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005041/  2.010010, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004945/  2.012592, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004646/  2.003324, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004701/  2.010846, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004571/  2.018382, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004567/  2.008998, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004576/  2.010718, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004558/  2.010476, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004570/  2.009977, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004497/  2.011545, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004322/  2.009988, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004370/  2.010461, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004477/  2.010340, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca3d249d76f4630af1c4223df81af9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▆▄▆▆▆▆█▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▆▅▅▆▆▅▅▇▆▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00448</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>2.01034</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-47</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qb7s9jtp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qb7s9jtp</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_165535-qb7s9jtp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6741dm56 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3817462029173444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_170154-6741dm56</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6741dm56' target=\"_blank\">restful-sweep-49</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6741dm56' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6741dm56</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.750773/  1.423294, tr:  39.53%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.114598/  1.248613, tr:  63.94%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.964639/  1.102004, tr:  66.29%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.842959/  1.107986, tr:  70.48%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.809074/  1.115039, tr:  70.48%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.782690/  1.359005, tr:  70.28%, val:  57.92%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.679735/  1.137687, tr:  75.28%, val:  62.92%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.647689/  1.209799, tr:  76.20%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.616821/  1.083282, tr:  77.53%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.489560/  1.371930, tr:  82.94%, val:  63.75%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.463487/  1.215631, tr:  85.19%, val:  67.50%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.448666/  1.329503, tr:  83.04%, val:  67.92%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.449404/  1.246416, tr:  83.35%, val:  69.17%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.359203/  1.359632, tr:  90.60%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.313045/  1.296392, tr:  92.65%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.311145/  1.382280, tr:  92.03%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.240719/  1.506852, tr:  95.40%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.252551/  1.438718, tr:  94.99%, val:  69.58%, val_best:  72.92%: 100%|██████████| 62/62 [1:05:05<00:00, 62.99s/it]                                     \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.268128/  1.345845, tr:  93.26%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.184657/  1.547681, tr:  98.26%, val:  74.17%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.176587/  1.416407, tr:  97.14%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.128164/  1.688384, tr:  99.39%, val:  74.58%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.149726/  1.544108, tr:  97.14%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.114199/  1.587244, tr:  99.28%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.076457/  1.714459, tr:  99.90%, val:  75.42%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.064663/  1.739902, tr:  99.80%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.054866/  1.719728, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.045338/  1.745490, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.041126/  1.821505, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.042244/  1.780721, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.031890/  1.811720, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.023767/  1.838802, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.028428/  1.836636, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017155/  1.873701, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.014405/  1.908759, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.013324/  1.899458, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010953/  1.947006, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.010739/  1.920854, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008417/  1.954180, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007911/  1.969383, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007823/  1.957809, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006819/  1.964096, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005908/  1.964202, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005754/  1.975454, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005757/  1.988575, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005155/  1.985531, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005034/  2.008160, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005168/  2.005582, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004828/  2.009415, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004497/  2.016747, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004595/  2.014001, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004650/  2.021221, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004294/  2.025319, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004277/  2.025373, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004145/  2.022084, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004149/  2.024194, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004228/  2.027628, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004168/  2.028447, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004149/  2.028134, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004193/  2.027756, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d88efa85e441cea7b91725982fcdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.957 MB of 4.957 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▄▆▄▅▇▅▅█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▆▇▆▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▆▇▆▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▆▅▅▆▆▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00419</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>2.02776</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-49</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6741dm56' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6741dm56</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_170154-6741dm56/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qvr5wwr2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.18004994785242726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_181319-qvr5wwr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qvr5wwr2' target=\"_blank\">dandy-sweep-62</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qvr5wwr2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qvr5wwr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.817514/  1.480563, tr:  37.39%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.151384/  1.287280, tr:  62.82%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.999417/  1.128924, tr:  65.47%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.895468/  1.136391, tr:  68.95%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.857207/  1.193521, tr:  69.97%, val:  62.08%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.833412/  1.261648, tr:  68.44%, val:  62.92%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.711715/  1.167197, tr:  74.67%, val:  62.50%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.681810/  1.233378, tr:  75.79%, val:  61.67%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.649085/  1.098147, tr:  76.71%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.491583/  1.272425, tr:  82.53%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.488537/  1.209401, tr:  84.27%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.467670/  1.303556, tr:  84.68%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.483010/  1.215842, tr:  84.27%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.406144/  1.300171, tr:  89.48%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.327639/  1.323560, tr:  91.93%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.327618/  1.344836, tr:  92.65%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.274157/  1.534330, tr:  94.69%, val:  72.92%, val_best:  74.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.264701/  1.388307, tr:  94.79%, val:  74.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.242342/  1.369684, tr:  94.69%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.182906/  1.436178, tr:  97.55%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.145794/  1.549998, tr:  99.18%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.109763/  1.645108, tr:  99.90%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.107582/  1.699045, tr:  98.77%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.108123/  1.676346, tr:  99.59%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.075183/  1.736097, tr:  99.90%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.057757/  1.804308, tr:  99.90%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.045658/  1.842807, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038940/  1.870228, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.037450/  1.907325, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.033153/  1.907611, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.036205/  1.976338, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.022856/  2.017003, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.025578/  2.005451, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015705/  2.034925, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013859/  2.051099, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011417/  2.060482, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010891/  2.064041, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009026/  2.083612, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007878/  2.091532, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006593/  2.105483, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006812/  2.116617, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006316/  2.122276, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005698/  2.131743, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006157/  2.142717, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005799/  2.153927, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005201/  2.158486, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004821/  2.165947, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004940/  2.162742, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004806/  2.168567, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004681/  2.169650, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004581/  2.170630, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004700/  2.168653, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004478/  2.174174, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004354/  2.175641, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004364/  2.180537, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004193/  2.175525, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004345/  2.177901, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004214/  2.178205, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004183/  2.178244, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004341/  2.177284, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64550dfffbdb4a7690a25f323ec9ceb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▆▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00434</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>2.17728</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-sweep-62</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qvr5wwr2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qvr5wwr2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_181319-qvr5wwr2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 36xx3z0u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.29373653391173926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_181934-36xx3z0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/36xx3z0u' target=\"_blank\">rare-sweep-65</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/36xx3z0u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/36xx3z0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.780665/  1.454055, tr:  38.71%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.137738/  1.261131, tr:  63.33%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.977469/  1.139846, tr:  66.29%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.871956/  1.110857, tr:  69.25%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.823046/  1.189684, tr:  70.58%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.816164/  1.246674, tr:  68.44%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.694029/  1.133759, tr:  74.67%, val:  62.08%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.664808/  1.194006, tr:  76.71%, val:  60.42%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.620945/  1.080573, tr:  77.43%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.472372/  1.305062, tr:  83.45%, val:  66.67%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.465757/  1.222310, tr:  84.98%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.437876/  1.306840, tr:  85.29%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.441435/  1.220838, tr:  86.52%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.376662/  1.392840, tr:  90.30%, val:  69.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.318289/  1.225767, tr:  92.75%, val:  74.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.305676/  1.320850, tr:  92.95%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.244472/  1.480993, tr:  95.40%, val:  74.58%, val_best:  77.50%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.247781/  1.391970, tr:  95.20%, val:  71.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.259252/  1.356690, tr:  94.38%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.176906/  1.519482, tr:  98.47%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.129869/  1.533213, tr:  99.18%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.103441/  1.584589, tr:  99.69%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.103285/  1.568594, tr:  99.08%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.092852/  1.604015, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.077731/  1.761585, tr: 100.00%, val:  77.50%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.065854/  1.659052, tr:  99.80%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.045141/  1.719644, tr:  99.90%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.034733/  1.737495, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.031934/  1.741911, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.029559/  1.867278, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.031117/  1.887516, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.020672/  1.886307, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.025948/  1.913977, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015088/  1.929507, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.014140/  1.917133, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011604/  1.936649, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009845/  1.935767, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008738/  1.980884, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007641/  1.980453, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006780/  1.994650, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007172/  2.004187, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006108/  2.013918, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005583/  2.010763, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005252/  2.010555, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005088/  2.015620, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.004795/  2.022202, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004746/  2.026817, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004702/  2.038886, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004801/  2.043391, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004198/  2.045977, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004297/  2.044731, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004203/  2.046103, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004241/  2.046678, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004033/  2.052154, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004091/  2.054545, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.84it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004054/  2.057291, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004088/  2.057283, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 13.02it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003924/  2.056318, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003770/  2.056743, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004156/  2.056736, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebbe4a04c224a68b183bb55bd8d6a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▇▅▆▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00416</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>2.05674</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-sweep-65</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/36xx3z0u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/36xx3z0u</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_181934-36xx3z0u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 33g9gcqp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.291980296730981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_182546-33g9gcqp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/33g9gcqp' target=\"_blank\">divine-sweep-68</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/33g9gcqp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/33g9gcqp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.779702/  1.453740, tr:  38.71%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.137686/  1.244656, tr:  63.23%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.983575/  1.142771, tr:  66.50%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.882213/  1.112129, tr:  69.25%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.825342/  1.154909, tr:  71.50%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.799775/  1.298672, tr:  69.87%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.692785/  1.132961, tr:  74.26%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.658708/  1.206949, tr:  76.40%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.629198/  1.097130, tr:  77.73%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.474747/  1.298333, tr:  82.74%, val:  67.08%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.481394/  1.224671, tr:  84.27%, val:  67.92%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.445886/  1.307099, tr:  83.66%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.457695/  1.213016, tr:  84.17%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.371076/  1.302264, tr:  89.89%, val:  69.17%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.313366/  1.313582, tr:  93.05%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.330291/  1.337074, tr:  91.01%, val:  72.08%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.261070/  1.460328, tr:  94.99%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.248178/  1.376659, tr:  95.61%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.245230/  1.366284, tr:  93.87%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.186732/  1.462971, tr:  97.75%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.137670/  1.572165, tr:  99.18%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.109973/  1.647958, tr:  99.59%, val:  75.83%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.112456/  1.593583, tr:  98.67%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.088387/  1.687168, tr:  99.90%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.066342/  1.847167, tr:  99.90%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.063627/  1.787679, tr:  99.80%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.048436/  1.772194, tr:  99.90%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.039119/  1.858650, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.030880/  1.871563, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.034619/  1.921603, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.036756/  1.915084, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.025902/  2.001617, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.028820/  2.035713, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.018624/  2.025964, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.014960/  2.052009, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011023/  2.057020, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009330/  2.078490, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008878/  2.075461, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.009004/  2.083465, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007952/  2.090783, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007813/  2.085634, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007075/  2.098610, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006330/  2.104195, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005706/  2.116816, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005731/  2.124935, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005330/  2.112226, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005146/  2.129449, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004912/  2.151925, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005295/  2.141323, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004632/  2.148758, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004583/  2.140461, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004575/  2.145815, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004639/  2.150627, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004452/  2.158834, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 13.53it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004472/  2.155323, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004412/  2.152437, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004547/  2.153105, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 13.49it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004450/  2.153553, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004446/  2.153219, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004625/  2.153595, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf897b05178b4dd0b600cf42da3ace07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▇▅▅▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00463</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.15359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-68</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/33g9gcqp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/33g9gcqp</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_182546-33g9gcqp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kymctstf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.08643352699743607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_183130-kymctstf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kymctstf' target=\"_blank\">earnest-sweep-70</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kymctstf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kymctstf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.840241/  1.501132, tr:  36.57%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.166852/  1.281876, tr:  62.21%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.012092/  1.162047, tr:  65.58%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.920428/  1.157094, tr:  67.82%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.870668/  1.219272, tr:  69.77%, val:  63.33%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.836641/  1.285106, tr:  68.54%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.735025/  1.168974, tr:  73.65%, val:  63.75%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.678139/  1.270326, tr:  75.79%, val:  61.67%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.679882/  1.114500, tr:  76.92%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.524180/  1.302928, tr:  82.23%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.509194/  1.193306, tr:  83.66%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.480372/  1.301237, tr:  82.84%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.488069/  1.201816, tr:  83.86%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.423830/  1.307802, tr:  88.97%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.363649/  1.330425, tr:  90.70%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.340513/  1.326958, tr:  92.85%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.302108/  1.521644, tr:  93.46%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.270638/  1.414961, tr:  95.51%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:04<00:00, 13.25it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.263964/  1.431163, tr:  94.69%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.215131/  1.539542, tr:  97.24%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.158760/  1.662175, tr:  99.28%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.114410/  1.748729, tr:  99.90%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.125154/  1.760772, tr:  98.47%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.131835/  1.750063, tr:  99.69%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.105580/  1.905975, tr:  99.59%, val:  75.00%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.079742/  1.886568, tr:  99.80%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.061258/  1.926589, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.048085/  1.956406, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.044416/  1.982914, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.034215/  2.067083, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.032803/  2.079809, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.033646/  2.113230, tr:  99.90%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.026450/  2.154708, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.016275/  2.164021, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.014868/  2.203961, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.012689/  2.216383, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.011125/  2.192945, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009880/  2.220159, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008069/  2.241864, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007477/  2.252009, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007665/  2.258237, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007081/  2.251796, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006662/  2.274122, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005954/  2.268870, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006030/  2.285056, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005602/  2.282649, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005545/  2.296860, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005680/  2.307823, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005383/  2.305021, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005131/  2.311068, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005240/  2.316785, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005074/  2.321239, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004992/  2.313716, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 12.69it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004907/  2.314287, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004862/  2.318392, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004822/  2.319982, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004924/  2.322270, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004802/  2.321615, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.50it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004758/  2.317649, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:04<00:00, 13.49it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004823/  2.317303, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776603a5de974a59aab92e78f6567c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▆▅▅▅▇▆▆█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇█▇▇████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇█▇▇████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▄▅▅▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00482</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.3173</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-70</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kymctstf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kymctstf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_183130-kymctstf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9w7kpmw7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3189241562745208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_183715-9w7kpmw7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9w7kpmw7' target=\"_blank\">brisk-sweep-72</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9w7kpmw7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9w7kpmw7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.771959/  1.451863, tr:  39.02%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.131802/  1.251648, tr:  63.23%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.975351/  1.139332, tr:  66.91%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.872351/  1.097944, tr:  69.36%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.830757/  1.152249, tr:  70.58%, val:  63.33%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.807359/  1.341482, tr:  70.79%, val:  60.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.707140/  1.126482, tr:  75.08%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.659611/  1.187372, tr:  76.30%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.618925/  1.107494, tr:  77.53%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.474629/  1.311719, tr:  83.04%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.474680/  1.242120, tr:  84.58%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.450344/  1.280867, tr:  83.35%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.461327/  1.225467, tr:  83.96%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.377165/  1.221053, tr:  89.27%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.313310/  1.268506, tr:  92.75%, val:  72.50%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.301682/  1.358000, tr:  93.46%, val:  73.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 13.32it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.238914/  1.468790, tr:  95.71%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.245901/  1.443758, tr:  95.30%, val:  70.83%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 13.43it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.282136/  1.317610, tr:  93.56%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.189614/  1.450137, tr:  97.85%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.145540/  1.499707, tr:  98.88%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.107192/  1.627889, tr:  99.90%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.03it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.099116/  1.599052, tr:  98.98%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.092987/  1.640771, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.074756/  1.754686, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:04<00:00, 13.17it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.072875/  1.698201, tr:  99.59%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.056396/  1.753108, tr:  99.80%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 13.67it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038014/  1.784436, tr:  99.90%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.033826/  1.847682, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.030813/  1.841968, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.023355/  1.870169, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.022099/  1.901786, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.023501/  1.920572, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015073/  1.879877, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013328/  1.923765, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011028/  1.938793, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009799/  1.953947, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008864/  1.951030, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 13.30it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007704/  1.974753, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007437/  1.975587, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.70it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006843/  1.998331, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006021/  2.011833, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006020/  2.011230, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005300/  2.025681, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.81it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005172/  2.035167, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005091/  2.032149, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004723/  2.034451, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004765/  2.032399, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004344/  2.039794, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 13.27it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004284/  2.031490, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004170/  2.039144, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004212/  2.035635, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004149/  2.036112, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004176/  2.038914, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004132/  2.037247, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004038/  2.035262, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 13.40it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003970/  2.037312, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003980/  2.036837, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003989/  2.037828, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004034/  2.037802, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 13.08it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27417c8c040640b09e34d44412ee7407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▇▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▆▅▅▆▅▅▅▆▆▆▆▆▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00403</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>2.0378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-72</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9w7kpmw7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9w7kpmw7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_183715-9w7kpmw7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jkcehg2t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.13001756304308723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_184248-jkcehg2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkcehg2t' target=\"_blank\">frosty-sweep-73</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkcehg2t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkcehg2t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.828296/  1.485196, tr:  37.08%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.158417/  1.276547, tr:  62.92%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.000232/  1.148454, tr:  65.37%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.906521/  1.156031, tr:  68.95%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.866461/  1.209006, tr:  69.97%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.833981/  1.272417, tr:  69.05%, val:  61.67%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.718091/  1.186274, tr:  74.26%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.685361/  1.301140, tr:  75.69%, val:  60.42%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.662831/  1.099564, tr:  76.30%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.508820/  1.261982, tr:  82.84%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.501058/  1.161721, tr:  84.88%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.484040/  1.252677, tr:  83.35%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.476912/  1.194342, tr:  84.78%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.410153/  1.263102, tr:  89.99%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.33it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.343902/  1.269973, tr:  91.32%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.338568/  1.287347, tr:  92.44%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.292507/  1.560769, tr:  94.89%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.274322/  1.384751, tr:  95.40%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.257612/  1.351449, tr:  93.87%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.189144/  1.462904, tr:  97.14%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.151383/  1.581411, tr:  99.28%, val:  76.25%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.120132/  1.632648, tr:  99.90%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.124583/  1.624829, tr:  98.77%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.116727/  1.665992, tr:  99.69%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.084779/  1.790613, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.072312/  1.823361, tr:  99.69%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  8.12it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.051771/  1.795992, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.044066/  1.874824, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.045366/  1.890506, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.038490/  1.923180, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.029304/  1.945288, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.023494/  1.976099, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.017997/  2.048245, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.013696/  2.069684, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011707/  2.068695, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.009846/  2.095092, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010775/  2.098786, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.010743/  2.114299, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008728/  2.126256, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007385/  2.144348, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007075/  2.146190, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006833/  2.131535, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006249/  2.159808, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006496/  2.174663, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006595/  2.173109, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006435/  2.183144, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005498/  2.190930, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005513/  2.193988, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005002/  2.202150, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004949/  2.199111, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004865/  2.206096, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004634/  2.203763, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004643/  2.206089, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004500/  2.203761, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004544/  2.200979, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004477/  2.200089, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004405/  2.202939, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004409/  2.202029, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004400/  2.201908, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004333/  2.202347, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e68ea9462c4480ebe9383266fda48ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▅▇▆▆▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▆▇▇▇▇█▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▆▇▇▇▇█▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00433</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.20235</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-sweep-73</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkcehg2t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jkcehg2t</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_184248-jkcehg2t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q18oet7c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.09231056995387946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_184900-q18oet7c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q18oet7c' target=\"_blank\">sunny-sweep-76</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q18oet7c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q18oet7c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.839046/  1.500846, tr:  37.18%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:07<00:00,  8.02it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.164687/  1.279268, tr:  62.61%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:08<00:00,  7.23it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.010509/  1.166432, tr:  65.27%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.924602/  1.134867, tr:  68.13%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:07<00:00,  8.47it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.872072/  1.205241, tr:  69.77%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:07<00:00,  8.61it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.833212/  1.284863, tr:  69.97%, val:  62.08%, val_best:  63.75%: 100%|██████████| 62/62 [00:08<00:00,  7.60it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.735723/  1.181900, tr:  74.36%, val:  62.92%, val_best:  63.75%: 100%|██████████| 62/62 [00:09<00:00,  6.24it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.694555/  1.293576, tr:  75.18%, val:  60.42%, val_best:  63.75%: 100%|██████████| 62/62 [00:07<00:00,  8.59it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.681555/  1.115613, tr:  76.61%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.516682/  1.277019, tr:  82.94%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.509668/  1.190459, tr:  84.27%, val:  67.50%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.481012/  1.268957, tr:  83.76%, val:  69.58%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.469599/  1.231001, tr:  84.37%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.413535/  1.317236, tr:  89.27%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.338638/  1.319537, tr:  91.32%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.328447/  1.322948, tr:  92.03%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.302765/  1.538264, tr:  93.36%, val:  73.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.275239/  1.426697, tr:  94.99%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.246199/  1.447436, tr:  94.79%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.199751/  1.545940, tr:  97.55%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.156929/  1.678328, tr:  99.28%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.119626/  1.750232, tr:  99.49%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.123943/  1.710286, tr:  98.37%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.102362/  1.731744, tr:  99.90%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.081110/  1.918739, tr: 100.00%, val:  77.08%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.074933/  1.896833, tr:  99.69%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.057812/  1.919157, tr:  99.90%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.041961/  1.961110, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.038254/  1.984164, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.041037/  2.017447, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.034677/  2.048615, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.026342/  2.089098, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.021463/  2.088445, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.014482/  2.120724, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.012918/  2.120128, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.012560/  2.185885, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009752/  2.215672, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009808/  2.225896, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008485/  2.220492, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.008400/  2.239726, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007262/  2.230087, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006784/  2.251152, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006588/  2.255967, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006501/  2.266054, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005822/  2.258478, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005731/  2.268365, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005581/  2.280062, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005246/  2.281950, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005440/  2.281626, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004882/  2.285883, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005220/  2.291039, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004894/  2.296163, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004791/  2.294672, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004764/  2.294755, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004833/  2.300055, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004787/  2.300160, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004754/  2.302578, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004627/  2.301806, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004617/  2.302333, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004729/  2.301545, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3279616f2942c2ad06a54f736208b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▅▇▆▇▇█▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▄▅▅▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00473</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>2.30154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-sweep-76</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q18oet7c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q18oet7c</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_184900-q18oet7c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ko60of9w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.013300884671759184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_185536-ko60of9w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ko60of9w' target=\"_blank\">grateful-sweep-79</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ko60of9w' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ko60of9w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.859133/  1.501480, tr:  36.98%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.183138/  1.322055, tr:  62.00%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.024600/  1.156014, tr:  65.07%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.921845/  1.140195, tr:  68.64%, val:  65.00%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.890911/  1.191365, tr:  69.66%, val:  63.75%, val_best:  66.67%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.844146/  1.335235, tr:  69.46%, val:  61.25%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.774798/  1.175431, tr:  72.11%, val:  64.17%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.712702/  1.303954, tr:  74.77%, val:  62.50%, val_best:  66.67%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.707922/  1.114222, tr:  76.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.549893/  1.305387, tr:  82.12%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.540478/  1.177747, tr:  83.15%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.517363/  1.270089, tr:  82.43%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.508861/  1.168630, tr:  84.98%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.454621/  1.289816, tr:  88.25%, val:  71.67%, val_best:  74.17%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.386300/  1.283006, tr:  89.89%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.365512/  1.317975, tr:  92.03%, val:  72.50%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.312529/  1.575914, tr:  93.46%, val:  71.25%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.291041/  1.471137, tr:  95.71%, val:  74.17%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.284337/  1.468820, tr:  94.99%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.232705/  1.581498, tr:  97.65%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.185172/  1.680512, tr:  98.77%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.138744/  1.726049, tr:  99.90%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.137476/  1.767696, tr:  98.98%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.136523/  1.799498, tr:  99.28%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.099740/  1.951231, tr:  99.80%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.083089/  1.917621, tr:  99.80%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.058957/  1.935856, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.050345/  2.036691, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.050264/  2.064843, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.039418/  2.106129, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.039187/  2.139157, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.031639/  2.178118, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.028013/  2.220468, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.018007/  2.226936, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.015565/  2.249317, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.015109/  2.276380, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.013352/  2.280511, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.010710/  2.293944, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.009905/  2.316301, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.009419/  2.317945, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008305/  2.357689, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.008095/  2.342953, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.007240/  2.353122, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006905/  2.358223, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006597/  2.376041, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006156/  2.380205, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005879/  2.393382, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.006215/  2.403912, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.006060/  2.408817, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005805/  2.407776, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005591/  2.413514, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005497/  2.410881, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005355/  2.412517, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.005245/  2.419988, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005344/  2.417236, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.005276/  2.422389, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.005190/  2.422839, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.005190/  2.422653, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.005026/  2.422637, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.005050/  2.422215, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd6f5c0c0e149f68940c2c6e7d90e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.956 MB of 4.956 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▅▅▇▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇▇█▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇▇█▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▄▄▅▅▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00505</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>2.42222</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-79</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ko60of9w' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ko60of9w</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_185536-ko60of9w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hn1e3oa5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.047803012105469646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_190157-hn1e3oa5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hn1e3oa5' target=\"_blank\">eager-sweep-82</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hn1e3oa5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hn1e3oa5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.851427/  1.503035, tr:  37.49%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.173578/  1.289582, tr:  62.82%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.019873/  1.158451, tr:  65.07%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.921115/  1.144270, tr:  68.54%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.886589/  1.224184, tr:  69.36%, val:  63.33%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.841923/  1.301208, tr:  69.77%, val:  62.50%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.751687/  1.166299, tr:  73.14%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.694015/  1.257786, tr:  75.59%, val:  62.92%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.690448/  1.133469, tr:  76.71%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.540303/  1.300771, tr:  82.02%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.524651/  1.170717, tr:  83.45%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.505883/  1.270534, tr:  83.04%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.489416/  1.207342, tr:  83.45%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.437634/  1.295958, tr:  89.27%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.365448/  1.330927, tr:  90.50%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.355583/  1.384540, tr:  92.85%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.316692/  1.552332, tr:  92.65%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.290178/  1.444835, tr:  94.59%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.273034/  1.418022, tr:  96.32%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.226036/  1.545303, tr:  97.45%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.169271/  1.635588, tr:  98.98%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.135220/  1.737827, tr:  99.90%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.140215/  1.700599, tr:  97.65%, val:  77.08%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.124630/  1.739216, tr:  99.69%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.096122/  1.941550, tr:  99.90%, val:  74.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.085236/  1.891223, tr:  99.69%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.059230/  1.898650, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.050680/  1.964283, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.042715/  2.013498, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.035053/  2.018469, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.033537/  2.059048, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.027137/  2.117353, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.027220/  2.153277, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017079/  2.168874, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.014662/  2.191884, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.012998/  2.212196, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.012262/  2.233033, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.011335/  2.258451, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.010514/  2.281214, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.009285/  2.271151, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008646/  2.276726, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007738/  2.284860, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006997/  2.295437, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006929/  2.305372, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006865/  2.318495, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006270/  2.319705, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.006281/  2.326423, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005755/  2.326505, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005644/  2.337411, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005348/  2.336215, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005531/  2.340052, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005449/  2.339915, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005313/  2.347742, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.005063/  2.348626, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005155/  2.351360, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.005112/  2.351019, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.005085/  2.349944, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.005223/  2.350519, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.005147/  2.350549, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.005056/  2.351581, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0fadb7557142cd9e00d9b08758a997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.127 MB of 5.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▆▅▆▄▅▆▆▆█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00506</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>2.35158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-82</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hn1e3oa5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hn1e3oa5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_190157-hn1e3oa5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9wqvzdu8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.1329140163282818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_190814-9wqvzdu8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9wqvzdu8' target=\"_blank\">sweet-sweep-85</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9wqvzdu8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9wqvzdu8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.828226/  1.487888, tr:  37.18%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.158788/  1.272266, tr:  62.41%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.004829/  1.142368, tr:  65.47%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.905864/  1.155570, tr:  68.34%, val:  63.33%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.869837/  1.213380, tr:  69.46%, val:  62.92%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.832751/  1.285828, tr:  69.25%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.720939/  1.163638, tr:  73.75%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.678958/  1.268742, tr:  75.79%, val:  60.83%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.660200/  1.103852, tr:  76.61%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.506896/  1.328293, tr:  82.64%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.502619/  1.175791, tr:  84.78%, val:  67.92%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.468218/  1.241524, tr:  83.45%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.480393/  1.219732, tr:  83.96%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.424548/  1.227893, tr:  88.46%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.347088/  1.307516, tr:  91.83%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.338317/  1.315540, tr:  93.26%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.284359/  1.487646, tr:  94.38%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.263631/  1.343661, tr:  95.30%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.252607/  1.344271, tr:  94.89%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.192349/  1.422749, tr:  96.63%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.153384/  1.523301, tr:  98.88%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.122463/  1.662877, tr:  99.80%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.131255/  1.619975, tr:  98.06%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.121490/  1.694783, tr:  99.28%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.099809/  1.823593, tr:  99.90%, val:  74.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.073846/  1.776095, tr:  99.90%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.048652/  1.806272, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.043800/  1.895646, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.051785/  1.898694, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.041682/  1.867442, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.028252/  1.904656, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.022271/  1.967958, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.021766/  1.984335, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.014785/  2.000345, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011213/  2.040165, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010958/  2.020216, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009246/  2.037858, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008152/  2.052503, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007939/  2.062643, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006737/  2.077765, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006671/  2.115855, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006152/  2.118960, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005992/  2.125478, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005712/  2.138442, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005555/  2.141188, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005341/  2.139549, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005104/  2.158113, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004888/  2.160832, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004914/  2.160864, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005028/  2.163020, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004643/  2.166168, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004698/  2.169217, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004479/  2.169856, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004372/  2.173241, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004423/  2.169368, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004400/  2.169846, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004379/  2.171044, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004330/  2.171508, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004326/  2.171592, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004514/  2.171605, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9066f6d008564a309f5bf84255d82abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.127 MB of 5.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▆▅▅▅▇▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00451</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.17161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-sweep-85</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9wqvzdu8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9wqvzdu8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_190814-9wqvzdu8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4k32x8vk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.24278541252168617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_191435-4k32x8vk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4k32x8vk' target=\"_blank\">grateful-sweep-88</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4k32x8vk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4k32x8vk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.798487/  1.467381, tr:  37.59%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.142851/  1.260225, tr:  63.43%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.988005/  1.130486, tr:  65.78%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00,  9.23it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.882656/  1.098523, tr:  70.28%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.833727/  1.179240, tr:  70.68%, val:  63.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.813620/  1.281406, tr:  69.46%, val:  61.25%, val_best:  65.83%: 100%|██████████| 62/62 [00:07<00:00,  8.61it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.698601/  1.184560, tr:  74.46%, val:  60.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.652825/  1.275391, tr:  76.40%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.641421/  1.116912, tr:  77.12%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.482090/  1.265836, tr:  82.64%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.480189/  1.287170, tr:  83.76%, val:  68.33%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.476826/  1.284944, tr:  83.76%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.467531/  1.181825, tr:  86.62%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.388995/  1.348491, tr:  90.40%, val:  70.83%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.324714/  1.257043, tr:  92.95%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.345618/  1.344981, tr:  90.70%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.260957/  1.487232, tr:  95.51%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.245380/  1.371941, tr:  94.79%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.226247/  1.401212, tr:  95.51%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.172895/  1.495915, tr:  98.67%, val:  77.08%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.129336/  1.606958, tr:  99.39%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.111260/  1.669490, tr:  99.49%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.120135/  1.664243, tr:  98.37%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.103713/  1.688332, tr:  99.39%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.069447/  1.795542, tr: 100.00%, val:  75.83%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.063393/  1.845449, tr:  99.90%, val:  75.42%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.047958/  1.809561, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.038291/  1.842482, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.032352/  1.882183, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.023291/  1.899075, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.020239/  1.953423, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.021650/  1.958402, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.038297/  1.999966, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.017686/  1.981804, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.012920/  2.004704, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.010491/  2.010106, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010572/  2.033750, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.010397/  2.037098, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007301/  2.050164, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.007954/  2.068790, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006711/  2.070384, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007448/  2.067944, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006020/  2.087278, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005950/  2.076732, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005801/  2.076660, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005484/  2.092488, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005391/  2.102188, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004962/  2.109661, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005201/  2.109935, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004912/  2.118808, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004960/  2.111112, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004740/  2.112005, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004609/  2.106606, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004560/  2.108124, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004539/  2.103287, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004514/  2.101353, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004363/  2.104796, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004370/  2.104770, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004277/  2.104519, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004489/  2.104333, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7e2e3e4eb042668b69ac92385aa869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.127 MB of 5.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▇▅▅▅▅▆▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇████▇██████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇████▇██████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00449</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.10433</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-88</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4k32x8vk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4k32x8vk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_191435-4k32x8vk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cyxon3ue with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3650794008016251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_192054-cyxon3ue</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cyxon3ue' target=\"_blank\">rural-sweep-91</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cyxon3ue' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cyxon3ue</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.757460/  1.425103, tr:  39.63%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.122175/  1.233967, tr:  63.64%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.962575/  1.097114, tr:  66.39%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.852787/  1.080303, tr:  69.66%, val:  65.00%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.811220/  1.116666, tr:  70.58%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.792222/  1.285919, tr:  70.07%, val:  60.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.687656/  1.184287, tr:  74.16%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.650070/  1.301079, tr:  76.30%, val:  59.17%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.628493/  1.130947, tr:  76.81%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.483942/  1.410275, tr:  83.04%, val:  63.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.475716/  1.206212, tr:  83.55%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.426375/  1.302194, tr:  83.86%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.424590/  1.223670, tr:  86.01%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.352833/  1.424239, tr:  91.52%, val:  66.67%, val_best:  72.08%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.322438/  1.312130, tr:  92.13%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.313091/  1.363220, tr:  92.34%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.254614/  1.517091, tr:  94.79%, val:  71.67%, val_best:  76.25%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.250139/  1.385581, tr:  95.10%, val:  71.67%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.260952/  1.293750, tr:  94.28%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.186133/  1.458589, tr:  98.26%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.154030/  1.539555, tr:  98.57%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.115406/  1.652204, tr:  99.28%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.131071/  1.551892, tr:  97.14%, val:  75.42%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.103159/  1.597708, tr:  99.69%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.071873/  1.730705, tr:  99.90%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.073488/  1.681142, tr:  99.90%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.053959/  1.717224, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.049759/  1.719831, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.038268/  1.753585, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.030693/  1.807389, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.031457/  1.755468, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.025669/  1.844684, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.037949/  1.875430, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.020398/  1.886389, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.018153/  1.883790, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.013799/  1.889294, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.012123/  1.930773, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.011184/  1.921000, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.009870/  1.939427, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.008487/  1.949327, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008278/  1.992239, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.008300/  1.975144, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.007054/  1.969350, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006226/  1.976022, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006432/  1.989100, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006406/  1.990626, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005797/  2.005718, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005269/  1.999339, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005323/  2.000491, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005023/  2.012688, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005122/  2.014855, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005120/  2.012793, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005028/  2.013192, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004883/  2.016818, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004974/  2.021282, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004702/  2.018982, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004598/  2.016959, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004663/  2.018819, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004641/  2.018634, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004844/  2.018586, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb7d569da484d0f9c8331eed96df650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.127 MB of 5.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▆▅▆▄▆▆▆▆█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▆▇▇▇▇▇██▇████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▆▇▇▇▇▇██▇████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00484</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.01859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rural-sweep-91</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cyxon3ue' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cyxon3ue</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_192054-cyxon3ue/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3tud7966 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.08015794034827435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "error: short read while indexing my_snn/result_save/iter_acc_array_main.npy\n",
      "error: my_snn/result_save/iter_acc_array_main.npy: failed to insert into database\n",
      "fatal: cannot hash my_snn/result_save/iter_acc_array_main.npy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_192717-3tud7966</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3tud7966' target=\"_blank\">efficient-sweep-94</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3tud7966' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3tud7966</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.841825/  1.497774, tr:  36.87%, val:  55.83%, val_best:  55.83%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.169187/  1.294862, tr:  62.41%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.015247/  1.159172, tr:  65.37%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.914231/  1.142169, tr:  68.64%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.871668/  1.205581, tr:  69.97%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.851818/  1.296133, tr:  68.54%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.734258/  1.144359, tr:  74.06%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.690759/  1.266091, tr:  74.77%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.688178/  1.094908, tr:  76.61%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.540878/  1.265865, tr:  82.23%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.509461/  1.149398, tr:  83.25%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.491129/  1.272952, tr:  83.15%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.491970/  1.165459, tr:  83.55%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.424969/  1.261958, tr:  89.38%, val:  70.83%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.367378/  1.334795, tr:  89.79%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.350544/  1.302734, tr:  92.34%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.302740/  1.520245, tr:  93.26%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.282954/  1.408276, tr:  95.51%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.262950/  1.402352, tr:  94.79%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.190550/  1.515794, tr:  97.96%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.161787/  1.656639, tr:  98.98%, val:  75.83%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.126491/  1.740544, tr:  99.90%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.123933/  1.698415, tr:  98.47%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.119166/  1.764290, tr:  99.69%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.088357/  1.844996, tr:  99.90%, val:  76.67%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.080580/  1.834129, tr:  99.49%, val:  76.25%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.056551/  1.893263, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.047833/  1.934900, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.038138/  2.005883, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.034774/  2.009151, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.032413/  2.025555, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.026829/  2.065755, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.022873/  2.104193, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.016036/  2.133036, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.014733/  2.131678, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.012541/  2.191050, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010961/  2.213301, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009633/  2.254683, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008847/  2.266147, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.008385/  2.286382, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008534/  2.265615, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.007641/  2.283553, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006843/  2.303468, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.006780/  2.302280, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006500/  2.326720, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006213/  2.324224, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005738/  2.320307, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.66it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005390/  2.332657, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005549/  2.333762, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005861/  2.331803, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005367/  2.343616, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.005395/  2.339365, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005118/  2.340990, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004905/  2.342803, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005001/  2.342148, tr: 100.00%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004997/  2.342216, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004948/  2.341901, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004897/  2.343540, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004845/  2.342870, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004909/  2.343252, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508897a9099f4b8c8666682b635142af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▅▆▅▅▅▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▄▄▅▅▄▅▆▅▆▆▆▆▆▇▇▇▇▇▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00491</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.34325</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-sweep-94</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3tud7966' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3tud7966</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_192717-3tud7966/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lt2xw18j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.3335045357825407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_193340-lt2xw18j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lt2xw18j' target=\"_blank\">pleasant-sweep-97</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lt2xw18j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lt2xw18j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.767970/  1.436320, tr:  38.82%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.127149/  1.244020, tr:  63.43%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.974518/  1.121076, tr:  66.70%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.876574/  1.104696, tr:  68.54%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.832416/  1.136820, tr:  69.25%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.803451/  1.289042, tr:  69.46%, val:  60.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.689780/  1.192419, tr:  75.08%, val:  62.50%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.650149/  1.271664, tr:  76.51%, val:  59.17%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.619691/  1.180605, tr:  77.73%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.474539/  1.337578, tr:  83.45%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.474487/  1.181750, tr:  84.07%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.437623/  1.332561, tr:  83.45%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.451204/  1.234290, tr:  84.27%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.365175/  1.338056, tr:  90.70%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.324162/  1.296147, tr:  91.32%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.323890/  1.408470, tr:  92.34%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.258582/  1.504285, tr:  95.71%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.244457/  1.472933, tr:  95.30%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.278181/  1.380940, tr:  93.16%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.190250/  1.437615, tr:  97.65%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.147375/  1.511637, tr:  98.37%, val:  75.42%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.109751/  1.612476, tr:  99.80%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.112585/  1.554400, tr:  98.67%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.111147/  1.584743, tr:  99.69%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.088304/  1.754102, tr: 100.00%, val:  74.58%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.066885/  1.678496, tr:  99.80%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.051000/  1.709611, tr:  99.90%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.039941/  1.769624, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.039740/  1.813430, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.032823/  1.861825, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.037217/  1.870288, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.023765/  1.838501, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.022333/  1.897700, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.015604/  1.890849, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.013545/  1.922796, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011943/  1.924434, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.009488/  1.946418, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.009365/  1.965278, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.008120/  1.977241, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.008001/  1.983524, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.007736/  1.974912, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.006744/  2.002993, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.006145/  2.008336, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005903/  2.032165, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006173/  2.026409, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.005369/  2.024845, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.005675/  2.029697, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:08<00:00,  7.09it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.005269/  2.054551, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004751/  2.040963, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004610/  2.036716, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004285/  2.038029, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004582/  2.031847, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:09<00:00,  6.59it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004439/  2.038130, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:16<00:00,  3.85it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.004259/  2.036860, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:15<00:00,  4.05it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.004221/  2.038134, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:15<00:00,  4.01it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004161/  2.039697, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:19<00:00,  3.23it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004128/  2.041747, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:10<00:00,  5.87it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004194/  2.040085, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004268/  2.041561, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004264/  2.041476, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb4abba53744c8a85af380c33bfdd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.127 MB of 5.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▆▅▆▅▅▇▆▆▇▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▆▆▅▅▆▆▆▆▆▆▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00426</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.04148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-97</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lt2xw18j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lt2xw18j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_193340-lt2xw18j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4e7a9zg1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.03761621890350564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_194055-4e7a9zg1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4e7a9zg1' target=\"_blank\">olive-sweep-100</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4e7a9zg1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4e7a9zg1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.853180/  1.504046, tr:  37.28%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:17<00:00,  3.63it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.179613/  1.296638, tr:  62.21%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:20<00:00,  3.05it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  1.021748/  1.159046, tr:  65.58%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:22<00:00,  2.73it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.926450/  1.134595, tr:  67.93%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:21<00:00,  2.91it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.884304/  1.201568, tr:  69.36%, val:  62.50%, val_best:  66.25%: 100%|██████████| 62/62 [00:19<00:00,  3.20it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.845395/  1.309841, tr:  69.66%, val:  60.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:24<00:00,  2.56it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.759910/  1.181631, tr:  73.03%, val:  63.33%, val_best:  66.25%: 100%|██████████| 62/62 [00:18<00:00,  3.32it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.715671/  1.291492, tr:  74.46%, val:  60.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:16<00:00,  3.68it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.707696/  1.112341, tr:  76.81%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:16<00:00,  3.77it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.538490/  1.301360, tr:  82.02%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:23<00:00,  2.65it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.522946/  1.189636, tr:  83.86%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:16<00:00,  3.76it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.510583/  1.312592, tr:  82.43%, val:  70.00%, val_best:  70.83%: 100%|██████████| 62/62 [00:08<00:00,  6.99it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.512250/  1.235473, tr:  83.04%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.440763/  1.292819, tr:  88.97%, val:  72.08%, val_best:  72.50%: 100%|██████████| 62/62 [00:07<00:00,  8.82it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.380163/  1.354838, tr:  90.09%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.362066/  1.341551, tr:  91.42%, val:  71.67%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.306757/  1.595852, tr:  93.36%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:08<00:00,  7.01it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.293318/  1.479889, tr:  94.79%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:18<00:00,  3.36it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.278918/  1.448807, tr:  94.28%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:19<00:00,  3.24it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.226807/  1.581501, tr:  96.32%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:20<00:00,  3.05it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.186299/  1.627955, tr:  98.67%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:20<00:00,  2.98it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.142613/  1.723365, tr:  99.80%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:19<00:00,  3.23it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.146689/  1.709975, tr:  97.96%, val:  76.67%, val_best:  79.58%: 100%|██████████| 62/62 [00:19<00:00,  3.15it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.117863/  1.819824, tr:  99.59%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:17<00:00,  3.50it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.094318/  1.932938, tr:  99.90%, val:  73.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:20<00:00,  3.00it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.082635/  1.923544, tr:  99.90%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:18<00:00,  3.39it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.061906/  1.961501, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:17<00:00,  3.60it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.053428/  1.998881, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:19<00:00,  3.17it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.043338/  2.040904, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:17<00:00,  3.55it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.041998/  2.060364, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:19<00:00,  3.19it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.036294/  2.123335, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:19<00:00,  3.20it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.029377/  2.147199, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:17<00:00,  3.63it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.030167/  2.173101, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:20<00:00,  3.04it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.018324/  2.201075, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:17<00:00,  3.45it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.016401/  2.235182, tr: 100.00%, val:  79.17%, val_best:  80.83%: 100%|██████████| 62/62 [00:18<00:00,  3.39it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.015168/  2.242664, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:20<00:00,  3.08it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.013359/  2.306250, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:22<00:00,  2.81it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.011982/  2.269875, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:23<00:00,  2.69it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.010937/  2.321492, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.11it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.009280/  2.321122, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:18<00:00,  3.41it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.008993/  2.333314, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.26it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.008467/  2.338935, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:15<00:00,  3.94it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.007736/  2.365122, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:16<00:00,  3.79it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.007506/  2.350739, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.006942/  2.356624, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:21<00:00,  2.92it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.006779/  2.357126, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.006449/  2.369725, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:17<00:00,  3.52it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.006355/  2.374475, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:22<00:00,  2.78it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.005784/  2.373629, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  2.99it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.005771/  2.378376, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:14<00:00,  4.38it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.005918/  2.377361, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.006159/  2.380696, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.005485/  2.383314, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.005372/  2.385666, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.005334/  2.389095, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:15<00:00,  4.04it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.004871/  2.387109, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.004920/  2.387721, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:16<00:00,  3.76it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.004800/  2.386907, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  2.95it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.004822/  2.387559, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:21<00:00,  2.84it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.004912/  2.386924, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:10<00:00,  6.15it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1faf1ed5d5043a8b6a7828fb5845cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.127 MB of 5.127 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▆▅▄▅▆▆▆▆█▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▅▄▄▅▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00491</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>2.38692</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-100</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4e7a9zg1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4e7a9zg1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_194055-4e7a9zg1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bo484su9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.27728798990060965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_195836-bo484su9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bo484su9' target=\"_blank\">sparkling-sweep-103</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bo484su9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bo484su9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.787374/  1.460400, tr:  38.41%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:08<00:00,  7.08it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.140672/  1.277239, tr:  63.13%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.989197/  1.145671, tr:  65.99%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.871675/  1.100580, tr:  68.95%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.825102/  1.176830, tr:  70.28%, val:  63.33%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.806635/  1.293360, tr:  69.66%, val:  62.50%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.696479/  1.144150, tr:  75.28%, val:  62.08%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.661242/  1.216962, tr:  76.20%, val:  63.33%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.618618/  1.094657, tr:  77.12%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.483333/  1.295714, tr:  82.74%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.480722/  1.288966, tr:  83.15%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.460576/  1.288188, tr:  84.58%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.456689/  1.205093, tr:  83.45%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.391321/  1.358506, tr:  90.19%, val:  70.00%, val_best:  74.17%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.317096/  1.307453, tr:  93.46%, val:  71.25%, val_best:  74.17%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.325853/  1.347348, tr:  92.03%, val:  72.08%, val_best:  74.17%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]                                    \n",
      "epoch-16  lr=['0.0078131'], tr/val_loss:  0.271092/  1.472440, tr:  94.08%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]                                    \n",
      "epoch-17  lr=['0.0076268'], tr/val_loss:  0.251552/  1.387365, tr:  94.99%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]                                    \n",
      "epoch-18  lr=['0.0074324'], tr/val_loss:  0.235421/  1.406573, tr:  95.81%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]                                    \n",
      "epoch-19  lr=['0.0072304'], tr/val_loss:  0.170692/  1.462786, tr:  98.26%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]                                    \n",
      "epoch-20  lr=['0.0070214'], tr/val_loss:  0.138363/  1.576640, tr:  99.28%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]                                    \n",
      "epoch-21  lr=['0.0068061'], tr/val_loss:  0.106337/  1.578979, tr:  99.69%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]                                    \n",
      "epoch-22  lr=['0.0065849'], tr/val_loss:  0.103429/  1.573913, tr:  98.98%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]                                    \n",
      "epoch-23  lr=['0.0063585'], tr/val_loss:  0.077926/  1.696637, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]                                    \n",
      "epoch-24  lr=['0.0061275'], tr/val_loss:  0.057796/  1.769619, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]                                    \n",
      "epoch-25  lr=['0.0058925'], tr/val_loss:  0.060284/  1.794458, tr:  99.90%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-26  lr=['0.0056542'], tr/val_loss:  0.041877/  1.769155, tr:  99.90%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]                                    \n",
      "epoch-27  lr=['0.0054132'], tr/val_loss:  0.036909/  1.829701, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]                                    \n",
      "epoch-28  lr=['0.0051703'], tr/val_loss:  0.031376/  1.839945, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]                                    \n",
      "epoch-29  lr=['0.0049259'], tr/val_loss:  0.027435/  1.887151, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]                                    \n",
      "epoch-30  lr=['0.0046810'], tr/val_loss:  0.025203/  1.881679, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]                                    \n",
      "epoch-31  lr=['0.0044360'], tr/val_loss:  0.018150/  1.965666, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]                                    \n",
      "epoch-32  lr=['0.0041917'], tr/val_loss:  0.018163/  1.956381, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]                                    \n",
      "epoch-33  lr=['0.0039487'], tr/val_loss:  0.012869/  1.930063, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]                                    \n",
      "epoch-34  lr=['0.0037077'], tr/val_loss:  0.011159/  1.971750, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]                                    \n",
      "epoch-35  lr=['0.0034694'], tr/val_loss:  0.011274/  2.005256, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]                                    \n",
      "epoch-36  lr=['0.0032345'], tr/val_loss:  0.010367/  2.014457, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]                                    \n",
      "epoch-37  lr=['0.0030035'], tr/val_loss:  0.008465/  1.982151, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.06it/s]                                    \n",
      "epoch-38  lr=['0.0027770'], tr/val_loss:  0.007484/  2.008953, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:07<00:00,  8.61it/s]                                    \n",
      "epoch-39  lr=['0.0025558'], tr/val_loss:  0.006815/  2.005609, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]                                    \n",
      "epoch-40  lr=['0.0023405'], tr/val_loss:  0.006426/  2.017740, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]                                    \n",
      "epoch-41  lr=['0.0021315'], tr/val_loss:  0.005368/  2.016919, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]                                    \n",
      "epoch-42  lr=['0.0019296'], tr/val_loss:  0.005030/  2.019254, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]                                    \n",
      "epoch-43  lr=['0.0017351'], tr/val_loss:  0.005365/  2.028218, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]                                    \n",
      "epoch-44  lr=['0.0015488'], tr/val_loss:  0.005306/  2.041295, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]                                    \n",
      "epoch-45  lr=['0.0013710'], tr/val_loss:  0.004986/  2.049562, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]                                    \n",
      "epoch-46  lr=['0.0012023'], tr/val_loss:  0.004529/  2.053017, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]                                    \n",
      "epoch-47  lr=['0.0010432'], tr/val_loss:  0.004894/  2.061277, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]                                    \n",
      "epoch-48  lr=['0.0008940'], tr/val_loss:  0.004605/  2.056876, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]                                    \n",
      "epoch-49  lr=['0.0007552'], tr/val_loss:  0.004422/  2.053249, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]                                    \n",
      "epoch-50  lr=['0.0006271'], tr/val_loss:  0.004282/  2.066560, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]                                    \n",
      "epoch-51  lr=['0.0005102'], tr/val_loss:  0.004345/  2.066234, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]                                    \n",
      "epoch-52  lr=['0.0004047'], tr/val_loss:  0.004264/  2.065615, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]                                    \n",
      "epoch-53  lr=['0.0003109'], tr/val_loss:  0.003965/  2.062669, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]                                    \n",
      "epoch-54  lr=['0.0002291'], tr/val_loss:  0.003866/  2.062510, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]                                    \n",
      "epoch-55  lr=['0.0001595'], tr/val_loss:  0.003830/  2.061947, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]                                    \n",
      "epoch-56  lr=['0.0001023'], tr/val_loss:  0.003789/  2.063650, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]                                    \n",
      "epoch-57  lr=['0.0000576'], tr/val_loss:  0.003731/  2.063964, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]                                    \n",
      "epoch-58  lr=['0.0000256'], tr/val_loss:  0.003714/  2.064056, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]                                    \n",
      "epoch-59  lr=['0.0000064'], tr/val_loss:  0.003762/  2.063857, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0139a9e3d2b40f6a721c511af9efcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.951 MB of 4.951 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▇▅▇▇▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00376</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>2.06386</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-103</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bo484su9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bo484su9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240821_195836-bo484su9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cns014qd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.17973830328506302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00936191669529645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240821_200514-cns014qd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cns014qd' target=\"_blank\">misty-sweep-104</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/gqhgeaun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cns014qd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cns014qd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0093619'], tr/val_loss:  1.816309/  1.477925, tr:  37.49%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]                                    \n",
      "epoch-1   lr=['0.0093555'], tr/val_loss:  1.148240/  1.277780, tr:  63.13%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]                                    \n",
      "epoch-2   lr=['0.0093363'], tr/val_loss:  0.994783/  1.138686, tr:  65.68%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]                                    \n",
      "epoch-3   lr=['0.0093043'], tr/val_loss:  0.889085/  1.142511, tr:  69.97%, val:  63.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]                                    \n",
      "epoch-4   lr=['0.0092596'], tr/val_loss:  0.850708/  1.189270, tr:  70.17%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]                                    \n",
      "epoch-5   lr=['0.0092024'], tr/val_loss:  0.834511/  1.254533, tr:  68.74%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]                                    \n",
      "epoch-6   lr=['0.0091328'], tr/val_loss:  0.708741/  1.168929, tr:  74.06%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]                                    \n",
      "epoch-7   lr=['0.0090510'], tr/val_loss:  0.676385/  1.233935, tr:  75.28%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]                                    \n",
      "epoch-8   lr=['0.0089572'], tr/val_loss:  0.653709/  1.073628, tr:  76.92%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]                                    \n",
      "epoch-9   lr=['0.0088517'], tr/val_loss:  0.502791/  1.285293, tr:  81.82%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]                                    \n",
      "epoch-10  lr=['0.0087348'], tr/val_loss:  0.500296/  1.181495, tr:  83.96%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]                                    \n",
      "epoch-11  lr=['0.0086067'], tr/val_loss:  0.463256/  1.293086, tr:  83.35%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]                                    \n",
      "epoch-12  lr=['0.0084679'], tr/val_loss:  0.479207/  1.233538, tr:  84.98%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]                                    \n",
      "epoch-13  lr=['0.0083187'], tr/val_loss:  0.403193/  1.284075, tr:  88.76%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-14  lr=['0.0081596'], tr/val_loss:  0.328130/  1.267651, tr:  92.95%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]                                    \n",
      "epoch-15  lr=['0.0079909'], tr/val_loss:  0.335400/  1.299201, tr:  92.24%, val:  74.17%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]                                    \n",
      "epoch-16  iter_acc:  93.75%, lr=['0.0078131'], iter/last_val_loss:  0.284947/  1.299201, last tr:  92.24%, last val:  74.17%, val_best:  75.42%:  79%|███████▉  | 49/62 [00:03<00:00, 15.22it/s]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"values\": [0.01]}, #0.00936191669529645\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"decay\": {\"values\": [0.25]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"epoch_num\": {\"values\": [60]},\n",
    "        \"dvs_duration\": {\"values\": [100_000]},\n",
    "        \"dvs_clipping\": {\"values\": [2]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "        \"const2\": {\"values\": [False]},\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "        \"e_transport_swap\": {\"values\": [0]},\n",
    "        \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "        \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000,0]},\n",
    "        \"lif_layer_sg_width\": {\"min\": 0.5, \"max\": 8.0},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    which_data  =  wandb.config.which_data\n",
    "    OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "    const2  =  wandb.config.const2\n",
    "    surrogate  =  wandb.config.surrogate\n",
    "    DFA_on  =  wandb.config.DFA_on\n",
    "    OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "    cfg  =  wandb.config.cfg\n",
    "    e_transport_swap  =  wandb.config.e_transport_swap\n",
    "    e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "    drop_rate  =  wandb.config.drop_rate\n",
    "    exclude_class  =  wandb.config.exclude_class\n",
    "    merge_polarities  =  wandb.config.merge_polarities\n",
    "    lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "    lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "    if const2 == True:\n",
    "        const2 = decay\n",
    "    else:\n",
    "        const2 = 0.0\n",
    "\n",
    "    my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = which_data,\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = cfg,\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    \n",
    "                drop_rate = drop_rate,\n",
    "\n",
    "                exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = 'gqhgeaun'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
