{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch} running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch %5 ==0 or epoch == 1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 5\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 16\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 8 # SAE일 때만 유효\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6xax2jii\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pzmj0v2i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 2400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.25\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_235128-pzmj0v2i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/pzmj0v2i' target=\"_blank\">faithful-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/pzmj0v2i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/pzmj0v2i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 0, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 8, 'v_decay': 0.25, 'v_threshold': 0.25, 'v_reset': 10000, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250102_235134_787', 'optimizer': 'SGD'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_235134_787\n",
      "\n",
      "epoch-0 loss : 0.43198\n",
      "ae train 실행 시간: 48.369초\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95062837 0.88502674 0.84958217 0.76350093 0.93069307 0.78035714\n",
      " 0.69930762 0.58259325 0.63580875 0.64599237 0.56996269 0.34911243\n",
      " 0.87759336 0.80037665 0.60673077 0.6010979 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.51%, post_traincycle_acc : 72.05%, total_acc : 72.37%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 72.05%\n",
      "accuracy_check 실행 시간: 15.092초\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2,4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  0\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_174013_409'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
