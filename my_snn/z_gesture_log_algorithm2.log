2025-11-18 14:31:12 wandb: WARNING Config item 'single_step' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'my_seed' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'TIME' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'which_data' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'data_path' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'rate_coding' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'pre_trained' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'cfg' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'net_print' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'pre_trained_path' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'learning_rate' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'epoch_num' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'tdBN_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'BN_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'surrogate' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'BPTT_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'optimizer_what' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'scheduler_name' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'ddp_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'dvs_clipping' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'dvs_duration' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'DFA_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'trace_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'exclude_class' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'merge_polarities' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'denoise_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'num_workers' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'chaching_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'pin_memory' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'UDA_on' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'alpha_uda' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'bias' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'last_lif' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'temporal_filter' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'initial_pooling' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 wandb: WARNING Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).

2025-11-18 14:31:12 param {'devices': '4', 'single_step': True, 'unique_name': '20251118_233110_176', 'my_seed': 42, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]}

2025-11-18 14:31:16 이 데이터셋의 데이터 개수는 979 입니다. (test set은 안바뀌게 해놨다 알제)

2025-11-18 14:31:16 이 데이터셋의 데이터 개수는 240 입니다. (test set은 안바뀌게 해놨다 알제)

2025-11-18 14:31:16 dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037

2025-11-18 14:31:16 cache path exists

2025-11-18 14:31:16 len(train_loader): 979 BATCH: 1 train_data_count: 979

2025-11-18 14:31:16 len(test_loader): 240 BATCH: 1

2025-11-18 14:31:16 device ==> cuda

2025-11-18 14:31:16  layer_count 1

2025-11-18 14:31:16 weight bias bit 0

2025-11-18 14:31:16 weight exp, bias exp None None

2025-11-18 14:31:16 bit_for_output 0 exp_for_output None

2025-11-18 14:31:16 LIF 1 sg_bit 0

2025-11-18 14:31:16 ++++++++++++++++++++++++

2025-11-18 14:31:16  lif layer 1 v_bit: 0, v_exp: None

2025-11-18 14:31:16 ++++++++++++++++++++++++++++++++++++++++++++++

2025-11-18 14:31:16  layer_count 2

2025-11-18 14:31:16 weight bias bit 0

2025-11-18 14:31:16 weight exp, bias exp None None

2025-11-18 14:31:16 bit_for_output 0 exp_for_output None

2025-11-18 14:31:16 LIF 2 sg_bit 0

2025-11-18 14:31:16 ++++++++++++++++++++++++

2025-11-18 14:31:16  lif layer 2 v_bit: 0, v_exp: None

2025-11-18 14:31:16 ++++++++++++++++++++++++++++++++++++++++++++++

2025-11-18 14:31:16  layer_count 3

2025-11-18 14:31:16 weight bias bit 0

2025-11-18 14:31:16 weight exp, bias exp None None

2025-11-18 14:31:16 bit_for_output 0 exp_for_output None

2025-11-18 14:31:20 DataParallel(

2025-11-18 14:31:20   (module): REBORN_MY_SNN_FC(

2025-11-18 14:31:20     (layers): REBORN_MY_Sequential(

2025-11-18 14:31:20       (0): DimChanger_for_FC()

2025-11-18 14:31:20       (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)

2025-11-18 14:31:20       (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)

2025-11-18 14:31:20       (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)

2025-11-18 14:31:20       (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)

2025-11-18 14:31:20       (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)

2025-11-18 14:31:20       (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)

2025-11-18 14:31:20       (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)

2025-11-18 14:31:20       (DFA_top): Top_Gradient(single_step=True)

2025-11-18 14:31:20     )

2025-11-18 14:31:20   )

2025-11-18 14:31:20 )

2025-11-18 14:31:20 ========================================================

2025-11-18 14:31:20 Trainable parameters: 238,000

2025-11-18 14:31:20 ========================================================

2025-11-18 14:31:20 MySGD (

2025-11-18 14:31:20 Parameter Group 0

2025-11-18 14:31:20     lr: 0.00390625

2025-11-18 14:31:20     momentum: 0.0

2025-11-18 14:31:20 )

2025-11-18 14:31:20 total_backward_count 0 real_backward_count 0   0.000%

2025-11-18 14:31:22 inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])

2025-11-18 14:31:22 self.weight_fb[0] tensor([ 1.8934e-02,  2.1093e-01, -1.6790e-02,  8.2860e-02, -1.8780e-01,

2025-11-18 14:31:22          6.3725e-02, -6.3379e-02, -7.9782e-02,  5.1524e-02, -1.2446e-01,

2025-11-18 14:31:22         -1.6221e-01, -2.9600e-02, -9.0339e-03,  1.9444e-02, -1.0934e-01,

2025-11-18 14:31:22          1.8129e-01, -6.9730e-02,  6.7152e-02,  7.7763e-02, -3.2597e-03,

2025-11-18 14:31:22          1.4558e-01, -5.0406e-02, -2.4797e-02,  1.4391e-01, -3.1818e-02,

2025-11-18 14:31:22         -1.1320e-01,  2.2984e-01, -6.7576e-02,  1.7931e-02, -1.1550e-01,

2025-11-18 14:31:22         -1.7594e-01, -1.5427e-01,  8.1846e-02,  1.3850e-01,  6.3135e-02,

2025-11-18 14:31:22          4.1502e-02, -1.5509e-01,  6.0735e-02,  1.6491e-01, -6.4878e-02,

2025-11-18 14:31:22          9.1983e-02,  7.6438e-03,  8.2616e-03, -1.3744e-02,  3.2357e-02,

2025-11-18 14:31:22         -5.7478e-02, -1.0464e-01,  9.3097e-03, -3.2663e-02, -5.1313e-02,

2025-11-18 14:31:22         -8.5647e-02,  3.8434e-02,  1.6001e-02, -1.9292e-02,  9.8606e-02,

2025-11-18 14:31:22         -1.3158e-01, -3.4134e-02, -6.2874e-02,  4.3602e-02, -5.2417e-02,

2025-11-18 14:31:22          1.2124e-01, -7.9496e-02,  2.4412e-02, -4.1696e-02,  1.0778e-01,

2025-11-18 14:31:22         -1.0762e-01,  5.4097e-02, -1.2537e-01, -3.7238e-02,  5.0156e-02,

2025-11-18 14:31:22          9.7776e-03,  2.5239e-02,  3.5296e-02,  2.2238e-01,  2.2782e-03,

2025-11-18 14:31:22          1.5446e-01, -1.1312e-01,  9.2554e-02, -4.4633e-02,  7.4222e-02,

2025-11-18 14:31:22         -5.6474e-02, -6.8803e-02, -7.0595e-02, -4.9484e-02, -4.2925e-02,

2025-11-18 14:31:22         -4.0809e-02,  1.6994e-02,  4.3201e-02,  4.9468e-02, -1.1875e-01,

2025-11-18 14:31:22         -2.6532e-02,  2.6988e-02, -1.4051e-01, -6.3074e-02,  7.3065e-03,

2025-11-18 14:31:22          1.8921e-02,  5.8165e-02,  2.2661e-02,  1.1140e-01, -6.6528e-02,

2025-11-18 14:31:22         -1.6133e-01,  5.8902e-04,  1.3482e-01,  1.2398e-01,  2.2678e-03,

2025-11-18 14:31:22         -1.2688e-01, -7.3284e-02,  3.6657e-02, -5.3425e-02, -3.8686e-03,

2025-11-18 14:31:22         -7.5912e-02, -2.4416e-01,  6.8315e-02, -9.1515e-03, -2.1105e-02,

2025-11-18 14:31:22          4.3759e-02, -3.0760e-02,  2.1116e-03,  6.1028e-02,  2.4064e-02,

2025-11-18 14:31:22          7.3052e-02, -1.1411e-02, -9.9703e-03, -4.8900e-02, -4.9272e-02,

2025-11-18 14:31:22         -1.1781e-01, -2.3789e-02, -6.6208e-02,  1.9253e-02,  9.5465e-02,

2025-11-18 14:31:22         -2.7977e-03,  1.6420e-01,  1.0646e-01, -9.6819e-02, -6.5508e-02,

2025-11-18 14:31:22          1.6782e-01,  2.4013e-01, -6.0490e-02,  1.2407e-01, -2.7312e-02,

2025-11-18 14:31:22          4.2546e-02,  4.1576e-02,  1.0389e-01, -1.9791e-01, -6.1734e-02,

2025-11-18 14:31:22          2.0598e-01, -9.2463e-03,  2.3019e-02, -7.1248e-02, -1.6451e-01,

2025-11-18 14:31:22          8.8945e-02,  7.6954e-02, -6.1358e-02,  2.1075e-01,  1.1362e-01,

2025-11-18 14:31:22         -4.1540e-02,  2.3355e-02, -1.2469e-01, -1.1774e-02, -5.9197e-02,

2025-11-18 14:31:22         -7.8824e-02,  2.0957e-04, -1.8973e-02,  7.3129e-02,  7.9223e-02,

2025-11-18 14:31:22          8.0468e-02, -5.9513e-02,  1.2675e-01, -1.0473e-01, -2.2743e-03,

2025-11-18 14:31:22         -3.5689e-02, -4.7485e-02,  1.4612e-02, -1.4731e-01,  3.0283e-02,

2025-11-18 14:31:22         -4.3783e-02, -1.0702e-01, -1.2393e-01, -1.5395e-01, -1.5502e-01,

2025-11-18 14:31:22         -6.4030e-02,  7.4169e-02, -5.9266e-02,  2.9501e-02, -1.3114e-01,

2025-11-18 14:31:22         -3.1084e-02,  5.7895e-02,  5.5842e-02, -7.3755e-02, -1.2356e-02,

2025-11-18 14:31:22         -4.2171e-02, -1.3607e-01,  3.7821e-02, -2.0038e-02,  5.8521e-02,

2025-11-18 14:31:22         -9.7889e-02, -3.6203e-04, -7.8263e-02,  3.8445e-02,  2.4739e-01],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[1] tensor([ 0.0243,  0.0875,  0.0762,  0.0893, -0.0358,  0.0084, -0.0823,  0.0415,

2025-11-18 14:31:22          0.1093,  0.0390, -0.0084,  0.0824, -0.0388, -0.0084,  0.1905, -0.0412,

2025-11-18 14:31:22          0.0535,  0.0146, -0.1927, -0.0034, -0.1234, -0.0248,  0.0023,  0.1960,

2025-11-18 14:31:22          0.0956,  0.1355, -0.0962, -0.0471, -0.0019, -0.1697,  0.0164,  0.0255,

2025-11-18 14:31:22         -0.0218, -0.0832,  0.0267,  0.0968,  0.1448,  0.0340,  0.0123, -0.0644,

2025-11-18 14:31:22         -0.1539, -0.0648,  0.1434,  0.0292, -0.0543,  0.0045, -0.1050, -0.0141,

2025-11-18 14:31:22         -0.0106, -0.0727, -0.0340,  0.0092,  0.0063, -0.0900,  0.0770, -0.1758,

2025-11-18 14:31:22         -0.1888,  0.1074,  0.0024,  0.0566,  0.0525,  0.0500, -0.1397,  0.2322,

2025-11-18 14:31:22         -0.1507, -0.0170, -0.0022,  0.0212,  0.0636,  0.1522,  0.0262,  0.0489,

2025-11-18 14:31:22         -0.0238, -0.0843,  0.0417, -0.0206, -0.1503, -0.0105, -0.0025, -0.0157,

2025-11-18 14:31:22          0.0537,  0.2482, -0.0157, -0.0847,  0.1378,  0.0673,  0.0827,  0.0278,

2025-11-18 14:31:22          0.0017,  0.0711,  0.1171, -0.0113, -0.1379, -0.0627,  0.0863,  0.0732,

2025-11-18 14:31:22          0.0663, -0.0518, -0.1748, -0.0279,  0.0079, -0.1269,  0.1308, -0.1293,

2025-11-18 14:31:22          0.0255,  0.0589, -0.1456, -0.1754,  0.1100,  0.1369, -0.0427, -0.0364,

2025-11-18 14:31:22         -0.1153, -0.2599, -0.0316,  0.0100,  0.1226, -0.1337,  0.0349,  0.1675,

2025-11-18 14:31:22         -0.2253,  0.1285, -0.1121, -0.1268, -0.0064,  0.1009, -0.2251, -0.0125,

2025-11-18 14:31:22          0.0833, -0.0059, -0.0931, -0.1747, -0.0026,  0.0089, -0.1154, -0.1073,

2025-11-18 14:31:22          0.2383,  0.0302, -0.1482, -0.0759,  0.0708,  0.0868,  0.1001,  0.0796,

2025-11-18 14:31:22          0.2262, -0.0222,  0.2962,  0.0536,  0.0022, -0.0399, -0.0256,  0.0852,

2025-11-18 14:31:22         -0.1183, -0.1185, -0.0293, -0.0370,  0.0309, -0.0984,  0.1941,  0.0216,

2025-11-18 14:31:22         -0.0090,  0.1404,  0.0598,  0.0650,  0.0744,  0.0426, -0.0094, -0.0445,

2025-11-18 14:31:22         -0.1149,  0.0229,  0.1572,  0.1014,  0.1170, -0.1135,  0.0229,  0.1222,

2025-11-18 14:31:22         -0.0146, -0.0612,  0.1128, -0.2361,  0.0667, -0.0671, -0.0090, -0.0696,

2025-11-18 14:31:22         -0.1264,  0.1187, -0.0047, -0.0778,  0.0414, -0.0189, -0.0153, -0.0139,

2025-11-18 14:31:22         -0.0278, -0.1414, -0.0518, -0.0080, -0.1608, -0.0265,  0.1849, -0.0543],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[2] tensor([-4.4951e-02, -3.0269e-02,  5.7666e-03,  5.0608e-02,  7.1861e-03,

2025-11-18 14:31:22          1.3723e-01, -4.7515e-02,  2.8713e-02,  1.1686e-01, -2.1819e-02,

2025-11-18 14:31:22          8.4215e-02,  3.5925e-02,  1.6644e-01, -8.9751e-02,  5.2478e-02,

2025-11-18 14:31:22          1.1553e-01,  1.6151e-01, -2.2964e-02, -1.6174e-01,  1.9235e-01,

2025-11-18 14:31:22          9.7453e-02,  7.7079e-02, -8.9056e-02,  8.0481e-02,  1.4806e-01,

2025-11-18 14:31:22         -1.6083e-02,  1.0203e-01, -3.7285e-02,  6.1060e-02,  9.6561e-03,

2025-11-18 14:31:22         -6.8472e-02,  1.0096e-02, -1.4065e-01,  2.3837e-01,  1.1363e-01,

2025-11-18 14:31:22          2.4803e-02, -3.5905e-02,  8.2499e-02,  4.0047e-02,  4.7051e-02,

2025-11-18 14:31:22         -1.8222e-01,  9.4498e-02, -9.1961e-02,  1.1252e-01,  7.8541e-02,

2025-11-18 14:31:22          1.0352e-01,  5.1129e-02, -1.3695e-02,  1.3555e-01,  3.0085e-02,

2025-11-18 14:31:22          4.2894e-02, -3.0123e-03, -1.0391e-01,  6.3762e-03,  2.7413e-02,

2025-11-18 14:31:22          2.0599e-01, -1.3469e-01, -4.1689e-02,  8.9827e-02, -1.3860e-01,

2025-11-18 14:31:22          5.3680e-02, -9.2493e-02,  2.8438e-02, -9.8101e-02, -2.9716e-02,

2025-11-18 14:31:22          1.5025e-02, -8.1340e-03,  8.0789e-03,  1.5008e-01,  1.7955e-02,

2025-11-18 14:31:22         -9.7189e-02,  4.2880e-02,  3.5098e-02, -7.5292e-02,  1.0018e-02,

2025-11-18 14:31:22         -3.8158e-02,  2.1247e-02,  8.8000e-02,  5.3422e-02,  8.5364e-02,

2025-11-18 14:31:22         -3.1726e-02, -4.0565e-02,  5.0597e-02, -5.4060e-02, -1.9612e-03,

2025-11-18 14:31:22          2.9600e-01,  9.2132e-02,  2.9507e-02, -9.2795e-02, -1.0727e-01,

2025-11-18 14:31:22         -9.4369e-04,  1.6943e-01, -1.1252e-01,  2.0963e-03, -4.7562e-02,

2025-11-18 14:31:22         -8.9568e-02, -1.6470e-01, -1.3752e-02, -4.9301e-03,  1.9867e-02,

2025-11-18 14:31:22          2.8623e-02, -1.4914e-01, -7.4637e-02,  4.3263e-02, -5.4997e-02,

2025-11-18 14:31:22         -5.1978e-02, -9.9176e-02, -1.9955e-02,  5.1099e-02,  1.8961e-02,

2025-11-18 14:31:22          3.6069e-02, -8.3924e-02,  1.0509e-01, -1.2345e-01, -6.2687e-02,

2025-11-18 14:31:22         -6.5892e-02,  7.2257e-02,  7.6160e-02, -1.0679e-02,  1.1915e-01,

2025-11-18 14:31:22         -1.1745e-01, -4.7364e-02,  8.2369e-03, -2.0607e-02, -8.7966e-03,

2025-11-18 14:31:22         -1.3239e-01, -1.0953e-02, -3.8245e-02,  1.7113e-01, -9.6756e-02,

2025-11-18 14:31:22         -2.3135e-01,  1.7700e-01, -9.4699e-02,  8.4271e-02,  1.7756e-01,

2025-11-18 14:31:22         -7.7262e-03,  2.4065e-01,  1.2335e-01,  5.0242e-02,  1.1121e-02,

2025-11-18 14:31:22         -1.3971e-01, -2.5510e-02,  1.1339e-02,  5.6864e-02, -2.9294e-02,

2025-11-18 14:31:22         -1.0927e-01,  9.0566e-02, -1.4698e-01,  1.0142e-01, -2.0078e-01,

2025-11-18 14:31:22         -2.5668e-02, -8.1559e-02, -2.6427e-02,  2.6780e-01,  4.4975e-02,

2025-11-18 14:31:22          1.1964e-01,  6.6056e-03,  8.9370e-02,  7.3522e-02, -5.8117e-02,

2025-11-18 14:31:22         -6.1687e-02, -3.5208e-02,  1.4783e-01, -1.6733e-02,  1.8550e-01,

2025-11-18 14:31:22         -5.9637e-02,  1.0120e-01,  3.3498e-02, -1.4412e-02,  1.4279e-01,

2025-11-18 14:31:22         -1.7611e-01,  2.3674e-02, -2.6663e-02,  2.8803e-02, -1.0240e-01,

2025-11-18 14:31:22         -8.6560e-02, -1.3708e-02,  2.1908e-01,  1.7359e-01,  1.6947e-02,

2025-11-18 14:31:22          1.3747e-01, -1.0779e-02, -5.6662e-02,  2.1867e-02,  9.4120e-02,

2025-11-18 14:31:22         -1.4148e-04,  1.3205e-01, -7.6242e-03, -6.1247e-02, -1.5935e-01,

2025-11-18 14:31:22          1.1932e-01, -1.7626e-01,  4.7519e-02, -6.7935e-02, -3.5344e-02,

2025-11-18 14:31:22         -5.6960e-02, -1.6597e-01,  3.6102e-02,  7.2538e-02, -1.1702e-02],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[3] tensor([-0.0897,  0.1346,  0.0082,  0.0404, -0.0141, -0.0915,  0.1112,  0.0613,

2025-11-18 14:31:22          0.0437,  0.2269, -0.0635,  0.0330, -0.0388,  0.0970,  0.1340, -0.0103,

2025-11-18 14:31:22         -0.0180, -0.2479, -0.1925, -0.0520, -0.0167,  0.2512,  0.2248,  0.0406,

2025-11-18 14:31:22         -0.0638, -0.1051,  0.0551,  0.1565, -0.0160, -0.0229,  0.0975,  0.0753,

2025-11-18 14:31:22         -0.0261,  0.0484,  0.0233,  0.1358, -0.0195,  0.1246, -0.1235, -0.0948,

2025-11-18 14:31:22          0.1241,  0.0367, -0.0132,  0.0701, -0.0866,  0.0677,  0.0747, -0.0005,

2025-11-18 14:31:22          0.0291, -0.0934,  0.0961,  0.0369,  0.1113, -0.0287,  0.0090,  0.2001,

2025-11-18 14:31:22         -0.0262,  0.0943, -0.1185, -0.1080, -0.1874, -0.2298, -0.0099,  0.1366,

2025-11-18 14:31:22         -0.0031, -0.2031,  0.0642, -0.0495, -0.0109,  0.0107, -0.0874, -0.0920,

2025-11-18 14:31:22         -0.0740, -0.0029, -0.0110, -0.0867,  0.0235, -0.0947,  0.0334,  0.0025,

2025-11-18 14:31:22         -0.1047, -0.1597,  0.0005, -0.1529,  0.0354,  0.1324, -0.1721, -0.0826,

2025-11-18 14:31:22          0.1246,  0.1224,  0.1146,  0.0836,  0.0127,  0.1906,  0.0699, -0.0207,

2025-11-18 14:31:22          0.0435, -0.0039, -0.1358, -0.0330, -0.1266,  0.1363,  0.0505, -0.1182,

2025-11-18 14:31:22         -0.0723, -0.1437,  0.1342,  0.0754, -0.0922,  0.1479, -0.1418, -0.0035,

2025-11-18 14:31:22          0.0841,  0.0382,  0.1203, -0.1159,  0.0937,  0.0410, -0.0786,  0.0332,

2025-11-18 14:31:22          0.0585,  0.0918,  0.0264,  0.0213, -0.0575,  0.1411, -0.0949,  0.0688,

2025-11-18 14:31:22          0.0401,  0.0027, -0.0604,  0.0814, -0.0098, -0.1172,  0.0241, -0.0613,

2025-11-18 14:31:22         -0.0740, -0.0775,  0.0796, -0.1757,  0.0731,  0.0651,  0.0684, -0.1016,

2025-11-18 14:31:22          0.2258,  0.0089,  0.0729, -0.1231,  0.0348,  0.0380, -0.1748, -0.0902,

2025-11-18 14:31:22          0.2137,  0.0032, -0.1064, -0.0598,  0.1530,  0.0615,  0.0364,  0.0570,

2025-11-18 14:31:22         -0.0708, -0.0792, -0.1045,  0.0952, -0.0262, -0.0666,  0.0778, -0.0828,

2025-11-18 14:31:22          0.0837,  0.0487,  0.0133,  0.0663,  0.0131,  0.1229,  0.1182,  0.0589,

2025-11-18 14:31:22         -0.0275, -0.0269, -0.0815, -0.1605,  0.0128, -0.0175,  0.0951, -0.1965,

2025-11-18 14:31:22         -0.1307, -0.0327,  0.2386, -0.0120, -0.0878,  0.2075,  0.1736,  0.1385,

2025-11-18 14:31:22         -0.0182, -0.1107, -0.2712,  0.1544,  0.2334, -0.0716, -0.0042, -0.0741],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[4] tensor([-0.1114, -0.1260, -0.1119, -0.1797, -0.0123, -0.1354, -0.0627,  0.0113,

2025-11-18 14:31:22         -0.2121, -0.0449, -0.1316,  0.0974, -0.0196, -0.2268, -0.0866,  0.0271,

2025-11-18 14:31:22         -0.0689,  0.0083, -0.1552,  0.1024,  0.0478, -0.0129, -0.0338,  0.0313,

2025-11-18 14:31:22         -0.0618,  0.0572, -0.0461,  0.0063,  0.1558, -0.0055, -0.2186,  0.1069,

2025-11-18 14:31:22         -0.0180,  0.0722, -0.0741, -0.0951,  0.1404, -0.0053,  0.0869,  0.1728,

2025-11-18 14:31:22          0.1237, -0.0906,  0.1067, -0.0791, -0.1660,  0.0487,  0.0635,  0.0555,

2025-11-18 14:31:22          0.0562, -0.0208, -0.0247, -0.0210, -0.1192,  0.0735, -0.0960,  0.0183,

2025-11-18 14:31:22          0.0923,  0.0311,  0.0228,  0.0739,  0.0312,  0.0293,  0.0242,  0.1432,

2025-11-18 14:31:22         -0.1495,  0.0705,  0.1607,  0.1131,  0.0455, -0.1201,  0.1743,  0.0608,

2025-11-18 14:31:22         -0.1190, -0.1751,  0.0174,  0.1122,  0.0615,  0.1286,  0.2249, -0.0399,

2025-11-18 14:31:22          0.1110, -0.3303, -0.1719, -0.1252,  0.1496, -0.0990, -0.0732,  0.1068,

2025-11-18 14:31:22         -0.0648, -0.0481, -0.1068, -0.0256,  0.1217, -0.1511,  0.0120, -0.0370,

2025-11-18 14:31:22         -0.0630,  0.0352, -0.0881, -0.0354, -0.2016,  0.0181, -0.0575, -0.0375,

2025-11-18 14:31:22          0.1403,  0.0006,  0.2255, -0.0530, -0.0560, -0.2372,  0.1225,  0.2346,

2025-11-18 14:31:22          0.1047, -0.0298,  0.0164, -0.0071, -0.0364,  0.1334,  0.1921,  0.0409,

2025-11-18 14:31:22          0.0370, -0.2028,  0.0428,  0.0574,  0.1313,  0.1827,  0.1051,  0.0931,

2025-11-18 14:31:22          0.1609, -0.1042, -0.0180,  0.1062, -0.2921,  0.1134, -0.0590, -0.1621,

2025-11-18 14:31:22          0.0792,  0.0747,  0.0440,  0.1033, -0.0561, -0.0242, -0.0610, -0.0865,

2025-11-18 14:31:22         -0.0366,  0.0475, -0.0406, -0.0448,  0.0063,  0.1424,  0.0130,  0.0362,

2025-11-18 14:31:22         -0.0880, -0.0607, -0.0947,  0.1126, -0.1080, -0.1318, -0.1815,  0.0529,

2025-11-18 14:31:22         -0.0257, -0.0751, -0.2009, -0.0415, -0.0961, -0.0399,  0.0027, -0.0857,

2025-11-18 14:31:22         -0.0904, -0.0699, -0.0287, -0.0942,  0.0285, -0.0968,  0.2108,  0.0588,

2025-11-18 14:31:22         -0.0367, -0.0581,  0.0109,  0.0122,  0.0639, -0.0397, -0.1301,  0.1894,

2025-11-18 14:31:22         -0.1012,  0.1052,  0.0252,  0.1616,  0.1519,  0.0793, -0.1125, -0.0098,

2025-11-18 14:31:22         -0.2642,  0.0059, -0.1486,  0.1224, -0.1979, -0.0971, -0.0462,  0.0212],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[5] tensor([-2.3097e-02, -1.4788e-01,  1.0210e-01,  3.3557e-02,  2.4169e-01,

2025-11-18 14:31:22         -1.3634e-01, -8.5383e-03, -3.8043e-02,  1.7316e-01, -4.1206e-02,

2025-11-18 14:31:22          2.8185e-02,  1.1411e-01,  3.9203e-02,  8.1501e-02,  9.3352e-02,

2025-11-18 14:31:22          2.0928e-01, -6.4334e-02,  3.8064e-02,  1.0619e-01,  9.6020e-02,

2025-11-18 14:31:22          1.0335e-01,  2.7876e-01,  6.5856e-02,  2.0067e-01,  8.0354e-02,

2025-11-18 14:31:22         -2.3247e-01,  1.2218e-01,  2.3015e-02,  1.7446e-01, -5.6854e-02,

2025-11-18 14:31:22         -5.4324e-02,  3.6970e-03,  5.6947e-02, -3.3943e-02,  1.6095e-01,

2025-11-18 14:31:22          1.9372e-03, -7.9038e-02,  9.8647e-02, -3.2229e-02,  5.0507e-02,

2025-11-18 14:31:22          9.7127e-02, -1.5709e-01,  2.4332e-02,  6.0119e-02, -1.0542e-01,

2025-11-18 14:31:22         -9.9471e-02, -9.7351e-02,  1.0731e-01,  1.3880e-01, -1.6828e-01,

2025-11-18 14:31:22          8.0962e-02, -5.6699e-02, -7.4759e-03, -6.4011e-03, -1.6884e-01,

2025-11-18 14:31:22         -1.3898e-01,  1.7222e-01, -8.1651e-02, -1.8829e-01, -5.1125e-02,

2025-11-18 14:31:22          1.3743e-01,  1.8289e-01, -4.9558e-02,  3.3120e-02, -3.1865e-02,

2025-11-18 14:31:22          8.0625e-02, -4.9182e-02, -2.8268e-02,  2.6301e-02, -9.2309e-03,

2025-11-18 14:31:22         -4.7385e-02, -1.8954e-01,  6.7699e-02,  7.9177e-03, -1.2038e-01,

2025-11-18 14:31:22          1.9006e-02,  1.7940e-02,  1.2187e-01, -5.8642e-02,  9.8349e-02,

2025-11-18 14:31:22         -1.5748e-01,  2.1717e-02, -5.9567e-02, -1.2667e-02,  1.7577e-02,

2025-11-18 14:31:22         -2.7029e-02, -1.3078e-01,  9.7926e-02,  2.2109e-02,  1.4673e-01,

2025-11-18 14:31:22         -2.8729e-02,  1.4028e-01, -1.5075e-01,  8.0415e-02,  1.0154e-01,

2025-11-18 14:31:22         -2.4165e-02, -2.6159e-02, -7.1517e-02, -4.9824e-02, -7.3641e-02,

2025-11-18 14:31:22         -6.3665e-02,  1.4753e-01,  2.2992e-02,  2.5068e-02,  8.3415e-02,

2025-11-18 14:31:22         -9.7786e-02,  1.5092e-01, -3.5185e-02, -1.6092e-02, -1.3254e-01,

2025-11-18 14:31:22         -1.3460e-01,  2.2992e-02,  1.0348e-01,  1.3005e-01,  1.0918e-01,

2025-11-18 14:31:22         -5.3370e-03,  3.2445e-02, -1.0142e-02, -9.9965e-03,  4.4736e-02,

2025-11-18 14:31:22         -8.6016e-02,  7.8391e-02, -4.4661e-02,  1.1245e-01, -4.3102e-02,

2025-11-18 14:31:22          1.1311e-01,  3.2954e-02, -2.3165e-02, -1.0094e-02, -5.7948e-02,

2025-11-18 14:31:22          3.6766e-02, -2.9717e-02, -1.2952e-02, -1.1631e-01, -1.0180e-01,

2025-11-18 14:31:22         -5.3192e-02,  3.6347e-02, -1.7114e-02,  5.3002e-02,  8.4525e-02,

2025-11-18 14:31:22         -1.0713e-01, -9.2328e-02, -7.2179e-02,  3.7902e-02, -1.4022e-01,

2025-11-18 14:31:22          5.5914e-02,  7.9675e-02,  3.9484e-02, -6.8603e-03, -5.1982e-02,

2025-11-18 14:31:22         -2.1808e-01, -1.2660e-01,  2.4476e-01, -1.2630e-01,  3.3029e-02,

2025-11-18 14:31:22          1.7699e-02,  9.0871e-02,  1.5078e-01, -7.2952e-02,  9.8937e-02,

2025-11-18 14:31:22         -7.6370e-02,  8.8079e-02, -8.8526e-02,  1.4171e-02, -3.5435e-02,

2025-11-18 14:31:22          4.1153e-03, -1.1882e-01, -5.6413e-02,  1.3846e-02, -4.2599e-02,

2025-11-18 14:31:22          8.8813e-02,  2.6194e-03, -5.3535e-02, -1.1002e-01,  1.8341e-01,

2025-11-18 14:31:22          9.4184e-02, -1.3347e-01,  5.6069e-02,  1.6303e-01,  1.1132e-04,

2025-11-18 14:31:22         -6.4000e-02,  6.0648e-02,  1.7026e-01,  2.7840e-02, -1.4208e-01,

2025-11-18 14:31:22         -1.4573e-01, -1.1765e-01,  4.9697e-02,  6.4271e-02, -1.9731e-01,

2025-11-18 14:31:22          4.8141e-02,  1.8684e-02, -6.3554e-02,  3.6129e-02,  1.9314e-01,

2025-11-18 14:31:22          1.0903e-01, -9.7833e-03,  6.3571e-02,  2.5554e-02, -1.0850e-01],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[6] tensor([ 0.0344, -0.0583, -0.0703, -0.2514, -0.0263, -0.1517, -0.0595,  0.0852,

2025-11-18 14:31:22         -0.0268,  0.1277,  0.0393,  0.0879, -0.1254, -0.3348, -0.0745, -0.0879,

2025-11-18 14:31:22          0.0474,  0.2322, -0.0987,  0.0354, -0.1064,  0.2409,  0.0734,  0.1306,

2025-11-18 14:31:22         -0.0146,  0.1136, -0.1571,  0.0971, -0.0936, -0.0309, -0.0165, -0.0660,

2025-11-18 14:31:22         -0.0744, -0.0196, -0.0644,  0.0964, -0.0135,  0.1379,  0.0341, -0.0277,

2025-11-18 14:31:22         -0.1563,  0.0474,  0.1149, -0.0199,  0.0589, -0.0346, -0.1100, -0.0020,

2025-11-18 14:31:22         -0.0207, -0.0792,  0.0376,  0.0803,  0.0011, -0.0536, -0.0457, -0.1338,

2025-11-18 14:31:22         -0.0419, -0.1026,  0.0135, -0.0070,  0.0092,  0.0340,  0.0115,  0.0074,

2025-11-18 14:31:22         -0.0919,  0.0340, -0.0404, -0.0352, -0.1594, -0.0584, -0.0647, -0.1073,

2025-11-18 14:31:22          0.0282, -0.0426, -0.0435,  0.0278, -0.0031,  0.0945,  0.1075,  0.0418,

2025-11-18 14:31:22         -0.1066,  0.0568, -0.0267,  0.0154, -0.1619, -0.0058,  0.1889, -0.0501,

2025-11-18 14:31:22         -0.0341, -0.0658,  0.1119, -0.1324,  0.0051, -0.0356, -0.0619,  0.0052,

2025-11-18 14:31:22         -0.1332,  0.0911,  0.1441,  0.0152, -0.1952, -0.0013, -0.0183, -0.0338,

2025-11-18 14:31:22          0.0631,  0.0013, -0.0094, -0.0361,  0.0370,  0.0204,  0.2303,  0.0010,

2025-11-18 14:31:22         -0.0754, -0.0257,  0.1069,  0.0503, -0.0969,  0.0752,  0.0786, -0.0510,

2025-11-18 14:31:22          0.0232, -0.1267,  0.0891,  0.1099,  0.0993, -0.0559, -0.0145, -0.0100,

2025-11-18 14:31:22          0.1262,  0.0168,  0.0875, -0.0091,  0.2017,  0.0385,  0.1079, -0.0034,

2025-11-18 14:31:22         -0.0704,  0.0213,  0.0039, -0.0300, -0.1966, -0.0747, -0.0787,  0.1549,

2025-11-18 14:31:22         -0.0108,  0.0581, -0.0527, -0.0684, -0.1514,  0.1286, -0.0561,  0.0960,

2025-11-18 14:31:22         -0.0797,  0.0104,  0.0925,  0.0467, -0.0793, -0.0287, -0.1249,  0.0754,

2025-11-18 14:31:22          0.0514, -0.1473,  0.1062, -0.0139, -0.0259,  0.0431, -0.0780,  0.0970,

2025-11-18 14:31:22          0.1067,  0.0072,  0.0515,  0.0534, -0.0132,  0.0470, -0.1017,  0.1103,

2025-11-18 14:31:22          0.0218, -0.1171,  0.0045,  0.2126,  0.0261, -0.0675,  0.0822,  0.0762,

2025-11-18 14:31:22         -0.0359, -0.0296,  0.0451, -0.1296, -0.0783, -0.0471, -0.0497, -0.0753,

2025-11-18 14:31:22         -0.0754,  0.0663, -0.0081,  0.1472,  0.1225, -0.0161, -0.0844, -0.0095],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[7] tensor([ 0.0324,  0.0432,  0.0128, -0.1048, -0.0309,  0.0343,  0.0725,  0.0905,

2025-11-18 14:31:22          0.0277, -0.0101, -0.2833,  0.0445,  0.0266, -0.0947, -0.0705,  0.0008,

2025-11-18 14:31:22          0.0852,  0.0237,  0.1369, -0.0885, -0.1265, -0.0279, -0.0524,  0.1058,

2025-11-18 14:31:22          0.0903,  0.1174,  0.0208,  0.1273, -0.0776,  0.0633,  0.1014,  0.0515,

2025-11-18 14:31:22          0.0878, -0.0716, -0.0953,  0.0094, -0.0114, -0.1050,  0.1013, -0.0545,

2025-11-18 14:31:22          0.2847,  0.1515,  0.0272, -0.0088, -0.0249,  0.1165, -0.0152, -0.0898,

2025-11-18 14:31:22          0.0555, -0.0581,  0.0530, -0.1249, -0.0017, -0.0968, -0.0731, -0.0366,

2025-11-18 14:31:22          0.0387, -0.0459, -0.0424,  0.0322, -0.0163, -0.0722,  0.0519, -0.2235,

2025-11-18 14:31:22         -0.0526, -0.1272, -0.1831,  0.0043, -0.0183,  0.0030, -0.0554,  0.1429,

2025-11-18 14:31:22         -0.0177, -0.0099, -0.0047, -0.0410,  0.1171,  0.0849, -0.0063,  0.0121,

2025-11-18 14:31:22          0.1281, -0.0245, -0.1118,  0.0065, -0.0303,  0.0243, -0.0665,  0.0273,

2025-11-18 14:31:22         -0.1180, -0.0921, -0.0741,  0.1799, -0.1599, -0.1509,  0.0317, -0.1675,

2025-11-18 14:31:22          0.0991, -0.1584,  0.0643, -0.0938, -0.0833,  0.0289, -0.1786, -0.0270,

2025-11-18 14:31:22         -0.0047, -0.0191,  0.0682, -0.1072,  0.0457,  0.0037,  0.0101, -0.0792,

2025-11-18 14:31:22         -0.0411, -0.0145,  0.2259, -0.0552, -0.0088,  0.2277,  0.1019, -0.0581,

2025-11-18 14:31:22         -0.0499,  0.0003, -0.0960,  0.1163,  0.0542, -0.0899,  0.0785, -0.0757,

2025-11-18 14:31:22          0.1136,  0.0955,  0.0024, -0.1075,  0.0386, -0.1068, -0.1145, -0.0436,

2025-11-18 14:31:22         -0.1211, -0.0174,  0.0412, -0.1130,  0.0218, -0.0999, -0.1438,  0.0179,

2025-11-18 14:31:22         -0.0548, -0.0479, -0.0121, -0.0538, -0.1268, -0.0741, -0.0415,  0.0144,

2025-11-18 14:31:22          0.0508,  0.0760, -0.0638, -0.1439,  0.0555, -0.0486,  0.0251,  0.0053,

2025-11-18 14:31:22          0.0245, -0.0231,  0.1099,  0.1551,  0.0105,  0.1027, -0.2184, -0.0827,

2025-11-18 14:31:22         -0.1366,  0.0940, -0.1021,  0.1093,  0.1131,  0.0516, -0.1181,  0.1755,

2025-11-18 14:31:22          0.0641,  0.0734,  0.1746,  0.1287, -0.0379,  0.0184,  0.0576, -0.0517,

2025-11-18 14:31:22          0.0330, -0.0928,  0.0623, -0.0064,  0.0763,  0.0913,  0.0678,  0.1516,

2025-11-18 14:31:22          0.0029, -0.0753, -0.0246,  0.0518, -0.0983,  0.1127,  0.0964, -0.1392],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[8] tensor([ 0.0620, -0.1085, -0.0364, -0.0362, -0.0345,  0.0245, -0.0383, -0.1592,

2025-11-18 14:31:22         -0.0493,  0.0025, -0.0031, -0.0267, -0.0372, -0.0254, -0.0815, -0.1367,

2025-11-18 14:31:22         -0.1122, -0.0198, -0.1505, -0.0171,  0.2510,  0.0592, -0.0906,  0.0650,

2025-11-18 14:31:22         -0.1193,  0.1853,  0.1500, -0.0254, -0.0351, -0.1932,  0.1420,  0.0618,

2025-11-18 14:31:22         -0.0726, -0.0382,  0.0244, -0.1537, -0.0670, -0.0176,  0.0063,  0.0121,

2025-11-18 14:31:22          0.1055, -0.1070, -0.0291, -0.1309, -0.0195,  0.0570, -0.0449,  0.1710,

2025-11-18 14:31:22         -0.0209,  0.1127, -0.0518, -0.0039,  0.0513, -0.0427,  0.0767, -0.0871,

2025-11-18 14:31:22         -0.0222,  0.0821, -0.0037, -0.0591, -0.2268,  0.0216,  0.0999, -0.0761,

2025-11-18 14:31:22         -0.0202,  0.0163,  0.0175,  0.0805,  0.2464,  0.0258,  0.0094, -0.2156,

2025-11-18 14:31:22         -0.1800, -0.0450, -0.0323,  0.0328,  0.1234,  0.0703,  0.1513, -0.0536,

2025-11-18 14:31:22         -0.0270,  0.1320,  0.1908,  0.0332, -0.0246, -0.0074,  0.0894,  0.1751,

2025-11-18 14:31:22         -0.0369, -0.0786, -0.1112, -0.0129,  0.1746,  0.0117,  0.1111, -0.0848,

2025-11-18 14:31:22          0.0966, -0.2175,  0.0244, -0.0435,  0.0372, -0.0111, -0.1484, -0.1168,

2025-11-18 14:31:22          0.0543,  0.0504, -0.0847, -0.1751, -0.0511,  0.2542,  0.0312,  0.1713,

2025-11-18 14:31:22         -0.0500,  0.0007, -0.0746,  0.0990,  0.0940, -0.0162, -0.0896,  0.0984,

2025-11-18 14:31:22         -0.1223, -0.1810, -0.0262,  0.0043,  0.0123, -0.1478, -0.0811, -0.0217,

2025-11-18 14:31:22         -0.2336, -0.1054, -0.1123,  0.0213,  0.1850, -0.0052, -0.0100, -0.0414,

2025-11-18 14:31:22         -0.0894,  0.0167,  0.1224, -0.0976, -0.0830,  0.1470, -0.1326, -0.0536,

2025-11-18 14:31:22         -0.2003,  0.0206,  0.0106, -0.1356,  0.2107, -0.0481, -0.0495, -0.1029,

2025-11-18 14:31:22          0.2354, -0.0199, -0.0308, -0.1495, -0.0890,  0.0694, -0.1402,  0.0187,

2025-11-18 14:31:22         -0.0880, -0.0337, -0.0247, -0.0611, -0.0248,  0.0132, -0.0624, -0.0821,

2025-11-18 14:31:22         -0.1276,  0.0288,  0.0071,  0.0083, -0.0146, -0.1069, -0.1822,  0.0275,

2025-11-18 14:31:22          0.1872,  0.0655,  0.1092, -0.0039,  0.0767,  0.0464, -0.0118, -0.0907,

2025-11-18 14:31:22          0.2852,  0.0258,  0.0703, -0.0427, -0.0363,  0.1239, -0.0180, -0.0091,

2025-11-18 14:31:22          0.0565, -0.1153, -0.0575, -0.0451,  0.1766, -0.1391,  0.0200,  0.1119],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[9] tensor([ 0.0004,  0.0098, -0.0630,  0.0729,  0.1286,  0.1135,  0.0132,  0.0753,

2025-11-18 14:31:22          0.1000,  0.0748,  0.0039, -0.1073, -0.0160,  0.0784,  0.0432,  0.0864,

2025-11-18 14:31:22          0.0586, -0.0512,  0.2272,  0.1022,  0.0344,  0.0295,  0.0027,  0.0091,

2025-11-18 14:31:22          0.0955,  0.0551, -0.1328, -0.0203,  0.2392, -0.1312, -0.0542,  0.1138,

2025-11-18 14:31:22          0.0317, -0.0134,  0.1082, -0.0630, -0.2079,  0.0328, -0.0148, -0.0055,

2025-11-18 14:31:22          0.0792,  0.0654,  0.0422,  0.0049, -0.1233, -0.0741,  0.1021, -0.0386,

2025-11-18 14:31:22         -0.0348,  0.0083, -0.0181,  0.0171,  0.0679,  0.0125, -0.0887, -0.0110,

2025-11-18 14:31:22          0.0730, -0.0927,  0.0534,  0.0082, -0.0331,  0.1718,  0.1019, -0.0851,

2025-11-18 14:31:22          0.0134,  0.1386, -0.0494,  0.0115,  0.0689,  0.0778,  0.0095,  0.1618,

2025-11-18 14:31:22          0.0119,  0.0620, -0.0528, -0.0109, -0.1644,  0.1267, -0.1405,  0.2506,

2025-11-18 14:31:22         -0.1118, -0.0659, -0.0724, -0.0041,  0.2570, -0.0359,  0.0570,  0.1049,

2025-11-18 14:31:22          0.0314,  0.0490, -0.1250,  0.0921, -0.1334, -0.0470,  0.0743,  0.2864,

2025-11-18 14:31:22          0.2034, -0.0486, -0.0558,  0.1079,  0.0035,  0.2203,  0.2007, -0.0190,

2025-11-18 14:31:22         -0.0402,  0.2442, -0.1645,  0.0048, -0.0110, -0.0840, -0.2092, -0.0796,

2025-11-18 14:31:22         -0.0620, -0.1374, -0.2458, -0.1597, -0.0614,  0.0840, -0.0038,  0.0786,

2025-11-18 14:31:22          0.0911, -0.0136, -0.1404, -0.0157,  0.1248, -0.0229, -0.0362, -0.0273,

2025-11-18 14:31:22         -0.1132,  0.0388, -0.0171, -0.1177, -0.1702, -0.1764, -0.0355,  0.0977,

2025-11-18 14:31:22         -0.0696,  0.1107,  0.1663, -0.0294,  0.1273,  0.0251,  0.0632,  0.0685,

2025-11-18 14:31:22         -0.1134, -0.2482, -0.0751, -0.0773, -0.0422,  0.1633,  0.0615,  0.0023,

2025-11-18 14:31:22         -0.2218, -0.1290, -0.0822, -0.0304,  0.0999,  0.1201, -0.0902,  0.0529,

2025-11-18 14:31:22         -0.0231,  0.1423, -0.1279,  0.0132, -0.1959, -0.1194,  0.2194,  0.0659,

2025-11-18 14:31:22          0.0531, -0.0018,  0.1107, -0.0963,  0.1062,  0.0171,  0.0575, -0.1313,

2025-11-18 14:31:22         -0.1070, -0.1193,  0.0607, -0.0449,  0.0803, -0.0565,  0.0955,  0.0853,

2025-11-18 14:31:22          0.1472, -0.0848, -0.0461,  0.0320, -0.0080,  0.1865, -0.0155,  0.0745,

2025-11-18 14:31:22          0.1170, -0.0421, -0.1014, -0.0092,  0.0323,  0.0626, -0.0019,  0.0560],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])

2025-11-18 14:31:22 self.weight_fb[0] tensor([ 0.0136, -0.0106, -0.0700,  0.0738,  0.0363, -0.0981,  0.0008,  0.0320,

2025-11-18 14:31:22          0.0276, -0.0871, -0.0159, -0.0787, -0.0114, -0.1574, -0.0150, -0.0063,

2025-11-18 14:31:22         -0.0520,  0.0052, -0.0031, -0.0725, -0.1130, -0.0024, -0.0740, -0.0406,

2025-11-18 14:31:22          0.0623, -0.0248, -0.1201, -0.1544,  0.0628,  0.0948, -0.1293, -0.0977,

2025-11-18 14:31:22         -0.0445,  0.0393, -0.0752, -0.1147, -0.0152, -0.0637,  0.0246,  0.0448,

2025-11-18 14:31:22          0.1848,  0.0159, -0.0257, -0.1081,  0.0749, -0.1096,  0.0297,  0.0380,

2025-11-18 14:31:22         -0.0246, -0.0982,  0.0286, -0.1074,  0.1856, -0.1482,  0.1644, -0.1338,

2025-11-18 14:31:22          0.0282,  0.0384,  0.0637, -0.0539,  0.0754,  0.0908,  0.0045,  0.0340,

2025-11-18 14:31:22          0.1005,  0.0013,  0.0536,  0.0342, -0.0304, -0.0040, -0.0625,  0.1837,

2025-11-18 14:31:22         -0.0095, -0.0813, -0.0995, -0.0855, -0.0032, -0.0013, -0.0328,  0.0576,

2025-11-18 14:31:22          0.0864,  0.0268,  0.0238,  0.0534,  0.0807, -0.0262, -0.0349,  0.0197,

2025-11-18 14:31:22         -0.1325,  0.0013,  0.0123, -0.1658, -0.0778, -0.0948, -0.1309,  0.1143,

2025-11-18 14:31:22          0.0970,  0.1279,  0.1991, -0.1371, -0.0006,  0.0825, -0.1059,  0.0706,

2025-11-18 14:31:22         -0.0534,  0.0225,  0.1133,  0.1787, -0.1257, -0.1148,  0.1220,  0.0250,

2025-11-18 14:31:22         -0.1914, -0.2004,  0.0467,  0.0144,  0.0167, -0.0004, -0.1363, -0.0944,

2025-11-18 14:31:22         -0.0846, -0.1734,  0.0105,  0.1364, -0.1122, -0.0127,  0.1167, -0.0659,

2025-11-18 14:31:22         -0.0496,  0.0946,  0.0137,  0.1505, -0.0582,  0.0473, -0.2295, -0.1048,

2025-11-18 14:31:22         -0.0118, -0.1000, -0.0767,  0.0394, -0.0572,  0.0360, -0.1225,  0.1299,

2025-11-18 14:31:22         -0.0898,  0.0036, -0.1052,  0.1738, -0.1547, -0.0046, -0.0737,  0.0932,

2025-11-18 14:31:22         -0.1146, -0.0283,  0.0006,  0.0109,  0.1251,  0.1539, -0.1232,  0.0430,

2025-11-18 14:31:22         -0.1511,  0.0493, -0.0529,  0.0596,  0.0372,  0.1905, -0.1539,  0.0558,

2025-11-18 14:31:22          0.1288,  0.1966,  0.0664, -0.0392,  0.0058, -0.1144,  0.0046, -0.0110,

2025-11-18 14:31:22          0.0415,  0.1495,  0.1298, -0.0630, -0.1861, -0.0034, -0.0232, -0.1339,

2025-11-18 14:31:22          0.0198, -0.0104,  0.0531,  0.0360,  0.0969, -0.0470, -0.1119,  0.1577,

2025-11-18 14:31:22          0.0795, -0.0187, -0.0610, -0.0518,  0.0902, -0.1077,  0.0492, -0.0430],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[1] tensor([ 3.9019e-02,  2.5154e-02,  9.0798e-02, -9.7679e-02,  2.8764e-02,

2025-11-18 14:31:22          7.0434e-02,  8.4063e-02,  2.5928e-02,  9.7380e-02,  1.6275e-02,

2025-11-18 14:31:22          8.7966e-02,  1.8267e-02, -2.7582e-02,  3.0036e-02, -1.6191e-01,

2025-11-18 14:31:22         -8.6450e-02, -1.8375e-03,  8.3683e-02,  1.2906e-02, -1.4225e-02,

2025-11-18 14:31:22          1.1338e-01,  3.5779e-02,  1.1134e-01,  3.2772e-02,  3.0779e-02,

2025-11-18 14:31:22          4.5491e-02,  6.9465e-02, -7.9200e-02,  1.2984e-01,  1.1974e-01,

2025-11-18 14:31:22          5.7609e-02, -1.1568e-01, -1.6414e-01,  3.0509e-02,  6.8447e-02,

2025-11-18 14:31:22         -6.2259e-02,  1.0754e-01, -2.4923e-02,  4.4897e-02,  5.2062e-02,

2025-11-18 14:31:22          1.1688e-01,  1.9003e-01,  2.0063e-02,  6.7085e-02,  1.0077e-01,

2025-11-18 14:31:22          5.4456e-02, -6.7470e-02,  1.3327e-01, -1.5840e-03, -6.3881e-02,

2025-11-18 14:31:22          3.4684e-02,  3.7240e-02,  6.3400e-02, -2.8443e-02, -9.6012e-02,

2025-11-18 14:31:22         -6.2349e-02, -1.1489e-01,  7.2854e-02, -1.0937e-01,  9.2610e-02,

2025-11-18 14:31:22         -2.1004e-04, -3.7679e-02, -9.4393e-03,  2.1505e-01,  1.5926e-01,

2025-11-18 14:31:22         -7.5369e-02,  1.9417e-01,  2.1636e-02, -8.1999e-02, -1.8520e-01,

2025-11-18 14:31:22          1.7142e-02, -2.9865e-02, -4.0532e-02, -9.7150e-02,  1.5350e-01,

2025-11-18 14:31:22         -1.8486e-01, -5.9385e-03,  1.1371e-02, -3.8125e-02, -1.3841e-02,

2025-11-18 14:31:22         -2.0428e-02, -1.0368e-01, -4.4102e-02, -2.1970e-02,  1.0765e-02,

2025-11-18 14:31:22         -5.5344e-02,  7.0728e-02,  4.6190e-02,  6.2990e-02, -5.4066e-02,

2025-11-18 14:31:22         -1.6213e-01, -3.9405e-02,  1.3400e-01,  8.2171e-02, -2.3741e-01,

2025-11-18 14:31:22          1.0548e-01, -9.5347e-02, -3.4751e-02, -3.8221e-02,  9.9864e-02,

2025-11-18 14:31:22         -1.1664e-01,  1.0195e-01,  3.3650e-02,  8.7214e-03, -5.3215e-02,

2025-11-18 14:31:22          7.9702e-02, -9.8969e-02,  1.6521e-01,  4.4730e-02, -2.8468e-02,

2025-11-18 14:31:22         -7.8716e-02, -6.4015e-03,  1.3884e-01, -2.8019e-02,  2.1341e-01,

2025-11-18 14:31:22         -9.0670e-02,  9.4125e-02, -6.3092e-02,  5.8177e-02,  6.7590e-02,

2025-11-18 14:31:22          4.8755e-02, -9.2646e-02, -1.4212e-01, -6.4560e-02, -2.2409e-01,

2025-11-18 14:31:22          1.1573e-03,  1.1887e-01, -7.8905e-02, -7.3512e-02, -3.9799e-02,

2025-11-18 14:31:22          1.3260e-01,  4.2742e-02,  7.5729e-02,  3.1080e-02, -6.4224e-02,

2025-11-18 14:31:22         -1.1484e-01,  1.0520e-01,  7.3674e-02, -1.0186e-01, -3.0466e-02,

2025-11-18 14:31:22         -4.0072e-02,  3.1730e-02,  9.9246e-02, -7.0664e-02,  2.0741e-02,

2025-11-18 14:31:22         -1.1007e-03, -2.3973e-01,  9.8560e-02,  4.4328e-02,  1.3719e-01,

2025-11-18 14:31:22          1.7300e-01,  5.2069e-02, -1.3163e-02, -4.8457e-03,  1.1188e-01,

2025-11-18 14:31:22         -4.3641e-02,  9.1629e-02, -7.9687e-02, -3.0985e-02, -5.0387e-02,

2025-11-18 14:31:22         -1.0267e-02, -8.4093e-02, -1.3090e-01, -9.6986e-02, -1.1397e-01,

2025-11-18 14:31:22          1.7749e-01, -7.0455e-03,  8.1856e-02, -3.4062e-02,  5.2526e-02,

2025-11-18 14:31:22         -2.2659e-01,  1.9467e-01,  7.6326e-02,  2.5363e-03,  6.2256e-02,

2025-11-18 14:31:22          9.6879e-02,  1.5179e-01, -1.3537e-01, -1.3574e-01, -2.1640e-03,

2025-11-18 14:31:22         -1.6477e-01,  1.0380e-01,  6.0904e-02,  1.8073e-02, -5.3058e-02,

2025-11-18 14:31:22          4.4933e-02,  2.5375e-01,  2.1265e-03, -2.3270e-02, -1.6723e-02,

2025-11-18 14:31:22         -3.1699e-02, -1.4938e-01, -2.2361e-02,  2.1272e-03, -7.7590e-02,

2025-11-18 14:31:22         -1.0800e-01, -2.0303e-02,  1.5057e-01, -2.4740e-02,  8.9488e-02],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[2] tensor([-0.1176, -0.0570, -0.0881,  0.0382, -0.0470, -0.0022, -0.0419,  0.0347,

2025-11-18 14:31:22         -0.0455,  0.1512, -0.2212,  0.0205,  0.0492,  0.0188,  0.1280,  0.0916,

2025-11-18 14:31:22         -0.2246, -0.0407, -0.0579, -0.0697, -0.0332, -0.0426, -0.0589, -0.0386,

2025-11-18 14:31:22          0.1296, -0.1049,  0.0089, -0.1006,  0.0838,  0.0634, -0.0685,  0.0280,

2025-11-18 14:31:22          0.0230, -0.0933, -0.0234,  0.0639,  0.0010,  0.0445,  0.0817, -0.1759,

2025-11-18 14:31:22          0.0889, -0.1021,  0.0453,  0.0165, -0.1924,  0.0662,  0.0422, -0.1617,

2025-11-18 14:31:22          0.0394, -0.0525, -0.1020,  0.0969,  0.1674, -0.0956,  0.0062, -0.2188,

2025-11-18 14:31:22         -0.1477, -0.0795, -0.0521,  0.0115, -0.0537, -0.0015,  0.0250,  0.0240,

2025-11-18 14:31:22         -0.2109, -0.0307, -0.1652, -0.1158,  0.0194, -0.1232, -0.0790,  0.0154,

2025-11-18 14:31:22         -0.1488, -0.0429, -0.0399,  0.0404, -0.0934,  0.0394, -0.0222,  0.0784,

2025-11-18 14:31:22         -0.0192,  0.0321,  0.1407,  0.0594,  0.0645,  0.2660,  0.1538, -0.0809,

2025-11-18 14:31:22          0.0616,  0.0261,  0.0989, -0.0503, -0.0319,  0.0858, -0.1420, -0.0518,

2025-11-18 14:31:22          0.1445, -0.0124, -0.0205, -0.1577, -0.0543, -0.0750,  0.0879,  0.0205,

2025-11-18 14:31:22         -0.0879,  0.1437, -0.1579, -0.1448, -0.1457, -0.0660, -0.0659, -0.0375,

2025-11-18 14:31:22          0.0527, -0.0404,  0.1653,  0.0289,  0.1094, -0.1015,  0.1626, -0.0075,

2025-11-18 14:31:22          0.1662,  0.2571,  0.0893,  0.0890, -0.0148, -0.0483, -0.0005,  0.0456,

2025-11-18 14:31:22          0.0326, -0.0538, -0.2244,  0.0251, -0.0627,  0.0730, -0.0966, -0.1493,

2025-11-18 14:31:22         -0.0732,  0.0858,  0.1233,  0.2035,  0.0183,  0.1147,  0.1068,  0.0161,

2025-11-18 14:31:22          0.0902, -0.0651, -0.0715,  0.0183,  0.0563,  0.1722,  0.0345, -0.0602,

2025-11-18 14:31:22         -0.1160,  0.0269, -0.1717,  0.0408,  0.0133,  0.1677,  0.0753,  0.2172,

2025-11-18 14:31:22         -0.0146,  0.0282, -0.0693,  0.1199, -0.0784, -0.0165,  0.1006,  0.0451,

2025-11-18 14:31:22         -0.1145,  0.1461,  0.0647, -0.0945,  0.0623, -0.1480, -0.0218, -0.1240,

2025-11-18 14:31:22         -0.0219,  0.0630, -0.0281, -0.0556,  0.0266,  0.0834, -0.0797, -0.1292,

2025-11-18 14:31:22          0.0918,  0.0871,  0.0766, -0.0546, -0.1768, -0.0866, -0.0672,  0.0826,

2025-11-18 14:31:22         -0.1746,  0.0408, -0.1357, -0.1097, -0.0017,  0.0469, -0.0158, -0.1136],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[3] tensor([-0.0365,  0.1492,  0.1437,  0.1214, -0.1905,  0.0414,  0.0920, -0.1194,

2025-11-18 14:31:22         -0.0793,  0.0523, -0.0206, -0.0877, -0.1264, -0.0247,  0.0060,  0.1693,

2025-11-18 14:31:22         -0.1031,  0.0021,  0.1151,  0.0680, -0.0114, -0.1083,  0.0192, -0.1049,

2025-11-18 14:31:22          0.0003,  0.1907, -0.1256,  0.0967,  0.0163,  0.0660,  0.1730, -0.0695,

2025-11-18 14:31:22          0.1811,  0.0153, -0.0434, -0.0872,  0.0316, -0.0302, -0.0075, -0.0259,

2025-11-18 14:31:22         -0.0154,  0.0773, -0.1435,  0.1663, -0.0149, -0.0396,  0.1477,  0.2279,

2025-11-18 14:31:22          0.0989,  0.0160,  0.0486,  0.0256,  0.0010,  0.0822,  0.0260,  0.0013,

2025-11-18 14:31:22         -0.0255, -0.0615,  0.0043, -0.1938, -0.0396, -0.0095,  0.0934,  0.0380,

2025-11-18 14:31:22         -0.0638,  0.1835, -0.0801, -0.1317,  0.2654,  0.0595, -0.0071, -0.1468,

2025-11-18 14:31:22         -0.0288, -0.1604,  0.0815, -0.0099, -0.0089, -0.0636,  0.0295, -0.0150,

2025-11-18 14:31:22         -0.1872, -0.0362,  0.1606, -0.1631, -0.0683,  0.1717, -0.1120, -0.0207,

2025-11-18 14:31:22         -0.0738, -0.0534,  0.1167,  0.0465, -0.1569,  0.0623,  0.1992, -0.0154,

2025-11-18 14:31:22         -0.0664,  0.0287,  0.0269, -0.0208,  0.0981,  0.1508,  0.0021,  0.0982,

2025-11-18 14:31:22          0.0723,  0.0228,  0.0112,  0.0613,  0.1816, -0.1070,  0.0553,  0.0236,

2025-11-18 14:31:22         -0.0179, -0.0131,  0.0833, -0.0739,  0.0031,  0.0167,  0.0272, -0.1319,

2025-11-18 14:31:22          0.0396,  0.0491,  0.0588,  0.0015, -0.0071,  0.1565, -0.0120, -0.1833,

2025-11-18 14:31:22          0.1558,  0.1691,  0.0405, -0.1244, -0.0768, -0.0768, -0.1019,  0.1306,

2025-11-18 14:31:22          0.0825, -0.0200, -0.0242,  0.0078,  0.0199, -0.1735, -0.1019, -0.0651,

2025-11-18 14:31:22         -0.1056, -0.0799,  0.1560,  0.1587, -0.0255,  0.1213, -0.0596,  0.1384,

2025-11-18 14:31:22         -0.0424,  0.0252, -0.1582,  0.1200, -0.0028, -0.1406, -0.2185,  0.1694,

2025-11-18 14:31:22          0.0334,  0.1966, -0.0360,  0.1704,  0.2084, -0.1135, -0.0869,  0.1150,

2025-11-18 14:31:22          0.0498,  0.0928, -0.0948, -0.0336,  0.1267,  0.0648, -0.0360,  0.0417,

2025-11-18 14:31:22         -0.0814, -0.0225,  0.2085, -0.0853,  0.0700,  0.1192, -0.0077,  0.0075,

2025-11-18 14:31:22         -0.0558, -0.1166,  0.0397,  0.0466,  0.0524, -0.0005,  0.0760,  0.0648,

2025-11-18 14:31:22         -0.0572, -0.0123, -0.1625, -0.2079,  0.0009,  0.1398, -0.1563, -0.0761],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[4] tensor([-0.0874, -0.2878,  0.0162,  0.1137, -0.0216, -0.0095, -0.0791, -0.0112,

2025-11-18 14:31:22          0.1378,  0.0276, -0.0191,  0.0996, -0.0046,  0.0440, -0.1734, -0.1609,

2025-11-18 14:31:22         -0.0709, -0.2547,  0.0804,  0.1218,  0.2098, -0.1937, -0.0028, -0.1298,

2025-11-18 14:31:22         -0.0120,  0.0623, -0.1709, -0.0088,  0.0245, -0.0329, -0.1025, -0.0525,

2025-11-18 14:31:22         -0.0827,  0.2040, -0.0738, -0.0449, -0.0073,  0.0925,  0.0297, -0.0470,

2025-11-18 14:31:22         -0.0164,  0.1825, -0.2102, -0.0393, -0.0126,  0.0600, -0.0207, -0.1989,

2025-11-18 14:31:22          0.0681,  0.0819, -0.0137,  0.0233,  0.0062, -0.0912, -0.0540, -0.0826,

2025-11-18 14:31:22          0.0754,  0.1373,  0.1662, -0.0536, -0.0954, -0.1096, -0.1003, -0.0158,

2025-11-18 14:31:22         -0.2121,  0.0899, -0.2017,  0.0826,  0.1063,  0.1378, -0.0192,  0.1304,

2025-11-18 14:31:22          0.2962, -0.0886,  0.0716,  0.2377,  0.0810,  0.0063,  0.0698,  0.1793,

2025-11-18 14:31:22         -0.0389,  0.0985, -0.1307, -0.2917, -0.1084, -0.1743,  0.0437,  0.0713,

2025-11-18 14:31:22         -0.0190, -0.1089, -0.1086,  0.0735,  0.0281,  0.0158,  0.0761, -0.2097,

2025-11-18 14:31:22          0.1789, -0.1032,  0.0685, -0.1225,  0.0463,  0.2206,  0.0182,  0.0383,

2025-11-18 14:31:22         -0.0163,  0.0126, -0.0634,  0.0739, -0.1272, -0.0418,  0.0581, -0.0152,

2025-11-18 14:31:22         -0.1131,  0.0571,  0.0255, -0.0762, -0.1088, -0.0394,  0.0134, -0.1451,

2025-11-18 14:31:22         -0.0832, -0.0144,  0.1111, -0.0474,  0.1000,  0.0990,  0.0673, -0.0446,

2025-11-18 14:31:22         -0.0586,  0.0127,  0.0218, -0.0582,  0.2106,  0.0093, -0.1277, -0.0548,

2025-11-18 14:31:22         -0.0257,  0.2035, -0.1348, -0.0572, -0.0537, -0.0828, -0.1483,  0.0311,

2025-11-18 14:31:22         -0.0788,  0.0215, -0.1438, -0.0198, -0.1424,  0.1543, -0.1733, -0.0286,

2025-11-18 14:31:22         -0.1172, -0.0252,  0.0334, -0.0683,  0.1256, -0.0856, -0.0397, -0.0185,

2025-11-18 14:31:22         -0.1631, -0.1860,  0.0950, -0.1286, -0.0509,  0.0371,  0.0340, -0.0386,

2025-11-18 14:31:22         -0.0047,  0.0548, -0.0648, -0.0035,  0.2056, -0.1304,  0.0738,  0.0144,

2025-11-18 14:31:22          0.0309, -0.1177, -0.1432,  0.0321,  0.0579, -0.1703, -0.0908,  0.0473,

2025-11-18 14:31:22          0.1625, -0.0337,  0.0552,  0.0707,  0.0216, -0.0073,  0.0840, -0.0357,

2025-11-18 14:31:22         -0.0778,  0.0333,  0.0204,  0.1302, -0.0612, -0.0760,  0.0045, -0.0715],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[5] tensor([ 0.1300, -0.0290,  0.0912, -0.1956,  0.0597,  0.0285, -0.1028,  0.0317,

2025-11-18 14:31:22         -0.0103,  0.1087,  0.0391,  0.0249,  0.1348,  0.0188,  0.2061, -0.0331,

2025-11-18 14:31:22         -0.0511,  0.1448, -0.0687, -0.0512,  0.1953, -0.1046, -0.1168,  0.0371,

2025-11-18 14:31:22         -0.0454,  0.1605,  0.2064,  0.0105,  0.0217, -0.1555,  0.0123, -0.0809,

2025-11-18 14:31:22          0.0847,  0.0267, -0.2364, -0.1307,  0.0148, -0.1221,  0.1381, -0.0256,

2025-11-18 14:31:22          0.0939,  0.0111, -0.0287, -0.2360,  0.0629,  0.1009,  0.0447,  0.1768,

2025-11-18 14:31:22         -0.0366, -0.0532,  0.2044,  0.1877, -0.0016,  0.1828, -0.1052, -0.1184,

2025-11-18 14:31:22         -0.2589,  0.1056,  0.2014, -0.0456,  0.0197, -0.0621,  0.0749, -0.0556,

2025-11-18 14:31:22         -0.1770,  0.1183,  0.2220, -0.0243, -0.0030,  0.0711,  0.0164, -0.0922,

2025-11-18 14:31:22          0.0700, -0.0595,  0.1727,  0.0145,  0.0382, -0.3578, -0.0543,  0.0084,

2025-11-18 14:31:22          0.0855, -0.0105, -0.0112,  0.0679, -0.1331,  0.0217,  0.0218,  0.0706,

2025-11-18 14:31:22         -0.1121, -0.0037,  0.0218, -0.0264, -0.0442,  0.0885, -0.0255, -0.0512,

2025-11-18 14:31:22         -0.0117, -0.0858, -0.1294, -0.0291, -0.0313,  0.1300, -0.1170,  0.0544,

2025-11-18 14:31:22          0.0718,  0.1288, -0.1224,  0.1531, -0.0877,  0.0856, -0.0822, -0.0295,

2025-11-18 14:31:22          0.0070, -0.0089, -0.1059, -0.1029,  0.1119, -0.1977,  0.1345, -0.1227,

2025-11-18 14:31:22         -0.1313, -0.0701,  0.0925,  0.0867, -0.0602, -0.0454, -0.1162,  0.1331,

2025-11-18 14:31:22         -0.0070,  0.0286,  0.1760, -0.1712,  0.0136,  0.0362,  0.0169, -0.0475,

2025-11-18 14:31:22         -0.0543, -0.1353, -0.0515,  0.0787, -0.0935, -0.2302,  0.0657, -0.0193,

2025-11-18 14:31:22         -0.0741, -0.1347, -0.1320, -0.0633,  0.0482,  0.0237,  0.0235,  0.1115,

2025-11-18 14:31:22          0.0948,  0.2133,  0.0239,  0.0536,  0.0297,  0.1637, -0.1271,  0.0527,

2025-11-18 14:31:22          0.0373, -0.0568,  0.0910, -0.0004, -0.1461,  0.1952, -0.0235,  0.0972,

2025-11-18 14:31:22          0.0026,  0.0695,  0.1002,  0.0492, -0.0383, -0.0427, -0.0296,  0.0046,

2025-11-18 14:31:22          0.0502,  0.0025,  0.0582,  0.1880, -0.0915, -0.0357,  0.0783,  0.0295,

2025-11-18 14:31:22         -0.0559, -0.1317,  0.0729, -0.0005,  0.0163, -0.0260, -0.0636, -0.0965,

2025-11-18 14:31:22         -0.0161,  0.0863,  0.0049, -0.0130, -0.0310,  0.0269,  0.0490, -0.0194],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[6] tensor([-0.0755,  0.1157,  0.1487,  0.0312,  0.0088, -0.0934,  0.1386,  0.0494,

2025-11-18 14:31:22          0.1581,  0.0538, -0.1382,  0.1405, -0.0518, -0.1131, -0.0435,  0.0108,

2025-11-18 14:31:22         -0.0136, -0.0261,  0.0036, -0.0735,  0.0057,  0.1861, -0.0205, -0.0147,

2025-11-18 14:31:22          0.1115, -0.1055, -0.0333, -0.0581,  0.0298, -0.1677,  0.0853, -0.1542,

2025-11-18 14:31:22          0.0841, -0.0789,  0.1823,  0.0546, -0.1157, -0.0021, -0.0624, -0.0842,

2025-11-18 14:31:22         -0.0643,  0.0172, -0.0460, -0.0905, -0.1069,  0.0294,  0.1544, -0.0694,

2025-11-18 14:31:22          0.0053,  0.0024,  0.1008,  0.1026,  0.2395,  0.0446, -0.0760,  0.0411,

2025-11-18 14:31:22         -0.0543,  0.0697, -0.0095,  0.2348, -0.0666,  0.0692, -0.0046,  0.0664,

2025-11-18 14:31:22         -0.0122, -0.0853,  0.0614, -0.0631,  0.1126, -0.1014, -0.0805,  0.0063,

2025-11-18 14:31:22          0.0694, -0.0091, -0.1463,  0.0367, -0.0787,  0.1328, -0.1187,  0.0344,

2025-11-18 14:31:22          0.1351, -0.1024,  0.0370, -0.0922, -0.0747,  0.0126,  0.0906, -0.0895,

2025-11-18 14:31:22         -0.1623,  0.0673,  0.0384, -0.0280,  0.0264,  0.0056,  0.0317, -0.0555,

2025-11-18 14:31:22          0.0636, -0.2060,  0.0456,  0.0843, -0.0197,  0.0903,  0.2240,  0.1724,

2025-11-18 14:31:22          0.0046,  0.0300,  0.0270,  0.0626,  0.1121,  0.0250, -0.0804,  0.0623,

2025-11-18 14:31:22          0.0696,  0.0334,  0.0043, -0.2056,  0.1308,  0.0856, -0.0198, -0.0268,

2025-11-18 14:31:22          0.1300, -0.0193,  0.0783,  0.0175, -0.0085,  0.0610, -0.0509,  0.0733,

2025-11-18 14:31:22          0.0186, -0.0053,  0.0114, -0.0056, -0.0509,  0.0588,  0.1049,  0.0542,

2025-11-18 14:31:22          0.1166, -0.1209,  0.0434,  0.1118,  0.0814, -0.0112,  0.0703, -0.0407,

2025-11-18 14:31:22         -0.0151, -0.0558,  0.0140,  0.1696, -0.0412,  0.1057,  0.0986, -0.0241,

2025-11-18 14:31:22         -0.0095, -0.0080, -0.0638, -0.0291,  0.0576, -0.0776, -0.1520, -0.1818,

2025-11-18 14:31:22          0.0851, -0.0793,  0.1604, -0.0665,  0.0501,  0.1502, -0.1287,  0.0479,

2025-11-18 14:31:22         -0.1453,  0.0263, -0.0035,  0.0960,  0.0638, -0.1566,  0.0418,  0.0929,

2025-11-18 14:31:22          0.1142, -0.0140,  0.0344,  0.1191, -0.1846, -0.0907,  0.1322, -0.0362,

2025-11-18 14:31:22          0.0544, -0.1205, -0.0043,  0.0934, -0.0007,  0.0405,  0.1871, -0.0829,

2025-11-18 14:31:22         -0.0702,  0.1021,  0.0760,  0.0168, -0.0093, -0.1217,  0.0335,  0.1808],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[7] tensor([ 0.0619,  0.1403, -0.1077, -0.2767,  0.2080,  0.0575, -0.0134, -0.1055,

2025-11-18 14:31:22          0.1499,  0.1858,  0.0217,  0.1187, -0.0649,  0.2870, -0.1568,  0.1042,

2025-11-18 14:31:22         -0.1069, -0.1348,  0.0584, -0.1022, -0.0325, -0.0836,  0.0143,  0.0472,

2025-11-18 14:31:22          0.0017, -0.0113, -0.0767, -0.1494,  0.0455, -0.1245, -0.0429,  0.0766,

2025-11-18 14:31:22          0.0107, -0.0946, -0.1371,  0.1191,  0.1512,  0.0053,  0.0394, -0.0465,

2025-11-18 14:31:22          0.0175, -0.1627,  0.0771,  0.0206,  0.1903, -0.1087,  0.1277,  0.0255,

2025-11-18 14:31:22          0.1399,  0.1205,  0.1156, -0.0843,  0.0157,  0.0475, -0.1077, -0.0837,

2025-11-18 14:31:22         -0.0339, -0.1300, -0.0038, -0.0063, -0.1576,  0.0628,  0.1015, -0.0629,

2025-11-18 14:31:22         -0.0113,  0.1316,  0.1097,  0.0832,  0.0638, -0.0506, -0.0556, -0.0724,

2025-11-18 14:31:22         -0.0188, -0.0401, -0.1590,  0.0450,  0.0624, -0.0515, -0.0752, -0.0796,

2025-11-18 14:31:22         -0.0007, -0.3024, -0.2144, -0.0835, -0.0758, -0.1519, -0.1939,  0.1572,

2025-11-18 14:31:22         -0.1857,  0.1345, -0.1711, -0.0674,  0.0412, -0.1714, -0.0072, -0.2019,

2025-11-18 14:31:22          0.0787,  0.0984,  0.0226, -0.0245, -0.0423,  0.1742, -0.2161, -0.0183,

2025-11-18 14:31:22         -0.0029, -0.0044,  0.1192,  0.0439,  0.1932,  0.0082,  0.1160, -0.1654,

2025-11-18 14:31:22         -0.0213, -0.1270, -0.0089, -0.0236, -0.0589,  0.1086,  0.1448, -0.0744,

2025-11-18 14:31:22         -0.0636, -0.0634,  0.0920, -0.0227, -0.0138, -0.2378,  0.0915,  0.0410,

2025-11-18 14:31:22         -0.0771, -0.2554, -0.0056, -0.0511,  0.0792, -0.1065,  0.0931,  0.0945,

2025-11-18 14:31:22          0.1621, -0.0576,  0.0169,  0.0327,  0.0696,  0.0691, -0.0391,  0.1367,

2025-11-18 14:31:22         -0.0409, -0.0418,  0.0063, -0.0193, -0.0210, -0.0267,  0.1050, -0.0354,

2025-11-18 14:31:22          0.1055,  0.0792,  0.0318, -0.0377,  0.0276, -0.1005, -0.1378, -0.0189,

2025-11-18 14:31:22          0.0850,  0.1300, -0.0152, -0.1383,  0.0798, -0.1142, -0.0370, -0.0458,

2025-11-18 14:31:22         -0.1406,  0.0460, -0.0168,  0.1019,  0.0849,  0.0184,  0.0901, -0.1363,

2025-11-18 14:31:22          0.2124,  0.0447, -0.1437,  0.0413, -0.3102,  0.0478,  0.0038, -0.0860,

2025-11-18 14:31:22         -0.1465, -0.0472, -0.1059,  0.2646,  0.0621, -0.1125,  0.0021,  0.0192,

2025-11-18 14:31:22         -0.0153, -0.1243, -0.0433, -0.1272, -0.0750,  0.0914, -0.1973,  0.0438],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[8] tensor([-4.2623e-02, -3.6569e-02,  2.1554e-01,  7.3948e-02,  4.5928e-02,

2025-11-18 14:31:22          8.9498e-02,  5.3931e-02,  7.0713e-02, -1.2092e-01,  1.1116e-01,

2025-11-18 14:31:22         -3.0323e-02, -1.2760e-01, -8.4349e-02,  8.3266e-02, -1.4023e-01,

2025-11-18 14:31:22         -1.5514e-02, -1.0077e-01,  1.6821e-02,  1.4161e-01,  4.8444e-02,

2025-11-18 14:31:22          2.6380e-01,  1.6819e-02,  2.7638e-02,  1.6771e-01, -4.9164e-02,

2025-11-18 14:31:22         -5.8186e-02,  3.7733e-02, -7.5490e-02, -1.2715e-01,  6.3545e-03,

2025-11-18 14:31:22          4.5001e-02, -1.1637e-01,  4.3808e-02, -6.4871e-02, -1.9854e-01,

2025-11-18 14:31:22         -8.2011e-02,  4.6362e-02,  4.2026e-02,  3.5503e-02, -9.2668e-03,

2025-11-18 14:31:22         -6.1567e-02, -7.3332e-02,  1.2077e-01,  9.6574e-03, -1.1398e-01,

2025-11-18 14:31:22         -8.3217e-02,  9.7229e-02, -1.8468e-01,  1.0019e-01,  1.1664e-01,

2025-11-18 14:31:22         -4.1808e-03, -1.5724e-01, -1.2025e-01, -4.9540e-02,  8.5170e-02,

2025-11-18 14:31:22          7.6881e-02,  1.2248e-01, -4.9930e-02, -1.4443e-01,  1.7782e-01,

2025-11-18 14:31:22          4.8178e-02,  5.4946e-02, -4.6922e-02,  2.5569e-02,  6.4497e-02,

2025-11-18 14:31:22          6.3852e-03, -2.8890e-02, -2.0665e-02,  6.1656e-02, -8.2958e-03,

2025-11-18 14:31:22         -1.1087e-01, -4.8137e-02,  1.0483e-01,  6.2579e-02, -1.6083e-04,

2025-11-18 14:31:22         -1.1344e-01, -8.9015e-02, -1.7166e-02, -4.1521e-02, -1.5454e-01,

2025-11-18 14:31:22         -1.4731e-01,  8.7373e-02, -2.9756e-02,  2.0193e-02, -1.1296e-01,

2025-11-18 14:31:22         -3.1650e-02,  4.1894e-03, -1.8676e-01,  6.8287e-02, -2.2091e-02,

2025-11-18 14:31:22         -1.2922e-01,  2.7839e-02, -1.4709e-01, -4.7553e-02, -3.7346e-03,

2025-11-18 14:31:22          2.2710e-02,  2.5883e-02, -2.9356e-02,  1.6152e-01,  1.6246e-01,

2025-11-18 14:31:22         -1.3543e-01,  8.9756e-02, -4.2627e-02, -8.3722e-02, -1.5255e-01,

2025-11-18 14:31:22          2.2945e-01, -1.2727e-01, -2.3556e-01, -2.0420e-02,  1.3193e-01,

2025-11-18 14:31:22          4.7064e-02,  1.3503e-01, -1.1775e-01,  4.4378e-02, -3.4163e-02,

2025-11-18 14:31:22         -1.9214e-01,  1.5731e-01, -3.1321e-02,  6.0982e-02, -5.8376e-03,

2025-11-18 14:31:22          1.5299e-01, -5.1013e-02, -1.3059e-01, -4.6080e-02, -4.5595e-02,

2025-11-18 14:31:22          1.3429e-02, -6.2867e-02, -9.5215e-02, -1.7407e-02,  7.2585e-02,

2025-11-18 14:31:22          3.3903e-02, -8.6348e-02, -1.3825e-01,  4.7451e-02, -5.0096e-02,

2025-11-18 14:31:22         -3.1774e-02,  6.5457e-02,  1.4885e-01, -2.2025e-01, -4.0868e-02,

2025-11-18 14:31:22          9.5003e-02, -2.9685e-02, -9.5620e-03, -1.2427e-01,  1.7506e-02,

2025-11-18 14:31:22         -6.4477e-02,  7.1862e-02,  7.0507e-03, -5.8418e-02,  1.5294e-03,

2025-11-18 14:31:22          3.2851e-02,  1.9095e-02, -8.0235e-02,  6.8884e-02,  6.0092e-02,

2025-11-18 14:31:22          1.5271e-01,  1.9154e-01, -1.1346e-01,  6.4830e-02,  3.5148e-02,

2025-11-18 14:31:22          1.3541e-01, -3.6145e-02,  7.7164e-02,  6.6006e-02, -9.8362e-02,

2025-11-18 14:31:22         -5.8074e-02, -6.8333e-02, -6.2350e-02, -1.1440e-01, -7.7808e-02,

2025-11-18 14:31:22         -5.0657e-02, -1.3394e-01,  7.3470e-03,  2.3200e-02,  5.6048e-02,

2025-11-18 14:31:22         -1.1629e-01,  1.7295e-02, -3.8359e-02, -9.3535e-02,  5.3482e-02,

2025-11-18 14:31:22          9.3346e-02, -5.7120e-03,  4.7397e-02, -1.3661e-01,  4.1543e-02,

2025-11-18 14:31:22         -3.0960e-02, -2.6104e-02,  3.4355e-02, -8.6857e-02,  9.2401e-03,

2025-11-18 14:31:22         -1.4995e-01,  1.1801e-01, -5.6550e-03, -9.9898e-02,  1.3610e-02,

2025-11-18 14:31:22          1.8182e-02, -1.3491e-01, -8.2483e-02, -6.1044e-02, -5.1449e-02],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:31:22 self.weight_fb[9] tensor([-0.0404,  0.0334, -0.0873, -0.0599, -0.0711,  0.0188,  0.0374,  0.0498,

2025-11-18 14:31:22          0.0180,  0.0348, -0.1043,  0.1819, -0.0947,  0.0222,  0.0732,  0.0492,

2025-11-18 14:31:22          0.1486,  0.1599, -0.0004,  0.1500,  0.0163, -0.0051,  0.1059,  0.0772,

2025-11-18 14:31:22          0.0216,  0.1549, -0.0047,  0.0367,  0.0610, -0.1326,  0.2364, -0.0735,

2025-11-18 14:31:22         -0.1667,  0.0856,  0.0432, -0.1610, -0.1542,  0.0944, -0.0258,  0.0386,

2025-11-18 14:31:22          0.0133,  0.0888,  0.0012, -0.1798,  0.0380, -0.0701,  0.0899, -0.0979,

2025-11-18 14:31:22          0.1967, -0.0406, -0.0714, -0.1593,  0.0574,  0.0158, -0.1353, -0.0116,

2025-11-18 14:31:22         -0.0659, -0.0594, -0.0836,  0.1687,  0.1432, -0.1235, -0.1411, -0.1314,

2025-11-18 14:31:22         -0.0911,  0.2131, -0.1926, -0.0544, -0.1664,  0.0304,  0.1048, -0.0392,

2025-11-18 14:31:22         -0.0422, -0.1233,  0.0076, -0.0738, -0.1557,  0.1152,  0.0373, -0.0577,

2025-11-18 14:31:22          0.0090, -0.0523,  0.0164,  0.0149, -0.0101, -0.0796,  0.0258, -0.1029,

2025-11-18 14:31:22          0.0345, -0.0131, -0.0666, -0.0779,  0.0692, -0.0341, -0.0940, -0.1161,

2025-11-18 14:31:22         -0.0177,  0.1019, -0.1398,  0.0373, -0.1376, -0.0576,  0.0860, -0.0356,

2025-11-18 14:31:22          0.1078,  0.0419,  0.2311, -0.0366,  0.1426, -0.1082, -0.0577, -0.0187,

2025-11-18 14:31:22          0.0658, -0.1028, -0.0874, -0.0337,  0.1840,  0.0999,  0.2344,  0.0839,

2025-11-18 14:31:22          0.1116,  0.0364,  0.0575,  0.0951,  0.0945,  0.0339, -0.0087,  0.0691,

2025-11-18 14:31:22          0.0113,  0.0132, -0.0651,  0.0311, -0.0628,  0.0944, -0.0417,  0.1208,

2025-11-18 14:31:22          0.0239,  0.1379,  0.1112,  0.1446, -0.1183, -0.0495, -0.0503, -0.1729,

2025-11-18 14:31:22          0.0460, -0.1241, -0.0561,  0.0750, -0.1225, -0.0539,  0.2356,  0.0499,

2025-11-18 14:31:22         -0.0831,  0.0315,  0.1233,  0.1682, -0.1815,  0.1077,  0.1187,  0.1555,

2025-11-18 14:31:22          0.1233, -0.0816, -0.0952, -0.1361,  0.0105,  0.0832,  0.0652,  0.0702,

2025-11-18 14:31:22          0.0459,  0.0453, -0.0204, -0.0968, -0.0660,  0.0714, -0.0433,  0.0744,

2025-11-18 14:31:22         -0.0709,  0.0625,  0.0672, -0.1082, -0.0944,  0.1826,  0.0588,  0.0226,

2025-11-18 14:31:22          0.1245, -0.0560,  0.1531,  0.0472,  0.0311, -0.0327, -0.1191,  0.0361,

2025-11-18 14:31:22         -0.1240,  0.0982,  0.0693,  0.0030, -0.1002,  0.2047,  0.0471, -0.0009],

2025-11-18 14:31:22        device='cuda:0', grad_fn=<SelectBackward0>)

2025-11-18 14:32:32 epoch-0   lr=['0.0039062'], tr/val_loss:  0.068312/  0.086322, val:  45.42%, val_best:  45.42%, tr:  71.81%, tr_best:  71.81%, epoch time: 70.84 seconds, 1.18 minutes

2025-11-18 14:32:32 layer   1  Sparsity: 91.0649%

2025-11-18 14:32:32 layer   2  Sparsity: 56.0550%

2025-11-18 14:32:32 layer   3  Sparsity: 58.4293%

2025-11-18 14:32:32 total_backward_count 9790 real_backward_count 3697  37.763%

2025-11-18 14:32:32 [module.layers.3] weight_fb parameter count: 2,000

2025-11-18 14:32:32 [module.layers.6] weight_fb parameter count: 2,000

2025-11-18 14:33:42 epoch-1   lr=['0.0039062'], tr/val_loss:  0.047200/  0.074272, val:  51.67%, val_best:  51.67%, tr:  85.90%, tr_best:  85.90%, epoch time: 69.75 seconds, 1.16 minutes

2025-11-18 14:33:42 layer   1  Sparsity: 91.0996%

2025-11-18 14:33:42 layer   2  Sparsity: 54.6490%

2025-11-18 14:33:42 layer   3  Sparsity: 54.9185%

2025-11-18 14:33:42 total_backward_count 19580 real_backward_count 5921  30.240%

2025-11-18 14:34:50 epoch-2   lr=['0.0039062'], tr/val_loss:  0.042517/  0.074539, val:  46.25%, val_best:  51.67%, tr:  87.64%, tr_best:  87.64%, epoch time: 68.96 seconds, 1.15 minutes

2025-11-18 14:34:50 layer   1  Sparsity: 91.0981%

2025-11-18 14:34:50 layer   2  Sparsity: 54.2127%

2025-11-18 14:34:50 layer   3  Sparsity: 54.1396%

2025-11-18 14:34:50 total_backward_count 29370 real_backward_count 7939  27.031%

2025-11-18 14:36:00 epoch-3   lr=['0.0039062'], tr/val_loss:  0.039769/  0.087622, val:  49.17%, val_best:  51.67%, tr:  88.87%, tr_best:  88.87%, epoch time: 68.73 seconds, 1.15 minutes

2025-11-18 14:36:00 layer   1  Sparsity: 91.0417%

2025-11-18 14:36:00 layer   2  Sparsity: 54.1470%

2025-11-18 14:36:00 layer   3  Sparsity: 53.1672%

2025-11-18 14:36:00 total_backward_count 39160 real_backward_count 9780  24.974%

2025-11-18 14:37:08 epoch-4   lr=['0.0039062'], tr/val_loss:  0.037874/  0.067115, val:  56.67%, val_best:  56.67%, tr:  90.81%, tr_best:  90.81%, epoch time: 68.51 seconds, 1.14 minutes

2025-11-18 14:37:08 layer   1  Sparsity: 91.0656%

2025-11-18 14:37:08 layer   2  Sparsity: 53.9633%

2025-11-18 14:37:08 layer   3  Sparsity: 52.9818%

2025-11-18 14:37:08 total_backward_count 48950 real_backward_count 11524  23.542%

2025-11-18 14:38:19 epoch-5   lr=['0.0039062'], tr/val_loss:  0.037105/  0.061044, val:  62.92%, val_best:  62.92%, tr:  90.81%, tr_best:  90.81%, epoch time: 69.35 seconds, 1.16 minutes

2025-11-18 14:38:19 layer   1  Sparsity: 91.0445%

2025-11-18 14:38:19 layer   2  Sparsity: 53.9559%

2025-11-18 14:38:19 layer   3  Sparsity: 52.7800%

2025-11-18 14:38:19 total_backward_count 58740 real_backward_count 13249  22.555%

2025-11-18 14:39:27 epoch-6   lr=['0.0039062'], tr/val_loss:  0.035615/  0.072307, val:  55.42%, val_best:  62.92%, tr:  90.81%, tr_best:  90.81%, epoch time: 69.72 seconds, 1.16 minutes

2025-11-18 14:39:27 layer   1  Sparsity: 91.0751%

2025-11-18 14:39:27 layer   2  Sparsity: 53.7495%

2025-11-18 14:39:27 layer   3  Sparsity: 52.2108%

2025-11-18 14:39:27 total_backward_count 68530 real_backward_count 14955  21.823%

2025-11-18 14:40:37 epoch-7   lr=['0.0039062'], tr/val_loss:  0.033337/  0.064388, val:  59.58%, val_best:  62.92%, tr:  92.95%, tr_best:  92.95%, epoch time: 69.12 seconds, 1.15 minutes

2025-11-18 14:40:37 layer   1  Sparsity: 91.0814%

2025-11-18 14:40:37 layer   2  Sparsity: 53.7830%

2025-11-18 14:40:37 layer   3  Sparsity: 52.1589%

2025-11-18 14:40:37 total_backward_count 78320 real_backward_count 16445  20.997%

2025-11-18 14:41:47 epoch-8   lr=['0.0039062'], tr/val_loss:  0.033116/  0.056706, val:  65.42%, val_best:  65.42%, tr:  93.26%, tr_best:  93.26%, epoch time: 69.26 seconds, 1.15 minutes

2025-11-18 14:41:47 layer   1  Sparsity: 91.0400%

2025-11-18 14:41:47 layer   2  Sparsity: 53.8875%

2025-11-18 14:41:47 layer   3  Sparsity: 51.5873%

2025-11-18 14:41:47 total_backward_count 88110 real_backward_count 17923  20.342%

2025-11-18 14:42:55 epoch-9   lr=['0.0039062'], tr/val_loss:  0.032050/  0.060484, val:  64.58%, val_best:  65.42%, tr:  94.18%, tr_best:  94.18%, epoch time: 68.88 seconds, 1.15 minutes

2025-11-18 14:42:55 layer   1  Sparsity: 91.1088%

2025-11-18 14:42:55 layer   2  Sparsity: 53.8635%

2025-11-18 14:42:55 layer   3  Sparsity: 51.4186%

2025-11-18 14:42:55 total_backward_count 97900 real_backward_count 19325  19.740%

2025-11-18 14:44:05 epoch-10  lr=['0.0039062'], tr/val_loss:  0.031206/  0.064576, val:  59.17%, val_best:  65.42%, tr:  95.30%, tr_best:  95.30%, epoch time: 69.65 seconds, 1.16 minutes

2025-11-18 14:44:05 layer   1  Sparsity: 91.0669%

2025-11-18 14:44:05 layer   2  Sparsity: 53.8042%

2025-11-18 14:44:05 layer   3  Sparsity: 51.1857%

2025-11-18 14:44:05 total_backward_count 107690 real_backward_count 20661  19.186%

2025-11-18 14:45:15 epoch-11  lr=['0.0039062'], tr/val_loss:  0.030873/  0.062843, val:  64.58%, val_best:  65.42%, tr:  94.28%, tr_best:  95.30%, epoch time: 69.82 seconds, 1.16 minutes

2025-11-18 14:45:15 layer   1  Sparsity: 91.0561%

2025-11-18 14:45:15 layer   2  Sparsity: 53.6479%

2025-11-18 14:45:15 layer   3  Sparsity: 51.4914%

2025-11-18 14:45:15 total_backward_count 117480 real_backward_count 22054  18.773%

2025-11-18 14:46:25 epoch-12  lr=['0.0039062'], tr/val_loss:  0.029028/  0.065344, val:  60.83%, val_best:  65.42%, tr:  96.53%, tr_best:  96.53%, epoch time: 69.89 seconds, 1.16 minutes

2025-11-18 14:46:25 layer   1  Sparsity: 91.0973%

2025-11-18 14:46:25 layer   2  Sparsity: 53.8317%

2025-11-18 14:46:25 layer   3  Sparsity: 51.4325%

2025-11-18 14:46:25 total_backward_count 127270 real_backward_count 23291  18.300%

2025-11-18 14:47:35 epoch-13  lr=['0.0039062'], tr/val_loss:  0.028675/  0.068922, val:  57.08%, val_best:  65.42%, tr:  95.51%, tr_best:  96.53%, epoch time: 69.97 seconds, 1.17 minutes

2025-11-18 14:47:35 layer   1  Sparsity: 91.1077%

2025-11-18 14:47:35 layer   2  Sparsity: 54.1086%

2025-11-18 14:47:35 layer   3  Sparsity: 51.3875%

2025-11-18 14:47:35 total_backward_count 137060 real_backward_count 24523  17.892%

2025-11-18 14:48:45 epoch-14  lr=['0.0039062'], tr/val_loss:  0.027449/  0.062796, val:  63.33%, val_best:  65.42%, tr:  97.96%, tr_best:  97.96%, epoch time: 69.63 seconds, 1.16 minutes

2025-11-18 14:48:45 layer   1  Sparsity: 91.1002%

2025-11-18 14:48:45 layer   2  Sparsity: 54.2976%

2025-11-18 14:48:45 layer   3  Sparsity: 51.2759%

2025-11-18 14:48:45 total_backward_count 146850 real_backward_count 25692  17.495%

2025-11-18 14:49:53 epoch-15  lr=['0.0039062'], tr/val_loss:  0.027537/  0.057694, val:  66.67%, val_best:  66.67%, tr:  96.32%, tr_best:  97.96%, epoch time: 69.26 seconds, 1.15 minutes

2025-11-18 14:49:53 layer   1  Sparsity: 91.0674%

2025-11-18 14:49:53 layer   2  Sparsity: 54.2638%

2025-11-18 14:49:53 layer   3  Sparsity: 51.6314%

2025-11-18 14:49:53 total_backward_count 156640 real_backward_count 26904  17.176%

2025-11-18 14:51:03 epoch-16  lr=['0.0039062'], tr/val_loss:  0.025613/  0.055983, val:  73.75%, val_best:  73.75%, tr:  98.06%, tr_best:  98.06%, epoch time: 69.72 seconds, 1.16 minutes

2025-11-18 14:51:03 layer   1  Sparsity: 91.0784%

2025-11-18 14:51:03 layer   2  Sparsity: 54.4321%

2025-11-18 14:51:03 layer   3  Sparsity: 51.1927%

2025-11-18 14:51:03 total_backward_count 166430 real_backward_count 27969  16.805%

2025-11-18 14:52:13 epoch-17  lr=['0.0039062'], tr/val_loss:  0.025910/  0.055004, val:  70.42%, val_best:  73.75%, tr:  97.85%, tr_best:  98.06%, epoch time: 69.22 seconds, 1.15 minutes

2025-11-18 14:52:13 layer   1  Sparsity: 91.0582%

2025-11-18 14:52:13 layer   2  Sparsity: 54.6100%

2025-11-18 14:52:13 layer   3  Sparsity: 51.0862%

2025-11-18 14:52:13 total_backward_count 176220 real_backward_count 29061  16.491%

2025-11-18 14:53:21 epoch-18  lr=['0.0039062'], tr/val_loss:  0.025980/  0.063570, val:  67.50%, val_best:  73.75%, tr:  98.57%, tr_best:  98.57%, epoch time: 69.08 seconds, 1.15 minutes

2025-11-18 14:53:21 layer   1  Sparsity: 91.0775%

2025-11-18 14:53:21 layer   2  Sparsity: 54.7519%

2025-11-18 14:53:21 layer   3  Sparsity: 50.8728%

2025-11-18 14:53:21 total_backward_count 186010 real_backward_count 30157  16.213%

2025-11-18 14:54:32 epoch-19  lr=['0.0039062'], tr/val_loss:  0.024227/  0.059071, val:  67.08%, val_best:  73.75%, tr:  98.77%, tr_best:  98.77%, epoch time: 69.27 seconds, 1.15 minutes

2025-11-18 14:54:32 layer   1  Sparsity: 91.0666%

2025-11-18 14:54:32 layer   2  Sparsity: 54.8321%

2025-11-18 14:54:32 layer   3  Sparsity: 50.5648%

2025-11-18 14:54:32 total_backward_count 195800 real_backward_count 31117  15.892%

2025-11-18 14:55:42 epoch-20  lr=['0.0039062'], tr/val_loss:  0.024356/  0.054849, val:  72.08%, val_best:  73.75%, tr:  99.08%, tr_best:  99.08%, epoch time: 69.56 seconds, 1.16 minutes

2025-11-18 14:55:42 layer   1  Sparsity: 91.0808%

2025-11-18 14:55:42 layer   2  Sparsity: 54.8272%

2025-11-18 14:55:42 layer   3  Sparsity: 50.7228%

2025-11-18 14:55:42 total_backward_count 205590 real_backward_count 32131  15.629%

2025-11-18 14:56:52 epoch-21  lr=['0.0039062'], tr/val_loss:  0.024107/  0.055709, val:  71.67%, val_best:  73.75%, tr:  98.67%, tr_best:  99.08%, epoch time: 69.65 seconds, 1.16 minutes

2025-11-18 14:56:52 layer   1  Sparsity: 91.0661%

2025-11-18 14:56:52 layer   2  Sparsity: 54.8007%

2025-11-18 14:56:52 layer   3  Sparsity: 50.7225%

2025-11-18 14:56:52 total_backward_count 215380 real_backward_count 33128  15.381%

2025-11-18 14:58:00 epoch-22  lr=['0.0039062'], tr/val_loss:  0.023228/  0.050947, val:  77.50%, val_best:  77.50%, tr:  99.08%, tr_best:  99.08%, epoch time: 69.14 seconds, 1.15 minutes

2025-11-18 14:58:00 layer   1  Sparsity: 91.0930%

2025-11-18 14:58:00 layer   2  Sparsity: 54.8251%

2025-11-18 14:58:00 layer   3  Sparsity: 50.7613%

2025-11-18 14:58:00 total_backward_count 225170 real_backward_count 34086  15.138%

2025-11-18 14:59:10 epoch-23  lr=['0.0039062'], tr/val_loss:  0.022802/  0.050403, val:  78.33%, val_best:  78.33%, tr:  98.98%, tr_best:  99.08%, epoch time: 69.11 seconds, 1.15 minutes

2025-11-18 14:59:10 layer   1  Sparsity: 91.0433%

2025-11-18 14:59:10 layer   2  Sparsity: 54.8906%

2025-11-18 14:59:10 layer   3  Sparsity: 50.8768%

2025-11-18 14:59:10 total_backward_count 234960 real_backward_count 35002  14.897%

2025-11-18 15:00:18 epoch-24  lr=['0.0039062'], tr/val_loss:  0.022053/  0.047033, val:  83.33%, val_best:  83.33%, tr:  99.39%, tr_best:  99.39%, epoch time: 69.51 seconds, 1.16 minutes

2025-11-18 15:00:18 layer   1  Sparsity: 91.0714%

2025-11-18 15:00:18 layer   2  Sparsity: 55.0268%

2025-11-18 15:00:18 layer   3  Sparsity: 50.7113%

2025-11-18 15:00:18 total_backward_count 244750 real_backward_count 35898  14.667%

2025-11-18 15:01:28 epoch-25  lr=['0.0039062'], tr/val_loss:  0.022261/  0.045933, val:  83.75%, val_best:  83.75%, tr:  99.18%, tr_best:  99.39%, epoch time: 69.58 seconds, 1.16 minutes

2025-11-18 15:01:28 layer   1  Sparsity: 91.0926%

2025-11-18 15:01:28 layer   2  Sparsity: 55.1450%

2025-11-18 15:01:28 layer   3  Sparsity: 50.7308%

2025-11-18 15:01:28 total_backward_count 254540 real_backward_count 36803  14.459%

2025-11-18 15:02:38 epoch-26  lr=['0.0039062'], tr/val_loss:  0.020904/  0.046194, val:  82.50%, val_best:  83.75%, tr:  99.49%, tr_best:  99.49%, epoch time: 69.61 seconds, 1.16 minutes

2025-11-18 15:02:38 layer   1  Sparsity: 91.0812%

2025-11-18 15:02:38 layer   2  Sparsity: 55.0820%

2025-11-18 15:02:38 layer   3  Sparsity: 50.4126%

2025-11-18 15:02:38 total_backward_count 264330 real_backward_count 37594  14.222%

2025-11-18 15:03:48 epoch-27  lr=['0.0039062'], tr/val_loss:  0.021340/  0.045608, val:  81.25%, val_best:  83.75%, tr:  99.28%, tr_best:  99.49%, epoch time: 69.51 seconds, 1.16 minutes

2025-11-18 15:03:48 layer   1  Sparsity: 91.0860%

2025-11-18 15:03:48 layer   2  Sparsity: 55.2331%

2025-11-18 15:03:48 layer   3  Sparsity: 50.2699%

2025-11-18 15:03:48 total_backward_count 274120 real_backward_count 38453  14.028%

2025-11-18 15:04:56 epoch-28  lr=['0.0039062'], tr/val_loss:  0.020196/  0.047527, val:  81.25%, val_best:  83.75%, tr:  99.28%, tr_best:  99.49%, epoch time: 68.97 seconds, 1.15 minutes

2025-11-18 15:04:56 layer   1  Sparsity: 91.0870%

2025-11-18 15:04:56 layer   2  Sparsity: 55.3352%

2025-11-18 15:04:56 layer   3  Sparsity: 50.3980%

2025-11-18 15:04:56 total_backward_count 283910 real_backward_count 39256  13.827%

2025-11-18 15:06:06 epoch-29  lr=['0.0039062'], tr/val_loss:  0.020553/  0.050171, val:  77.08%, val_best:  83.75%, tr:  98.98%, tr_best:  99.49%, epoch time: 69.38 seconds, 1.16 minutes

2025-11-18 15:06:06 layer   1  Sparsity: 91.0873%

2025-11-18 15:06:06 layer   2  Sparsity: 55.3094%

2025-11-18 15:06:06 layer   3  Sparsity: 50.5167%

2025-11-18 15:06:06 total_backward_count 293700 real_backward_count 40094  13.651%

2025-11-18 15:07:16 epoch-30  lr=['0.0039062'], tr/val_loss:  0.019845/  0.045053, val:  82.92%, val_best:  83.75%, tr:  99.49%, tr_best:  99.49%, epoch time: 69.07 seconds, 1.15 minutes

2025-11-18 15:07:16 layer   1  Sparsity: 91.1149%

2025-11-18 15:07:16 layer   2  Sparsity: 55.3224%

2025-11-18 15:07:16 layer   3  Sparsity: 50.2474%

2025-11-18 15:07:16 total_backward_count 303490 real_backward_count 40844  13.458%

2025-11-18 15:08:24 epoch-31  lr=['0.0039062'], tr/val_loss:  0.019658/  0.045326, val:  80.42%, val_best:  83.75%, tr:  99.69%, tr_best:  99.69%, epoch time: 68.80 seconds, 1.15 minutes

2025-11-18 15:08:24 layer   1  Sparsity: 91.0914%

2025-11-18 15:08:24 layer   2  Sparsity: 55.3313%

2025-11-18 15:08:24 layer   3  Sparsity: 50.1134%

2025-11-18 15:08:24 total_backward_count 313280 real_backward_count 41578  13.272%

2025-11-18 15:09:32 epoch-32  lr=['0.0039062'], tr/val_loss:  0.019063/  0.046495, val:  80.00%, val_best:  83.75%, tr:  99.18%, tr_best:  99.69%, epoch time: 68.18 seconds, 1.14 minutes

2025-11-18 15:09:32 layer   1  Sparsity: 91.0848%

2025-11-18 15:09:32 layer   2  Sparsity: 55.3107%

2025-11-18 15:09:32 layer   3  Sparsity: 50.6105%

2025-11-18 15:09:32 total_backward_count 323070 real_backward_count 42307  13.095%

2025-11-18 15:10:41 epoch-33  lr=['0.0039062'], tr/val_loss:  0.019067/  0.049657, val:  81.25%, val_best:  83.75%, tr:  99.69%, tr_best:  99.69%, epoch time: 67.96 seconds, 1.13 minutes

2025-11-18 15:10:41 layer   1  Sparsity: 91.0707%

2025-11-18 15:10:41 layer   2  Sparsity: 55.5277%

2025-11-18 15:10:41 layer   3  Sparsity: 50.6210%

2025-11-18 15:10:41 total_backward_count 332860 real_backward_count 43025  12.926%

2025-11-18 15:11:49 epoch-34  lr=['0.0039062'], tr/val_loss:  0.018618/  0.048899, val:  74.17%, val_best:  83.75%, tr:  99.49%, tr_best:  99.69%, epoch time: 68.80 seconds, 1.15 minutes

2025-11-18 15:11:49 layer   1  Sparsity: 91.1050%

2025-11-18 15:11:49 layer   2  Sparsity: 55.3730%

2025-11-18 15:11:49 layer   3  Sparsity: 50.6954%

2025-11-18 15:11:49 total_backward_count 342650 real_backward_count 43754  12.769%

2025-11-18 15:12:59 epoch-35  lr=['0.0039062'], tr/val_loss:  0.018990/  0.043689, val:  81.67%, val_best:  83.75%, tr:  99.39%, tr_best:  99.69%, epoch time: 68.93 seconds, 1.15 minutes

2025-11-18 15:12:59 layer   1  Sparsity: 91.1053%

2025-11-18 15:12:59 layer   2  Sparsity: 55.4055%

2025-11-18 15:12:59 layer   3  Sparsity: 50.8895%

2025-11-18 15:12:59 total_backward_count 352440 real_backward_count 44508  12.629%

2025-11-18 15:14:07 epoch-36  lr=['0.0039062'], tr/val_loss:  0.018410/  0.041367, val:  85.42%, val_best:  85.42%, tr:  99.39%, tr_best:  99.69%, epoch time: 69.18 seconds, 1.15 minutes

2025-11-18 15:14:09 layer   1  Sparsity: 91.0572%

2025-11-18 15:14:09 layer   2  Sparsity: 55.5358%

2025-11-18 15:14:09 layer   3  Sparsity: 50.8717%

2025-11-18 15:14:09 total_backward_count 362230 real_backward_count 45233  12.487%

2025-11-18 15:15:17 epoch-37  lr=['0.0039062'], tr/val_loss:  0.017471/  0.052860, val:  72.50%, val_best:  85.42%, tr:  99.59%, tr_best:  99.69%, epoch time: 69.21 seconds, 1.15 minutes

2025-11-18 15:15:17 layer   1  Sparsity: 91.0972%

2025-11-18 15:15:17 layer   2  Sparsity: 55.3825%

2025-11-18 15:15:17 layer   3  Sparsity: 50.7820%

2025-11-18 15:15:17 total_backward_count 372020 real_backward_count 45888  12.335%

2025-11-18 15:16:27 epoch-38  lr=['0.0039062'], tr/val_loss:  0.018078/  0.044461, val:  83.33%, val_best:  85.42%, tr:  99.80%, tr_best:  99.80%, epoch time: 69.34 seconds, 1.16 minutes

2025-11-18 15:16:27 layer   1  Sparsity: 91.0952%

2025-11-18 15:16:27 layer   2  Sparsity: 55.3498%

2025-11-18 15:16:27 layer   3  Sparsity: 50.8361%

2025-11-18 15:16:27 total_backward_count 381810 real_backward_count 46588  12.202%

2025-11-18 15:17:35 epoch-39  lr=['0.0039062'], tr/val_loss:  0.017718/  0.043099, val:  83.75%, val_best:  85.42%, tr:  99.49%, tr_best:  99.80%, epoch time: 69.33 seconds, 1.16 minutes

2025-11-18 15:17:35 layer   1  Sparsity: 91.0679%

2025-11-18 15:17:35 layer   2  Sparsity: 55.5156%

2025-11-18 15:17:35 layer   3  Sparsity: 50.8501%

2025-11-18 15:17:35 total_backward_count 391600 real_backward_count 47254  12.067%

2025-11-18 15:18:45 epoch-40  lr=['0.0039062'], tr/val_loss:  0.017480/  0.041667, val:  85.00%, val_best:  85.42%, tr:  99.49%, tr_best:  99.80%, epoch time: 69.54 seconds, 1.16 minutes

2025-11-18 15:18:45 layer   1  Sparsity: 91.1176%

2025-11-18 15:18:45 layer   2  Sparsity: 55.5673%

2025-11-18 15:18:45 layer   3  Sparsity: 50.8194%

2025-11-18 15:18:45 total_backward_count 401390 real_backward_count 47909  11.936%

2025-11-18 15:19:55 epoch-41  lr=['0.0039062'], tr/val_loss:  0.017038/  0.047281, val:  82.08%, val_best:  85.42%, tr:  99.69%, tr_best:  99.80%, epoch time: 68.92 seconds, 1.15 minutes

2025-11-18 15:19:55 layer   1  Sparsity: 91.0735%

2025-11-18 15:19:55 layer   2  Sparsity: 55.6766%

2025-11-18 15:19:55 layer   3  Sparsity: 50.8264%

2025-11-18 15:19:55 total_backward_count 411180 real_backward_count 48565  11.811%

2025-11-18 15:21:03 epoch-42  lr=['0.0039062'], tr/val_loss:  0.016763/  0.040637, val:  87.92%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 68.78 seconds, 1.15 minutes

2025-11-18 15:21:03 layer   1  Sparsity: 91.0646%

2025-11-18 15:21:03 layer   2  Sparsity: 55.6364%

2025-11-18 15:21:03 layer   3  Sparsity: 50.9215%

2025-11-18 15:21:03 total_backward_count 420970 real_backward_count 49212  11.690%

2025-11-18 15:22:13 epoch-43  lr=['0.0039062'], tr/val_loss:  0.017021/  0.041091, val:  85.83%, val_best:  87.92%, tr:  99.49%, tr_best:  99.80%, epoch time: 69.08 seconds, 1.15 minutes

2025-11-18 15:22:13 layer   1  Sparsity: 91.0437%

2025-11-18 15:22:13 layer   2  Sparsity: 55.6352%

2025-11-18 15:22:13 layer   3  Sparsity: 50.8227%

2025-11-18 15:22:13 total_backward_count 430760 real_backward_count 49835  11.569%

2025-11-18 15:23:21 epoch-44  lr=['0.0039062'], tr/val_loss:  0.016791/  0.043273, val:  80.83%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 69.64 seconds, 1.16 minutes

2025-11-18 15:23:21 layer   1  Sparsity: 91.0867%

2025-11-18 15:23:21 layer   2  Sparsity: 55.6238%

2025-11-18 15:23:21 layer   3  Sparsity: 50.9771%

2025-11-18 15:23:23 total_backward_count 440550 real_backward_count 50484  11.459%

2025-11-18 15:24:31 epoch-45  lr=['0.0039062'], tr/val_loss:  0.016594/  0.041954, val:  85.42%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 69.44 seconds, 1.16 minutes

2025-11-18 15:24:31 layer   1  Sparsity: 91.0767%

2025-11-18 15:24:31 layer   2  Sparsity: 55.6443%

2025-11-18 15:24:31 layer   3  Sparsity: 50.9369%

2025-11-18 15:24:31 total_backward_count 450340 real_backward_count 51107  11.349%

2025-11-18 15:25:41 epoch-46  lr=['0.0039062'], tr/val_loss:  0.016444/  0.043968, val:  81.67%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 68.79 seconds, 1.15 minutes

2025-11-18 15:25:41 layer   1  Sparsity: 91.0994%

2025-11-18 15:25:41 layer   2  Sparsity: 55.6516%

2025-11-18 15:25:41 layer   3  Sparsity: 50.7073%

2025-11-18 15:25:41 total_backward_count 460130 real_backward_count 51738  11.244%

2025-11-18 15:26:50 epoch-47  lr=['0.0039062'], tr/val_loss:  0.016048/  0.051185, val:  80.00%, val_best:  87.92%, tr:  99.80%, tr_best:  99.80%, epoch time: 69.20 seconds, 1.15 minutes

2025-11-18 15:26:50 layer   1  Sparsity: 91.0787%

2025-11-18 15:26:50 layer   2  Sparsity: 55.7126%

2025-11-18 15:26:50 layer   3  Sparsity: 50.6553%

2025-11-18 15:26:50 total_backward_count 469920 real_backward_count 52314  11.133%

2025-11-18 15:28:00 epoch-48  lr=['0.0039062'], tr/val_loss:  0.015499/  0.040252, val:  85.00%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 69.41 seconds, 1.16 minutes

2025-11-18 15:28:00 layer   1  Sparsity: 91.1031%

2025-11-18 15:28:00 layer   2  Sparsity: 55.6927%

2025-11-18 15:28:00 layer   3  Sparsity: 50.7258%

2025-11-18 15:28:00 total_backward_count 479710 real_backward_count 52888  11.025%

2025-11-18 15:29:10 epoch-49  lr=['0.0039062'], tr/val_loss:  0.015141/  0.041055, val:  85.42%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 69.58 seconds, 1.16 minutes

2025-11-18 15:29:10 layer   1  Sparsity: 91.0213%

2025-11-18 15:29:10 layer   2  Sparsity: 55.5565%

2025-11-18 15:29:10 layer   3  Sparsity: 50.7544%

2025-11-18 15:29:10 total_backward_count 489500 real_backward_count 53443  10.918%

2025-11-18 15:30:18 epoch-50  lr=['0.0039062'], tr/val_loss:  0.015531/  0.042127, val:  81.67%, val_best:  87.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 69.09 seconds, 1.15 minutes

2025-11-18 15:30:18 layer   1  Sparsity: 91.0838%

2025-11-18 15:30:18 layer   2  Sparsity: 55.7416%

2025-11-18 15:30:18 layer   3  Sparsity: 50.7813%

2025-11-18 15:30:18 total_backward_count 499290 real_backward_count 54025  10.820%

2025-11-18 15:31:28 epoch-51  lr=['0.0039062'], tr/val_loss:  0.015105/  0.038628, val:  88.33%, val_best:  88.33%, tr:  99.90%, tr_best:  99.90%, epoch time: 69.05 seconds, 1.15 minutes

2025-11-18 15:31:28 layer   1  Sparsity: 91.0755%

2025-11-18 15:31:28 layer   2  Sparsity: 55.6920%

2025-11-18 15:31:28 layer   3  Sparsity: 50.8519%

2025-11-18 15:31:28 total_backward_count 509080 real_backward_count 54582  10.722%

2025-11-18 15:32:36 epoch-52  lr=['0.0039062'], tr/val_loss:  0.015384/  0.044381, val:  82.92%, val_best:  88.33%, tr:  99.69%, tr_best:  99.90%, epoch time: 69.33 seconds, 1.16 minutes

2025-11-18 15:32:36 layer   1  Sparsity: 91.0562%

2025-11-18 15:32:36 layer   2  Sparsity: 55.7621%

2025-11-18 15:32:36 layer   3  Sparsity: 50.7903%

2025-11-18 15:32:36 total_backward_count 518870 real_backward_count 55166  10.632%

2025-11-18 15:33:46 epoch-53  lr=['0.0039062'], tr/val_loss:  0.015235/  0.040826, val:  86.25%, val_best:  88.33%, tr:  99.80%, tr_best:  99.90%, epoch time: 69.00 seconds, 1.15 minutes

2025-11-18 15:33:46 layer   1  Sparsity: 91.0452%

2025-11-18 15:33:46 layer   2  Sparsity: 55.7296%

2025-11-18 15:33:46 layer   3  Sparsity: 50.6591%

2025-11-18 15:33:46 total_backward_count 528660 real_backward_count 55719  10.540%

2025-11-18 15:34:56 epoch-54  lr=['0.0039062'], tr/val_loss:  0.015056/  0.037452, val:  85.00%, val_best:  88.33%, tr:  99.90%, tr_best:  99.90%, epoch time: 69.60 seconds, 1.16 minutes

2025-11-18 15:34:56 layer   1  Sparsity: 91.0646%

2025-11-18 15:34:56 layer   2  Sparsity: 55.7666%

2025-11-18 15:34:56 layer   3  Sparsity: 50.6716%

2025-11-18 15:34:56 total_backward_count 538450 real_backward_count 56278  10.452%

2025-11-18 15:36:04 epoch-55  lr=['0.0039062'], tr/val_loss:  0.014819/  0.038303, val:  86.67%, val_best:  88.33%, tr:  99.59%, tr_best:  99.90%, epoch time: 68.52 seconds, 1.14 minutes

2025-11-18 15:36:04 layer   1  Sparsity: 91.1056%

2025-11-18 15:36:04 layer   2  Sparsity: 55.7371%

2025-11-18 15:36:04 layer   3  Sparsity: 50.7142%

2025-11-18 15:36:04 total_backward_count 548240 real_backward_count 56852  10.370%

2025-11-18 15:37:14 epoch-56  lr=['0.0039062'], tr/val_loss:  0.014778/  0.042373, val:  82.92%, val_best:  88.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.99 seconds, 1.15 minutes

2025-11-18 15:37:14 layer   1  Sparsity: 91.0299%

2025-11-18 15:37:14 layer   2  Sparsity: 55.5764%

2025-11-18 15:37:14 layer   3  Sparsity: 50.7676%

2025-11-18 15:37:14 total_backward_count 558030 real_backward_count 57421  10.290%

2025-11-18 15:38:22 epoch-57  lr=['0.0039062'], tr/val_loss:  0.014384/  0.037970, val:  87.50%, val_best:  88.33%, tr:  99.59%, tr_best: 100.00%, epoch time: 69.28 seconds, 1.15 minutes

2025-11-18 15:38:22 layer   1  Sparsity: 91.0367%

2025-11-18 15:38:22 layer   2  Sparsity: 55.7215%

2025-11-18 15:38:22 layer   3  Sparsity: 50.7597%

2025-11-18 15:38:22 total_backward_count 567820 real_backward_count 57932  10.203%

2025-11-18 15:39:32 epoch-58  lr=['0.0039062'], tr/val_loss:  0.014574/  0.040316, val:  86.67%, val_best:  88.33%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.19 seconds, 1.15 minutes

2025-11-18 15:39:32 layer   1  Sparsity: 91.0634%

2025-11-18 15:39:32 layer   2  Sparsity: 55.7215%

2025-11-18 15:39:32 layer   3  Sparsity: 50.8014%

2025-11-18 15:39:32 total_backward_count 577610 real_backward_count 58484  10.125%

2025-11-18 15:40:40 epoch-59  lr=['0.0039062'], tr/val_loss:  0.014241/  0.038531, val:  85.83%, val_best:  88.33%, tr:  99.69%, tr_best: 100.00%, epoch time: 69.15 seconds, 1.15 minutes

2025-11-18 15:40:40 layer   1  Sparsity: 91.0853%

2025-11-18 15:40:40 layer   2  Sparsity: 55.7124%

2025-11-18 15:40:40 layer   3  Sparsity: 50.5874%

2025-11-18 15:40:40 total_backward_count 587400 real_backward_count 58994  10.043%

2025-11-18 15:41:50 epoch-60  lr=['0.0039062'], tr/val_loss:  0.014227/  0.038685, val:  87.08%, val_best:  88.33%, tr:  99.69%, tr_best: 100.00%, epoch time: 69.00 seconds, 1.15 minutes

2025-11-18 15:41:50 layer   1  Sparsity: 91.0784%

2025-11-18 15:41:50 layer   2  Sparsity: 55.6970%

2025-11-18 15:41:50 layer   3  Sparsity: 50.6241%

2025-11-18 15:41:50 total_backward_count 597190 real_backward_count 59511   9.965%

2025-11-18 15:42:58 epoch-61  lr=['0.0039062'], tr/val_loss:  0.014475/  0.039351, val:  88.75%, val_best:  88.75%, tr:  99.59%, tr_best: 100.00%, epoch time: 68.80 seconds, 1.15 minutes

2025-11-18 15:42:58 layer   1  Sparsity: 91.0350%

2025-11-18 15:42:58 layer   2  Sparsity: 55.6770%

2025-11-18 15:42:58 layer   3  Sparsity: 50.7091%

2025-11-18 15:42:58 total_backward_count 606980 real_backward_count 60056   9.894%

2025-11-18 15:44:09 epoch-62  lr=['0.0039062'], tr/val_loss:  0.014158/  0.039859, val:  85.83%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.79 seconds, 1.15 minutes

2025-11-18 15:44:09 layer   1  Sparsity: 91.0837%

2025-11-18 15:44:09 layer   2  Sparsity: 55.6885%

2025-11-18 15:44:09 layer   3  Sparsity: 50.7332%

2025-11-18 15:44:09 total_backward_count 616770 real_backward_count 60586   9.823%

2025-11-18 15:45:17 epoch-63  lr=['0.0039062'], tr/val_loss:  0.013723/  0.041968, val:  83.75%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.50 seconds, 1.14 minutes

2025-11-18 15:45:17 layer   1  Sparsity: 91.0488%

2025-11-18 15:45:17 layer   2  Sparsity: 55.6856%

2025-11-18 15:45:17 layer   3  Sparsity: 50.7824%

2025-11-18 15:45:17 total_backward_count 626560 real_backward_count 61097   9.751%

2025-11-18 15:46:27 epoch-64  lr=['0.0039062'], tr/val_loss:  0.013843/  0.039179, val:  84.58%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.17 seconds, 1.15 minutes

2025-11-18 15:46:27 layer   1  Sparsity: 91.0919%

2025-11-18 15:46:27 layer   2  Sparsity: 55.6260%

2025-11-18 15:46:27 layer   3  Sparsity: 50.8667%

2025-11-18 15:46:27 total_backward_count 636350 real_backward_count 61629   9.685%

2025-11-18 15:47:35 epoch-65  lr=['0.0039062'], tr/val_loss:  0.013377/  0.039303, val:  87.08%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.49 seconds, 1.14 minutes

2025-11-18 15:47:35 layer   1  Sparsity: 91.0565%

2025-11-18 15:47:35 layer   2  Sparsity: 55.7131%

2025-11-18 15:47:35 layer   3  Sparsity: 50.8703%

2025-11-18 15:47:35 total_backward_count 646140 real_backward_count 62106   9.612%

2025-11-18 15:48:43 epoch-66  lr=['0.0039062'], tr/val_loss:  0.013503/  0.040930, val:  84.17%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.32 seconds, 1.16 minutes

2025-11-18 15:48:43 layer   1  Sparsity: 91.0584%

2025-11-18 15:48:43 layer   2  Sparsity: 55.8368%

2025-11-18 15:48:43 layer   3  Sparsity: 50.7317%

2025-11-18 15:48:45 total_backward_count 655930 real_backward_count 62605   9.544%

2025-11-18 15:49:53 epoch-67  lr=['0.0039062'], tr/val_loss:  0.013601/  0.037889, val:  86.25%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.68 seconds, 1.14 minutes

2025-11-18 15:49:53 layer   1  Sparsity: 91.0433%

2025-11-18 15:49:53 layer   2  Sparsity: 55.7374%

2025-11-18 15:49:53 layer   3  Sparsity: 50.6558%

2025-11-18 15:49:53 total_backward_count 665720 real_backward_count 63106   9.479%

2025-11-18 15:51:03 epoch-68  lr=['0.0039062'], tr/val_loss:  0.013213/  0.040014, val:  87.50%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.35 seconds, 1.16 minutes

2025-11-18 15:51:03 layer   1  Sparsity: 91.0797%

2025-11-18 15:51:03 layer   2  Sparsity: 55.7613%

2025-11-18 15:51:03 layer   3  Sparsity: 50.7056%

2025-11-18 15:51:03 total_backward_count 675510 real_backward_count 63595   9.414%

2025-11-18 15:52:11 epoch-69  lr=['0.0039062'], tr/val_loss:  0.012943/  0.040986, val:  83.75%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.72 seconds, 1.15 minutes

2025-11-18 15:52:11 layer   1  Sparsity: 91.0853%

2025-11-18 15:52:11 layer   2  Sparsity: 55.7067%

2025-11-18 15:52:11 layer   3  Sparsity: 50.6200%

2025-11-18 15:52:11 total_backward_count 685300 real_backward_count 64069   9.349%

2025-11-18 15:53:21 epoch-70  lr=['0.0039062'], tr/val_loss:  0.013317/  0.037610, val:  85.00%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.34 seconds, 1.16 minutes

2025-11-18 15:53:21 layer   1  Sparsity: 91.0675%

2025-11-18 15:53:21 layer   2  Sparsity: 55.6535%

2025-11-18 15:53:21 layer   3  Sparsity: 50.7786%

2025-11-18 15:53:21 total_backward_count 695090 real_backward_count 64553   9.287%

2025-11-18 15:54:29 epoch-71  lr=['0.0039062'], tr/val_loss:  0.013042/  0.041307, val:  82.50%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.99 seconds, 1.15 minutes

2025-11-18 15:54:29 layer   1  Sparsity: 91.0901%

2025-11-18 15:54:29 layer   2  Sparsity: 55.7415%

2025-11-18 15:54:29 layer   3  Sparsity: 50.7700%

2025-11-18 15:54:29 total_backward_count 704880 real_backward_count 65021   9.224%

2025-11-18 15:55:39 epoch-72  lr=['0.0039062'], tr/val_loss:  0.012482/  0.040226, val:  85.42%, val_best:  88.75%, tr:  99.69%, tr_best: 100.00%, epoch time: 70.16 seconds, 1.17 minutes

2025-11-18 15:55:39 layer   1  Sparsity: 91.0943%

2025-11-18 15:55:39 layer   2  Sparsity: 55.7221%

2025-11-18 15:55:39 layer   3  Sparsity: 50.7529%

2025-11-18 15:55:39 total_backward_count 714670 real_backward_count 65475   9.162%

2025-11-18 15:56:49 epoch-73  lr=['0.0039062'], tr/val_loss:  0.012259/  0.041680, val:  82.50%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.46 seconds, 1.16 minutes

2025-11-18 15:56:49 layer   1  Sparsity: 91.0797%

2025-11-18 15:56:49 layer   2  Sparsity: 55.7096%

2025-11-18 15:56:49 layer   3  Sparsity: 50.8723%

2025-11-18 15:56:49 total_backward_count 724460 real_backward_count 65877   9.093%

2025-11-18 15:57:59 epoch-74  lr=['0.0039062'], tr/val_loss:  0.012656/  0.039311, val:  85.00%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.23 seconds, 1.15 minutes

2025-11-18 15:57:59 layer   1  Sparsity: 91.0760%

2025-11-18 15:57:59 layer   2  Sparsity: 55.7416%

2025-11-18 15:57:59 layer   3  Sparsity: 50.5654%

2025-11-18 15:57:59 total_backward_count 734250 real_backward_count 66316   9.032%

2025-11-18 15:59:07 epoch-75  lr=['0.0039062'], tr/val_loss:  0.012393/  0.038297, val:  85.00%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.42 seconds, 1.16 minutes

2025-11-18 15:59:07 layer   1  Sparsity: 91.0750%

2025-11-18 15:59:07 layer   2  Sparsity: 55.8049%

2025-11-18 15:59:07 layer   3  Sparsity: 50.5721%

2025-11-18 15:59:07 total_backward_count 744040 real_backward_count 66750   8.971%

2025-11-18 16:00:18 epoch-76  lr=['0.0039062'], tr/val_loss:  0.012881/  0.037376, val:  86.67%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.11 seconds, 1.15 minutes

2025-11-18 16:00:18 layer   1  Sparsity: 91.0580%

2025-11-18 16:00:18 layer   2  Sparsity: 55.8298%

2025-11-18 16:00:18 layer   3  Sparsity: 50.6202%

2025-11-18 16:00:18 total_backward_count 753830 real_backward_count 67209   8.916%

2025-11-18 16:01:28 epoch-77  lr=['0.0039062'], tr/val_loss:  0.012557/  0.040855, val:  84.17%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.79 seconds, 1.16 minutes

2025-11-18 16:01:28 layer   1  Sparsity: 91.0902%

2025-11-18 16:01:28 layer   2  Sparsity: 55.7778%

2025-11-18 16:01:28 layer   3  Sparsity: 50.6151%

2025-11-18 16:01:28 total_backward_count 763620 real_backward_count 67678   8.863%

2025-11-18 16:02:36 epoch-78  lr=['0.0039062'], tr/val_loss:  0.012750/  0.042343, val:  82.50%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.38 seconds, 1.16 minutes

2025-11-18 16:02:36 layer   1  Sparsity: 91.0534%

2025-11-18 16:02:36 layer   2  Sparsity: 55.8048%

2025-11-18 16:02:36 layer   3  Sparsity: 50.6044%

2025-11-18 16:02:36 total_backward_count 773410 real_backward_count 68147   8.811%

2025-11-18 16:03:46 epoch-79  lr=['0.0039062'], tr/val_loss:  0.011970/  0.041357, val:  83.75%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.79 seconds, 1.15 minutes

2025-11-18 16:03:46 layer   1  Sparsity: 91.0668%

2025-11-18 16:03:46 layer   2  Sparsity: 55.9523%

2025-11-18 16:03:46 layer   3  Sparsity: 50.6987%

2025-11-18 16:03:46 total_backward_count 783200 real_backward_count 68580   8.756%

2025-11-18 16:04:56 epoch-80  lr=['0.0039062'], tr/val_loss:  0.011907/  0.048157, val:  81.67%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.48 seconds, 1.16 minutes

2025-11-18 16:04:56 layer   1  Sparsity: 91.1026%

2025-11-18 16:04:56 layer   2  Sparsity: 55.8255%

2025-11-18 16:04:56 layer   3  Sparsity: 50.4886%

2025-11-18 16:04:56 total_backward_count 792990 real_backward_count 68993   8.700%

2025-11-18 16:06:04 epoch-81  lr=['0.0039062'], tr/val_loss:  0.011906/  0.042504, val:  83.33%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.46 seconds, 1.16 minutes

2025-11-18 16:06:04 layer   1  Sparsity: 91.0738%

2025-11-18 16:06:04 layer   2  Sparsity: 55.8024%

2025-11-18 16:06:04 layer   3  Sparsity: 50.5375%

2025-11-18 16:06:04 total_backward_count 802780 real_backward_count 69420   8.647%

2025-11-18 16:07:10 epoch-82  lr=['0.0039062'], tr/val_loss:  0.011931/  0.039106, val:  85.00%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 65.00 seconds, 1.08 minutes

2025-11-18 16:07:10 layer   1  Sparsity: 91.0749%

2025-11-18 16:07:10 layer   2  Sparsity: 55.8231%

2025-11-18 16:07:10 layer   3  Sparsity: 50.6008%

2025-11-18 16:07:10 total_backward_count 812570 real_backward_count 69863   8.598%

2025-11-18 16:08:18 epoch-83  lr=['0.0039062'], tr/val_loss:  0.011997/  0.037918, val:  85.83%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.38 seconds, 1.14 minutes

2025-11-18 16:08:18 layer   1  Sparsity: 91.0299%

2025-11-18 16:08:18 layer   2  Sparsity: 55.7807%

2025-11-18 16:08:18 layer   3  Sparsity: 50.4919%

2025-11-18 16:08:18 total_backward_count 822360 real_backward_count 70304   8.549%

2025-11-18 16:09:28 epoch-84  lr=['0.0039062'], tr/val_loss:  0.012131/  0.041396, val:  86.25%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.26 seconds, 1.15 minutes

2025-11-18 16:09:28 layer   1  Sparsity: 91.0930%

2025-11-18 16:09:28 layer   2  Sparsity: 55.7868%

2025-11-18 16:09:28 layer   3  Sparsity: 50.3731%

2025-11-18 16:09:28 total_backward_count 832150 real_backward_count 70748   8.502%

2025-11-18 16:10:36 epoch-85  lr=['0.0039062'], tr/val_loss:  0.011891/  0.037912, val:  86.25%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.20 seconds, 1.15 minutes

2025-11-18 16:10:36 layer   1  Sparsity: 91.0540%

2025-11-18 16:10:36 layer   2  Sparsity: 55.7749%

2025-11-18 16:10:36 layer   3  Sparsity: 50.2564%

2025-11-18 16:10:36 total_backward_count 841940 real_backward_count 71164   8.452%

2025-11-18 16:11:46 epoch-86  lr=['0.0039062'], tr/val_loss:  0.011860/  0.041205, val:  83.33%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.12 seconds, 1.15 minutes

2025-11-18 16:11:46 layer   1  Sparsity: 91.1203%

2025-11-18 16:11:46 layer   2  Sparsity: 55.6808%

2025-11-18 16:11:46 layer   3  Sparsity: 50.3746%

2025-11-18 16:11:46 total_backward_count 851730 real_backward_count 71588   8.405%

2025-11-18 16:12:54 epoch-87  lr=['0.0039062'], tr/val_loss:  0.011929/  0.037979, val:  85.42%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.35 seconds, 1.16 minutes

2025-11-18 16:12:54 layer   1  Sparsity: 91.1100%

2025-11-18 16:12:54 layer   2  Sparsity: 55.7373%

2025-11-18 16:12:54 layer   3  Sparsity: 50.3682%

2025-11-18 16:12:56 total_backward_count 861520 real_backward_count 72016   8.359%

2025-11-18 16:14:04 epoch-88  lr=['0.0039062'], tr/val_loss:  0.011580/  0.038945, val:  85.00%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.15 seconds, 1.15 minutes

2025-11-18 16:14:04 layer   1  Sparsity: 91.0610%

2025-11-18 16:14:04 layer   2  Sparsity: 55.7063%

2025-11-18 16:14:04 layer   3  Sparsity: 50.3788%

2025-11-18 16:14:04 total_backward_count 871310 real_backward_count 72429   8.313%

2025-11-18 16:15:14 epoch-89  lr=['0.0039062'], tr/val_loss:  0.012075/  0.036522, val:  88.75%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.53 seconds, 1.16 minutes

2025-11-18 16:15:14 layer   1  Sparsity: 91.0869%

2025-11-18 16:15:14 layer   2  Sparsity: 55.7849%

2025-11-18 16:15:14 layer   3  Sparsity: 50.3119%

2025-11-18 16:15:14 total_backward_count 881100 real_backward_count 72865   8.270%

2025-11-18 16:16:22 epoch-90  lr=['0.0039062'], tr/val_loss:  0.011462/  0.038598, val:  85.00%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.27 seconds, 1.15 minutes

2025-11-18 16:16:22 layer   1  Sparsity: 91.0813%

2025-11-18 16:16:22 layer   2  Sparsity: 55.8940%

2025-11-18 16:16:22 layer   3  Sparsity: 50.3526%

2025-11-18 16:16:22 total_backward_count 890890 real_backward_count 73265   8.224%

2025-11-18 16:17:33 epoch-91  lr=['0.0039062'], tr/val_loss:  0.011145/  0.036316, val:  85.42%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.75 seconds, 1.15 minutes

2025-11-18 16:17:33 layer   1  Sparsity: 91.0882%

2025-11-18 16:17:33 layer   2  Sparsity: 55.9026%

2025-11-18 16:17:33 layer   3  Sparsity: 50.2065%

2025-11-18 16:17:33 total_backward_count 900680 real_backward_count 73660   8.178%

2025-11-18 16:18:41 epoch-92  lr=['0.0039062'], tr/val_loss:  0.011183/  0.037580, val:  87.50%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.67 seconds, 1.14 minutes

2025-11-18 16:18:41 layer   1  Sparsity: 91.0566%

2025-11-18 16:18:41 layer   2  Sparsity: 55.9319%

2025-11-18 16:18:41 layer   3  Sparsity: 50.2689%

2025-11-18 16:18:41 total_backward_count 910470 real_backward_count 74068   8.135%

2025-11-18 16:19:49 epoch-93  lr=['0.0039062'], tr/val_loss:  0.010951/  0.038117, val:  85.83%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.70 seconds, 1.14 minutes

2025-11-18 16:19:51 layer   1  Sparsity: 91.0871%

2025-11-18 16:19:51 layer   2  Sparsity: 55.8766%

2025-11-18 16:19:51 layer   3  Sparsity: 50.2515%

2025-11-18 16:19:51 total_backward_count 920260 real_backward_count 74458   8.091%

2025-11-18 16:20:59 epoch-94  lr=['0.0039062'], tr/val_loss:  0.011210/  0.041721, val:  85.42%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.54 seconds, 1.16 minutes

2025-11-18 16:20:59 layer   1  Sparsity: 91.0952%

2025-11-18 16:20:59 layer   2  Sparsity: 55.8167%

2025-11-18 16:20:59 layer   3  Sparsity: 50.0690%

2025-11-18 16:20:59 total_backward_count 930050 real_backward_count 74872   8.050%

2025-11-18 16:22:09 epoch-95  lr=['0.0039062'], tr/val_loss:  0.011317/  0.038525, val:  84.58%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.64 seconds, 1.14 minutes

2025-11-18 16:22:09 layer   1  Sparsity: 91.1091%

2025-11-18 16:22:09 layer   2  Sparsity: 55.8753%

2025-11-18 16:22:09 layer   3  Sparsity: 50.0386%

2025-11-18 16:22:09 total_backward_count 939840 real_backward_count 75295   8.011%

2025-11-18 16:23:17 epoch-96  lr=['0.0039062'], tr/val_loss:  0.010556/  0.037133, val:  86.67%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.15 seconds, 1.15 minutes

2025-11-18 16:23:17 layer   1  Sparsity: 91.0816%

2025-11-18 16:23:17 layer   2  Sparsity: 55.8877%

2025-11-18 16:23:17 layer   3  Sparsity: 50.0709%

2025-11-18 16:23:17 total_backward_count 949630 real_backward_count 75663   7.968%

2025-11-18 16:24:27 epoch-97  lr=['0.0039062'], tr/val_loss:  0.010195/  0.037661, val:  85.83%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.20 seconds, 1.15 minutes

2025-11-18 16:24:27 layer   1  Sparsity: 91.0930%

2025-11-18 16:24:27 layer   2  Sparsity: 55.9664%

2025-11-18 16:24:27 layer   3  Sparsity: 50.0902%

2025-11-18 16:24:27 total_backward_count 959420 real_backward_count 76008   7.922%

2025-11-18 16:25:35 epoch-98  lr=['0.0039062'], tr/val_loss:  0.010515/  0.040697, val:  85.42%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.29 seconds, 1.15 minutes

2025-11-18 16:25:35 layer   1  Sparsity: 91.0700%

2025-11-18 16:25:35 layer   2  Sparsity: 55.9576%

2025-11-18 16:25:35 layer   3  Sparsity: 50.1711%

2025-11-18 16:25:35 total_backward_count 969210 real_backward_count 76394   7.882%

2025-11-18 16:26:45 epoch-99  lr=['0.0039062'], tr/val_loss:  0.010736/  0.036754, val:  87.50%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.85 seconds, 1.15 minutes

2025-11-18 16:26:45 layer   1  Sparsity: 91.1149%

2025-11-18 16:26:45 layer   2  Sparsity: 55.9885%

2025-11-18 16:26:45 layer   3  Sparsity: 50.0929%

2025-11-18 16:26:45 total_backward_count 979000 real_backward_count 76761   7.841%

2025-11-18 16:27:55 epoch-100 lr=['0.0039062'], tr/val_loss:  0.010519/  0.034903, val:  89.58%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.28 seconds, 1.15 minutes

2025-11-18 16:27:55 layer   1  Sparsity: 91.0803%

2025-11-18 16:27:55 layer   2  Sparsity: 55.9605%

2025-11-18 16:27:55 layer   3  Sparsity: 50.0197%

2025-11-18 16:27:55 total_backward_count 988790 real_backward_count 77116   7.799%

2025-11-18 16:29:03 epoch-101 lr=['0.0039062'], tr/val_loss:  0.010811/  0.037035, val:  86.25%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.11 seconds, 1.15 minutes

2025-11-18 16:29:03 layer   1  Sparsity: 91.0724%

2025-11-18 16:29:03 layer   2  Sparsity: 56.0057%

2025-11-18 16:29:03 layer   3  Sparsity: 50.0987%

2025-11-18 16:29:03 total_backward_count 998580 real_backward_count 77514   7.762%

2025-11-18 16:30:13 epoch-102 lr=['0.0039062'], tr/val_loss:  0.009810/  0.035926, val:  88.33%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.08 seconds, 1.15 minutes

2025-11-18 16:30:13 layer   1  Sparsity: 91.0885%

2025-11-18 16:30:13 layer   2  Sparsity: 55.9991%

2025-11-18 16:30:13 layer   3  Sparsity: 50.1249%

2025-11-18 16:30:13 total_backward_count 1008370 real_backward_count 77846   7.720%

2025-11-18 16:31:21 epoch-103 lr=['0.0039062'], tr/val_loss:  0.010528/  0.037034, val:  85.42%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.56 seconds, 1.14 minutes

2025-11-18 16:31:21 layer   1  Sparsity: 91.0593%

2025-11-18 16:31:21 layer   2  Sparsity: 56.0015%

2025-11-18 16:31:21 layer   3  Sparsity: 50.0964%

2025-11-18 16:31:21 total_backward_count 1018160 real_backward_count 78228   7.683%

2025-11-18 16:32:31 epoch-104 lr=['0.0039062'], tr/val_loss:  0.010619/  0.035896, val:  88.33%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.74 seconds, 1.16 minutes

2025-11-18 16:32:31 layer   1  Sparsity: 91.0589%

2025-11-18 16:32:31 layer   2  Sparsity: 56.0294%

2025-11-18 16:32:31 layer   3  Sparsity: 50.2932%

2025-11-18 16:32:31 total_backward_count 1027950 real_backward_count 78609   7.647%

2025-11-18 16:33:42 epoch-105 lr=['0.0039062'], tr/val_loss:  0.010372/  0.038994, val:  87.08%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.53 seconds, 1.16 minutes

2025-11-18 16:33:42 layer   1  Sparsity: 91.0595%

2025-11-18 16:33:42 layer   2  Sparsity: 55.9836%

2025-11-18 16:33:42 layer   3  Sparsity: 50.3095%

2025-11-18 16:33:42 total_backward_count 1037740 real_backward_count 78979   7.611%

2025-11-18 16:34:50 epoch-106 lr=['0.0039062'], tr/val_loss:  0.009907/  0.036702, val:  87.50%, val_best:  89.58%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.17 seconds, 1.15 minutes

2025-11-18 16:34:50 layer   1  Sparsity: 91.0701%

2025-11-18 16:34:50 layer   2  Sparsity: 56.0303%

2025-11-18 16:34:50 layer   3  Sparsity: 50.0696%

2025-11-18 16:34:50 total_backward_count 1047530 real_backward_count 79324   7.572%

2025-11-18 16:36:00 epoch-107 lr=['0.0039062'], tr/val_loss:  0.010431/  0.037917, val:  85.83%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.48 seconds, 1.16 minutes

2025-11-18 16:36:00 layer   1  Sparsity: 91.0810%

2025-11-18 16:36:00 layer   2  Sparsity: 56.0997%

2025-11-18 16:36:00 layer   3  Sparsity: 50.2084%

2025-11-18 16:36:00 total_backward_count 1057320 real_backward_count 79702   7.538%

2025-11-18 16:37:10 epoch-108 lr=['0.0039062'], tr/val_loss:  0.010310/  0.037785, val:  88.75%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.28 seconds, 1.15 minutes

2025-11-18 16:37:10 layer   1  Sparsity: 91.0757%

2025-11-18 16:37:10 layer   2  Sparsity: 56.1297%

2025-11-18 16:37:10 layer   3  Sparsity: 50.0375%

2025-11-18 16:37:10 total_backward_count 1067110 real_backward_count 80084   7.505%

2025-11-18 16:38:18 epoch-109 lr=['0.0039062'], tr/val_loss:  0.010334/  0.038196, val:  86.67%, val_best:  89.58%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.32 seconds, 1.16 minutes

2025-11-18 16:38:18 layer   1  Sparsity: 91.0448%

2025-11-18 16:38:18 layer   2  Sparsity: 56.1629%

2025-11-18 16:38:18 layer   3  Sparsity: 49.9592%

2025-11-18 16:38:18 total_backward_count 1076900 real_backward_count 80442   7.470%

2025-11-18 16:39:28 epoch-110 lr=['0.0039062'], tr/val_loss:  0.009815/  0.036688, val:  87.50%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.75 seconds, 1.16 minutes

2025-11-18 16:39:28 layer   1  Sparsity: 91.0777%

2025-11-18 16:39:28 layer   2  Sparsity: 56.2071%

2025-11-18 16:39:28 layer   3  Sparsity: 49.9917%

2025-11-18 16:39:28 total_backward_count 1086690 real_backward_count 80782   7.434%

2025-11-18 16:40:38 epoch-111 lr=['0.0039062'], tr/val_loss:  0.010268/  0.036282, val:  87.50%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.67 seconds, 1.16 minutes

2025-11-18 16:40:38 layer   1  Sparsity: 91.0608%

2025-11-18 16:40:38 layer   2  Sparsity: 56.1112%

2025-11-18 16:40:38 layer   3  Sparsity: 49.8393%

2025-11-18 16:40:38 total_backward_count 1096480 real_backward_count 81152   7.401%

2025-11-18 16:41:46 epoch-112 lr=['0.0039062'], tr/val_loss:  0.009913/  0.034866, val:  88.33%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.06 seconds, 1.15 minutes

2025-11-18 16:41:48 layer   1  Sparsity: 91.0553%

2025-11-18 16:41:48 layer   2  Sparsity: 56.1248%

2025-11-18 16:41:48 layer   3  Sparsity: 49.9129%

2025-11-18 16:41:48 total_backward_count 1106270 real_backward_count 81519   7.369%

2025-11-18 16:42:58 epoch-113 lr=['0.0039062'], tr/val_loss:  0.009730/  0.036031, val:  87.92%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.07 seconds, 1.17 minutes

2025-11-18 16:42:58 layer   1  Sparsity: 91.1123%

2025-11-18 16:42:58 layer   2  Sparsity: 56.1988%

2025-11-18 16:42:58 layer   3  Sparsity: 49.9701%

2025-11-18 16:42:58 total_backward_count 1116060 real_backward_count 81869   7.336%

2025-11-18 16:44:06 epoch-114 lr=['0.0039062'], tr/val_loss:  0.009994/  0.040124, val:  84.17%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.15 seconds, 1.15 minutes

2025-11-18 16:44:06 layer   1  Sparsity: 91.0628%

2025-11-18 16:44:06 layer   2  Sparsity: 56.1615%

2025-11-18 16:44:06 layer   3  Sparsity: 49.9582%

2025-11-18 16:44:06 total_backward_count 1125850 real_backward_count 82230   7.304%

2025-11-18 16:45:16 epoch-115 lr=['0.0039062'], tr/val_loss:  0.009832/  0.037453, val:  86.67%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.61 seconds, 1.16 minutes

2025-11-18 16:45:16 layer   1  Sparsity: 91.1017%

2025-11-18 16:45:16 layer   2  Sparsity: 56.2450%

2025-11-18 16:45:16 layer   3  Sparsity: 49.9497%

2025-11-18 16:45:16 total_backward_count 1135640 real_backward_count 82579   7.272%

2025-11-18 16:46:26 epoch-116 lr=['0.0039062'], tr/val_loss:  0.009745/  0.041451, val:  83.75%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.68 seconds, 1.16 minutes

2025-11-18 16:46:26 layer   1  Sparsity: 91.0849%

2025-11-18 16:46:26 layer   2  Sparsity: 56.1078%

2025-11-18 16:46:26 layer   3  Sparsity: 49.9027%

2025-11-18 16:46:26 total_backward_count 1145430 real_backward_count 82917   7.239%

2025-11-18 16:47:36 epoch-117 lr=['0.0039062'], tr/val_loss:  0.009709/  0.038317, val:  86.67%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.68 seconds, 1.16 minutes

2025-11-18 16:47:36 layer   1  Sparsity: 91.0495%

2025-11-18 16:47:36 layer   2  Sparsity: 56.1531%

2025-11-18 16:47:36 layer   3  Sparsity: 49.8746%

2025-11-18 16:47:36 total_backward_count 1155220 real_backward_count 83258   7.207%

2025-11-18 16:48:44 epoch-118 lr=['0.0039062'], tr/val_loss:  0.009798/  0.035546, val:  88.33%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.44 seconds, 1.16 minutes

2025-11-18 16:48:44 layer   1  Sparsity: 91.0827%

2025-11-18 16:48:44 layer   2  Sparsity: 56.2780%

2025-11-18 16:48:44 layer   3  Sparsity: 49.8379%

2025-11-18 16:48:44 total_backward_count 1165010 real_backward_count 83591   7.175%

2025-11-18 16:49:55 epoch-119 lr=['0.0039062'], tr/val_loss:  0.009440/  0.035130, val:  89.17%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.58 seconds, 1.16 minutes

2025-11-18 16:49:55 layer   1  Sparsity: 91.0849%

2025-11-18 16:49:55 layer   2  Sparsity: 56.1677%

2025-11-18 16:49:55 layer   3  Sparsity: 49.8685%

2025-11-18 16:49:55 total_backward_count 1174800 real_backward_count 83900   7.142%

2025-11-18 16:51:03 epoch-120 lr=['0.0039062'], tr/val_loss:  0.009764/  0.037765, val:  87.50%, val_best:  89.58%, tr:  99.80%, tr_best: 100.00%, epoch time: 68.70 seconds, 1.15 minutes

2025-11-18 16:51:05 layer   1  Sparsity: 91.0841%

2025-11-18 16:51:05 layer   2  Sparsity: 56.2112%

2025-11-18 16:51:05 layer   3  Sparsity: 50.0719%

2025-11-18 16:51:05 total_backward_count 1184590 real_backward_count 84273   7.114%

2025-11-18 16:52:13 epoch-121 lr=['0.0039062'], tr/val_loss:  0.010090/  0.035152, val:  87.50%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.67 seconds, 1.14 minutes

2025-11-18 16:52:13 layer   1  Sparsity: 91.0666%

2025-11-18 16:52:13 layer   2  Sparsity: 56.0828%

2025-11-18 16:52:13 layer   3  Sparsity: 50.1242%

2025-11-18 16:52:13 total_backward_count 1194380 real_backward_count 84609   7.084%

2025-11-18 16:53:21 epoch-122 lr=['0.0039062'], tr/val_loss:  0.009251/  0.036745, val:  87.92%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.52 seconds, 1.14 minutes

2025-11-18 16:53:21 layer   1  Sparsity: 91.0675%

2025-11-18 16:53:21 layer   2  Sparsity: 56.0511%

2025-11-18 16:53:21 layer   3  Sparsity: 50.1351%

2025-11-18 16:53:21 total_backward_count 1204170 real_backward_count 84937   7.054%

2025-11-18 16:54:31 epoch-123 lr=['0.0039062'], tr/val_loss:  0.009334/  0.035996, val:  87.50%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.92 seconds, 1.15 minutes

2025-11-18 16:54:31 layer   1  Sparsity: 91.0839%

2025-11-18 16:54:31 layer   2  Sparsity: 56.1099%

2025-11-18 16:54:31 layer   3  Sparsity: 50.0425%

2025-11-18 16:54:31 total_backward_count 1213960 real_backward_count 85250   7.022%

2025-11-18 16:55:39 epoch-124 lr=['0.0039062'], tr/val_loss:  0.009317/  0.035293, val:  89.17%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.41 seconds, 1.16 minutes

2025-11-18 16:55:39 layer   1  Sparsity: 91.1125%

2025-11-18 16:55:39 layer   2  Sparsity: 56.1883%

2025-11-18 16:55:39 layer   3  Sparsity: 50.0450%

2025-11-18 16:55:39 total_backward_count 1223750 real_backward_count 85585   6.994%

2025-11-18 16:56:49 epoch-125 lr=['0.0039062'], tr/val_loss:  0.009738/  0.037891, val:  87.92%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.62 seconds, 1.16 minutes

2025-11-18 16:56:49 layer   1  Sparsity: 91.0327%

2025-11-18 16:56:49 layer   2  Sparsity: 56.2216%

2025-11-18 16:56:49 layer   3  Sparsity: 49.9434%

2025-11-18 16:56:49 total_backward_count 1233540 real_backward_count 85925   6.966%

2025-11-18 16:57:59 epoch-126 lr=['0.0039062'], tr/val_loss:  0.009473/  0.039579, val:  85.00%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.84 seconds, 1.16 minutes

2025-11-18 16:57:59 layer   1  Sparsity: 91.0862%

2025-11-18 16:57:59 layer   2  Sparsity: 56.3305%

2025-11-18 16:57:59 layer   3  Sparsity: 49.9331%

2025-11-18 16:57:59 total_backward_count 1243330 real_backward_count 86260   6.938%

2025-11-18 16:59:09 epoch-127 lr=['0.0039062'], tr/val_loss:  0.009312/  0.040178, val:  88.75%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.69 seconds, 1.16 minutes

2025-11-18 16:59:09 layer   1  Sparsity: 91.0643%

2025-11-18 16:59:09 layer   2  Sparsity: 56.3485%

2025-11-18 16:59:09 layer   3  Sparsity: 50.0100%

2025-11-18 16:59:09 total_backward_count 1253120 real_backward_count 86596   6.910%

2025-11-18 17:00:19 epoch-128 lr=['0.0039062'], tr/val_loss:  0.009014/  0.034336, val:  88.33%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.75 seconds, 1.16 minutes

2025-11-18 17:00:19 layer   1  Sparsity: 91.0465%

2025-11-18 17:00:19 layer   2  Sparsity: 56.3421%

2025-11-18 17:00:19 layer   3  Sparsity: 50.0054%

2025-11-18 17:00:19 total_backward_count 1262910 real_backward_count 86902   6.881%

2025-11-18 17:01:29 epoch-129 lr=['0.0039062'], tr/val_loss:  0.008845/  0.036034, val:  89.17%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.55 seconds, 1.16 minutes

2025-11-18 17:01:29 layer   1  Sparsity: 91.0760%

2025-11-18 17:01:29 layer   2  Sparsity: 56.2639%

2025-11-18 17:01:29 layer   3  Sparsity: 50.0319%

2025-11-18 17:01:29 total_backward_count 1272700 real_backward_count 87190   6.851%

2025-11-18 17:02:39 epoch-130 lr=['0.0039062'], tr/val_loss:  0.008944/  0.038672, val:  87.50%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.35 seconds, 1.16 minutes

2025-11-18 17:02:39 layer   1  Sparsity: 91.0912%

2025-11-18 17:02:39 layer   2  Sparsity: 56.3227%

2025-11-18 17:02:39 layer   3  Sparsity: 50.0517%

2025-11-18 17:02:39 total_backward_count 1282490 real_backward_count 87502   6.823%

2025-11-18 17:03:47 epoch-131 lr=['0.0039062'], tr/val_loss:  0.009456/  0.035479, val:  88.33%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.67 seconds, 1.16 minutes

2025-11-18 17:03:47 layer   1  Sparsity: 91.0717%

2025-11-18 17:03:47 layer   2  Sparsity: 56.2621%

2025-11-18 17:03:47 layer   3  Sparsity: 49.9505%

2025-11-18 17:03:47 total_backward_count 1292280 real_backward_count 87833   6.797%

2025-11-18 17:04:57 epoch-132 lr=['0.0039062'], tr/val_loss:  0.008777/  0.035598, val:  89.58%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.24 seconds, 1.15 minutes

2025-11-18 17:04:57 layer   1  Sparsity: 91.0918%

2025-11-18 17:04:57 layer   2  Sparsity: 56.2106%

2025-11-18 17:04:57 layer   3  Sparsity: 49.9332%

2025-11-18 17:04:57 total_backward_count 1302070 real_backward_count 88114   6.767%

2025-11-18 17:06:07 epoch-133 lr=['0.0039062'], tr/val_loss:  0.008919/  0.035815, val:  87.50%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.56 seconds, 1.16 minutes

2025-11-18 17:06:07 layer   1  Sparsity: 91.1066%

2025-11-18 17:06:07 layer   2  Sparsity: 56.1819%

2025-11-18 17:06:07 layer   3  Sparsity: 49.9688%

2025-11-18 17:06:07 total_backward_count 1311860 real_backward_count 88397   6.738%

2025-11-18 17:07:16 epoch-134 lr=['0.0039062'], tr/val_loss:  0.008670/  0.037752, val:  86.67%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.15 seconds, 1.15 minutes

2025-11-18 17:07:16 layer   1  Sparsity: 91.0906%

2025-11-18 17:07:16 layer   2  Sparsity: 56.2598%

2025-11-18 17:07:16 layer   3  Sparsity: 49.9297%

2025-11-18 17:07:16 total_backward_count 1321650 real_backward_count 88671   6.709%

2025-11-18 17:08:26 epoch-135 lr=['0.0039062'], tr/val_loss:  0.009276/  0.039292, val:  86.67%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.34 seconds, 1.16 minutes

2025-11-18 17:08:26 layer   1  Sparsity: 91.0777%

2025-11-18 17:08:26 layer   2  Sparsity: 56.2830%

2025-11-18 17:08:26 layer   3  Sparsity: 49.9212%

2025-11-18 17:08:26 total_backward_count 1331440 real_backward_count 88992   6.684%

2025-11-18 17:09:36 epoch-136 lr=['0.0039062'], tr/val_loss:  0.008569/  0.036372, val:  89.17%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.36 seconds, 1.16 minutes

2025-11-18 17:09:36 layer   1  Sparsity: 91.0819%

2025-11-18 17:09:36 layer   2  Sparsity: 56.3292%

2025-11-18 17:09:36 layer   3  Sparsity: 49.9916%

2025-11-18 17:09:36 total_backward_count 1341230 real_backward_count 89283   6.657%

2025-11-18 17:10:44 epoch-137 lr=['0.0039062'], tr/val_loss:  0.009247/  0.035695, val:  88.75%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.31 seconds, 1.16 minutes

2025-11-18 17:10:44 layer   1  Sparsity: 91.0534%

2025-11-18 17:10:44 layer   2  Sparsity: 56.4051%

2025-11-18 17:10:44 layer   3  Sparsity: 49.9998%

2025-11-18 17:10:44 total_backward_count 1351020 real_backward_count 89606   6.632%

2025-11-18 17:11:56 epoch-138 lr=['0.0039062'], tr/val_loss:  0.008578/  0.036264, val:  87.08%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.23 seconds, 1.17 minutes

2025-11-18 17:11:56 layer   1  Sparsity: 91.0926%

2025-11-18 17:11:56 layer   2  Sparsity: 56.3490%

2025-11-18 17:11:56 layer   3  Sparsity: 50.0298%

2025-11-18 17:11:56 total_backward_count 1360810 real_backward_count 89900   6.606%

2025-11-18 17:13:04 epoch-139 lr=['0.0039062'], tr/val_loss:  0.008952/  0.033789, val:  90.42%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.47 seconds, 1.16 minutes

2025-11-18 17:13:04 layer   1  Sparsity: 91.0707%

2025-11-18 17:13:04 layer   2  Sparsity: 56.4062%

2025-11-18 17:13:04 layer   3  Sparsity: 50.0867%

2025-11-18 17:13:04 total_backward_count 1370600 real_backward_count 90197   6.581%

2025-11-18 17:14:14 epoch-140 lr=['0.0039062'], tr/val_loss:  0.008653/  0.036389, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.84 seconds, 1.15 minutes

2025-11-18 17:14:14 layer   1  Sparsity: 91.0826%

2025-11-18 17:14:14 layer   2  Sparsity: 56.4100%

2025-11-18 17:14:14 layer   3  Sparsity: 50.0706%

2025-11-18 17:14:14 total_backward_count 1380390 real_backward_count 90467   6.554%

2025-11-18 17:15:22 epoch-141 lr=['0.0039062'], tr/val_loss:  0.008778/  0.037905, val:  85.83%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.40 seconds, 1.16 minutes

2025-11-18 17:15:22 layer   1  Sparsity: 91.0984%

2025-11-18 17:15:22 layer   2  Sparsity: 56.3890%

2025-11-18 17:15:22 layer   3  Sparsity: 50.0791%

2025-11-18 17:15:22 total_backward_count 1390180 real_backward_count 90780   6.530%

2025-11-18 17:16:32 epoch-142 lr=['0.0039062'], tr/val_loss:  0.009083/  0.035794, val:  87.08%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.71 seconds, 1.16 minutes

2025-11-18 17:16:32 layer   1  Sparsity: 91.1195%

2025-11-18 17:16:32 layer   2  Sparsity: 56.4602%

2025-11-18 17:16:32 layer   3  Sparsity: 50.0911%

2025-11-18 17:16:32 total_backward_count 1399970 real_backward_count 91092   6.507%

2025-11-18 17:17:42 epoch-143 lr=['0.0039062'], tr/val_loss:  0.008837/  0.038251, val:  86.25%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.42 seconds, 1.16 minutes

2025-11-18 17:17:42 layer   1  Sparsity: 91.0553%

2025-11-18 17:17:42 layer   2  Sparsity: 56.3712%

2025-11-18 17:17:42 layer   3  Sparsity: 50.2369%

2025-11-18 17:17:42 total_backward_count 1409760 real_backward_count 91404   6.484%

2025-11-18 17:18:52 epoch-144 lr=['0.0039062'], tr/val_loss:  0.008378/  0.036180, val:  85.83%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.27 seconds, 1.15 minutes

2025-11-18 17:18:52 layer   1  Sparsity: 91.0459%

2025-11-18 17:18:52 layer   2  Sparsity: 56.3554%

2025-11-18 17:18:52 layer   3  Sparsity: 50.2660%

2025-11-18 17:18:52 total_backward_count 1419550 real_backward_count 91675   6.458%

2025-11-18 17:20:00 epoch-145 lr=['0.0039062'], tr/val_loss:  0.008523/  0.036356, val:  87.08%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.99 seconds, 1.15 minutes

2025-11-18 17:20:00 layer   1  Sparsity: 91.0705%

2025-11-18 17:20:00 layer   2  Sparsity: 56.3720%

2025-11-18 17:20:00 layer   3  Sparsity: 50.2855%

2025-11-18 17:20:00 total_backward_count 1429340 real_backward_count 91958   6.434%

2025-11-18 17:21:10 epoch-146 lr=['0.0039062'], tr/val_loss:  0.008332/  0.035774, val:  86.67%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.23 seconds, 1.15 minutes

2025-11-18 17:21:10 layer   1  Sparsity: 91.0844%

2025-11-18 17:21:10 layer   2  Sparsity: 56.3132%

2025-11-18 17:21:10 layer   3  Sparsity: 50.2736%

2025-11-18 17:21:10 total_backward_count 1439130 real_backward_count 92231   6.409%

2025-11-18 17:22:20 epoch-147 lr=['0.0039062'], tr/val_loss:  0.008713/  0.037585, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.58 seconds, 1.16 minutes

2025-11-18 17:22:20 layer   1  Sparsity: 91.0577%

2025-11-18 17:22:20 layer   2  Sparsity: 56.2941%

2025-11-18 17:22:20 layer   3  Sparsity: 50.2007%

2025-11-18 17:22:20 total_backward_count 1448920 real_backward_count 92526   6.386%

2025-11-18 17:23:29 epoch-148 lr=['0.0039062'], tr/val_loss:  0.008438/  0.035586, val:  86.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.28 seconds, 1.15 minutes

2025-11-18 17:23:29 layer   1  Sparsity: 91.0882%

2025-11-18 17:23:29 layer   2  Sparsity: 56.3453%

2025-11-18 17:23:29 layer   3  Sparsity: 50.2156%

2025-11-18 17:23:29 total_backward_count 1458710 real_backward_count 92805   6.362%

2025-11-18 17:24:39 epoch-149 lr=['0.0039062'], tr/val_loss:  0.008368/  0.038931, val:  85.83%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.25 seconds, 1.15 minutes

2025-11-18 17:24:39 layer   1  Sparsity: 91.1005%

2025-11-18 17:24:39 layer   2  Sparsity: 56.4075%

2025-11-18 17:24:39 layer   3  Sparsity: 50.0520%

2025-11-18 17:24:39 total_backward_count 1468500 real_backward_count 93082   6.339%

2025-11-18 17:25:47 epoch-150 lr=['0.0039062'], tr/val_loss:  0.008535/  0.038602, val:  85.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.38 seconds, 1.14 minutes

2025-11-18 17:25:47 layer   1  Sparsity: 91.0893%

2025-11-18 17:25:47 layer   2  Sparsity: 56.4236%

2025-11-18 17:25:47 layer   3  Sparsity: 50.0101%

2025-11-18 17:25:47 total_backward_count 1478290 real_backward_count 93373   6.316%

2025-11-18 17:26:55 epoch-151 lr=['0.0039062'], tr/val_loss:  0.008325/  0.036979, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.72 seconds, 1.15 minutes

2025-11-18 17:26:55 layer   1  Sparsity: 91.0572%

2025-11-18 17:26:55 layer   2  Sparsity: 56.4739%

2025-11-18 17:26:55 layer   3  Sparsity: 50.0035%

2025-11-18 17:26:55 total_backward_count 1488080 real_backward_count 93637   6.292%

2025-11-18 17:28:05 epoch-152 lr=['0.0039062'], tr/val_loss:  0.008326/  0.035771, val:  87.08%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.69 seconds, 1.14 minutes

2025-11-18 17:28:05 layer   1  Sparsity: 91.0748%

2025-11-18 17:28:05 layer   2  Sparsity: 56.4222%

2025-11-18 17:28:05 layer   3  Sparsity: 49.9941%

2025-11-18 17:28:05 total_backward_count 1497870 real_backward_count 93914   6.270%

2025-11-18 17:29:13 epoch-153 lr=['0.0039062'], tr/val_loss:  0.008196/  0.036277, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.46 seconds, 1.16 minutes

2025-11-18 17:29:13 layer   1  Sparsity: 91.0663%

2025-11-18 17:29:13 layer   2  Sparsity: 56.5106%

2025-11-18 17:29:13 layer   3  Sparsity: 50.1947%

2025-11-18 17:29:15 total_backward_count 1507660 real_backward_count 94176   6.247%

2025-11-18 17:30:23 epoch-154 lr=['0.0039062'], tr/val_loss:  0.008161/  0.033264, val:  90.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.86 seconds, 1.15 minutes

2025-11-18 17:30:23 layer   1  Sparsity: 91.0871%

2025-11-18 17:30:23 layer   2  Sparsity: 56.4328%

2025-11-18 17:30:23 layer   3  Sparsity: 50.2204%

2025-11-18 17:30:23 total_backward_count 1517450 real_backward_count 94452   6.224%

2025-11-18 17:31:31 epoch-155 lr=['0.0039062'], tr/val_loss:  0.008159/  0.037468, val:  86.25%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.75 seconds, 1.15 minutes

2025-11-18 17:31:31 layer   1  Sparsity: 91.0989%

2025-11-18 17:31:31 layer   2  Sparsity: 56.4278%

2025-11-18 17:31:31 layer   3  Sparsity: 50.0205%

2025-11-18 17:31:31 total_backward_count 1527240 real_backward_count 94710   6.201%

2025-11-18 17:32:41 epoch-156 lr=['0.0039062'], tr/val_loss:  0.008512/  0.036815, val:  87.92%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.24 seconds, 1.15 minutes

2025-11-18 17:32:41 layer   1  Sparsity: 91.0950%

2025-11-18 17:32:41 layer   2  Sparsity: 56.4428%

2025-11-18 17:32:41 layer   3  Sparsity: 49.9681%

2025-11-18 17:32:41 total_backward_count 1537030 real_backward_count 94997   6.181%

2025-11-18 17:33:49 epoch-157 lr=['0.0039062'], tr/val_loss:  0.008116/  0.033687, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.14 seconds, 1.15 minutes

2025-11-18 17:33:51 layer   1  Sparsity: 91.0606%

2025-11-18 17:33:51 layer   2  Sparsity: 56.3737%

2025-11-18 17:33:51 layer   3  Sparsity: 50.0622%

2025-11-18 17:33:51 total_backward_count 1546820 real_backward_count 95267   6.159%

2025-11-18 17:34:59 epoch-158 lr=['0.0039062'], tr/val_loss:  0.007827/  0.034604, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.28 seconds, 1.15 minutes

2025-11-18 17:34:59 layer   1  Sparsity: 91.0529%

2025-11-18 17:34:59 layer   2  Sparsity: 56.3536%

2025-11-18 17:34:59 layer   3  Sparsity: 50.0809%

2025-11-18 17:34:59 total_backward_count 1556610 real_backward_count 95529   6.137%

2025-11-18 17:36:09 epoch-159 lr=['0.0039062'], tr/val_loss:  0.007881/  0.033762, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.88 seconds, 1.15 minutes

2025-11-18 17:36:09 layer   1  Sparsity: 91.1178%

2025-11-18 17:36:09 layer   2  Sparsity: 56.3938%

2025-11-18 17:36:09 layer   3  Sparsity: 50.0952%

2025-11-18 17:36:09 total_backward_count 1566400 real_backward_count 95782   6.115%

2025-11-18 17:37:17 epoch-160 lr=['0.0039062'], tr/val_loss:  0.008078/  0.034500, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.33 seconds, 1.16 minutes

2025-11-18 17:37:17 layer   1  Sparsity: 91.0867%

2025-11-18 17:37:17 layer   2  Sparsity: 56.3960%

2025-11-18 17:37:17 layer   3  Sparsity: 50.0244%

2025-11-18 17:37:17 total_backward_count 1576190 real_backward_count 96057   6.094%

2025-11-18 17:38:27 epoch-161 lr=['0.0039062'], tr/val_loss:  0.008038/  0.037230, val:  87.50%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.65 seconds, 1.16 minutes

2025-11-18 17:38:27 layer   1  Sparsity: 91.0726%

2025-11-18 17:38:27 layer   2  Sparsity: 56.4243%

2025-11-18 17:38:27 layer   3  Sparsity: 50.1624%

2025-11-18 17:38:27 total_backward_count 1585980 real_backward_count 96322   6.073%

2025-11-18 17:39:38 epoch-162 lr=['0.0039062'], tr/val_loss:  0.008086/  0.036981, val:  84.58%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.22 seconds, 1.15 minutes

2025-11-18 17:39:38 layer   1  Sparsity: 91.0791%

2025-11-18 17:39:38 layer   2  Sparsity: 56.4240%

2025-11-18 17:39:38 layer   3  Sparsity: 50.1474%

2025-11-18 17:39:38 total_backward_count 1595770 real_backward_count 96569   6.052%

2025-11-18 17:40:48 epoch-163 lr=['0.0039062'], tr/val_loss:  0.007973/  0.033939, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.74 seconds, 1.16 minutes

2025-11-18 17:40:48 layer   1  Sparsity: 91.0673%

2025-11-18 17:40:48 layer   2  Sparsity: 56.4018%

2025-11-18 17:40:48 layer   3  Sparsity: 50.0620%

2025-11-18 17:40:48 total_backward_count 1605560 real_backward_count 96834   6.031%

2025-11-18 17:41:56 epoch-164 lr=['0.0039062'], tr/val_loss:  0.007523/  0.034235, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.19 seconds, 1.15 minutes

2025-11-18 17:41:56 layer   1  Sparsity: 91.0864%

2025-11-18 17:41:56 layer   2  Sparsity: 56.3643%

2025-11-18 17:41:56 layer   3  Sparsity: 50.0393%

2025-11-18 17:41:56 total_backward_count 1615350 real_backward_count 97085   6.010%

2025-11-18 17:43:06 epoch-165 lr=['0.0039062'], tr/val_loss:  0.007710/  0.035441, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.49 seconds, 1.16 minutes

2025-11-18 17:43:06 layer   1  Sparsity: 91.0616%

2025-11-18 17:43:06 layer   2  Sparsity: 56.4592%

2025-11-18 17:43:06 layer   3  Sparsity: 50.0600%

2025-11-18 17:43:06 total_backward_count 1625140 real_backward_count 97322   5.989%

2025-11-18 17:44:16 epoch-166 lr=['0.0039062'], tr/val_loss:  0.007983/  0.034720, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.45 seconds, 1.16 minutes

2025-11-18 17:44:16 layer   1  Sparsity: 91.0678%

2025-11-18 17:44:16 layer   2  Sparsity: 56.4827%

2025-11-18 17:44:16 layer   3  Sparsity: 50.0749%

2025-11-18 17:44:16 total_backward_count 1634930 real_backward_count 97565   5.968%

2025-11-18 17:45:24 epoch-167 lr=['0.0039062'], tr/val_loss:  0.007883/  0.034619, val:  87.92%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.35 seconds, 1.16 minutes

2025-11-18 17:45:24 layer   1  Sparsity: 91.0815%

2025-11-18 17:45:24 layer   2  Sparsity: 56.4521%

2025-11-18 17:45:24 layer   3  Sparsity: 50.2261%

2025-11-18 17:45:24 total_backward_count 1644720 real_backward_count 97831   5.948%

2025-11-18 17:46:34 epoch-168 lr=['0.0039062'], tr/val_loss:  0.007764/  0.035713, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.10 seconds, 1.15 minutes

2025-11-18 17:46:34 layer   1  Sparsity: 91.0816%

2025-11-18 17:46:34 layer   2  Sparsity: 56.4622%

2025-11-18 17:46:34 layer   3  Sparsity: 50.2881%

2025-11-18 17:46:34 total_backward_count 1654510 real_backward_count 98102   5.929%

2025-11-18 17:47:42 epoch-169 lr=['0.0039062'], tr/val_loss:  0.007582/  0.035598, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.79 seconds, 1.15 minutes

2025-11-18 17:47:42 layer   1  Sparsity: 91.0601%

2025-11-18 17:47:42 layer   2  Sparsity: 56.5103%

2025-11-18 17:47:42 layer   3  Sparsity: 50.2822%

2025-11-18 17:47:42 total_backward_count 1664300 real_backward_count 98340   5.909%

2025-11-18 17:48:52 epoch-170 lr=['0.0039062'], tr/val_loss:  0.007614/  0.036259, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.77 seconds, 1.15 minutes

2025-11-18 17:48:52 layer   1  Sparsity: 91.1141%

2025-11-18 17:48:52 layer   2  Sparsity: 56.5245%

2025-11-18 17:48:52 layer   3  Sparsity: 50.3635%

2025-11-18 17:48:52 total_backward_count 1674090 real_backward_count 98581   5.889%

2025-11-18 17:50:00 epoch-171 lr=['0.0039062'], tr/val_loss:  0.007537/  0.036509, val:  86.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.93 seconds, 1.15 minutes

2025-11-18 17:50:00 layer   1  Sparsity: 91.0424%

2025-11-18 17:50:00 layer   2  Sparsity: 56.4884%

2025-11-18 17:50:00 layer   3  Sparsity: 50.4371%

2025-11-18 17:50:00 total_backward_count 1683880 real_backward_count 98825   5.869%

2025-11-18 17:51:10 epoch-172 lr=['0.0039062'], tr/val_loss:  0.007704/  0.035589, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.66 seconds, 1.16 minutes

2025-11-18 17:51:10 layer   1  Sparsity: 91.1045%

2025-11-18 17:51:10 layer   2  Sparsity: 56.5151%

2025-11-18 17:51:10 layer   3  Sparsity: 50.4831%

2025-11-18 17:51:10 total_backward_count 1693670 real_backward_count 99071   5.849%

2025-11-18 17:52:20 epoch-173 lr=['0.0039062'], tr/val_loss:  0.007514/  0.035470, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.36 seconds, 1.16 minutes

2025-11-18 17:52:20 layer   1  Sparsity: 91.0742%

2025-11-18 17:52:20 layer   2  Sparsity: 56.5764%

2025-11-18 17:52:20 layer   3  Sparsity: 50.5386%

2025-11-18 17:52:20 total_backward_count 1703460 real_backward_count 99313   5.830%

2025-11-18 17:53:28 epoch-174 lr=['0.0039062'], tr/val_loss:  0.007447/  0.033635, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.88 seconds, 1.15 minutes

2025-11-18 17:53:28 layer   1  Sparsity: 91.1101%

2025-11-18 17:53:28 layer   2  Sparsity: 56.5946%

2025-11-18 17:53:28 layer   3  Sparsity: 50.5662%

2025-11-18 17:53:28 total_backward_count 1713250 real_backward_count 99532   5.810%

2025-11-18 17:54:38 epoch-175 lr=['0.0039062'], tr/val_loss:  0.007541/  0.034415, val:  87.08%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.19 seconds, 1.15 minutes

2025-11-18 17:54:38 layer   1  Sparsity: 91.0537%

2025-11-18 17:54:38 layer   2  Sparsity: 56.5743%

2025-11-18 17:54:38 layer   3  Sparsity: 50.5107%

2025-11-18 17:54:38 total_backward_count 1723040 real_backward_count 99781   5.791%

2025-11-18 17:55:46 epoch-176 lr=['0.0039062'], tr/val_loss:  0.007731/  0.034274, val:  88.75%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.93 seconds, 1.15 minutes

2025-11-18 17:55:46 layer   1  Sparsity: 91.0843%

2025-11-18 17:55:46 layer   2  Sparsity: 56.4917%

2025-11-18 17:55:46 layer   3  Sparsity: 50.2328%

2025-11-18 17:55:46 total_backward_count 1732830 real_backward_count 100026   5.772%

2025-11-18 17:56:57 epoch-177 lr=['0.0039062'], tr/val_loss:  0.007445/  0.034314, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.00 seconds, 1.15 minutes

2025-11-18 17:56:57 layer   1  Sparsity: 91.0312%

2025-11-18 17:56:57 layer   2  Sparsity: 56.4458%

2025-11-18 17:56:57 layer   3  Sparsity: 50.2123%

2025-11-18 17:56:57 total_backward_count 1742620 real_backward_count 100273   5.754%

2025-11-18 17:58:05 epoch-178 lr=['0.0039062'], tr/val_loss:  0.007518/  0.034209, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.85 seconds, 1.15 minutes

2025-11-18 17:58:05 layer   1  Sparsity: 91.0376%

2025-11-18 17:58:05 layer   2  Sparsity: 56.4615%

2025-11-18 17:58:05 layer   3  Sparsity: 50.2431%

2025-11-18 17:58:05 total_backward_count 1752410 real_backward_count 100517   5.736%

2025-11-18 17:59:13 epoch-179 lr=['0.0039062'], tr/val_loss:  0.007915/  0.034068, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.19 seconds, 1.14 minutes

2025-11-18 17:59:13 layer   1  Sparsity: 91.0602%

2025-11-18 17:59:13 layer   2  Sparsity: 56.4650%

2025-11-18 17:59:13 layer   3  Sparsity: 50.1912%

2025-11-18 17:59:13 total_backward_count 1762200 real_backward_count 100800   5.720%

2025-11-18 18:00:21 epoch-180 lr=['0.0039062'], tr/val_loss:  0.007503/  0.034913, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.47 seconds, 1.14 minutes

2025-11-18 18:00:23 layer   1  Sparsity: 91.1020%

2025-11-18 18:00:23 layer   2  Sparsity: 56.5496%

2025-11-18 18:00:23 layer   3  Sparsity: 49.9797%

2025-11-18 18:00:23 total_backward_count 1771990 real_backward_count 101045   5.702%

2025-11-18 18:01:29 epoch-181 lr=['0.0039062'], tr/val_loss:  0.007453/  0.034860, val:  87.50%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 67.92 seconds, 1.13 minutes

2025-11-18 18:01:29 layer   1  Sparsity: 91.0643%

2025-11-18 18:01:29 layer   2  Sparsity: 56.6374%

2025-11-18 18:01:29 layer   3  Sparsity: 49.9822%

2025-11-18 18:01:29 total_backward_count 1781780 real_backward_count 101297   5.685%

2025-11-18 18:02:39 epoch-182 lr=['0.0039062'], tr/val_loss:  0.007618/  0.035805, val:  88.33%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.28 seconds, 1.15 minutes

2025-11-18 18:02:39 layer   1  Sparsity: 91.0480%

2025-11-18 18:02:39 layer   2  Sparsity: 56.5766%

2025-11-18 18:02:39 layer   3  Sparsity: 50.0132%

2025-11-18 18:02:39 total_backward_count 1791570 real_backward_count 101538   5.668%

2025-11-18 18:03:49 epoch-183 lr=['0.0039062'], tr/val_loss:  0.007084/  0.034812, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.84 seconds, 1.15 minutes

2025-11-18 18:03:49 layer   1  Sparsity: 91.0426%

2025-11-18 18:03:49 layer   2  Sparsity: 56.5874%

2025-11-18 18:03:49 layer   3  Sparsity: 50.0805%

2025-11-18 18:03:49 total_backward_count 1801360 real_backward_count 101761   5.649%

2025-11-18 18:04:57 epoch-184 lr=['0.0039062'], tr/val_loss:  0.007312/  0.035279, val:  89.17%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.63 seconds, 1.14 minutes

2025-11-18 18:04:57 layer   1  Sparsity: 91.0658%

2025-11-18 18:04:57 layer   2  Sparsity: 56.5290%

2025-11-18 18:04:57 layer   3  Sparsity: 50.1426%

2025-11-18 18:04:57 total_backward_count 1811150 real_backward_count 101999   5.632%

2025-11-18 18:06:05 epoch-185 lr=['0.0039062'], tr/val_loss:  0.007164/  0.034640, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.93 seconds, 1.15 minutes

2025-11-18 18:06:05 layer   1  Sparsity: 91.0619%

2025-11-18 18:06:05 layer   2  Sparsity: 56.5255%

2025-11-18 18:06:05 layer   3  Sparsity: 50.1315%

2025-11-18 18:06:05 total_backward_count 1820940 real_backward_count 102216   5.613%

2025-11-18 18:07:15 epoch-186 lr=['0.0039062'], tr/val_loss:  0.007505/  0.034814, val:  87.50%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.76 seconds, 1.15 minutes

2025-11-18 18:07:15 layer   1  Sparsity: 91.0948%

2025-11-18 18:07:15 layer   2  Sparsity: 56.5169%

2025-11-18 18:07:15 layer   3  Sparsity: 50.1602%

2025-11-18 18:07:15 total_backward_count 1830730 real_backward_count 102464   5.597%

2025-11-18 18:08:23 epoch-187 lr=['0.0039062'], tr/val_loss:  0.007401/  0.036323, val:  88.75%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.84 seconds, 1.15 minutes

2025-11-18 18:08:23 layer   1  Sparsity: 91.0857%

2025-11-18 18:08:23 layer   2  Sparsity: 56.5970%

2025-11-18 18:08:23 layer   3  Sparsity: 50.1551%

2025-11-18 18:08:23 total_backward_count 1840520 real_backward_count 102687   5.579%

2025-11-18 18:09:31 epoch-188 lr=['0.0039062'], tr/val_loss:  0.007214/  0.034090, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.69 seconds, 1.14 minutes

2025-11-18 18:09:33 layer   1  Sparsity: 91.0981%

2025-11-18 18:09:33 layer   2  Sparsity: 56.6023%

2025-11-18 18:09:33 layer   3  Sparsity: 50.1842%

2025-11-18 18:09:33 total_backward_count 1850310 real_backward_count 102923   5.562%

2025-11-18 18:10:41 epoch-189 lr=['0.0039062'], tr/val_loss:  0.007485/  0.035222, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.71 seconds, 1.15 minutes

2025-11-18 18:10:41 layer   1  Sparsity: 91.0810%

2025-11-18 18:10:41 layer   2  Sparsity: 56.6779%

2025-11-18 18:10:41 layer   3  Sparsity: 50.1085%

2025-11-18 18:10:41 total_backward_count 1860100 real_backward_count 103158   5.546%

2025-11-18 18:11:49 epoch-190 lr=['0.0039062'], tr/val_loss:  0.007300/  0.035251, val:  88.75%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.56 seconds, 1.14 minutes

2025-11-18 18:11:49 layer   1  Sparsity: 91.0908%

2025-11-18 18:11:49 layer   2  Sparsity: 56.6137%

2025-11-18 18:11:49 layer   3  Sparsity: 50.1062%

2025-11-18 18:11:49 total_backward_count 1869890 real_backward_count 103387   5.529%

2025-11-18 18:13:00 epoch-191 lr=['0.0039062'], tr/val_loss:  0.006932/  0.042100, val:  82.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.90 seconds, 1.15 minutes

2025-11-18 18:13:00 layer   1  Sparsity: 91.0654%

2025-11-18 18:13:00 layer   2  Sparsity: 56.6231%

2025-11-18 18:13:00 layer   3  Sparsity: 50.0710%

2025-11-18 18:13:00 total_backward_count 1879680 real_backward_count 103598   5.511%

2025-11-18 18:14:08 epoch-192 lr=['0.0039062'], tr/val_loss:  0.006981/  0.035787, val:  86.67%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.07 seconds, 1.15 minutes

2025-11-18 18:14:08 layer   1  Sparsity: 91.0619%

2025-11-18 18:14:08 layer   2  Sparsity: 56.6212%

2025-11-18 18:14:08 layer   3  Sparsity: 50.0128%

2025-11-18 18:14:08 total_backward_count 1889470 real_backward_count 103827   5.495%

2025-11-18 18:15:16 epoch-193 lr=['0.0039062'], tr/val_loss:  0.007182/  0.035498, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.69 seconds, 1.14 minutes

2025-11-18 18:15:18 layer   1  Sparsity: 91.0434%

2025-11-18 18:15:18 layer   2  Sparsity: 56.6702%

2025-11-18 18:15:18 layer   3  Sparsity: 49.9818%

2025-11-18 18:15:18 total_backward_count 1899260 real_backward_count 104055   5.479%

2025-11-18 18:16:26 epoch-194 lr=['0.0039062'], tr/val_loss:  0.006825/  0.034985, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.34 seconds, 1.16 minutes

2025-11-18 18:16:26 layer   1  Sparsity: 91.0323%

2025-11-18 18:16:26 layer   2  Sparsity: 56.7013%

2025-11-18 18:16:26 layer   3  Sparsity: 50.0315%

2025-11-18 18:16:26 total_backward_count 1909050 real_backward_count 104285   5.463%

2025-11-18 18:17:36 epoch-195 lr=['0.0039062'], tr/val_loss:  0.007046/  0.035779, val:  86.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.97 seconds, 1.15 minutes

2025-11-18 18:17:36 layer   1  Sparsity: 91.0684%

2025-11-18 18:17:36 layer   2  Sparsity: 56.6411%

2025-11-18 18:17:36 layer   3  Sparsity: 50.1334%

2025-11-18 18:17:36 total_backward_count 1918840 real_backward_count 104505   5.446%

2025-11-18 18:18:44 epoch-196 lr=['0.0039062'], tr/val_loss:  0.006975/  0.033896, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.04 seconds, 1.15 minutes

2025-11-18 18:18:44 layer   1  Sparsity: 91.0613%

2025-11-18 18:18:44 layer   2  Sparsity: 56.6329%

2025-11-18 18:18:44 layer   3  Sparsity: 50.2065%

2025-11-18 18:18:44 total_backward_count 1928630 real_backward_count 104727   5.430%

2025-11-18 18:19:52 epoch-197 lr=['0.0039062'], tr/val_loss:  0.007019/  0.034529, val:  90.42%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.55 seconds, 1.14 minutes

2025-11-18 18:19:52 layer   1  Sparsity: 91.0931%

2025-11-18 18:19:52 layer   2  Sparsity: 56.6269%

2025-11-18 18:19:52 layer   3  Sparsity: 50.1219%

2025-11-18 18:19:54 total_backward_count 1938420 real_backward_count 104953   5.414%

2025-11-18 18:21:02 epoch-198 lr=['0.0039062'], tr/val_loss:  0.006625/  0.036124, val:  87.50%, val_best:  90.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 68.93 seconds, 1.15 minutes

2025-11-18 18:21:02 layer   1  Sparsity: 91.0980%

2025-11-18 18:21:02 layer   2  Sparsity: 56.6533%

2025-11-18 18:21:02 layer   3  Sparsity: 50.2339%

2025-11-18 18:21:02 total_backward_count 1948210 real_backward_count 105159   5.398%

2025-11-18 18:22:10 epoch-199 lr=['0.0039062'], tr/val_loss:  0.006843/  0.034443, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.42 seconds, 1.14 minutes

2025-11-18 18:22:10 layer   1  Sparsity: 91.0501%

2025-11-18 18:22:10 layer   2  Sparsity: 56.6169%

2025-11-18 18:22:10 layer   3  Sparsity: 50.2143%
