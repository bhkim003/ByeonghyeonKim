{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch} running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch %5 ==0 or epoch == 1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 5\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 16\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 8 # SAE일 때만 유효\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2,4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  4\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "sweep_id = '6xax2jii'\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_174013_409'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
