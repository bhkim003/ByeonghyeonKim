{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch} running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch %5 ==0 or epoch == 1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 5\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 16\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 8 # SAE일 때만 유효\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c39s2esd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 2400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.25\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_235307-c39s2esd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/c39s2esd' target=\"_blank\">clear-sweep-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/c39s2esd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/c39s2esd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 1, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 16, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 6, 'v_decay': 0.75, 'v_threshold': 0.25, 'v_reset': 10000, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250102_235314_446', 'optimizer': 'Adam'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_235314_446\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2,4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  1\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "sweep_id = '6xax2jii' \n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_174013_409'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
