{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "0 60000\n",
      "1 60000\n",
      "2 60000\n",
      "3 60000\n",
      "4 60000\n",
      "5 60000\n",
      "6 60000\n",
      "7 60000\n",
      "8 60000\n",
      "9 60000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m train_snn(snn, trainset\u001b[38;5;241m.\u001b[39mdata, trainset\u001b[38;5;241m.\u001b[39mtargets)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# SNN 테스트\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43mtest_snn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 77\u001b[0m, in \u001b[0;36mtest_snn\u001b[0;34m(snn, x_test, y_test)\u001b[0m\n\u001b[1;32m     75\u001b[0m inputs \u001b[38;5;241m=\u001b[39m x_test[i]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# inputs 텐서를 평탄화\u001b[39;00m\n\u001b[1;32m     76\u001b[0m label \u001b[38;5;241m=\u001b[39m y_test[i]\n\u001b[0;32m---> 77\u001b[0m output_spikes \u001b[38;5;241m=\u001b[39m \u001b[43msnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(torch\u001b[38;5;241m.\u001b[39mtensor(output_spikes))  \u001b[38;5;66;03m# 리스트를 텐서로 변환\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_label \u001b[38;5;241m==\u001b[39m label:\n",
      "Cell \u001b[0;32mIn[46], line 51\u001b[0m, in \u001b[0;36mSNN.simulate\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     neuron\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons):\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     output_spikes\u001b[38;5;241m.\u001b[39mappend(neuron\u001b[38;5;241m.\u001b[39mspike)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_spikes\n",
      "Cell \u001b[0;32mIn[46], line 30\u001b[0m, in \u001b[0;36mLIFNeuron.integrate\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m total_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(inputs)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmembrane_potential \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_input\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmembrane_potential \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_spike_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# MNIST 데이터 로드 및 전처리\n",
    "def load_mnist():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    trainset = datasets.MNIST('/data2/mnist/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "    testset = datasets.MNIST('/data2/mnist/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "    return trainset, testset\n",
    "\n",
    "# LIF 뉴런 모델\n",
    "class LIFNeuron:\n",
    "    def __init__(self, tau=10, threshold=1, reset_potential=0, dt=1):\n",
    "        self.tau = tau\n",
    "        self.threshold = threshold\n",
    "        self.reset_potential = reset_potential\n",
    "        self.dt = dt\n",
    "        self.membrane_potential = reset_potential\n",
    "        self.spike = 0\n",
    "        self.last_spike_time = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.membrane_potential = self.reset_potential\n",
    "        self.spike = 0\n",
    "\n",
    "    def integrate(self, inputs):\n",
    "        self.membrane_potential *= torch.exp(-torch.tensor(self.dt) / torch.tensor(self.tau))  # 실수를 텐서로 변환\n",
    "        total_input = torch.sum(inputs)\n",
    "        self.membrane_potential += total_input\n",
    "        if self.membrane_potential >= self.threshold:\n",
    "            self.spike = 1\n",
    "            self.last_spike_time = 0\n",
    "            self.membrane_potential = self.reset_potential\n",
    "        else:\n",
    "            self.spike = 0\n",
    "            self.last_spike_time += 1\n",
    "\n",
    "# SNN 모델\n",
    "class SNN:\n",
    "    def __init__(self, num_neurons):\n",
    "        self.num_neurons = num_neurons\n",
    "        self.neurons = [LIFNeuron() for _ in range(num_neurons)]\n",
    "        self.weights = torch.rand(num_neurons, num_neurons)\n",
    "\n",
    "    def simulate(self, inputs):\n",
    "        output_spikes = []\n",
    "        for neuron in self.neurons:\n",
    "            neuron.reset()\n",
    "\n",
    "        for i, neuron in enumerate(self.neurons):\n",
    "            neuron.integrate(inputs * self.weights[i])\n",
    "            output_spikes.append(neuron.spike)\n",
    "        \n",
    "        return output_spikes\n",
    "\n",
    "    def train_stdp(self, input_spikes, output_spikes):\n",
    "        pass  # STDP 훈련 알고리즘 구현\n",
    "\n",
    "# 훈련 함수\n",
    "def train_snn(snn, x_train, y_train, epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch:\", epoch+1)\n",
    "        for i in range(10):\n",
    "            print(i,len(x_train))\n",
    "            inputs = x_train[i].view(-1)\n",
    "            label = y_train[i]\n",
    "            output_spikes = snn.simulate(inputs)\n",
    "            snn.train_stdp(inputs, output_spikes)\n",
    "            # 이후에 다른 훈련 알고리즘 적용 가능\n",
    "\n",
    "# 테스트 함수\n",
    "def test_snn(snn, x_test, y_test):\n",
    "    correct = 0\n",
    "    for i in range(len(x_test)):\n",
    "        inputs = x_test[i].view(-1)  # inputs 텐서를 평탄화\n",
    "        label = y_test[i]\n",
    "        output_spikes = snn.simulate(inputs)\n",
    "        predicted_label = torch.argmax(torch.tensor(output_spikes))  # 리스트를 텐서로 변환\n",
    "        if predicted_label == label:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(x_test)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# MNIST 데이터 로드\n",
    "trainset, testset = load_mnist()\n",
    "\n",
    "# SNN 모델 초기화\n",
    "num_neurons = 784  # MNIST 이미지 크기에 맞는 입력 뉴런 수\n",
    "snn = SNN(num_neurons)\n",
    "\n",
    "# SNN 훈련\n",
    "train_snn(snn, trainset.data, trainset.targets)\n",
    "\n",
    "# SNN 테스트\n",
    "test_snn(snn, testset.data, testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spikes:\n",
      "[False False False False False]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파라미터 설정\n",
    "num_inputs = 10\n",
    "num_neurons = 5\n",
    "threshold = 2.5\n",
    "\n",
    "# 가중치와 입력 초기화\n",
    "weights = np.random.rand(num_inputs, num_neurons)\n",
    "inputs = np.random.rand(num_inputs)\n",
    "\n",
    "# 뉴런의 출력 계산\n",
    "outputs = np.dot(inputs, weights)\n",
    "\n",
    "# 임계값을 초과하는 뉴런에 대해 스파이크 발생\n",
    "spikes = outputs > threshold\n",
    "\n",
    "print(\"Spikes:\")\n",
    "print(spikes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
