{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    seed_assign(my_seed)\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "        \n",
    "        if(epoch %50 ==0 or epoch == 1): \n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                start_time = time.time()\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i in range(num_cluster):\n",
    "                        spike_torch = torch.from_numpy(spike_template[i, :])\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                        else:\n",
    "                            spike_torch = spike_torch.unsqueeze(0)\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        # if 'SAE' in net.module.__class__.__name__:\n",
    "                        #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                        #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                        #     print(all_equal, inner_inf)\n",
    "\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.view(1,-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        Cluster[i, :] = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i in range(len(spike)):\n",
    "                        spike_torch = torch.from_numpy(spike[i, :])\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                        else:\n",
    "                            spike_torch = spike_torch.unsqueeze(0)\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.view(1,-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[i, :] = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                print(f\"1실행 시간: {time.time()-start_time}초\")\n",
    "\n",
    "                \n",
    "                start_time = time.time()\n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                spike_norm = np.linalg.norm(spike_hidden, axis=1)  # shape (len(spike))\n",
    "                cluster_norm = np.linalg.norm(Cluster, axis=1)  # shape (num_cluster)\n",
    "\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                print(Cluster)\n",
    "                print(spike_id)\n",
    "                print(f\"2실행 시간: {time.time()-start_time}초\")\n",
    "\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                print(f\"3실행 시간: {time.time()-start_time}초\")\n",
    "\n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "        \n",
    "\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            # print(data)\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_211145-uwn97z14</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/uwn97z14' target=\"_blank\">colorful-durian-89</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/uwn97z14' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/uwn97z14</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 0, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 1, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 8, 'v_decay': 0.75, 'v_threshold': 0.25, 'v_reset': 10000.0, 'BPTT_on': True, 'SAE_hidden_nomean': False, 'current_time': '20250102_211143_694', 'optimizer': 'Adam'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (3): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (5): LIF_layer()\n",
      "      (6): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (8): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (9): LIF_layer()\n",
      "      (10): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (11): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (12): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (13): LIF_layer()\n",
      "      (14): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (15): SSBH_DimChanger_for_fc()\n",
      "      (16): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (17): SSBH_L2NormLayer()\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_211143_694\n",
      "\n",
      "epoch-0 accuracy check\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([58, 4])\n",
      "1실행 시간: 2.1372528076171875초\n",
      "[[-0.19584869  0.595324    0.09228673  0.33738923]\n",
      " [ 0.01394781  0.5834453   0.1793331  -0.11138032]\n",
      " [ 0.05430233  0.58440673  0.08241488  0.54820466]\n",
      " [-0.00561501  0.0092794   0.00230237  0.00894242]]\n",
      "[3. 1. 2. ... 3. 1. 3.]\n",
      "2실행 시간: 0.4028358459472656초\n",
      "3실행 시간: 0.20738840103149414초\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([66, 4])\n",
      "1실행 시간: 0.17032885551452637초\n",
      "[[-0.13955031  0.6740403   0.00562013  0.44267064]\n",
      " [-0.22256753  0.5164073   0.09645879 -0.21947914]\n",
      " [ 0.09099345  0.5616329   0.09236177  0.5451396 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[1. 2. 2. ... 2. 4. 2.]\n",
      "2실행 시간: 0.37293434143066406초\n",
      "3실행 시간: 0.1544966697692871초\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([128, 4])\n",
      "inner.inf torch.Size([21, 4])\n",
      "1실행 시간: 0.14290118217468262초\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = 0\n",
    "Conv_net = True\n",
    "SAE_net = True\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 1\n",
    "learning_rate = 0.001\n",
    "normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 8 # SAE일 때만 유효\n",
    "v_decay = 0.75 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True \n",
    "\n",
    "SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    current_time = current_time,\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [10]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001]},\n",
    "#         \"normalize_on\": {\"values\": [False]},\n",
    "#         \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [True, False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [4,6,8,10]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  1\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "#         )\n",
    "    \n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# current_time = '20250102_174013_409'\n",
    "\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "# JSON으로 저장\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "    loaded_hyperparameters = json.load(f)\n",
    "\n",
    "loss_history = data['loss_history']\n",
    "mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "print(data)\n",
    "max_acc = 0\n",
    "for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "    if i[1] > max_acc:\n",
    "        max_acc = i[1]\n",
    "\n",
    "# 설정 정보 제목 작성\n",
    "title = (\n",
    "    f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "    f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "    f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "    f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    ")\n",
    "\n",
    "# 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "data_list = [\n",
    "    (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "]\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 첫 번째 y축: Accuracy 관련 데이터\n",
    "for label, data in data_list:\n",
    "    epochs, values = zip(*data)  # epoch, value 분리\n",
    "    ax1.plot(epochs, values, label=label)\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.legend(loc=\"center right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# x축을 정수만 표시하도록 설정\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# 두 번째 y축: Loss History\n",
    "ax2 = ax1.twinx()\n",
    "epochs, values = zip(*loss_history)\n",
    "ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "ax2.legend(loc=\"center left\")\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
