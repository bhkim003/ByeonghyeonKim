{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29906/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. 전체 state_dict 로드\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. 현재 모델의 state_dict 가져오기\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'가 포함된 key만 필터링 (현재 모델에도 존재하는 key만)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. 업데이트된 키 출력\n",
    "        print(\"🔄 업데이트된 SYNAPSE 관련 레이어들:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. 모델 dict 업데이트 및 로딩\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> 클래스 인덱스\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE 스타일의 gradient를 흉내냄\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # 이거 걍 1.0임\n",
    "    #         return input_one_hot - target_one_hot, None  # target에는 gradient 없음\n",
    "    \n",
    "\n",
    "    print(\"작은걸크게\")\n",
    "    print(\"작은걸크게\")\n",
    "    print(\"작은걸크게\")\n",
    "    print(\"작은걸크게\")\n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    input_argmin = input_slice.argmin(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient 방향을 argmin 쪽으로\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"모든 파라미터에 대해 gradient descent 수행\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradient를 이용해 파라미터 업데이트\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer 초기화\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    \n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                            \n",
    "                    \n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO 처리 ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw 위 연산이랑 다름. inmemory연산이라 좀 다른 듯\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight 프린트 ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # 통계량 계산\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # 절대값 기반 max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # 그래프 그리기\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # 제목에 통계값 포함\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight 프린트 ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "            ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpe별로 sum값이 10미만일 시 제외\n",
    "            #     # time step별 합 계산: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 이상인 타임스텝만 선택\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # 해당 타임스텝만 추출\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # valid한 time step의 개수\n",
    "            #     net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 중 하나 선택\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                    optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch 크기 ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "                        ## 데이터마다 TIMESTEPS다르다 ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpe별로 sum값이 10미만일 시 제외\n",
    "                        #     # time step별 합 계산: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 이상인 타임스텝만 선택\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # 해당 타임스텝만 추출\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # valid한 time step의 개수\n",
    "                        #     net.module.change_timesteps(TIME) # net에 TIME 설정\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "\n",
    "# unique_name = 'main'\n",
    "# run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 4, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 1, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 # n_tidigits_tonic 8\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'n_tidigits_tonic',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.03125,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = [200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "#                 # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "#                 # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 1000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 0, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "#                 # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용 # trace_on False면 의미없음.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 9, \n",
    "\n",
    "#                 num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "#                 chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = False, # True # False \n",
    "\n",
    "#                 last_lif = False, # True # False \n",
    "\n",
    "#                 temporal_filter = 8, \n",
    "#                 initial_pooling = 1,\n",
    "\n",
    "#                 temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "#                 quantize_bit_list=[8,8,8],\n",
    "#                 scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "#                 # quantize_bit_list=[],\n",
    "#                 # scale_exp=[], \n",
    "#                 timestep_sums_threshold = 0,\n",
    "# # 1w -11~-9\n",
    "# # 1b -11~ -7\n",
    "# # 2w -10~-8\n",
    "# # 2b -10~-8\n",
    "# # 3w -10\n",
    "# # 3b -10\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    "\n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: wvrv58g1\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aiuc0x8k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009765625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250805_135138-aiuc0x8k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/aiuc0x8k' target=\"_blank\">vague-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/aiuc0x8k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/aiuc0x8k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250805_135145_510', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 10, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0009765625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-13, -13], [-13, -13], [-12, -12]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=10, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=10, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0009765625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-0   lr=['0.0009766'], tr/val_loss:  2.302627/  2.290385, val:  50.22%, val_best:  50.22%, tr:  75.45%, tr_best:  75.45%, epoch time: 113.30 seconds, 1.89 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 381 occurrences\n",
      "test - Value 1: 71 occurrences\n",
      "epoch-1   lr=['0.0009766'], tr/val_loss:  2.302642/  2.285637, val:  59.96%, val_best:  59.96%, tr:  83.68%, tr_best:  83.68%, epoch time: 116.89 seconds, 1.95 minutes\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1940 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['0.0009766'], tr/val_loss:  2.302480/  2.325120, val:  50.00%, val_best:  59.96%, tr:  85.37%, tr_best:  85.37%, epoch time: 133.06 seconds, 2.22 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-3   lr=['0.0009766'], tr/val_loss:  2.305861/  2.300282, val:  51.55%, val_best:  59.96%, tr:  88.44%, tr_best:  88.44%, epoch time: 133.78 seconds, 2.23 minutes\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-4   lr=['0.0009766'], tr/val_loss:  2.299962/  2.285677, val:  61.28%, val_best:  61.28%, tr:  88.54%, tr_best:  88.54%, epoch time: 133.75 seconds, 2.23 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['0.0009766'], tr/val_loss:  2.302245/  2.349386, val:  50.00%, val_best:  61.28%, tr:  89.48%, tr_best:  89.48%, epoch time: 139.10 seconds, 2.32 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-6   lr=['0.0009766'], tr/val_loss:  2.304349/  2.298372, val:  58.41%, val_best:  61.28%, tr:  89.66%, tr_best:  89.66%, epoch time: 139.58 seconds, 2.33 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-7   lr=['0.0009766'], tr/val_loss:  2.302950/  2.293492, val:  73.89%, val_best:  73.89%, tr:  90.72%, tr_best:  90.72%, epoch time: 136.54 seconds, 2.28 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-8   lr=['0.0009766'], tr/val_loss:  2.305904/  2.276180, val:  82.96%, val_best:  82.96%, tr:  90.85%, tr_best:  90.85%, epoch time: 137.17 seconds, 2.29 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-9   lr=['0.0009766'], tr/val_loss:  2.305476/  2.306095, val:  68.58%, val_best:  82.96%, tr:  91.57%, tr_best:  91.57%, epoch time: 138.74 seconds, 2.31 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['0.0009766'], tr/val_loss:  2.301760/  2.302379, val:  50.00%, val_best:  82.96%, tr:  89.91%, tr_best:  91.57%, epoch time: 139.00 seconds, 2.32 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-11  lr=['0.0009766'], tr/val_loss:  2.303148/  2.330832, val:  58.63%, val_best:  82.96%, tr:  91.17%, tr_best:  91.57%, epoch time: 138.07 seconds, 2.30 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-12  lr=['0.0009766'], tr/val_loss:  2.304444/  2.317447, val:  57.96%, val_best:  82.96%, tr:  90.70%, tr_best:  91.57%, epoch time: 134.92 seconds, 2.25 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['0.0009766'], tr/val_loss:  2.304988/  2.320125, val:  50.00%, val_best:  82.96%, tr:  91.22%, tr_best:  91.57%, epoch time: 138.24 seconds, 2.30 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-14  lr=['0.0009766'], tr/val_loss:  2.301799/  2.301630, val:  66.15%, val_best:  82.96%, tr:  91.20%, tr_best:  91.57%, epoch time: 138.11 seconds, 2.30 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-15  lr=['0.0009766'], tr/val_loss:  2.302863/  2.292830, val:  76.77%, val_best:  82.96%, tr:  90.00%, tr_best:  91.57%, epoch time: 138.37 seconds, 2.31 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-16  lr=['0.0009766'], tr/val_loss:  2.303968/  2.264118, val:  53.76%, val_best:  82.96%, tr:  90.03%, tr_best:  91.57%, epoch time: 138.18 seconds, 2.30 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-17  lr=['0.0009766'], tr/val_loss:  2.305797/  2.307552, val:  50.66%, val_best:  82.96%, tr:  92.61%, tr_best:  92.61%, epoch time: 137.56 seconds, 2.29 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-18  lr=['0.0009766'], tr/val_loss:  2.303551/  2.334445, val:  52.21%, val_best:  82.96%, tr:  91.84%, tr_best:  92.61%, epoch time: 138.68 seconds, 2.31 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-19  lr=['0.0009766'], tr/val_loss:  2.305561/  2.283479, val:  50.44%, val_best:  82.96%, tr:  91.02%, tr_best:  92.61%, epoch time: 139.93 seconds, 2.33 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 351 occurrences\n",
      "test - Value 1: 101 occurrences\n",
      "epoch-20  lr=['0.0009766'], tr/val_loss:  2.306704/  2.305723, val:  71.02%, val_best:  82.96%, tr:  91.72%, tr_best:  92.61%, epoch time: 138.83 seconds, 2.31 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-21  lr=['0.0009766'], tr/val_loss:  2.301111/  2.311245, val:  62.39%, val_best:  82.96%, tr:  90.75%, tr_best:  92.61%, epoch time: 137.65 seconds, 2.29 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-22  lr=['0.0009766'], tr/val_loss:  2.306600/  2.311889, val:  57.08%, val_best:  82.96%, tr:  91.79%, tr_best:  92.61%, epoch time: 138.93 seconds, 2.32 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 304 occurrences\n",
      "test - Value 1: 148 occurrences\n",
      "epoch-23  lr=['0.0009766'], tr/val_loss:  2.301696/  2.335579, val:  76.99%, val_best:  82.96%, tr:  91.84%, tr_best:  92.61%, epoch time: 139.23 seconds, 2.32 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-24  lr=['0.0009766'], tr/val_loss:  2.305502/  2.256872, val:  50.22%, val_best:  82.96%, tr:  91.64%, tr_best:  92.61%, epoch time: 136.03 seconds, 2.27 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-25  lr=['0.0009766'], tr/val_loss:  2.303102/  2.301623, val:  51.99%, val_best:  82.96%, tr:  92.06%, tr_best:  92.61%, epoch time: 139.37 seconds, 2.32 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-26  lr=['0.0009766'], tr/val_loss:  2.303197/  2.322263, val:  53.10%, val_best:  82.96%, tr:  92.91%, tr_best:  92.91%, epoch time: 139.24 seconds, 2.32 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-27  lr=['0.0009766'], tr/val_loss:  2.302888/  2.320277, val:  78.54%, val_best:  82.96%, tr:  92.34%, tr_best:  92.91%, epoch time: 135.45 seconds, 2.26 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-28  lr=['0.0009766'], tr/val_loss:  2.304660/  2.275562, val:  59.29%, val_best:  82.96%, tr:  91.89%, tr_best:  92.91%, epoch time: 134.11 seconds, 2.24 minutes\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['0.0009766'], tr/val_loss:  2.308703/  2.348801, val:  50.00%, val_best:  82.96%, tr:  93.97%, tr_best:  93.97%, epoch time: 134.18 seconds, 2.24 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 384 occurrences\n",
      "test - Value 1: 68 occurrences\n",
      "epoch-30  lr=['0.0009766'], tr/val_loss:  2.305128/  2.304201, val:  62.83%, val_best:  82.96%, tr:  93.11%, tr_best:  93.97%, epoch time: 137.24 seconds, 2.29 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 417 occurrences\n",
      "test - Value 1: 35 occurrences\n",
      "epoch-31  lr=['0.0009766'], tr/val_loss:  2.306717/  2.295867, val:  57.30%, val_best:  82.96%, tr:  92.86%, tr_best:  93.97%, epoch time: 134.82 seconds, 2.25 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-32  lr=['0.0009766'], tr/val_loss:  2.302569/  2.281685, val:  63.05%, val_best:  82.96%, tr:  91.94%, tr_best:  93.97%, epoch time: 137.41 seconds, 2.29 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 346 occurrences\n",
      "test - Value 1: 106 occurrences\n",
      "epoch-33  lr=['0.0009766'], tr/val_loss:  2.304672/  2.269470, val:  70.35%, val_best:  82.96%, tr:  90.38%, tr_best:  93.97%, epoch time: 139.73 seconds, 2.33 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 323 occurrences\n",
      "test - Value 1: 129 occurrences\n",
      "epoch-34  lr=['0.0009766'], tr/val_loss:  2.305315/  2.301139, val:  71.90%, val_best:  82.96%, tr:  90.85%, tr_best:  93.97%, epoch time: 138.79 seconds, 2.31 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-35  lr=['0.0009766'], tr/val_loss:  2.305881/  2.322461, val:  52.43%, val_best:  82.96%, tr:  91.59%, tr_best:  93.97%, epoch time: 138.75 seconds, 2.31 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-36  lr=['0.0009766'], tr/val_loss:  2.305071/  2.282080, val:  52.65%, val_best:  82.96%, tr:  89.86%, tr_best:  93.97%, epoch time: 138.44 seconds, 2.31 minutes\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1940 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-37  lr=['0.0009766'], tr/val_loss:  2.305453/  2.311762, val:  52.88%, val_best:  82.96%, tr:  91.57%, tr_best:  93.97%, epoch time: 138.43 seconds, 2.31 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-38  lr=['0.0009766'], tr/val_loss:  2.308842/  2.310202, val:  52.88%, val_best:  82.96%, tr:  92.73%, tr_best:  93.97%, epoch time: 136.17 seconds, 2.27 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-39  lr=['0.0009766'], tr/val_loss:  2.303260/  2.336649, val:  50.44%, val_best:  82.96%, tr:  92.58%, tr_best:  93.97%, epoch time: 138.62 seconds, 2.31 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 336 occurrences\n",
      "test - Value 1: 116 occurrences\n",
      "epoch-40  lr=['0.0009766'], tr/val_loss:  2.305438/  2.264388, val:  70.35%, val_best:  82.96%, tr:  90.75%, tr_best:  93.97%, epoch time: 138.76 seconds, 2.31 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-41  lr=['0.0009766'], tr/val_loss:  2.303374/  2.321964, val:  62.17%, val_best:  82.96%, tr:  91.27%, tr_best:  93.97%, epoch time: 138.11 seconds, 2.30 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-42  lr=['0.0009766'], tr/val_loss:  2.302534/  2.283892, val:  66.15%, val_best:  82.96%, tr:  90.82%, tr_best:  93.97%, epoch time: 137.05 seconds, 2.28 minutes\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 383 occurrences\n",
      "test - Value 1: 69 occurrences\n",
      "epoch-43  lr=['0.0009766'], tr/val_loss:  2.303077/  2.298325, val:  64.38%, val_best:  82.96%, tr:  91.64%, tr_best:  93.97%, epoch time: 138.45 seconds, 2.31 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-44  lr=['0.0009766'], tr/val_loss:  2.304096/  2.318901, val:  59.73%, val_best:  82.96%, tr:  92.34%, tr_best:  93.97%, epoch time: 138.11 seconds, 2.30 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-45  lr=['0.0009766'], tr/val_loss:  2.303615/  2.290533, val:  50.22%, val_best:  82.96%, tr:  90.67%, tr_best:  93.97%, epoch time: 138.06 seconds, 2.30 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['0.0009766'], tr/val_loss:  2.301107/  2.285423, val:  50.00%, val_best:  82.96%, tr:  91.37%, tr_best:  93.97%, epoch time: 136.92 seconds, 2.28 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-47  lr=['0.0009766'], tr/val_loss:  2.303580/  2.268352, val:  50.44%, val_best:  82.96%, tr:  92.36%, tr_best:  93.97%, epoch time: 137.39 seconds, 2.29 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-48  lr=['0.0009766'], tr/val_loss:  2.301883/  2.312090, val:  74.78%, val_best:  82.96%, tr:  92.04%, tr_best:  93.97%, epoch time: 133.12 seconds, 2.22 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-49  lr=['0.0009766'], tr/val_loss:  2.299124/  2.310127, val:  54.87%, val_best:  82.96%, tr:  91.67%, tr_best:  93.97%, epoch time: 132.44 seconds, 2.21 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['0.0009766'], tr/val_loss:  2.302413/  2.341928, val:  50.00%, val_best:  82.96%, tr:  91.79%, tr_best:  93.97%, epoch time: 134.22 seconds, 2.24 minutes\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1961 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-51  lr=['0.0009766'], tr/val_loss:  2.303918/  2.270386, val:  66.15%, val_best:  82.96%, tr:  92.63%, tr_best:  93.97%, epoch time: 136.84 seconds, 2.28 minutes\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-52  lr=['0.0009766'], tr/val_loss:  2.302423/  2.288615, val:  50.66%, val_best:  82.96%, tr:  92.14%, tr_best:  93.97%, epoch time: 139.33 seconds, 2.32 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-53  lr=['0.0009766'], tr/val_loss:  2.298731/  2.255813, val:  50.44%, val_best:  82.96%, tr:  91.96%, tr_best:  93.97%, epoch time: 136.55 seconds, 2.28 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-54  lr=['0.0009766'], tr/val_loss:  2.303337/  2.291899, val:  50.88%, val_best:  82.96%, tr:  90.35%, tr_best:  93.97%, epoch time: 133.90 seconds, 2.23 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 360 occurrences\n",
      "test - Value 1: 92 occurrences\n",
      "epoch-55  lr=['0.0009766'], tr/val_loss:  2.302562/  2.286034, val:  67.70%, val_best:  82.96%, tr:  91.05%, tr_best:  93.97%, epoch time: 136.72 seconds, 2.28 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-56  lr=['0.0009766'], tr/val_loss:  2.304440/  2.322548, val:  50.00%, val_best:  82.96%, tr:  91.22%, tr_best:  93.97%, epoch time: 139.23 seconds, 2.32 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 384 occurrences\n",
      "test - Value 1: 68 occurrences\n",
      "epoch-57  lr=['0.0009766'], tr/val_loss:  2.304726/  2.296998, val:  64.16%, val_best:  82.96%, tr:  90.87%, tr_best:  93.97%, epoch time: 138.35 seconds, 2.31 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 414 occurrences\n",
      "test - Value 1: 38 occurrences\n",
      "epoch-58  lr=['0.0009766'], tr/val_loss:  2.306100/  2.298669, val:  58.41%, val_best:  82.96%, tr:  91.44%, tr_best:  93.97%, epoch time: 138.62 seconds, 2.31 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-59  lr=['0.0009766'], tr/val_loss:  2.302591/  2.276086, val:  52.88%, val_best:  82.96%, tr:  90.87%, tr_best:  93.97%, epoch time: 139.03 seconds, 2.32 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 349 occurrences\n",
      "test - Value 1: 103 occurrences\n",
      "epoch-60  lr=['0.0009766'], tr/val_loss:  2.304889/  2.326927, val:  67.48%, val_best:  82.96%, tr:  91.07%, tr_best:  93.97%, epoch time: 139.06 seconds, 2.32 minutes\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['0.0009766'], tr/val_loss:  2.301720/  2.301999, val:  50.00%, val_best:  82.96%, tr:  91.42%, tr_best:  93.97%, epoch time: 140.13 seconds, 2.34 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-62  lr=['0.0009766'], tr/val_loss:  2.303712/  2.306035, val:  50.00%, val_best:  82.96%, tr:  91.20%, tr_best:  93.97%, epoch time: 139.70 seconds, 2.33 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-63  lr=['0.0009766'], tr/val_loss:  2.304303/  2.294002, val:  52.43%, val_best:  82.96%, tr:  90.67%, tr_best:  93.97%, epoch time: 138.73 seconds, 2.31 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-64  lr=['0.0009766'], tr/val_loss:  2.305768/  2.288061, val:  53.98%, val_best:  82.96%, tr:  92.26%, tr_best:  93.97%, epoch time: 140.04 seconds, 2.33 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-65  lr=['0.0009766'], tr/val_loss:  2.304807/  2.305721, val:  76.11%, val_best:  82.96%, tr:  92.58%, tr_best:  93.97%, epoch time: 137.62 seconds, 2.29 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-66  lr=['0.0009766'], tr/val_loss:  2.304046/  2.294399, val:  59.51%, val_best:  82.96%, tr:  92.24%, tr_best:  93.97%, epoch time: 134.74 seconds, 2.25 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 368 occurrences\n",
      "test - Value 1: 84 occurrences\n",
      "epoch-67  lr=['0.0009766'], tr/val_loss:  2.301468/  2.297149, val:  65.93%, val_best:  82.96%, tr:  92.11%, tr_best:  93.97%, epoch time: 139.34 seconds, 2.32 minutes\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-68  lr=['0.0009766'], tr/val_loss:  2.303231/  2.316901, val:  54.87%, val_best:  82.96%, tr:  91.96%, tr_best:  93.97%, epoch time: 138.90 seconds, 2.31 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-69  lr=['0.0009766'], tr/val_loss:  2.307419/  2.268927, val:  60.40%, val_best:  82.96%, tr:  92.16%, tr_best:  93.97%, epoch time: 136.79 seconds, 2.28 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-70  lr=['0.0009766'], tr/val_loss:  2.304614/  2.319616, val:  52.43%, val_best:  82.96%, tr:  92.11%, tr_best:  93.97%, epoch time: 135.26 seconds, 2.25 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-71  lr=['0.0009766'], tr/val_loss:  2.304595/  2.317427, val:  72.35%, val_best:  82.96%, tr:  91.91%, tr_best:  93.97%, epoch time: 137.23 seconds, 2.29 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['0.0009766'], tr/val_loss:  2.305645/  2.329004, val:  50.00%, val_best:  82.96%, tr:  91.49%, tr_best:  93.97%, epoch time: 136.90 seconds, 2.28 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 320 occurrences\n",
      "test - Value 1: 132 occurrences\n",
      "epoch-73  lr=['0.0009766'], tr/val_loss:  2.305636/  2.302169, val:  74.78%, val_best:  82.96%, tr:  91.69%, tr_best:  93.97%, epoch time: 136.44 seconds, 2.27 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-74  lr=['0.0009766'], tr/val_loss:  2.306952/  2.354135, val:  50.44%, val_best:  82.96%, tr:  92.09%, tr_best:  93.97%, epoch time: 138.56 seconds, 2.31 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 281 occurrences\n",
      "test - Value 1: 171 occurrences\n",
      "epoch-75  lr=['0.0009766'], tr/val_loss:  2.307373/  2.279611, val:  80.75%, val_best:  82.96%, tr:  92.51%, tr_best:  93.97%, epoch time: 137.65 seconds, 2.29 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-76  lr=['0.0009766'], tr/val_loss:  2.303294/  2.265385, val:  55.09%, val_best:  82.96%, tr:  91.34%, tr_best:  93.97%, epoch time: 138.86 seconds, 2.31 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-77  lr=['0.0009766'], tr/val_loss:  2.303668/  2.271117, val:  51.11%, val_best:  82.96%, tr:  91.10%, tr_best:  93.97%, epoch time: 137.56 seconds, 2.29 minutes\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-78  lr=['0.0009766'], tr/val_loss:  2.303558/  2.341095, val:  53.54%, val_best:  82.96%, tr:  91.27%, tr_best:  93.97%, epoch time: 135.82 seconds, 2.26 minutes\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-79  lr=['0.0009766'], tr/val_loss:  2.305195/  2.276739, val:  66.81%, val_best:  82.96%, tr:  91.15%, tr_best:  93.97%, epoch time: 133.48 seconds, 2.22 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['0.0009766'], tr/val_loss:  2.305184/  2.259047, val:  50.00%, val_best:  82.96%, tr:  91.49%, tr_best:  93.97%, epoch time: 135.19 seconds, 2.25 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-81  lr=['0.0009766'], tr/val_loss:  2.304207/  2.344667, val:  77.21%, val_best:  82.96%, tr:  91.74%, tr_best:  93.97%, epoch time: 136.77 seconds, 2.28 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-82  lr=['0.0009766'], tr/val_loss:  2.306485/  2.338501, val:  50.22%, val_best:  82.96%, tr:  91.89%, tr_best:  93.97%, epoch time: 137.96 seconds, 2.30 minutes\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-83  lr=['0.0009766'], tr/val_loss:  2.301347/  2.320620, val:  50.22%, val_best:  82.96%, tr:  91.37%, tr_best:  93.97%, epoch time: 139.00 seconds, 2.32 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-84  lr=['0.0009766'], tr/val_loss:  2.305093/  2.351737, val:  60.40%, val_best:  82.96%, tr:  91.96%, tr_best:  93.97%, epoch time: 138.33 seconds, 2.31 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-85  lr=['0.0009766'], tr/val_loss:  2.302429/  2.278958, val:  79.65%, val_best:  82.96%, tr:  91.91%, tr_best:  93.97%, epoch time: 137.52 seconds, 2.29 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-86  lr=['0.0009766'], tr/val_loss:  2.304239/  2.308807, val:  65.93%, val_best:  82.96%, tr:  92.24%, tr_best:  93.97%, epoch time: 138.60 seconds, 2.31 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-87  lr=['0.0009766'], tr/val_loss:  2.301487/  2.309650, val:  62.83%, val_best:  82.96%, tr:  91.89%, tr_best:  93.97%, epoch time: 138.06 seconds, 2.30 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-88  lr=['0.0009766'], tr/val_loss:  2.304238/  2.318108, val:  51.55%, val_best:  82.96%, tr:  92.76%, tr_best:  93.97%, epoch time: 138.14 seconds, 2.30 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-89  lr=['0.0009766'], tr/val_loss:  2.301688/  2.283672, val:  57.30%, val_best:  82.96%, tr:  91.25%, tr_best:  93.97%, epoch time: 137.42 seconds, 2.29 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-90  lr=['0.0009766'], tr/val_loss:  2.298724/  2.305078, val:  50.66%, val_best:  82.96%, tr:  93.45%, tr_best:  93.97%, epoch time: 138.32 seconds, 2.31 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 328 occurrences\n",
      "test - Value 1: 124 occurrences\n",
      "epoch-91  lr=['0.0009766'], tr/val_loss:  2.305375/  2.304160, val:  75.66%, val_best:  82.96%, tr:  91.34%, tr_best:  93.97%, epoch time: 138.47 seconds, 2.31 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-92  lr=['0.0009766'], tr/val_loss:  2.301651/  2.309331, val:  50.66%, val_best:  82.96%, tr:  91.17%, tr_best:  93.97%, epoch time: 139.58 seconds, 2.33 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-93  lr=['0.0009766'], tr/val_loss:  2.304593/  2.318094, val:  52.43%, val_best:  82.96%, tr:  92.39%, tr_best:  93.97%, epoch time: 138.58 seconds, 2.31 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-94  lr=['0.0009766'], tr/val_loss:  2.304447/  2.267902, val:  68.14%, val_best:  82.96%, tr:  92.91%, tr_best:  93.97%, epoch time: 139.82 seconds, 2.33 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['0.0009766'], tr/val_loss:  2.303668/  2.332204, val:  50.00%, val_best:  82.96%, tr:  92.29%, tr_best:  93.97%, epoch time: 139.72 seconds, 2.33 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['0.0009766'], tr/val_loss:  2.304478/  2.340420, val:  50.00%, val_best:  82.96%, tr:  91.77%, tr_best:  93.97%, epoch time: 138.04 seconds, 2.30 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-97  lr=['0.0009766'], tr/val_loss:  2.305766/  2.278089, val:  50.66%, val_best:  82.96%, tr:  92.53%, tr_best:  93.97%, epoch time: 139.60 seconds, 2.33 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-98  lr=['0.0009766'], tr/val_loss:  2.305777/  2.270106, val:  50.00%, val_best:  82.96%, tr:  92.41%, tr_best:  93.97%, epoch time: 139.69 seconds, 2.33 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['0.0009766'], tr/val_loss:  2.303522/  2.316750, val:  50.00%, val_best:  82.96%, tr:  92.63%, tr_best:  93.97%, epoch time: 138.91 seconds, 2.32 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 384 occurrences\n",
      "test - Value 1: 68 occurrences\n",
      "epoch-100 lr=['0.0009766'], tr/val_loss:  2.304969/  2.332157, val:  65.04%, val_best:  82.96%, tr:  92.61%, tr_best:  93.97%, epoch time: 138.42 seconds, 2.31 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-101 lr=['0.0009766'], tr/val_loss:  2.305445/  2.290866, val:  77.21%, val_best:  82.96%, tr:  92.76%, tr_best:  93.97%, epoch time: 138.71 seconds, 2.31 minutes\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-102 lr=['0.0009766'], tr/val_loss:  2.302623/  2.309784, val:  83.63%, val_best:  83.63%, tr:  91.77%, tr_best:  93.97%, epoch time: 139.14 seconds, 2.32 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 348 occurrences\n",
      "test - Value 1: 104 occurrences\n",
      "epoch-103 lr=['0.0009766'], tr/val_loss:  2.306524/  2.312322, val:  72.57%, val_best:  83.63%, tr:  93.23%, tr_best:  93.97%, epoch time: 136.52 seconds, 2.28 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['0.0009766'], tr/val_loss:  2.304892/  2.327768, val:  50.00%, val_best:  83.63%, tr:  91.84%, tr_best:  93.97%, epoch time: 133.34 seconds, 2.22 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-105 lr=['0.0009766'], tr/val_loss:  2.305088/  2.329465, val:  50.66%, val_best:  83.63%, tr:  92.14%, tr_best:  93.97%, epoch time: 138.47 seconds, 2.31 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-106 lr=['0.0009766'], tr/val_loss:  2.303857/  2.324904, val:  51.33%, val_best:  83.63%, tr:  92.56%, tr_best:  93.97%, epoch time: 139.85 seconds, 2.33 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 38 occurrences\n",
      "test - Value 1: 414 occurrences\n",
      "epoch-107 lr=['0.0009766'], tr/val_loss:  2.305249/  2.320341, val:  58.41%, val_best:  83.63%, tr:  92.44%, tr_best:  93.97%, epoch time: 138.02 seconds, 2.30 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 360 occurrences\n",
      "test - Value 1: 92 occurrences\n",
      "epoch-108 lr=['0.0009766'], tr/val_loss:  2.303282/  2.307751, val:  68.58%, val_best:  83.63%, tr:  92.86%, tr_best:  93.97%, epoch time: 136.30 seconds, 2.27 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-109 lr=['0.0009766'], tr/val_loss:  2.303040/  2.321295, val:  60.18%, val_best:  83.63%, tr:  92.93%, tr_best:  93.97%, epoch time: 137.95 seconds, 2.30 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-110 lr=['0.0009766'], tr/val_loss:  2.303743/  2.325941, val:  53.98%, val_best:  83.63%, tr:  92.93%, tr_best:  93.97%, epoch time: 138.65 seconds, 2.31 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 366 occurrences\n",
      "test - Value 1: 86 occurrences\n",
      "epoch-111 lr=['0.0009766'], tr/val_loss:  2.305190/  2.297979, val:  66.81%, val_best:  83.63%, tr:  92.96%, tr_best:  93.97%, epoch time: 138.49 seconds, 2.31 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 401 occurrences\n",
      "test - Value 1: 51 occurrences\n",
      "epoch-112 lr=['0.0009766'], tr/val_loss:  2.303435/  2.286409, val:  61.28%, val_best:  83.63%, tr:  92.49%, tr_best:  93.97%, epoch time: 139.42 seconds, 2.32 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-113 lr=['0.0009766'], tr/val_loss:  2.306298/  2.290089, val:  50.22%, val_best:  83.63%, tr:  92.81%, tr_best:  93.97%, epoch time: 137.58 seconds, 2.29 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['0.0009766'], tr/val_loss:  2.303422/  2.285727, val:  50.00%, val_best:  83.63%, tr:  91.25%, tr_best:  93.97%, epoch time: 137.79 seconds, 2.30 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-115 lr=['0.0009766'], tr/val_loss:  2.305750/  2.313691, val:  67.70%, val_best:  83.63%, tr:  92.98%, tr_best:  93.97%, epoch time: 136.98 seconds, 2.28 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-116 lr=['0.0009766'], tr/val_loss:  2.304710/  2.291252, val:  59.29%, val_best:  83.63%, tr:  91.64%, tr_best:  93.97%, epoch time: 139.86 seconds, 2.33 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-117 lr=['0.0009766'], tr/val_loss:  2.302589/  2.298834, val:  74.56%, val_best:  83.63%, tr:  91.17%, tr_best:  93.97%, epoch time: 136.78 seconds, 2.28 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-118 lr=['0.0009766'], tr/val_loss:  2.304936/  2.302270, val:  74.34%, val_best:  83.63%, tr:  92.88%, tr_best:  93.97%, epoch time: 139.53 seconds, 2.33 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 244 occurrences\n",
      "test - Value 1: 208 occurrences\n",
      "epoch-119 lr=['0.0009766'], tr/val_loss:  2.305711/  2.284436, val:  81.86%, val_best:  83.63%, tr:  91.07%, tr_best:  93.97%, epoch time: 138.72 seconds, 2.31 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-120 lr=['0.0009766'], tr/val_loss:  2.303268/  2.312657, val:  52.88%, val_best:  83.63%, tr:  92.19%, tr_best:  93.97%, epoch time: 138.82 seconds, 2.31 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['0.0009766'], tr/val_loss:  2.301138/  2.347778, val:  50.00%, val_best:  83.63%, tr:  91.62%, tr_best:  93.97%, epoch time: 138.76 seconds, 2.31 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-122 lr=['0.0009766'], tr/val_loss:  2.303354/  2.310910, val:  50.66%, val_best:  83.63%, tr:  91.54%, tr_best:  93.97%, epoch time: 139.09 seconds, 2.32 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-123 lr=['0.0009766'], tr/val_loss:  2.305030/  2.320666, val:  50.44%, val_best:  83.63%, tr:  91.99%, tr_best:  93.97%, epoch time: 136.73 seconds, 2.28 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-124 lr=['0.0009766'], tr/val_loss:  2.306081/  2.287578, val:  51.99%, val_best:  83.63%, tr:  92.34%, tr_best:  93.97%, epoch time: 136.82 seconds, 2.28 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 294 occurrences\n",
      "test - Value 1: 158 occurrences\n",
      "epoch-125 lr=['0.0009766'], tr/val_loss:  2.303804/  2.300870, val:  73.89%, val_best:  83.63%, tr:  90.95%, tr_best:  93.97%, epoch time: 138.20 seconds, 2.30 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-126 lr=['0.0009766'], tr/val_loss:  2.303394/  2.318901, val:  53.98%, val_best:  83.63%, tr:  91.25%, tr_best:  93.97%, epoch time: 140.18 seconds, 2.34 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-127 lr=['0.0009766'], tr/val_loss:  2.302968/  2.300174, val:  50.00%, val_best:  83.63%, tr:  92.21%, tr_best:  93.97%, epoch time: 138.11 seconds, 2.30 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 307 occurrences\n",
      "test - Value 1: 145 occurrences\n",
      "epoch-128 lr=['0.0009766'], tr/val_loss:  2.305555/  2.313204, val:  76.77%, val_best:  83.63%, tr:  92.56%, tr_best:  93.97%, epoch time: 135.41 seconds, 2.26 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-129 lr=['0.0009766'], tr/val_loss:  2.304378/  2.319509, val:  56.19%, val_best:  83.63%, tr:  92.24%, tr_best:  93.97%, epoch time: 134.63 seconds, 2.24 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-130 lr=['0.0009766'], tr/val_loss:  2.303302/  2.293173, val:  80.09%, val_best:  83.63%, tr:  93.18%, tr_best:  93.97%, epoch time: 135.49 seconds, 2.26 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-131 lr=['0.0009766'], tr/val_loss:  2.302994/  2.314419, val:  58.63%, val_best:  83.63%, tr:  92.39%, tr_best:  93.97%, epoch time: 140.29 seconds, 2.34 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 390 occurrences\n",
      "test - Value 1: 62 occurrences\n",
      "epoch-132 lr=['0.0009766'], tr/val_loss:  2.302590/  2.280561, val:  63.27%, val_best:  83.63%, tr:  92.93%, tr_best:  93.97%, epoch time: 137.82 seconds, 2.30 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-133 lr=['0.0009766'], tr/val_loss:  2.304023/  2.307348, val:  51.33%, val_best:  83.63%, tr:  92.39%, tr_best:  93.97%, epoch time: 138.03 seconds, 2.30 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-134 lr=['0.0009766'], tr/val_loss:  2.302668/  2.342090, val:  50.22%, val_best:  83.63%, tr:  92.11%, tr_best:  93.97%, epoch time: 139.31 seconds, 2.32 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 349 occurrences\n",
      "test - Value 1: 103 occurrences\n",
      "epoch-135 lr=['0.0009766'], tr/val_loss:  2.299866/  2.328226, val:  71.46%, val_best:  83.63%, tr:  92.46%, tr_best:  93.97%, epoch time: 138.57 seconds, 2.31 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 249 occurrences\n",
      "test - Value 1: 203 occurrences\n",
      "epoch-136 lr=['0.0009766'], tr/val_loss:  2.303495/  2.313904, val:  79.87%, val_best:  83.63%, tr:  92.73%, tr_best:  93.97%, epoch time: 138.51 seconds, 2.31 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-137 lr=['0.0009766'], tr/val_loss:  2.303848/  2.269568, val:  50.00%, val_best:  83.63%, tr:  92.19%, tr_best:  93.97%, epoch time: 138.85 seconds, 2.31 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-138 lr=['0.0009766'], tr/val_loss:  2.304195/  2.281272, val:  55.31%, val_best:  83.63%, tr:  92.21%, tr_best:  93.97%, epoch time: 139.00 seconds, 2.32 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-139 lr=['0.0009766'], tr/val_loss:  2.301530/  2.310664, val:  53.54%, val_best:  83.63%, tr:  91.72%, tr_best:  93.97%, epoch time: 137.50 seconds, 2.29 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-140 lr=['0.0009766'], tr/val_loss:  2.305855/  2.294203, val:  63.94%, val_best:  83.63%, tr:  92.26%, tr_best:  93.97%, epoch time: 137.66 seconds, 2.29 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-141 lr=['0.0009766'], tr/val_loss:  2.303091/  2.292282, val:  82.52%, val_best:  83.63%, tr:  92.14%, tr_best:  93.97%, epoch time: 135.89 seconds, 2.26 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 377 occurrences\n",
      "test - Value 1: 75 occurrences\n",
      "epoch-142 lr=['0.0009766'], tr/val_loss:  2.304121/  2.293100, val:  66.59%, val_best:  83.63%, tr:  93.53%, tr_best:  93.97%, epoch time: 139.84 seconds, 2.33 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-143 lr=['0.0009766'], tr/val_loss:  2.300357/  2.291364, val:  66.37%, val_best:  83.63%, tr:  92.41%, tr_best:  93.97%, epoch time: 138.97 seconds, 2.32 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-144 lr=['0.0009766'], tr/val_loss:  2.301458/  2.282078, val:  62.39%, val_best:  83.63%, tr:  90.43%, tr_best:  93.97%, epoch time: 138.33 seconds, 2.31 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-145 lr=['0.0009766'], tr/val_loss:  2.303479/  2.251759, val:  50.00%, val_best:  83.63%, tr:  91.96%, tr_best:  93.97%, epoch time: 138.42 seconds, 2.31 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-146 lr=['0.0009766'], tr/val_loss:  2.302298/  2.317960, val:  60.40%, val_best:  83.63%, tr:  92.36%, tr_best:  93.97%, epoch time: 140.37 seconds, 2.34 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-147 lr=['0.0009766'], tr/val_loss:  2.301507/  2.310812, val:  77.65%, val_best:  83.63%, tr:  91.27%, tr_best:  93.97%, epoch time: 136.19 seconds, 2.27 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-148 lr=['0.0009766'], tr/val_loss:  2.302976/  2.305990, val:  64.82%, val_best:  83.63%, tr:  92.26%, tr_best:  93.97%, epoch time: 140.21 seconds, 2.34 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-149 lr=['0.0009766'], tr/val_loss:  2.304036/  2.313606, val:  57.30%, val_best:  83.63%, tr:  91.77%, tr_best:  93.97%, epoch time: 138.27 seconds, 2.30 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-150 lr=['0.0009766'], tr/val_loss:  2.300920/  2.311447, val:  50.22%, val_best:  83.63%, tr:  91.64%, tr_best:  93.97%, epoch time: 138.07 seconds, 2.30 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-151 lr=['0.0009766'], tr/val_loss:  2.302926/  2.317028, val:  55.09%, val_best:  83.63%, tr:  93.01%, tr_best:  93.97%, epoch time: 135.93 seconds, 2.27 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-152 lr=['0.0009766'], tr/val_loss:  2.301733/  2.268404, val:  58.63%, val_best:  83.63%, tr:  92.96%, tr_best:  93.97%, epoch time: 135.46 seconds, 2.26 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-153 lr=['0.0009766'], tr/val_loss:  2.303225/  2.310304, val:  51.99%, val_best:  83.63%, tr:  93.18%, tr_best:  93.97%, epoch time: 137.90 seconds, 2.30 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 85 occurrences\n",
      "test - Value 1: 367 occurrences\n",
      "epoch-154 lr=['0.0009766'], tr/val_loss:  2.300375/  2.322381, val:  67.92%, val_best:  83.63%, tr:  91.79%, tr_best:  93.97%, epoch time: 135.14 seconds, 2.25 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-155 lr=['0.0009766'], tr/val_loss:  2.305501/  2.297444, val:  50.00%, val_best:  83.63%, tr:  93.80%, tr_best:  93.97%, epoch time: 134.22 seconds, 2.24 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-156 lr=['0.0009766'], tr/val_loss:  2.298874/  2.289689, val:  80.97%, val_best:  83.63%, tr:  92.96%, tr_best:  93.97%, epoch time: 137.13 seconds, 2.29 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-157 lr=['0.0009766'], tr/val_loss:  2.302983/  2.299628, val:  64.60%, val_best:  83.63%, tr:  92.29%, tr_best:  93.97%, epoch time: 138.35 seconds, 2.31 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 388 occurrences\n",
      "test - Value 1: 64 occurrences\n",
      "epoch-158 lr=['0.0009766'], tr/val_loss:  2.298670/  2.303153, val:  64.16%, val_best:  83.63%, tr:  92.01%, tr_best:  93.97%, epoch time: 136.51 seconds, 2.28 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-159 lr=['0.0009766'], tr/val_loss:  2.306685/  2.374708, val:  51.11%, val_best:  83.63%, tr:  93.13%, tr_best:  93.97%, epoch time: 135.70 seconds, 2.26 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-160 lr=['0.0009766'], tr/val_loss:  2.305406/  2.320893, val:  78.54%, val_best:  83.63%, tr:  94.07%, tr_best:  94.07%, epoch time: 137.04 seconds, 2.28 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-161 lr=['0.0009766'], tr/val_loss:  2.303085/  2.306348, val:  71.46%, val_best:  83.63%, tr:  93.58%, tr_best:  94.07%, epoch time: 136.71 seconds, 2.28 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-162 lr=['0.0009766'], tr/val_loss:  2.303248/  2.258003, val:  54.42%, val_best:  83.63%, tr:  92.41%, tr_best:  94.07%, epoch time: 136.21 seconds, 2.27 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-163 lr=['0.0009766'], tr/val_loss:  2.308099/  2.307449, val:  69.03%, val_best:  83.63%, tr:  93.30%, tr_best:  94.07%, epoch time: 137.46 seconds, 2.29 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-164 lr=['0.0009766'], tr/val_loss:  2.311350/  2.297607, val:  66.81%, val_best:  83.63%, tr:  93.11%, tr_best:  94.07%, epoch time: 136.93 seconds, 2.28 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-165 lr=['0.0009766'], tr/val_loss:  2.307498/  2.287771, val:  51.33%, val_best:  83.63%, tr:  92.78%, tr_best:  94.07%, epoch time: 136.93 seconds, 2.28 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-166 lr=['0.0009766'], tr/val_loss:  2.308836/  2.298321, val:  54.65%, val_best:  83.63%, tr:  93.38%, tr_best:  94.07%, epoch time: 133.94 seconds, 2.23 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-167 lr=['0.0009766'], tr/val_loss:  2.307603/  2.394814, val:  50.44%, val_best:  83.63%, tr:  93.15%, tr_best:  94.07%, epoch time: 138.21 seconds, 2.30 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['0.0009766'], tr/val_loss:  2.304694/  2.332295, val:  50.00%, val_best:  83.63%, tr:  92.76%, tr_best:  94.07%, epoch time: 138.55 seconds, 2.31 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-169 lr=['0.0009766'], tr/val_loss:  2.305789/  2.265415, val:  62.83%, val_best:  83.63%, tr:  93.95%, tr_best:  94.07%, epoch time: 138.13 seconds, 2.30 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['0.0009766'], tr/val_loss:  2.306687/  2.373274, val:  50.00%, val_best:  83.63%, tr:  93.35%, tr_best:  94.07%, epoch time: 135.57 seconds, 2.26 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-171 lr=['0.0009766'], tr/val_loss:  2.302467/  2.288914, val:  60.40%, val_best:  83.63%, tr:  93.13%, tr_best:  94.07%, epoch time: 134.95 seconds, 2.25 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-172 lr=['0.0009766'], tr/val_loss:  2.300838/  2.286033, val:  81.19%, val_best:  83.63%, tr:  93.43%, tr_best:  94.07%, epoch time: 137.08 seconds, 2.28 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-173 lr=['0.0009766'], tr/val_loss:  2.308050/  2.286478, val:  79.87%, val_best:  83.63%, tr:  92.01%, tr_best:  94.07%, epoch time: 142.99 seconds, 2.38 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-174 lr=['0.0009766'], tr/val_loss:  2.301333/  2.316542, val:  52.65%, val_best:  83.63%, tr:  91.57%, tr_best:  94.07%, epoch time: 142.23 seconds, 2.37 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-175 lr=['0.0009766'], tr/val_loss:  2.302543/  2.313399, val:  50.88%, val_best:  83.63%, tr:  92.29%, tr_best:  94.07%, epoch time: 142.92 seconds, 2.38 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-176 lr=['0.0009766'], tr/val_loss:  2.301080/  2.295475, val:  61.95%, val_best:  83.63%, tr:  92.51%, tr_best:  94.07%, epoch time: 141.18 seconds, 2.35 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-177 lr=['0.0009766'], tr/val_loss:  2.303542/  2.310689, val:  82.08%, val_best:  83.63%, tr:  91.34%, tr_best:  94.07%, epoch time: 142.32 seconds, 2.37 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 363 occurrences\n",
      "test - Value 1: 89 occurrences\n",
      "epoch-178 lr=['0.0009766'], tr/val_loss:  2.302378/  2.324613, val:  67.92%, val_best:  83.63%, tr:  91.64%, tr_best:  94.07%, epoch time: 142.99 seconds, 2.38 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 51 occurrences\n",
      "test - Value 1: 401 occurrences\n",
      "epoch-179 lr=['0.0009766'], tr/val_loss:  2.304102/  2.319840, val:  60.84%, val_best:  83.63%, tr:  91.15%, tr_best:  94.07%, epoch time: 139.92 seconds, 2.33 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 304 occurrences\n",
      "test - Value 1: 148 occurrences\n",
      "epoch-180 lr=['0.0009766'], tr/val_loss:  2.304071/  2.312574, val:  76.55%, val_best:  83.63%, tr:  92.41%, tr_best:  94.07%, epoch time: 138.36 seconds, 2.31 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-181 lr=['0.0009766'], tr/val_loss:  2.301545/  2.301202, val:  50.00%, val_best:  83.63%, tr:  91.27%, tr_best:  94.07%, epoch time: 140.47 seconds, 2.34 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-182 lr=['0.0009766'], tr/val_loss:  2.302502/  2.293587, val:  81.86%, val_best:  83.63%, tr:  92.41%, tr_best:  94.07%, epoch time: 141.29 seconds, 2.35 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-183 lr=['0.0009766'], tr/val_loss:  2.302590/  2.297865, val:  75.88%, val_best:  83.63%, tr:  91.77%, tr_best:  94.07%, epoch time: 142.80 seconds, 2.38 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['0.0009766'], tr/val_loss:  2.303310/  2.376659, val:  50.00%, val_best:  83.63%, tr:  92.41%, tr_best:  94.07%, epoch time: 142.54 seconds, 2.38 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-185 lr=['0.0009766'], tr/val_loss:  2.303513/  2.300125, val:  52.88%, val_best:  83.63%, tr:  91.91%, tr_best:  94.07%, epoch time: 141.20 seconds, 2.35 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['0.0009766'], tr/val_loss:  2.303464/  2.315733, val:  50.00%, val_best:  83.63%, tr:  91.94%, tr_best:  94.07%, epoch time: 141.13 seconds, 2.35 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['0.0009766'], tr/val_loss:  2.305621/  2.353964, val:  50.00%, val_best:  83.63%, tr:  90.90%, tr_best:  94.07%, epoch time: 141.64 seconds, 2.36 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-188 lr=['0.0009766'], tr/val_loss:  2.307714/  2.314059, val:  72.35%, val_best:  83.63%, tr:  92.83%, tr_best:  94.07%, epoch time: 142.35 seconds, 2.37 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-189 lr=['0.0009766'], tr/val_loss:  2.300607/  2.288389, val:  71.24%, val_best:  83.63%, tr:  91.89%, tr_best:  94.07%, epoch time: 143.06 seconds, 2.38 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-190 lr=['0.0009766'], tr/val_loss:  2.308273/  2.340980, val:  50.00%, val_best:  83.63%, tr:  92.68%, tr_best:  94.07%, epoch time: 141.57 seconds, 2.36 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-191 lr=['0.0009766'], tr/val_loss:  2.305283/  2.270490, val:  50.88%, val_best:  83.63%, tr:  90.87%, tr_best:  94.07%, epoch time: 143.15 seconds, 2.39 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-192 lr=['0.0009766'], tr/val_loss:  2.302136/  2.336316, val:  61.50%, val_best:  83.63%, tr:  91.67%, tr_best:  94.07%, epoch time: 144.49 seconds, 2.41 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['0.0009766'], tr/val_loss:  2.301085/  2.339684, val:  50.00%, val_best:  83.63%, tr:  93.48%, tr_best:  94.07%, epoch time: 143.48 seconds, 2.39 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-194 lr=['0.0009766'], tr/val_loss:  2.298012/  2.354063, val:  50.00%, val_best:  83.63%, tr:  92.66%, tr_best:  94.07%, epoch time: 142.09 seconds, 2.37 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-195 lr=['0.0009766'], tr/val_loss:  2.307954/  2.355706, val:  53.76%, val_best:  83.63%, tr:  92.21%, tr_best:  94.07%, epoch time: 142.73 seconds, 2.38 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-196 lr=['0.0009766'], tr/val_loss:  2.304985/  2.292896, val:  51.33%, val_best:  83.63%, tr:  93.30%, tr_best:  94.07%, epoch time: 143.49 seconds, 2.39 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-197 lr=['0.0009766'], tr/val_loss:  2.307636/  2.346772, val:  66.59%, val_best:  83.63%, tr:  92.93%, tr_best:  94.07%, epoch time: 142.57 seconds, 2.38 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-198 lr=['0.0009766'], tr/val_loss:  2.301893/  2.274322, val:  73.23%, val_best:  83.63%, tr:  93.63%, tr_best:  94.07%, epoch time: 144.35 seconds, 2.41 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-199 lr=['0.0009766'], tr/val_loss:  2.307878/  2.301160, val:  76.99%, val_best:  83.63%, tr:  92.58%, tr_best:  94.07%, epoch time: 143.38 seconds, 2.39 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b423d5d54a7b4769aec3ec17dce8d13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█████████████████████▁█▁█████▁██████████</td></tr><tr><td>summary_val_acc</td><td>▃▁▃▇▄▁▃▂▄▁▅▅▁▄▆▁▇▄▇▁▇▃▅▆▁▁▁▁▅▇▁▄▅▁██▇▁▁▇</td></tr><tr><td>tr_acc</td><td>▁▅▆▆▆▇█▇▆▆▇▆▇▇▇▆▇▇▆▇▇▇█▆▇▇▇▇▇▆█▇██▇▆▇▆█▇</td></tr><tr><td>tr_epoch_loss</td><td>▃▃▄▃▂▃▇▆▄▄▄▃▂▂▅▄▄▂▆▆▆▅▅▃▂▃▄▄▁▂▄▃███▄▃▆▂█</td></tr><tr><td>val_acc_best</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▃▁▃▇▄▁▃▂▄▁▅▅▁▄▆▁▇▄▇▁▇▃▅▆▁▁▁▁▅▇▁▄▅▁██▇▁▁▇</td></tr><tr><td>val_loss</td><td>▂▅▄▂▃▃▂▄▄▂▁▂▃▃▄▁▅▃▃▁▂▄▃▃▅▃▃▁▂▃▃▃▃█▂▃▃▆▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.92584</td></tr><tr><td>tr_epoch_loss</td><td>2.30788</td></tr><tr><td>val_acc_best</td><td>0.83628</td></tr><tr><td>val_acc_now</td><td>0.76991</td></tr><tr><td>val_loss</td><td>2.30116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/aiuc0x8k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/aiuc0x8k</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250805_135138-aiuc0x8k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ribnnorh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250805_213240-ribnnorh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ribnnorh' target=\"_blank\">fast-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ribnnorh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ribnnorh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250805_213249_204', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 15, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.308794/  2.222820, val:  51.55%, val_best:  51.55%, tr:  74.23%, tr_best:  74.23%, epoch time: 99.49 seconds, 1.66 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.303594/  2.279470, val:  72.57%, val_best:  72.57%, tr:  81.55%, tr_best:  81.55%, epoch time: 98.93 seconds, 1.65 minutes\n",
      "train - Value 0: 1918 occurrences\n",
      "train - Value 1: 2114 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.306676/  2.361944, val:  50.00%, val_best:  72.57%, tr:  83.88%, tr_best:  83.88%, epoch time: 99.21 seconds, 1.65 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.293938/  2.359330, val:  50.00%, val_best:  72.57%, tr:  85.07%, tr_best:  85.07%, epoch time: 101.48 seconds, 1.69 minutes\n",
      "train - Value 0: 1936 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.306493/  2.387964, val:  72.35%, val_best:  72.57%, tr:  88.29%, tr_best:  88.29%, epoch time: 104.94 seconds, 1.75 minutes\n",
      "train - Value 0: 1892 occurrences\n",
      "train - Value 1: 2140 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.318628/  2.392883, val:  58.85%, val_best:  72.57%, tr:  90.13%, tr_best:  90.13%, epoch time: 100.95 seconds, 1.68 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.318432/  2.281578, val:  79.65%, val_best:  79.65%, tr:  90.75%, tr_best:  90.75%, epoch time: 100.87 seconds, 1.68 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.327008/  2.320434, val:  75.22%, val_best:  79.65%, tr:  91.44%, tr_best:  91.44%, epoch time: 102.43 seconds, 1.71 minutes\n",
      "train - Value 0: 1835 occurrences\n",
      "train - Value 1: 2197 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.322528/  2.304283, val:  50.22%, val_best:  79.65%, tr:  88.72%, tr_best:  91.44%, epoch time: 105.64 seconds, 1.76 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.315688/  2.288318, val:  50.88%, val_best:  79.65%, tr:  89.96%, tr_best:  91.44%, epoch time: 102.88 seconds, 1.71 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 320 occurrences\n",
      "test - Value 1: 132 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.307488/  2.282116, val:  75.22%, val_best:  79.65%, tr:  90.40%, tr_best:  91.44%, epoch time: 104.02 seconds, 1.73 minutes\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.306863/  2.346016, val:  61.95%, val_best:  79.65%, tr:  91.07%, tr_best:  91.44%, epoch time: 104.33 seconds, 1.74 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.283991/  2.251821, val:  65.93%, val_best:  79.65%, tr:  92.58%, tr_best:  92.58%, epoch time: 104.32 seconds, 1.74 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.303041/  2.387047, val:  65.71%, val_best:  79.65%, tr:  91.39%, tr_best:  92.58%, epoch time: 104.29 seconds, 1.74 minutes\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 48 occurrences\n",
      "test - Value 1: 404 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.294437/  2.345028, val:  60.62%, val_best:  79.65%, tr:  93.48%, tr_best:  93.48%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.317593/  2.296426, val:  79.65%, val_best:  79.65%, tr:  95.91%, tr_best:  95.91%, epoch time: 103.15 seconds, 1.72 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.306229/  2.362610, val:  62.17%, val_best:  79.65%, tr:  95.93%, tr_best:  95.93%, epoch time: 104.06 seconds, 1.73 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.301674/  2.372584, val:  59.07%, val_best:  79.65%, tr:  95.56%, tr_best:  95.93%, epoch time: 105.24 seconds, 1.75 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.306355/  2.398681, val:  52.43%, val_best:  79.65%, tr:  94.79%, tr_best:  95.93%, epoch time: 103.75 seconds, 1.73 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.326410/  2.229170, val:  59.96%, val_best:  79.65%, tr:  94.15%, tr_best:  95.93%, epoch time: 105.19 seconds, 1.75 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.324849/  2.392023, val:  78.32%, val_best:  79.65%, tr:  96.13%, tr_best:  96.13%, epoch time: 103.23 seconds, 1.72 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.324586/  2.299604, val:  80.09%, val_best:  80.09%, tr:  95.36%, tr_best:  96.13%, epoch time: 103.97 seconds, 1.73 minutes\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.323013/  2.409476, val:  53.54%, val_best:  80.09%, tr:  93.55%, tr_best:  96.13%, epoch time: 103.75 seconds, 1.73 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.313468/  2.245246, val:  81.19%, val_best:  81.19%, tr:  95.78%, tr_best:  96.13%, epoch time: 103.55 seconds, 1.73 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.311907/  2.229584, val:  73.23%, val_best:  81.19%, tr:  94.62%, tr_best:  96.13%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 31 occurrences\n",
      "test - Value 1: 421 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.322765/  2.418764, val:  56.86%, val_best:  81.19%, tr:  96.33%, tr_best:  96.33%, epoch time: 101.74 seconds, 1.70 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.314590/  2.321752, val:  61.95%, val_best:  81.19%, tr:  96.45%, tr_best:  96.45%, epoch time: 102.47 seconds, 1.71 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 48 occurrences\n",
      "test - Value 1: 404 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.315066/  2.351153, val:  60.62%, val_best:  81.19%, tr:  96.45%, tr_best:  96.45%, epoch time: 103.80 seconds, 1.73 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.322472/  2.293669, val:  83.63%, val_best:  83.63%, tr:  97.00%, tr_best:  97.00%, epoch time: 104.91 seconds, 1.75 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.323268/  2.388345, val:  78.10%, val_best:  83.63%, tr:  96.92%, tr_best:  97.00%, epoch time: 103.51 seconds, 1.73 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.325057/  2.312603, val:  85.62%, val_best:  85.62%, tr:  98.04%, tr_best:  98.04%, epoch time: 101.42 seconds, 1.69 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.315004/  2.271111, val:  83.41%, val_best:  85.62%, tr:  97.07%, tr_best:  98.04%, epoch time: 101.01 seconds, 1.68 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.310021/  2.322238, val:  82.52%, val_best:  85.62%, tr:  96.45%, tr_best:  98.04%, epoch time: 102.40 seconds, 1.71 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 263 occurrences\n",
      "test - Value 1: 189 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.317450/  2.371055, val:  84.73%, val_best:  85.62%, tr:  95.91%, tr_best:  98.04%, epoch time: 103.80 seconds, 1.73 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.311555/  2.254752, val:  76.77%, val_best:  85.62%, tr:  96.53%, tr_best:  98.04%, epoch time: 103.70 seconds, 1.73 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.299142/  2.372672, val:  54.87%, val_best:  85.62%, tr:  96.60%, tr_best:  98.04%, epoch time: 103.31 seconds, 1.72 minutes\n",
      "train - Value 0: 1922 occurrences\n",
      "train - Value 1: 2110 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 365 occurrences\n",
      "test - Value 1: 87 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.299904/  2.319247, val:  68.36%, val_best:  85.62%, tr:  95.93%, tr_best:  98.04%, epoch time: 102.12 seconds, 1.70 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.318860/  2.424774, val:  54.20%, val_best:  85.62%, tr:  96.55%, tr_best:  98.04%, epoch time: 103.13 seconds, 1.72 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.288905/  2.234461, val:  80.97%, val_best:  85.62%, tr:  95.76%, tr_best:  98.04%, epoch time: 101.28 seconds, 1.69 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.298725/  2.352151, val:  65.71%, val_best:  85.62%, tr:  94.27%, tr_best:  98.04%, epoch time: 99.90 seconds, 1.67 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.298921/  2.296746, val:  82.30%, val_best:  85.62%, tr:  96.38%, tr_best:  98.04%, epoch time: 99.43 seconds, 1.66 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.289053/  2.329069, val:  76.77%, val_best:  85.62%, tr:  96.35%, tr_best:  98.04%, epoch time: 101.15 seconds, 1.69 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.312206/  2.236144, val:  80.75%, val_best:  85.62%, tr:  96.43%, tr_best:  98.04%, epoch time: 103.06 seconds, 1.72 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 294 occurrences\n",
      "test - Value 1: 158 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.286596/  2.276744, val:  80.97%, val_best:  85.62%, tr:  95.51%, tr_best:  98.04%, epoch time: 102.90 seconds, 1.71 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.295653/  2.370688, val:  58.85%, val_best:  85.62%, tr:  97.12%, tr_best:  98.04%, epoch time: 102.38 seconds, 1.71 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 302 occurrences\n",
      "test - Value 1: 150 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.309567/  2.277967, val:  77.88%, val_best:  85.62%, tr:  96.78%, tr_best:  98.04%, epoch time: 103.54 seconds, 1.73 minutes\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.293565/  2.293871, val:  84.73%, val_best:  85.62%, tr:  97.07%, tr_best:  98.04%, epoch time: 103.85 seconds, 1.73 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 370 occurrences\n",
      "test - Value 1: 82 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.318098/  2.280576, val:  67.26%, val_best:  85.62%, tr:  97.27%, tr_best:  98.04%, epoch time: 103.36 seconds, 1.72 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.311382/  2.303653, val:  82.52%, val_best:  85.62%, tr:  96.75%, tr_best:  98.04%, epoch time: 102.83 seconds, 1.71 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.320838/  2.374573, val:  54.87%, val_best:  85.62%, tr:  96.50%, tr_best:  98.04%, epoch time: 103.03 seconds, 1.72 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.323436/  2.439006, val:  80.53%, val_best:  85.62%, tr:  97.40%, tr_best:  98.04%, epoch time: 102.38 seconds, 1.71 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.321196/  2.319610, val:  76.55%, val_best:  85.62%, tr:  95.59%, tr_best:  98.04%, epoch time: 101.64 seconds, 1.69 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.323685/  2.409244, val:  70.13%, val_best:  85.62%, tr:  95.11%, tr_best:  98.04%, epoch time: 101.42 seconds, 1.69 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.323329/  2.328163, val:  81.86%, val_best:  85.62%, tr:  96.33%, tr_best:  98.04%, epoch time: 103.88 seconds, 1.73 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.311984/  2.265253, val:  81.86%, val_best:  85.62%, tr:  97.42%, tr_best:  98.04%, epoch time: 102.41 seconds, 1.71 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.328025/  2.326861, val:  81.86%, val_best:  85.62%, tr:  97.12%, tr_best:  98.04%, epoch time: 103.34 seconds, 1.72 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.329978/  2.330851, val:  61.95%, val_best:  85.62%, tr:  97.45%, tr_best:  98.04%, epoch time: 101.87 seconds, 1.70 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.316246/  2.271480, val:  80.31%, val_best:  85.62%, tr:  97.69%, tr_best:  98.04%, epoch time: 100.99 seconds, 1.68 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.295923/  2.395651, val:  55.53%, val_best:  85.62%, tr:  96.68%, tr_best:  98.04%, epoch time: 103.49 seconds, 1.72 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.312945/  2.307562, val:  82.96%, val_best:  85.62%, tr:  97.72%, tr_best:  98.04%, epoch time: 101.89 seconds, 1.70 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.327091/  2.332888, val:  80.31%, val_best:  85.62%, tr:  97.67%, tr_best:  98.04%, epoch time: 103.14 seconds, 1.72 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.310416/  2.346925, val:  61.06%, val_best:  85.62%, tr:  97.69%, tr_best:  98.04%, epoch time: 103.30 seconds, 1.72 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.318541/  2.316105, val:  80.53%, val_best:  85.62%, tr:  97.59%, tr_best:  98.04%, epoch time: 103.00 seconds, 1.72 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.309151/  2.309927, val:  81.64%, val_best:  85.62%, tr:  96.70%, tr_best:  98.04%, epoch time: 103.88 seconds, 1.73 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.303940/  2.323266, val:  80.97%, val_best:  85.62%, tr:  97.84%, tr_best:  98.04%, epoch time: 103.50 seconds, 1.72 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.304204/  2.402848, val:  70.35%, val_best:  85.62%, tr:  97.20%, tr_best:  98.04%, epoch time: 102.75 seconds, 1.71 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.311147/  2.394342, val:  76.99%, val_best:  85.62%, tr:  97.15%, tr_best:  98.04%, epoch time: 104.14 seconds, 1.74 minutes\n",
      "train - Value 0: 1940 occurrences\n",
      "train - Value 1: 2092 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.306196/  2.389524, val:  74.56%, val_best:  85.62%, tr:  96.28%, tr_best:  98.04%, epoch time: 103.35 seconds, 1.72 minutes\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.322337/  2.296492, val:  77.65%, val_best:  85.62%, tr:  95.49%, tr_best:  98.04%, epoch time: 103.43 seconds, 1.72 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.303905/  2.306563, val:  59.73%, val_best:  85.62%, tr:  97.32%, tr_best:  98.04%, epoch time: 102.14 seconds, 1.70 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.321265/  2.294590, val:  83.41%, val_best:  85.62%, tr:  97.10%, tr_best:  98.04%, epoch time: 102.46 seconds, 1.71 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.333838/  2.387107, val:  84.51%, val_best:  85.62%, tr:  97.40%, tr_best:  98.04%, epoch time: 103.36 seconds, 1.72 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.323971/  2.376640, val:  60.84%, val_best:  85.62%, tr:  97.77%, tr_best:  98.04%, epoch time: 102.51 seconds, 1.71 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.303897/  2.294270, val:  84.96%, val_best:  85.62%, tr:  97.64%, tr_best:  98.04%, epoch time: 99.54 seconds, 1.66 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.305534/  2.355920, val:  69.91%, val_best:  85.62%, tr:  96.83%, tr_best:  98.04%, epoch time: 99.13 seconds, 1.65 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.315881/  2.279494, val:  78.32%, val_best:  85.62%, tr:  94.72%, tr_best:  98.04%, epoch time: 100.64 seconds, 1.68 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.305032/  2.263422, val:  84.29%, val_best:  85.62%, tr:  95.88%, tr_best:  98.04%, epoch time: 102.54 seconds, 1.71 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.299616/  2.270196, val:  80.53%, val_best:  85.62%, tr:  96.53%, tr_best:  98.04%, epoch time: 102.18 seconds, 1.70 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.298081/  2.364920, val:  69.47%, val_best:  85.62%, tr:  96.48%, tr_best:  98.04%, epoch time: 101.88 seconds, 1.70 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.304499/  2.271978, val:  79.42%, val_best:  85.62%, tr:  96.35%, tr_best:  98.04%, epoch time: 102.18 seconds, 1.70 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.309447/  2.275392, val:  83.19%, val_best:  85.62%, tr:  95.96%, tr_best:  98.04%, epoch time: 103.77 seconds, 1.73 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.301386/  2.360537, val:  80.75%, val_best:  85.62%, tr:  97.25%, tr_best:  98.04%, epoch time: 102.59 seconds, 1.71 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.298049/  2.299639, val:  64.60%, val_best:  85.62%, tr:  96.70%, tr_best:  98.04%, epoch time: 102.22 seconds, 1.70 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.291183/  2.348212, val:  51.11%, val_best:  85.62%, tr:  97.02%, tr_best:  98.04%, epoch time: 101.58 seconds, 1.69 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.294690/  2.286888, val:  63.27%, val_best:  85.62%, tr:  96.73%, tr_best:  98.04%, epoch time: 103.01 seconds, 1.72 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.304383/  2.383785, val:  78.98%, val_best:  85.62%, tr:  96.65%, tr_best:  98.04%, epoch time: 103.11 seconds, 1.72 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.313103/  2.399520, val:  63.05%, val_best:  85.62%, tr:  95.44%, tr_best:  98.04%, epoch time: 101.73 seconds, 1.70 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.301669/  2.323449, val:  60.62%, val_best:  85.62%, tr:  95.78%, tr_best:  98.04%, epoch time: 101.69 seconds, 1.69 minutes\n",
      "train - Value 0: 2106 occurrences\n",
      "train - Value 1: 1926 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.294579/  2.317279, val:  65.93%, val_best:  85.62%, tr:  94.00%, tr_best:  98.04%, epoch time: 102.13 seconds, 1.70 minutes\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.296845/  2.332152, val:  78.54%, val_best:  85.62%, tr:  95.49%, tr_best:  98.04%, epoch time: 103.71 seconds, 1.73 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.301512/  2.336796, val:  72.57%, val_best:  85.62%, tr:  97.02%, tr_best:  98.04%, epoch time: 102.50 seconds, 1.71 minutes\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.311339/  2.331414, val:  81.86%, val_best:  85.62%, tr:  95.81%, tr_best:  98.04%, epoch time: 102.08 seconds, 1.70 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.302466/  2.350597, val:  71.46%, val_best:  85.62%, tr:  95.16%, tr_best:  98.04%, epoch time: 102.19 seconds, 1.70 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.293352/  2.308116, val:  84.96%, val_best:  85.62%, tr:  96.58%, tr_best:  98.04%, epoch time: 103.37 seconds, 1.72 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.303577/  2.267894, val:  59.51%, val_best:  85.62%, tr:  95.98%, tr_best:  98.04%, epoch time: 103.38 seconds, 1.72 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.292491/  2.279818, val:  76.33%, val_best:  85.62%, tr:  97.62%, tr_best:  98.04%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.297385/  2.376900, val:  71.68%, val_best:  85.62%, tr:  96.60%, tr_best:  98.04%, epoch time: 103.97 seconds, 1.73 minutes\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.291895/  2.233696, val:  80.75%, val_best:  85.62%, tr:  96.80%, tr_best:  98.04%, epoch time: 102.99 seconds, 1.72 minutes\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.306432/  2.396418, val:  76.55%, val_best:  85.62%, tr:  96.01%, tr_best:  98.04%, epoch time: 103.50 seconds, 1.72 minutes\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.320173/  2.325150, val:  73.67%, val_best:  85.62%, tr:  96.50%, tr_best:  98.04%, epoch time: 104.24 seconds, 1.74 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.280828/  2.242402, val:  80.97%, val_best:  85.62%, tr:  95.98%, tr_best:  98.04%, epoch time: 103.63 seconds, 1.73 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.277881/  2.307179, val:  73.67%, val_best:  85.62%, tr:  97.57%, tr_best:  98.04%, epoch time: 103.10 seconds, 1.72 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.271531/  2.238390, val:  80.75%, val_best:  85.62%, tr:  97.07%, tr_best:  98.04%, epoch time: 103.46 seconds, 1.72 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.287422/  2.311743, val:  84.29%, val_best:  85.62%, tr:  97.15%, tr_best:  98.04%, epoch time: 101.91 seconds, 1.70 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.293909/  2.338162, val:  59.51%, val_best:  85.62%, tr:  96.85%, tr_best:  98.04%, epoch time: 103.07 seconds, 1.72 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.303725/  2.348224, val:  59.29%, val_best:  85.62%, tr:  96.92%, tr_best:  98.04%, epoch time: 104.41 seconds, 1.74 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.296870/  2.339859, val:  62.17%, val_best:  85.62%, tr:  96.90%, tr_best:  98.04%, epoch time: 103.62 seconds, 1.73 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.276212/  2.255938, val:  76.55%, val_best:  85.62%, tr:  96.30%, tr_best:  98.04%, epoch time: 100.45 seconds, 1.67 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.270527/  2.259044, val:  79.20%, val_best:  85.62%, tr:  96.63%, tr_best:  98.04%, epoch time: 99.35 seconds, 1.66 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.276043/  2.261849, val:  73.67%, val_best:  85.62%, tr:  96.75%, tr_best:  98.04%, epoch time: 100.61 seconds, 1.68 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.286999/  2.253428, val:  64.38%, val_best:  85.62%, tr:  96.35%, tr_best:  98.04%, epoch time: 104.35 seconds, 1.74 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.288422/  2.345478, val:  66.59%, val_best:  85.62%, tr:  96.06%, tr_best:  98.04%, epoch time: 103.81 seconds, 1.73 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.313720/  2.326473, val:  72.12%, val_best:  85.62%, tr:  96.33%, tr_best:  98.04%, epoch time: 103.20 seconds, 1.72 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.286185/  2.420757, val:  74.12%, val_best:  85.62%, tr:  97.42%, tr_best:  98.04%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.281209/  2.306545, val:  81.64%, val_best:  85.62%, tr:  97.42%, tr_best:  98.04%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.274768/  2.229662, val:  50.00%, val_best:  85.62%, tr:  94.59%, tr_best:  98.04%, epoch time: 103.93 seconds, 1.73 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.271873/  2.246894, val:  72.79%, val_best:  85.62%, tr:  96.65%, tr_best:  98.04%, epoch time: 104.32 seconds, 1.74 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.274994/  2.263084, val:  76.33%, val_best:  85.62%, tr:  97.77%, tr_best:  98.04%, epoch time: 102.72 seconds, 1.71 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.294116/  2.252666, val:  74.34%, val_best:  85.62%, tr:  98.34%, tr_best:  98.34%, epoch time: 103.89 seconds, 1.73 minutes\n",
      "train - Value 0: 2093 occurrences\n",
      "train - Value 1: 1939 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.270269/  2.255944, val:  73.45%, val_best:  85.62%, tr:  95.86%, tr_best:  98.34%, epoch time: 104.24 seconds, 1.74 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.267877/  2.276688, val:  72.35%, val_best:  85.62%, tr:  97.97%, tr_best:  98.34%, epoch time: 103.72 seconds, 1.73 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.278998/  2.270594, val:  71.68%, val_best:  85.62%, tr:  97.97%, tr_best:  98.34%, epoch time: 104.14 seconds, 1.74 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.286148/  2.283287, val:  83.85%, val_best:  85.62%, tr:  97.99%, tr_best:  98.34%, epoch time: 103.30 seconds, 1.72 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.299342/  2.242606, val:  74.12%, val_best:  85.62%, tr:  97.79%, tr_best:  98.34%, epoch time: 103.41 seconds, 1.72 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.317266/  2.231376, val:  83.41%, val_best:  85.62%, tr:  96.95%, tr_best:  98.34%, epoch time: 104.31 seconds, 1.74 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.306320/  2.300064, val:  80.97%, val_best:  85.62%, tr:  96.35%, tr_best:  98.34%, epoch time: 105.17 seconds, 1.75 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 31 occurrences\n",
      "test - Value 1: 421 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.298956/  2.387627, val:  56.86%, val_best:  85.62%, tr:  97.22%, tr_best:  98.34%, epoch time: 104.58 seconds, 1.74 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.313312/  2.366537, val:  79.87%, val_best:  85.62%, tr:  97.35%, tr_best:  98.34%, epoch time: 103.88 seconds, 1.73 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.325500/  2.298224, val:  82.52%, val_best:  85.62%, tr:  97.97%, tr_best:  98.34%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.313435/  2.294258, val:  79.65%, val_best:  85.62%, tr:  98.04%, tr_best:  98.34%, epoch time: 102.54 seconds, 1.71 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.322764/  2.373928, val:  77.21%, val_best:  85.62%, tr:  98.14%, tr_best:  98.34%, epoch time: 102.64 seconds, 1.71 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.309881/  2.274799, val:  85.40%, val_best:  85.62%, tr:  98.71%, tr_best:  98.71%, epoch time: 103.78 seconds, 1.73 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.297746/  2.298595, val:  75.66%, val_best:  85.62%, tr:  97.82%, tr_best:  98.71%, epoch time: 104.42 seconds, 1.74 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.291051/  2.315906, val:  82.30%, val_best:  85.62%, tr:  98.26%, tr_best:  98.71%, epoch time: 103.14 seconds, 1.72 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.303721/  2.371428, val:  77.88%, val_best:  85.62%, tr:  99.13%, tr_best:  99.13%, epoch time: 102.25 seconds, 1.70 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.309222/  2.290536, val:  78.98%, val_best:  85.62%, tr:  98.69%, tr_best:  99.13%, epoch time: 103.13 seconds, 1.72 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.302646/  2.378568, val:  67.04%, val_best:  85.62%, tr:  98.29%, tr_best:  99.13%, epoch time: 102.91 seconds, 1.72 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.290179/  2.259849, val:  81.42%, val_best:  85.62%, tr:  98.21%, tr_best:  99.13%, epoch time: 104.09 seconds, 1.73 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.302183/  2.282997, val:  83.85%, val_best:  85.62%, tr:  98.21%, tr_best:  99.13%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.290448/  2.379676, val:  72.12%, val_best:  85.62%, tr:  99.08%, tr_best:  99.13%, epoch time: 104.52 seconds, 1.74 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.295737/  2.282335, val:  74.78%, val_best:  85.62%, tr:  98.96%, tr_best:  99.13%, epoch time: 104.55 seconds, 1.74 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 328 occurrences\n",
      "test - Value 1: 124 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.300154/  2.269746, val:  73.45%, val_best:  85.62%, tr:  98.49%, tr_best:  99.13%, epoch time: 100.75 seconds, 1.68 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 306 occurrences\n",
      "test - Value 1: 146 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.302594/  2.264804, val:  80.53%, val_best:  85.62%, tr:  98.54%, tr_best:  99.13%, epoch time: 100.47 seconds, 1.67 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.303718/  2.378988, val:  77.21%, val_best:  85.62%, tr:  98.36%, tr_best:  99.13%, epoch time: 100.90 seconds, 1.68 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.312145/  2.340278, val:  84.29%, val_best:  85.62%, tr:  98.83%, tr_best:  99.13%, epoch time: 104.05 seconds, 1.73 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.309110/  2.317974, val:  85.18%, val_best:  85.62%, tr:  98.76%, tr_best:  99.13%, epoch time: 103.62 seconds, 1.73 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 313 occurrences\n",
      "test - Value 1: 139 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.317031/  2.326520, val:  78.10%, val_best:  85.62%, tr:  97.99%, tr_best:  99.13%, epoch time: 103.84 seconds, 1.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.291876/  2.295054, val:  70.35%, val_best:  85.62%, tr:  98.19%, tr_best:  99.13%, epoch time: 104.50 seconds, 1.74 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.284454/  2.283855, val:  59.73%, val_best:  85.62%, tr:  98.14%, tr_best:  99.13%, epoch time: 104.01 seconds, 1.73 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.278626/  2.289830, val:  78.98%, val_best:  85.62%, tr:  98.44%, tr_best:  99.13%, epoch time: 104.05 seconds, 1.73 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.285219/  2.266432, val:  87.17%, val_best:  87.17%, tr:  98.69%, tr_best:  99.13%, epoch time: 103.41 seconds, 1.72 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.282639/  2.393767, val:  52.88%, val_best:  87.17%, tr:  98.24%, tr_best:  99.13%, epoch time: 103.41 seconds, 1.72 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.281832/  2.293168, val:  82.74%, val_best:  87.17%, tr:  98.14%, tr_best:  99.13%, epoch time: 103.41 seconds, 1.72 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.275262/  2.287756, val:  72.12%, val_best:  87.17%, tr:  99.21%, tr_best:  99.21%, epoch time: 104.84 seconds, 1.75 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.278319/  2.291686, val:  72.57%, val_best:  87.17%, tr:  99.40%, tr_best:  99.40%, epoch time: 104.31 seconds, 1.74 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.278046/  2.295202, val:  73.67%, val_best:  87.17%, tr:  99.26%, tr_best:  99.40%, epoch time: 102.09 seconds, 1.70 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.283502/  2.305834, val:  68.81%, val_best:  87.17%, tr:  98.93%, tr_best:  99.40%, epoch time: 102.79 seconds, 1.71 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.283885/  2.366855, val:  58.63%, val_best:  87.17%, tr:  98.36%, tr_best:  99.40%, epoch time: 104.30 seconds, 1.74 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.275074/  2.285603, val:  80.97%, val_best:  87.17%, tr:  98.59%, tr_best:  99.40%, epoch time: 104.13 seconds, 1.74 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.280502/  2.303486, val:  58.19%, val_best:  87.17%, tr:  99.36%, tr_best:  99.40%, epoch time: 101.81 seconds, 1.70 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.286450/  2.314438, val:  71.90%, val_best:  87.17%, tr:  98.78%, tr_best:  99.40%, epoch time: 101.85 seconds, 1.70 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.292376/  2.316672, val:  59.96%, val_best:  87.17%, tr:  99.26%, tr_best:  99.40%, epoch time: 102.44 seconds, 1.71 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.297826/  2.301731, val:  76.55%, val_best:  87.17%, tr:  99.48%, tr_best:  99.48%, epoch time: 103.86 seconds, 1.73 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.285863/  2.304790, val:  71.90%, val_best:  87.17%, tr:  99.31%, tr_best:  99.48%, epoch time: 103.99 seconds, 1.73 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.305463/  2.329645, val:  74.34%, val_best:  87.17%, tr:  99.18%, tr_best:  99.48%, epoch time: 103.68 seconds, 1.73 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.307863/  2.336808, val:  78.76%, val_best:  87.17%, tr:  99.06%, tr_best:  99.48%, epoch time: 105.12 seconds, 1.75 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.315780/  2.333996, val:  59.07%, val_best:  87.17%, tr:  98.31%, tr_best:  99.48%, epoch time: 103.01 seconds, 1.72 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.311724/  2.337495, val:  58.85%, val_best:  87.17%, tr:  99.03%, tr_best:  99.48%, epoch time: 104.27 seconds, 1.74 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.300518/  2.313799, val:  59.73%, val_best:  87.17%, tr:  99.45%, tr_best:  99.48%, epoch time: 103.89 seconds, 1.73 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.304369/  2.314630, val:  83.63%, val_best:  87.17%, tr:  99.33%, tr_best:  99.48%, epoch time: 104.48 seconds, 1.74 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.298944/  2.311566, val:  71.46%, val_best:  87.17%, tr:  99.11%, tr_best:  99.48%, epoch time: 103.16 seconds, 1.72 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.306057/  2.316243, val:  77.88%, val_best:  87.17%, tr:  99.60%, tr_best:  99.60%, epoch time: 103.69 seconds, 1.73 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.306135/  2.326814, val:  83.85%, val_best:  87.17%, tr:  99.28%, tr_best:  99.60%, epoch time: 104.09 seconds, 1.73 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.314104/  2.320843, val:  81.86%, val_best:  87.17%, tr:  98.39%, tr_best:  99.60%, epoch time: 103.45 seconds, 1.72 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.311854/  2.315088, val:  55.75%, val_best:  87.17%, tr:  98.81%, tr_best:  99.60%, epoch time: 104.33 seconds, 1.74 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.305225/  2.323259, val:  81.19%, val_best:  87.17%, tr:  98.56%, tr_best:  99.60%, epoch time: 101.38 seconds, 1.69 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.302827/  2.320452, val:  83.63%, val_best:  87.17%, tr:  98.61%, tr_best:  99.60%, epoch time: 100.32 seconds, 1.67 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.302534/  2.313391, val:  80.75%, val_best:  87.17%, tr:  98.88%, tr_best:  99.60%, epoch time: 101.59 seconds, 1.69 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.302122/  2.309579, val:  73.01%, val_best:  87.17%, tr:  98.83%, tr_best:  99.60%, epoch time: 103.72 seconds, 1.73 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.291181/  2.290228, val:  59.96%, val_best:  87.17%, tr:  98.91%, tr_best:  99.60%, epoch time: 104.10 seconds, 1.73 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.287271/  2.285467, val:  78.76%, val_best:  87.17%, tr:  98.96%, tr_best:  99.60%, epoch time: 103.25 seconds, 1.72 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.279151/  2.288411, val:  80.75%, val_best:  87.17%, tr:  99.01%, tr_best:  99.60%, epoch time: 102.78 seconds, 1.71 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.282810/  2.275902, val:  80.97%, val_best:  87.17%, tr:  99.28%, tr_best:  99.60%, epoch time: 103.29 seconds, 1.72 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.275088/  2.277990, val:  67.04%, val_best:  87.17%, tr:  99.26%, tr_best:  99.60%, epoch time: 104.52 seconds, 1.74 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.293898/  2.378400, val:  59.29%, val_best:  87.17%, tr:  99.28%, tr_best:  99.60%, epoch time: 104.14 seconds, 1.74 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.293159/  2.307664, val:  73.89%, val_best:  87.17%, tr:  98.83%, tr_best:  99.60%, epoch time: 102.80 seconds, 1.71 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.290199/  2.288142, val:  82.08%, val_best:  87.17%, tr:  98.54%, tr_best:  99.60%, epoch time: 102.80 seconds, 1.71 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.291306/  2.372656, val:  63.50%, val_best:  87.17%, tr:  98.81%, tr_best:  99.60%, epoch time: 105.26 seconds, 1.75 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.282717/  2.276510, val:  83.41%, val_best:  87.17%, tr:  97.99%, tr_best:  99.60%, epoch time: 104.95 seconds, 1.75 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.276876/  2.280399, val:  73.89%, val_best:  87.17%, tr:  98.56%, tr_best:  99.60%, epoch time: 104.39 seconds, 1.74 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.275818/  2.364830, val:  68.36%, val_best:  87.17%, tr:  98.66%, tr_best:  99.60%, epoch time: 103.61 seconds, 1.73 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 284 occurrences\n",
      "test - Value 1: 168 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.295354/  2.304207, val:  81.42%, val_best:  87.17%, tr:  98.07%, tr_best:  99.60%, epoch time: 104.46 seconds, 1.74 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.286154/  2.283250, val:  82.52%, val_best:  87.17%, tr:  98.46%, tr_best:  99.60%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.285291/  2.288879, val:  64.82%, val_best:  87.17%, tr:  99.18%, tr_best:  99.60%, epoch time: 104.87 seconds, 1.75 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.289239/  2.371189, val:  59.07%, val_best:  87.17%, tr:  98.44%, tr_best:  99.60%, epoch time: 104.97 seconds, 1.75 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.283103/  2.369327, val:  82.08%, val_best:  87.17%, tr:  98.56%, tr_best:  99.60%, epoch time: 104.18 seconds, 1.74 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.281193/  2.290658, val:  50.00%, val_best:  87.17%, tr:  98.71%, tr_best:  99.60%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.275053/  2.290189, val:  71.68%, val_best:  87.17%, tr:  98.76%, tr_best:  99.60%, epoch time: 104.21 seconds, 1.74 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 55 occurrences\n",
      "test - Value 1: 397 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.280804/  2.286283, val:  62.17%, val_best:  87.17%, tr:  98.96%, tr_best:  99.60%, epoch time: 104.86 seconds, 1.75 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.287970/  2.366642, val:  66.59%, val_best:  87.17%, tr:  98.46%, tr_best:  99.60%, epoch time: 103.40 seconds, 1.72 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7afc2c9a584e5b963b9f1ab6f8efeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>███████████████████▁████████████████████</td></tr><tr><td>summary_val_acc</td><td>▅▂▃▇▇▁█▁▆▆▆▇▂▆█▇▇▂▇▇▅▆▄▆▅▇▇▇▆▅▅▂▅▂▇▇▄▃▃▄</td></tr><tr><td>tr_acc</td><td>▁▄▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>▄▆▅▆▇▇▆▄▃▅▆▇▅▅█▄▄▄▅▃▁▁▃▁▁▆▃▃▄▃▁▂▂▅▆▄▁▃▂▃</td></tr><tr><td>val_acc_best</td><td>▁▁▄▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>val_acc_now</td><td>▅▂▃▇▇▁█▁▆▆▆▇▂▆█▇▇▂▇▇▅▆▄▆▅▇▇▇▆▅▅▂▅▂▇▇▄▃▃▄</td></tr><tr><td>val_loss</td><td>▃▇▅▃▃█▂▆▅▃▄▅▅▇▇▂▆▄▅▁▄▂▅▂▂▆▄▂▆▃▃▆▄▅▄▄▃▆▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98462</td></tr><tr><td>tr_epoch_loss</td><td>2.28797</td></tr><tr><td>val_acc_best</td><td>0.87168</td></tr><tr><td>val_acc_now</td><td>0.66593</td></tr><tr><td>val_loss</td><td>2.36664</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-2</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ribnnorh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ribnnorh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250805_213240-ribnnorh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pdo8w2z5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_031719-pdo8w2z5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pdo8w2z5' target=\"_blank\">fine-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pdo8w2z5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pdo8w2z5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250806_031728_188', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 15, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-13, -13], [-13, -13], [-12, -12]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 106.84 seconds, 1.78 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 107.01 seconds, 1.78 minutes\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 105.55 seconds, 1.76 minutes\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 106.05 seconds, 1.77 minutes\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 105.45 seconds, 1.76 minutes\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 106.01 seconds, 1.77 minutes\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 103.57 seconds, 1.73 minutes\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.302637/  2.302577, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 2723 occurrences\n",
      "train - Value 1: 1309 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.302665/  2.302429, val:  50.00%, val_best:  50.00%, tr:  48.59%, tr_best:  50.00%, epoch time: 104.37 seconds, 1.74 minutes\n",
      "train - Value 0: 2330 occurrences\n",
      "train - Value 1: 1702 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.302640/  2.302341, val:  50.00%, val_best:  50.00%, tr:  48.66%, tr_best:  50.00%, epoch time: 102.08 seconds, 1.70 minutes\n",
      "train - Value 0: 2262 occurrences\n",
      "train - Value 1: 1770 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.302554/  2.303005, val:  50.00%, val_best:  50.00%, tr:  49.01%, tr_best:  50.00%, epoch time: 101.27 seconds, 1.69 minutes\n",
      "train - Value 0: 2267 occurrences\n",
      "train - Value 1: 1765 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.302879/  2.302207, val:  50.00%, val_best:  50.00%, tr:  49.73%, tr_best:  50.00%, epoch time: 101.71 seconds, 1.70 minutes\n",
      "train - Value 0: 2591 occurrences\n",
      "train - Value 1: 1441 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.302357/  2.303292, val:  36.06%, val_best:  50.00%, tr:  48.14%, tr_best:  50.00%, epoch time: 104.97 seconds, 1.75 minutes\n",
      "train - Value 0: 2275 occurrences\n",
      "train - Value 1: 1757 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.302986/  2.302251, val:  42.92%, val_best:  50.00%, tr:  53.00%, tr_best:  53.00%, epoch time: 104.44 seconds, 1.74 minutes\n",
      "train - Value 0: 2120 occurrences\n",
      "train - Value 1: 1912 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.302533/  2.302571, val:  50.00%, val_best:  50.00%, tr:  57.09%, tr_best:  57.09%, epoch time: 104.36 seconds, 1.74 minutes\n",
      "train - Value 0: 2373 occurrences\n",
      "train - Value 1: 1659 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.302301/  2.303298, val:  53.10%, val_best:  53.10%, tr:  57.76%, tr_best:  57.76%, epoch time: 104.81 seconds, 1.75 minutes\n",
      "train - Value 0: 2187 occurrences\n",
      "train - Value 1: 1845 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.302648/  2.301740, val:  50.00%, val_best:  53.10%, tr:  59.30%, tr_best:  59.30%, epoch time: 104.90 seconds, 1.75 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.302876/  2.303692, val:  44.25%, val_best:  53.10%, tr:  59.50%, tr_best:  59.50%, epoch time: 104.42 seconds, 1.74 minutes\n",
      "train - Value 0: 2308 occurrences\n",
      "train - Value 1: 1724 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.302510/  2.303015, val:  45.35%, val_best:  53.10%, tr:  59.92%, tr_best:  59.92%, epoch time: 103.94 seconds, 1.73 minutes\n",
      "train - Value 0: 2102 occurrences\n",
      "train - Value 1: 1930 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.302608/  2.302821, val:  48.89%, val_best:  53.10%, tr:  61.46%, tr_best:  61.46%, epoch time: 104.93 seconds, 1.75 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.302855/  2.300985, val:  56.19%, val_best:  56.19%, tr:  60.64%, tr_best:  61.46%, epoch time: 104.93 seconds, 1.75 minutes\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.302903/  2.303039, val:  50.00%, val_best:  56.19%, tr:  60.39%, tr_best:  61.46%, epoch time: 103.90 seconds, 1.73 minutes\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.302612/  2.303234, val:  49.34%, val_best:  56.19%, tr:  62.05%, tr_best:  62.05%, epoch time: 104.31 seconds, 1.74 minutes\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.302820/  2.301218, val:  50.00%, val_best:  56.19%, tr:  61.09%, tr_best:  62.05%, epoch time: 104.11 seconds, 1.74 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.302570/  2.303073, val:  50.00%, val_best:  56.19%, tr:  63.24%, tr_best:  63.24%, epoch time: 105.41 seconds, 1.76 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.302944/  2.306562, val:  49.34%, val_best:  56.19%, tr:  64.43%, tr_best:  64.43%, epoch time: 104.76 seconds, 1.75 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.302479/  2.301790, val:  48.89%, val_best:  56.19%, tr:  62.50%, tr_best:  64.43%, epoch time: 104.65 seconds, 1.74 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.302919/  2.303658, val:  46.68%, val_best:  56.19%, tr:  62.50%, tr_best:  64.43%, epoch time: 105.60 seconds, 1.76 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.302623/  2.300310, val:  60.40%, val_best:  60.40%, tr:  64.93%, tr_best:  64.93%, epoch time: 103.97 seconds, 1.73 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.302706/  2.304258, val:  49.78%, val_best:  60.40%, tr:  64.76%, tr_best:  64.93%, epoch time: 105.68 seconds, 1.76 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.302572/  2.301137, val:  50.00%, val_best:  60.40%, tr:  64.76%, tr_best:  64.93%, epoch time: 105.15 seconds, 1.75 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 302 occurrences\n",
      "test - Value 1: 150 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.302759/  2.301414, val:  68.14%, val_best:  68.14%, tr:  66.89%, tr_best:  66.89%, epoch time: 102.99 seconds, 1.72 minutes\n",
      "train - Value 0: 2120 occurrences\n",
      "train - Value 1: 1912 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.302738/  2.302004, val:  52.65%, val_best:  68.14%, tr:  65.03%, tr_best:  66.89%, epoch time: 102.89 seconds, 1.71 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.302717/  2.304157, val:  52.21%, val_best:  68.14%, tr:  64.41%, tr_best:  66.89%, epoch time: 104.18 seconds, 1.74 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.302731/  2.301863, val:  51.11%, val_best:  68.14%, tr:  64.01%, tr_best:  66.89%, epoch time: 105.60 seconds, 1.76 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.302509/  2.302732, val:  50.44%, val_best:  68.14%, tr:  66.00%, tr_best:  66.89%, epoch time: 103.43 seconds, 1.72 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.302732/  2.302016, val:  51.77%, val_best:  68.14%, tr:  64.96%, tr_best:  66.89%, epoch time: 103.79 seconds, 1.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.302533/  2.302881, val:  49.78%, val_best:  68.14%, tr:  64.26%, tr_best:  66.89%, epoch time: 102.85 seconds, 1.71 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.302901/  2.303005, val:  57.52%, val_best:  68.14%, tr:  65.75%, tr_best:  66.89%, epoch time: 105.54 seconds, 1.76 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.302305/  2.301460, val:  50.00%, val_best:  68.14%, tr:  65.18%, tr_best:  66.89%, epoch time: 104.78 seconds, 1.75 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.302622/  2.304881, val:  68.36%, val_best:  68.36%, tr:  66.52%, tr_best:  66.89%, epoch time: 104.65 seconds, 1.74 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.302324/  2.299485, val:  51.11%, val_best:  68.36%, tr:  64.09%, tr_best:  66.89%, epoch time: 105.41 seconds, 1.76 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.302761/  2.302640, val:  55.31%, val_best:  68.36%, tr:  66.96%, tr_best:  66.96%, epoch time: 102.91 seconds, 1.72 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.302547/  2.301141, val:  50.00%, val_best:  68.36%, tr:  66.47%, tr_best:  66.96%, epoch time: 101.54 seconds, 1.69 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.302777/  2.304386, val:  50.00%, val_best:  68.36%, tr:  64.78%, tr_best:  66.96%, epoch time: 101.41 seconds, 1.69 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.302719/  2.296972, val:  50.66%, val_best:  68.36%, tr:  66.37%, tr_best:  66.96%, epoch time: 102.79 seconds, 1.71 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.302831/  2.300434, val:  50.00%, val_best:  68.36%, tr:  65.87%, tr_best:  66.96%, epoch time: 104.64 seconds, 1.74 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.302462/  2.302746, val:  51.33%, val_best:  68.36%, tr:  67.01%, tr_best:  67.01%, epoch time: 104.20 seconds, 1.74 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.303035/  2.302391, val:  50.00%, val_best:  68.36%, tr:  68.20%, tr_best:  68.20%, epoch time: 105.19 seconds, 1.75 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.302583/  2.304023, val:  50.00%, val_best:  68.36%, tr:  68.33%, tr_best:  68.33%, epoch time: 104.78 seconds, 1.75 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.302588/  2.304315, val:  49.78%, val_best:  68.36%, tr:  65.77%, tr_best:  68.33%, epoch time: 104.91 seconds, 1.75 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.302945/  2.304167, val:  50.00%, val_best:  68.36%, tr:  65.45%, tr_best:  68.33%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.302824/  2.305041, val:  50.00%, val_best:  68.36%, tr:  67.49%, tr_best:  68.33%, epoch time: 104.51 seconds, 1.74 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.302568/  2.303209, val:  69.91%, val_best:  69.91%, tr:  66.84%, tr_best:  68.33%, epoch time: 105.23 seconds, 1.75 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.302356/  2.299277, val:  51.77%, val_best:  69.91%, tr:  66.25%, tr_best:  68.33%, epoch time: 104.82 seconds, 1.75 minutes\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.302799/  2.301289, val:  50.00%, val_best:  69.91%, tr:  65.00%, tr_best:  68.33%, epoch time: 104.60 seconds, 1.74 minutes\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1943 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.302713/  2.301964, val:  50.00%, val_best:  69.91%, tr:  68.03%, tr_best:  68.33%, epoch time: 104.15 seconds, 1.74 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.302830/  2.301471, val:  62.61%, val_best:  69.91%, tr:  68.33%, tr_best:  68.33%, epoch time: 103.70 seconds, 1.73 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 427 occurrences\n",
      "test - Value 1: 25 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.302775/  2.300896, val:  54.65%, val_best:  69.91%, tr:  68.23%, tr_best:  68.33%, epoch time: 103.78 seconds, 1.73 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 325 occurrences\n",
      "test - Value 1: 127 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.302755/  2.301839, val:  66.15%, val_best:  69.91%, tr:  69.47%, tr_best:  69.47%, epoch time: 105.07 seconds, 1.75 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.303220/  2.309489, val:  59.96%, val_best:  69.91%, tr:  66.77%, tr_best:  69.47%, epoch time: 105.55 seconds, 1.76 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.302609/  2.304427, val:  50.00%, val_best:  69.91%, tr:  68.75%, tr_best:  69.47%, epoch time: 102.99 seconds, 1.72 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.302896/  2.293721, val:  53.10%, val_best:  69.91%, tr:  67.68%, tr_best:  69.47%, epoch time: 103.96 seconds, 1.73 minutes\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.302662/  2.301533, val:  62.17%, val_best:  69.91%, tr:  67.24%, tr_best:  69.47%, epoch time: 104.98 seconds, 1.75 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 351 occurrences\n",
      "test - Value 1: 101 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.302697/  2.300587, val:  63.50%, val_best:  69.91%, tr:  68.58%, tr_best:  69.47%, epoch time: 104.38 seconds, 1.74 minutes\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.302436/  2.310801, val:  50.00%, val_best:  69.91%, tr:  67.51%, tr_best:  69.47%, epoch time: 105.01 seconds, 1.75 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.302706/  2.300054, val:  63.72%, val_best:  69.91%, tr:  67.29%, tr_best:  69.47%, epoch time: 104.78 seconds, 1.75 minutes\n",
      "train - Value 0: 1902 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.303769/  2.305032, val:  52.65%, val_best:  69.91%, tr:  67.86%, tr_best:  69.47%, epoch time: 104.86 seconds, 1.75 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.303087/  2.302405, val:  50.22%, val_best:  69.91%, tr:  67.53%, tr_best:  69.47%, epoch time: 102.61 seconds, 1.71 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.302874/  2.296968, val:  52.43%, val_best:  69.91%, tr:  68.40%, tr_best:  69.47%, epoch time: 104.72 seconds, 1.75 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.302763/  2.303595, val:  60.40%, val_best:  69.91%, tr:  67.11%, tr_best:  69.47%, epoch time: 105.13 seconds, 1.75 minutes\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.302735/  2.296517, val:  50.00%, val_best:  69.91%, tr:  65.97%, tr_best:  69.47%, epoch time: 103.87 seconds, 1.73 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.302266/  2.306806, val:  50.00%, val_best:  69.91%, tr:  67.29%, tr_best:  69.47%, epoch time: 104.94 seconds, 1.75 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.302894/  2.302317, val:  66.37%, val_best:  69.91%, tr:  67.24%, tr_best:  69.47%, epoch time: 105.02 seconds, 1.75 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.303077/  2.305089, val:  49.78%, val_best:  69.91%, tr:  69.69%, tr_best:  69.69%, epoch time: 104.32 seconds, 1.74 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 278 occurrences\n",
      "test - Value 1: 174 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.302782/  2.304897, val:  57.52%, val_best:  69.91%, tr:  68.18%, tr_best:  69.69%, epoch time: 105.66 seconds, 1.76 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.302547/  2.291688, val:  50.44%, val_best:  69.91%, tr:  69.54%, tr_best:  69.69%, epoch time: 102.85 seconds, 1.71 minutes\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1961 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.302554/  2.301825, val:  50.00%, val_best:  69.91%, tr:  68.87%, tr_best:  69.69%, epoch time: 100.96 seconds, 1.68 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.302855/  2.309910, val:  50.00%, val_best:  69.91%, tr:  69.27%, tr_best:  69.69%, epoch time: 101.06 seconds, 1.68 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.302356/  2.299704, val:  50.00%, val_best:  69.91%, tr:  70.26%, tr_best:  70.26%, epoch time: 103.74 seconds, 1.73 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.302679/  2.295043, val:  50.00%, val_best:  69.91%, tr:  69.57%, tr_best:  70.26%, epoch time: 105.37 seconds, 1.76 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.302099/  2.299744, val:  50.00%, val_best:  69.91%, tr:  71.28%, tr_best:  71.28%, epoch time: 104.76 seconds, 1.75 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.302880/  2.303663, val:  51.77%, val_best:  69.91%, tr:  68.15%, tr_best:  71.28%, epoch time: 104.05 seconds, 1.73 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.303138/  2.305516, val:  50.00%, val_best:  69.91%, tr:  70.21%, tr_best:  71.28%, epoch time: 102.25 seconds, 1.70 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.303234/  2.307706, val:  50.00%, val_best:  69.91%, tr:  70.26%, tr_best:  71.28%, epoch time: 104.72 seconds, 1.75 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.302638/  2.305767, val:  50.00%, val_best:  69.91%, tr:  70.06%, tr_best:  71.28%, epoch time: 102.53 seconds, 1.71 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.303388/  2.302720, val:  50.00%, val_best:  69.91%, tr:  72.74%, tr_best:  72.74%, epoch time: 104.33 seconds, 1.74 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.303278/  2.303181, val:  52.21%, val_best:  69.91%, tr:  69.99%, tr_best:  72.74%, epoch time: 102.66 seconds, 1.71 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.302534/  2.307873, val:  50.00%, val_best:  69.91%, tr:  70.81%, tr_best:  72.74%, epoch time: 103.46 seconds, 1.72 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.303180/  2.302168, val:  52.65%, val_best:  69.91%, tr:  70.71%, tr_best:  72.74%, epoch time: 105.15 seconds, 1.75 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.302703/  2.310361, val:  50.00%, val_best:  69.91%, tr:  70.46%, tr_best:  72.74%, epoch time: 102.42 seconds, 1.71 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.302541/  2.301846, val:  51.99%, val_best:  69.91%, tr:  70.59%, tr_best:  72.74%, epoch time: 104.63 seconds, 1.74 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.302654/  2.302733, val:  50.00%, val_best:  69.91%, tr:  69.54%, tr_best:  72.74%, epoch time: 104.51 seconds, 1.74 minutes\n",
      "train - Value 0: 2085 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.302120/  2.303027, val:  51.33%, val_best:  69.91%, tr:  70.66%, tr_best:  72.74%, epoch time: 104.91 seconds, 1.75 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.302646/  2.299448, val:  50.00%, val_best:  69.91%, tr:  70.19%, tr_best:  72.74%, epoch time: 104.30 seconds, 1.74 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.302372/  2.305456, val:  52.21%, val_best:  69.91%, tr:  67.56%, tr_best:  72.74%, epoch time: 103.25 seconds, 1.72 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.303061/  2.301816, val:  50.00%, val_best:  69.91%, tr:  67.61%, tr_best:  72.74%, epoch time: 104.88 seconds, 1.75 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.302014/  2.292776, val:  50.22%, val_best:  69.91%, tr:  65.67%, tr_best:  72.74%, epoch time: 104.08 seconds, 1.73 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.302202/  2.301553, val:  51.77%, val_best:  69.91%, tr:  66.42%, tr_best:  72.74%, epoch time: 105.31 seconds, 1.76 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.302035/  2.301529, val:  50.00%, val_best:  69.91%, tr:  68.13%, tr_best:  72.74%, epoch time: 104.86 seconds, 1.75 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.302893/  2.306211, val:  61.73%, val_best:  69.91%, tr:  67.96%, tr_best:  72.74%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 388 occurrences\n",
      "test - Value 1: 64 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.302769/  2.299485, val:  61.50%, val_best:  69.91%, tr:  66.99%, tr_best:  72.74%, epoch time: 104.07 seconds, 1.73 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.303056/  2.292747, val:  50.00%, val_best:  69.91%, tr:  68.50%, tr_best:  72.74%, epoch time: 104.50 seconds, 1.74 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.303232/  2.299886, val:  55.75%, val_best:  69.91%, tr:  68.58%, tr_best:  72.74%, epoch time: 104.06 seconds, 1.73 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.303090/  2.305127, val:  50.00%, val_best:  69.91%, tr:  67.71%, tr_best:  72.74%, epoch time: 103.73 seconds, 1.73 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.303224/  2.303914, val:  50.00%, val_best:  69.91%, tr:  68.25%, tr_best:  72.74%, epoch time: 103.28 seconds, 1.72 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.302882/  2.311271, val:  50.00%, val_best:  69.91%, tr:  69.32%, tr_best:  72.74%, epoch time: 104.16 seconds, 1.74 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.302061/  2.309591, val:  50.00%, val_best:  69.91%, tr:  70.34%, tr_best:  72.74%, epoch time: 105.08 seconds, 1.75 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 399 occurrences\n",
      "test - Value 1: 53 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.301912/  2.294093, val:  59.51%, val_best:  69.91%, tr:  71.08%, tr_best:  72.74%, epoch time: 103.33 seconds, 1.72 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.302289/  2.303912, val:  50.00%, val_best:  69.91%, tr:  69.17%, tr_best:  72.74%, epoch time: 102.33 seconds, 1.71 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 50 occurrences\n",
      "test - Value 1: 402 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.303340/  2.304664, val:  57.52%, val_best:  69.91%, tr:  72.02%, tr_best:  72.74%, epoch time: 102.31 seconds, 1.71 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.302886/  2.299025, val:  53.76%, val_best:  69.91%, tr:  70.54%, tr_best:  72.74%, epoch time: 101.75 seconds, 1.70 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.302378/  2.304433, val:  73.89%, val_best:  73.89%, tr:  68.80%, tr_best:  72.74%, epoch time: 100.22 seconds, 1.67 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.302914/  2.295852, val:  52.65%, val_best:  73.89%, tr:  69.72%, tr_best:  72.74%, epoch time: 101.38 seconds, 1.69 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.302759/  2.304793, val:  52.88%, val_best:  73.89%, tr:  71.75%, tr_best:  72.74%, epoch time: 104.02 seconds, 1.73 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.302916/  2.302910, val:  57.74%, val_best:  73.89%, tr:  68.95%, tr_best:  72.74%, epoch time: 104.93 seconds, 1.75 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.303117/  2.304218, val:  50.00%, val_best:  73.89%, tr:  69.62%, tr_best:  72.74%, epoch time: 104.21 seconds, 1.74 minutes\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1953 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.303255/  2.302848, val:  69.69%, val_best:  73.89%, tr:  68.38%, tr_best:  72.74%, epoch time: 104.68 seconds, 1.74 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.302744/  2.306912, val:  50.00%, val_best:  73.89%, tr:  69.05%, tr_best:  72.74%, epoch time: 104.27 seconds, 1.74 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.303339/  2.303119, val:  73.45%, val_best:  73.89%, tr:  68.45%, tr_best:  72.74%, epoch time: 102.64 seconds, 1.71 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.302724/  2.302094, val:  68.14%, val_best:  73.89%, tr:  68.33%, tr_best:  72.74%, epoch time: 104.96 seconds, 1.75 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.302382/  2.301939, val:  50.00%, val_best:  73.89%, tr:  67.68%, tr_best:  72.74%, epoch time: 104.17 seconds, 1.74 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.302991/  2.309594, val:  50.00%, val_best:  73.89%, tr:  69.99%, tr_best:  72.74%, epoch time: 104.41 seconds, 1.74 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.302630/  2.311841, val:  50.00%, val_best:  73.89%, tr:  70.01%, tr_best:  72.74%, epoch time: 103.90 seconds, 1.73 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.303241/  2.292826, val:  51.77%, val_best:  73.89%, tr:  69.05%, tr_best:  72.74%, epoch time: 103.93 seconds, 1.73 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.302613/  2.295343, val:  52.65%, val_best:  73.89%, tr:  70.11%, tr_best:  72.74%, epoch time: 104.78 seconds, 1.75 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.302730/  2.305834, val:  58.41%, val_best:  73.89%, tr:  68.75%, tr_best:  72.74%, epoch time: 105.62 seconds, 1.76 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.302623/  2.303186, val:  52.21%, val_best:  73.89%, tr:  68.60%, tr_best:  72.74%, epoch time: 105.45 seconds, 1.76 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.302928/  2.302768, val:  52.21%, val_best:  73.89%, tr:  67.98%, tr_best:  72.74%, epoch time: 105.62 seconds, 1.76 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.302733/  2.298545, val:  50.00%, val_best:  73.89%, tr:  71.35%, tr_best:  72.74%, epoch time: 103.98 seconds, 1.73 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.303017/  2.305995, val:  64.82%, val_best:  73.89%, tr:  70.39%, tr_best:  72.74%, epoch time: 104.90 seconds, 1.75 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.302564/  2.306571, val:  50.00%, val_best:  73.89%, tr:  70.06%, tr_best:  72.74%, epoch time: 105.15 seconds, 1.75 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.302543/  2.298460, val:  62.61%, val_best:  73.89%, tr:  70.59%, tr_best:  72.74%, epoch time: 104.82 seconds, 1.75 minutes\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.302264/  2.307946, val:  50.00%, val_best:  73.89%, tr:  71.13%, tr_best:  72.74%, epoch time: 103.73 seconds, 1.73 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.302532/  2.306111, val:  50.00%, val_best:  73.89%, tr:  72.62%, tr_best:  72.74%, epoch time: 102.53 seconds, 1.71 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.302902/  2.301341, val:  54.87%, val_best:  73.89%, tr:  70.86%, tr_best:  72.74%, epoch time: 103.24 seconds, 1.72 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.303265/  2.298372, val:  55.09%, val_best:  73.89%, tr:  71.90%, tr_best:  72.74%, epoch time: 104.27 seconds, 1.74 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 399 occurrences\n",
      "test - Value 1: 53 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.302757/  2.289234, val:  61.28%, val_best:  73.89%, tr:  70.81%, tr_best:  72.74%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.303323/  2.301211, val:  50.00%, val_best:  73.89%, tr:  68.90%, tr_best:  72.74%, epoch time: 102.64 seconds, 1.71 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.303304/  2.309825, val:  65.49%, val_best:  73.89%, tr:  69.47%, tr_best:  72.74%, epoch time: 103.22 seconds, 1.72 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.302584/  2.299415, val:  50.44%, val_best:  73.89%, tr:  70.93%, tr_best:  72.74%, epoch time: 104.43 seconds, 1.74 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.302083/  2.302161, val:  49.56%, val_best:  73.89%, tr:  71.21%, tr_best:  72.74%, epoch time: 105.12 seconds, 1.75 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 416 occurrences\n",
      "test - Value 1: 36 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.303299/  2.299731, val:  57.96%, val_best:  73.89%, tr:  70.68%, tr_best:  72.74%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.303179/  2.291325, val:  50.88%, val_best:  73.89%, tr:  69.77%, tr_best:  72.74%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.302972/  2.295336, val:  54.87%, val_best:  73.89%, tr:  70.68%, tr_best:  72.74%, epoch time: 101.73 seconds, 1.70 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.302806/  2.302563, val:  56.42%, val_best:  73.89%, tr:  69.47%, tr_best:  72.74%, epoch time: 101.21 seconds, 1.69 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.302612/  2.306839, val:  52.43%, val_best:  73.89%, tr:  69.15%, tr_best:  72.74%, epoch time: 101.45 seconds, 1.69 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.302606/  2.304964, val:  67.04%, val_best:  73.89%, tr:  72.17%, tr_best:  72.74%, epoch time: 103.84 seconds, 1.73 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.302553/  2.301488, val:  50.00%, val_best:  73.89%, tr:  71.95%, tr_best:  72.74%, epoch time: 103.97 seconds, 1.73 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.302595/  2.304291, val:  50.00%, val_best:  73.89%, tr:  69.30%, tr_best:  72.74%, epoch time: 104.94 seconds, 1.75 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.302159/  2.292130, val:  50.00%, val_best:  73.89%, tr:  70.88%, tr_best:  72.74%, epoch time: 104.77 seconds, 1.75 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.302095/  2.304515, val:  50.00%, val_best:  73.89%, tr:  72.02%, tr_best:  72.74%, epoch time: 103.90 seconds, 1.73 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.303182/  2.297581, val:  50.44%, val_best:  73.89%, tr:  70.78%, tr_best:  72.74%, epoch time: 104.71 seconds, 1.75 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.303350/  2.316559, val:  50.00%, val_best:  73.89%, tr:  71.33%, tr_best:  72.74%, epoch time: 103.56 seconds, 1.73 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.302852/  2.305565, val:  50.00%, val_best:  73.89%, tr:  70.59%, tr_best:  72.74%, epoch time: 105.00 seconds, 1.75 minutes\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.302435/  2.290815, val:  50.00%, val_best:  73.89%, tr:  68.87%, tr_best:  72.74%, epoch time: 105.38 seconds, 1.76 minutes\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.303372/  2.292941, val:  50.22%, val_best:  73.89%, tr:  69.92%, tr_best:  72.74%, epoch time: 104.60 seconds, 1.74 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.302538/  2.300209, val:  70.35%, val_best:  73.89%, tr:  68.85%, tr_best:  72.74%, epoch time: 104.18 seconds, 1.74 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.302797/  2.287098, val:  50.88%, val_best:  73.89%, tr:  69.49%, tr_best:  72.74%, epoch time: 104.11 seconds, 1.74 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.302962/  2.306516, val:  50.00%, val_best:  73.89%, tr:  70.68%, tr_best:  72.74%, epoch time: 102.96 seconds, 1.72 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.302898/  2.309407, val:  50.00%, val_best:  73.89%, tr:  71.78%, tr_best:  72.74%, epoch time: 102.89 seconds, 1.71 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.302924/  2.307288, val:  50.00%, val_best:  73.89%, tr:  70.56%, tr_best:  72.74%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 420 occurrences\n",
      "test - Value 1: 32 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.303497/  2.299083, val:  57.08%, val_best:  73.89%, tr:  73.56%, tr_best:  73.56%, epoch time: 104.50 seconds, 1.74 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.302745/  2.304194, val:  50.00%, val_best:  73.89%, tr:  71.06%, tr_best:  73.56%, epoch time: 101.80 seconds, 1.70 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.302329/  2.301262, val:  50.00%, val_best:  73.89%, tr:  71.30%, tr_best:  73.56%, epoch time: 103.42 seconds, 1.72 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.303123/  2.308360, val:  51.77%, val_best:  73.89%, tr:  70.59%, tr_best:  73.56%, epoch time: 103.99 seconds, 1.73 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.302884/  2.302392, val:  50.00%, val_best:  73.89%, tr:  73.31%, tr_best:  73.56%, epoch time: 104.35 seconds, 1.74 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.303044/  2.303540, val:  50.00%, val_best:  73.89%, tr:  71.21%, tr_best:  73.56%, epoch time: 104.02 seconds, 1.73 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.302848/  2.301866, val:  50.00%, val_best:  73.89%, tr:  71.45%, tr_best:  73.56%, epoch time: 105.53 seconds, 1.76 minutes\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.303051/  2.293484, val:  50.00%, val_best:  73.89%, tr:  69.79%, tr_best:  73.56%, epoch time: 104.92 seconds, 1.75 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.302938/  2.311731, val:  50.00%, val_best:  73.89%, tr:  69.69%, tr_best:  73.56%, epoch time: 103.64 seconds, 1.73 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.302505/  2.290565, val:  52.43%, val_best:  73.89%, tr:  71.38%, tr_best:  73.56%, epoch time: 104.05 seconds, 1.73 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.303038/  2.302374, val:  50.00%, val_best:  73.89%, tr:  70.66%, tr_best:  73.56%, epoch time: 103.97 seconds, 1.73 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.302927/  2.289081, val:  50.66%, val_best:  73.89%, tr:  71.06%, tr_best:  73.56%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.302923/  2.314527, val:  50.88%, val_best:  73.89%, tr:  70.81%, tr_best:  73.56%, epoch time: 103.79 seconds, 1.73 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.303566/  2.286658, val:  50.00%, val_best:  73.89%, tr:  70.09%, tr_best:  73.56%, epoch time: 104.32 seconds, 1.74 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.302718/  2.303383, val:  50.00%, val_best:  73.89%, tr:  69.02%, tr_best:  73.56%, epoch time: 104.20 seconds, 1.74 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.302854/  2.311653, val:  59.07%, val_best:  73.89%, tr:  71.06%, tr_best:  73.56%, epoch time: 103.31 seconds, 1.72 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.303278/  2.289772, val:  50.00%, val_best:  73.89%, tr:  70.51%, tr_best:  73.56%, epoch time: 101.27 seconds, 1.69 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.303014/  2.304046, val:  50.00%, val_best:  73.89%, tr:  68.30%, tr_best:  73.56%, epoch time: 101.43 seconds, 1.69 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.304098/  2.291433, val:  50.00%, val_best:  73.89%, tr:  70.39%, tr_best:  73.56%, epoch time: 101.35 seconds, 1.69 minutes\n",
      "train - Value 0: 1901 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 340 occurrences\n",
      "test - Value 1: 112 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.303356/  2.305683, val:  67.70%, val_best:  73.89%, tr:  69.82%, tr_best:  73.56%, epoch time: 103.51 seconds, 1.73 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.302608/  2.295631, val:  73.89%, val_best:  73.89%, tr:  69.64%, tr_best:  73.56%, epoch time: 104.57 seconds, 1.74 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.302798/  2.299229, val:  67.92%, val_best:  73.89%, tr:  69.42%, tr_best:  73.56%, epoch time: 105.32 seconds, 1.76 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.302640/  2.304020, val:  50.00%, val_best:  73.89%, tr:  70.11%, tr_best:  73.56%, epoch time: 104.08 seconds, 1.73 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.302070/  2.304473, val:  50.00%, val_best:  73.89%, tr:  68.80%, tr_best:  73.56%, epoch time: 102.64 seconds, 1.71 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.301958/  2.301403, val:  58.41%, val_best:  73.89%, tr:  68.75%, tr_best:  73.56%, epoch time: 102.45 seconds, 1.71 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.303020/  2.303563, val:  50.00%, val_best:  73.89%, tr:  70.46%, tr_best:  73.56%, epoch time: 104.25 seconds, 1.74 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.302587/  2.300143, val:  56.19%, val_best:  73.89%, tr:  70.11%, tr_best:  73.56%, epoch time: 103.92 seconds, 1.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.302293/  2.306150, val:  62.17%, val_best:  73.89%, tr:  70.66%, tr_best:  73.56%, epoch time: 102.94 seconds, 1.72 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.302230/  2.310488, val:  60.40%, val_best:  73.89%, tr:  69.54%, tr_best:  73.56%, epoch time: 103.40 seconds, 1.72 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.303044/  2.293086, val:  50.00%, val_best:  73.89%, tr:  68.92%, tr_best:  73.56%, epoch time: 103.16 seconds, 1.72 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.303107/  2.308144, val:  50.00%, val_best:  73.89%, tr:  69.74%, tr_best:  73.56%, epoch time: 104.44 seconds, 1.74 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.302401/  2.302027, val:  50.00%, val_best:  73.89%, tr:  69.79%, tr_best:  73.56%, epoch time: 104.66 seconds, 1.74 minutes\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.302714/  2.302202, val:  50.00%, val_best:  73.89%, tr:  70.29%, tr_best:  73.56%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.302581/  2.306416, val:  71.24%, val_best:  73.89%, tr:  69.27%, tr_best:  73.56%, epoch time: 104.06 seconds, 1.73 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.302694/  2.297050, val:  52.43%, val_best:  73.89%, tr:  68.33%, tr_best:  73.56%, epoch time: 104.02 seconds, 1.73 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.303240/  2.303657, val:  50.22%, val_best:  73.89%, tr:  71.45%, tr_best:  73.56%, epoch time: 104.36 seconds, 1.74 minutes\n",
      "train - Value 0: 2115 occurrences\n",
      "train - Value 1: 1917 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.301993/  2.302733, val:  50.00%, val_best:  73.89%, tr:  70.61%, tr_best:  73.56%, epoch time: 104.42 seconds, 1.74 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.302341/  2.303588, val:  51.33%, val_best:  73.89%, tr:  69.05%, tr_best:  73.56%, epoch time: 104.99 seconds, 1.75 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece5b5accae342d2b9569d7a143d1ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▁▁▁▁▁▁█▁███████▁▁██▁██▁████▁▁█▁▁██▁▁██▁</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▂▁▁▇▁▂▁▁▁▁▂▁▁▁▂▂▁▅▁▂█▁▂▁▅▂▇▁█▁▁▁▄▇▁▁▂</td></tr><tr><td>tr_acc</td><td>▁▁▁▄▄▆▆▆▅▆▆▆▇▇▆▇█▇█▆▆▇▇▇▇▇██▇██▇████▇▇▇▇</td></tr><tr><td>tr_epoch_loss</td><td>▃▃▄▂▅▅▄▃▂▄▅▄▃█▄▃▁▆▃▁▄▁▄▆▂▃▂▄▆▃▆▃▄▅▅▄▄▅▃▂</td></tr><tr><td>val_acc_best</td><td>▁▁▁▂▃▃▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▂▁▁▇▁▂▁▁▁▁▂▁▁▁▂▂▁▅▁▂█▁▂▁▅▂▇▁█▁▁▁▄▇▁▁▂</td></tr><tr><td>val_loss</td><td>▄▄▄▅▅▅▄▄▄▃▅▄▅▅▃▄▄▅▄▂▄▆▄▅▄▅▆▁▂▅█▄▅▅▁▇▄▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.69048</td></tr><tr><td>tr_epoch_loss</td><td>2.30234</td></tr><tr><td>val_acc_best</td><td>0.73894</td></tr><tr><td>val_acc_now</td><td>0.51327</td></tr><tr><td>val_loss</td><td>2.30359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-3</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pdo8w2z5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pdo8w2z5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_031719-pdo8w2z5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5ff12kcg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000244140625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_090512-5ff12kcg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/5ff12kcg' target=\"_blank\">pleasant-sweep-4</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/5ff12kcg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/5ff12kcg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250806_090520_459', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.000244140625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-11, -11], [-11, -11], [-10, -10]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -11\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -11\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.000244140625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-0   lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.47 seconds, 1.72 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-1   lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.68 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-2   lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.00 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-3   lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.25 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-4   lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.32 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-5   lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.93 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-6   lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.29 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-7   lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.80 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-8   lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.21 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-9   lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.11 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-10  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.59 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-11  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.25 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-12  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.36 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-13  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.31 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-14  lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 100.96 seconds, 1.68 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-15  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.37 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-16  lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.03 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-17  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.52 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-18  lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.45 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-19  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.85 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-20  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.23 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-21  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.44 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-22  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.63 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-23  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.25 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-24  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.67 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-25  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.25 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-26  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.82 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-27  lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.32 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-28  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.12 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-29  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.05 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-30  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.44 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-31  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.86 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-32  lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.22 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-33  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.74 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-34  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.88 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-35  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.14 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-36  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.25 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-37  lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.80 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-38  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.10 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-39  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.74 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-40  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.26 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-41  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.38 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-42  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.52 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-43  lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.73 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-44  lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.96 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-45  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.40 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-46  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.18 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-47  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.24 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-48  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.90 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-49  lr=['0.0002441'], tr/val_loss:  2.351856/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.05 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-50  lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.13 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-51  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.99 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-52  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.88 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-53  lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.75 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-54  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.82 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-55  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.09 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-56  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.21 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-57  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.35 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-58  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.86 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-59  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.10 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-60  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.70 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-61  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.91 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-62  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.38 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-63  lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.85 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-64  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-65  lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.55 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-66  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.55 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-67  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.46 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-68  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.62 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-69  lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.41 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-70  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.66 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-71  lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.13 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-72  lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.09 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-73  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.54 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-74  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.10 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-75  lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.20 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-76  lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.79 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-77  lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.05 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-78  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.96 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-79  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.57 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-80  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.75 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-81  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.50 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-82  lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.97 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-83  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-84  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.47 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-85  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.89 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-86  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.73 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-87  lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.22 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-88  lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.76 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-89  lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.18 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-90  lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.48 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-91  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.38 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-92  lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.16 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-93  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.70 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-94  lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.23 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-95  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.56 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-96  lr=['0.0002441'], tr/val_loss:  2.351867/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.66 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-97  lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.82 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-98  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.91 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-99  lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.36 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-100 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.08 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-101 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.29 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-102 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.20 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-103 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.62 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-104 lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.54 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-105 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.05 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-106 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.98 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-107 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.90 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-108 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.33 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-109 lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.59 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-110 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.85 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-111 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.67 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-112 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.29 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-113 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.11 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-114 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.91 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-115 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.34 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-116 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.09 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-117 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.36 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-118 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.69 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-119 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.74 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-120 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.88 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-121 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.24 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-122 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.63 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-123 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.05 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-124 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.60 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-125 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.36 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-126 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.10 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-127 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.48 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-128 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.24 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-129 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.65 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-130 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.24 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-131 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.61 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-132 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.48 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-133 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.13 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-134 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.44 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-135 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.38 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-136 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.61 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-137 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.97 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-138 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.18 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-139 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.22 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-140 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.21 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-141 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.63 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-142 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.19 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-143 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.56 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-144 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.81 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-145 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.30 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-146 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.86 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-147 lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.88 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-148 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.38 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-149 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.09 seconds, 1.68 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-150 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.04 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-151 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.37 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-152 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.65 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-153 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.00 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-154 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.13 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-155 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.77 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-156 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.54 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-157 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.55 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-158 lr=['0.0002441'], tr/val_loss:  2.351866/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.92 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-159 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.26 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-160 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.13 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-161 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.28 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-162 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.93 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-163 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.88 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-164 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.50 seconds, 1.76 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-165 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 105.21 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-166 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.57 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-167 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.98 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-168 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.25 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-169 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.31 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-170 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.15 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-171 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.66 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-172 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.84 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-173 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.67 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-174 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.80 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-175 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.55 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-176 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.34 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-177 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.59 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-178 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.47 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-179 lr=['0.0002441'], tr/val_loss:  2.351857/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.28 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-180 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.59 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-181 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.92 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-182 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.61 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-183 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 101.38 seconds, 1.69 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-184 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.53 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-185 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.43 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-186 lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.38 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-187 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.44 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-188 lr=['0.0002441'], tr/val_loss:  2.351862/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.07 seconds, 1.70 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-189 lr=['0.0002441'], tr/val_loss:  2.351864/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.64 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-190 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.07 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-191 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 102.78 seconds, 1.71 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-192 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.45 seconds, 1.72 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-193 lr=['0.0002441'], tr/val_loss:  2.351863/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 103.68 seconds, 1.73 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-194 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.74 seconds, 1.75 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-195 lr=['0.0002441'], tr/val_loss:  2.351859/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.15 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-196 lr=['0.0002441'], tr/val_loss:  2.351858/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.22 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-197 lr=['0.0002441'], tr/val_loss:  2.351865/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.32 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-198 lr=['0.0002441'], tr/val_loss:  2.351860/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.35 seconds, 1.74 minutes\n",
      "train - Value 0: 1584 occurrences\n",
      "train - Value 1: 2448 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-199 lr=['0.0002441'], tr/val_loss:  2.351861/  2.327937, val:  50.44%, val_best:  50.44%, tr:  51.24%, tr_best:  51.24%, epoch time: 104.89 seconds, 1.75 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabd23b52044483bb819fd4c9841df1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▁▁▁▁███████▁████▁▁▁▁█▁▁▁▁▁▁███▁███▁▁██▁</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_epoch_loss</td><td>█▆▆▃▄▃▄▆▆▅▄▄▃▆▇▇▅▇▄▅▂▆▃▄▂▇▄▄▃▁▃▃▆▇▄▃▂▅▆▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.5124</td></tr><tr><td>tr_epoch_loss</td><td>2.35186</td></tr><tr><td>val_acc_best</td><td>0.50442</td></tr><tr><td>val_acc_now</td><td>0.50442</td></tr><tr><td>val_loss</td><td>2.32794</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-4</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/5ff12kcg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/5ff12kcg</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_090512-5ff12kcg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8wo2zp42 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_145243-8wo2zp42</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/8wo2zp42' target=\"_blank\">treasured-sweep-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/8wo2zp42' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/8wo2zp42</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250806_145252_472', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 15, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-13, -13], [-13, -13], [-12, -12]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.300473/  2.291968, val:  50.00%, val_best:  50.00%, tr:  80.36%, tr_best:  80.36%, epoch time: 151.74 seconds, 2.53 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.306421/  2.263227, val:  50.00%, val_best:  50.00%, tr:  86.63%, tr_best:  86.63%, epoch time: 150.10 seconds, 2.50 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.294253/  2.336678, val:  69.69%, val_best:  69.69%, tr:  86.21%, tr_best:  86.63%, epoch time: 152.55 seconds, 2.54 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.309356/  2.338398, val:  50.00%, val_best:  69.69%, tr:  86.04%, tr_best:  86.63%, epoch time: 152.71 seconds, 2.55 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.299812/  2.277688, val:  50.66%, val_best:  69.69%, tr:  89.46%, tr_best:  89.46%, epoch time: 149.74 seconds, 2.50 minutes\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.303365/  2.286393, val:  50.00%, val_best:  69.69%, tr:  89.46%, tr_best:  89.46%, epoch time: 148.71 seconds, 2.48 minutes\n",
      "train - Value 0: 2179 occurrences\n",
      "train - Value 1: 1853 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.300751/  2.386115, val:  50.00%, val_best:  69.69%, tr:  90.00%, tr_best:  90.00%, epoch time: 148.77 seconds, 2.48 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.295898/  2.306806, val:  50.00%, val_best:  69.69%, tr:  85.22%, tr_best:  90.00%, epoch time: 147.61 seconds, 2.46 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.304873/  2.362462, val:  54.87%, val_best:  69.69%, tr:  81.82%, tr_best:  90.00%, epoch time: 147.60 seconds, 2.46 minutes\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.310904/  2.389348, val:  50.00%, val_best:  69.69%, tr:  90.72%, tr_best:  90.72%, epoch time: 147.65 seconds, 2.46 minutes\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.292517/  2.301520, val:  50.00%, val_best:  69.69%, tr:  90.43%, tr_best:  90.72%, epoch time: 146.77 seconds, 2.45 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.316088/  2.391640, val:  50.00%, val_best:  69.69%, tr:  87.80%, tr_best:  90.72%, epoch time: 144.16 seconds, 2.40 minutes\n",
      "train - Value 0: 2153 occurrences\n",
      "train - Value 1: 1879 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.299416/  2.281916, val:  50.22%, val_best:  69.69%, tr:  84.65%, tr_best:  90.72%, epoch time: 146.28 seconds, 2.44 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.298043/  2.288659, val:  50.00%, val_best:  69.69%, tr:  89.11%, tr_best:  90.72%, epoch time: 148.85 seconds, 2.48 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.299360/  2.334524, val:  50.00%, val_best:  69.69%, tr:  87.70%, tr_best:  90.72%, epoch time: 147.92 seconds, 2.47 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.322591/  2.276775, val:  50.00%, val_best:  69.69%, tr:  90.13%, tr_best:  90.72%, epoch time: 149.58 seconds, 2.49 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.313338/  2.330693, val:  50.00%, val_best:  69.69%, tr:  84.57%, tr_best:  90.72%, epoch time: 148.75 seconds, 2.48 minutes\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.292878/  2.268419, val:  63.94%, val_best:  69.69%, tr:  90.97%, tr_best:  90.97%, epoch time: 149.28 seconds, 2.49 minutes\n",
      "train - Value 0: 2111 occurrences\n",
      "train - Value 1: 1921 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.303900/  2.392476, val:  50.00%, val_best:  69.69%, tr:  91.44%, tr_best:  91.44%, epoch time: 148.94 seconds, 2.48 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.319721/  2.215485, val:  50.00%, val_best:  69.69%, tr:  87.80%, tr_best:  91.44%, epoch time: 148.87 seconds, 2.48 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.331966/  2.351959, val:  50.00%, val_best:  69.69%, tr:  83.51%, tr_best:  91.44%, epoch time: 149.67 seconds, 2.49 minutes\n",
      "train - Value 0: 1742 occurrences\n",
      "train - Value 1: 2290 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.310662/  2.302880, val:  72.35%, val_best:  72.35%, tr:  85.57%, tr_best:  91.44%, epoch time: 148.33 seconds, 2.47 minutes\n",
      "train - Value 0: 2141 occurrences\n",
      "train - Value 1: 1891 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.321594/  2.331698, val:  50.00%, val_best:  72.35%, tr:  86.88%, tr_best:  91.44%, epoch time: 147.67 seconds, 2.46 minutes\n",
      "train - Value 0: 2121 occurrences\n",
      "train - Value 1: 1911 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.290367/  2.321243, val:  54.20%, val_best:  72.35%, tr:  86.78%, tr_best:  91.44%, epoch time: 146.20 seconds, 2.44 minutes\n",
      "train - Value 0: 2185 occurrences\n",
      "train - Value 1: 1847 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.308887/  2.289691, val:  50.22%, val_best:  72.35%, tr:  84.00%, tr_best:  91.44%, epoch time: 143.74 seconds, 2.40 minutes\n",
      "train - Value 0: 1793 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.320042/  2.319897, val:  50.66%, val_best:  72.35%, tr:  86.73%, tr_best:  91.44%, epoch time: 147.21 seconds, 2.45 minutes\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.308290/  2.356067, val:  50.00%, val_best:  72.35%, tr:  87.10%, tr_best:  91.44%, epoch time: 147.36 seconds, 2.46 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.323097/  2.405135, val:  50.00%, val_best:  72.35%, tr:  79.39%, tr_best:  91.44%, epoch time: 147.41 seconds, 2.46 minutes\n",
      "train - Value 0: 1886 occurrences\n",
      "train - Value 1: 2146 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.335406/  2.327216, val:  50.22%, val_best:  72.35%, tr:  83.93%, tr_best:  91.44%, epoch time: 147.25 seconds, 2.45 minutes\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.303644/  2.340521, val:  50.00%, val_best:  72.35%, tr:  91.52%, tr_best:  91.52%, epoch time: 146.33 seconds, 2.44 minutes\n",
      "train - Value 0: 2205 occurrences\n",
      "train - Value 1: 1827 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.310596/  2.295001, val:  50.00%, val_best:  72.35%, tr:  85.14%, tr_best:  91.52%, epoch time: 146.80 seconds, 2.45 minutes\n",
      "train - Value 0: 2219 occurrences\n",
      "train - Value 1: 1813 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.273559/  2.289960, val:  50.44%, val_best:  72.35%, tr:  89.51%, tr_best:  91.52%, epoch time: 147.20 seconds, 2.45 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.309640/  2.293584, val:  50.00%, val_best:  72.35%, tr:  84.75%, tr_best:  91.52%, epoch time: 148.02 seconds, 2.47 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.323124/  2.377969, val:  65.27%, val_best:  72.35%, tr:  87.25%, tr_best:  91.52%, epoch time: 148.18 seconds, 2.47 minutes\n",
      "train - Value 0: 1727 occurrences\n",
      "train - Value 1: 2305 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.323300/  2.329093, val:  50.00%, val_best:  72.35%, tr:  85.79%, tr_best:  91.52%, epoch time: 144.25 seconds, 2.40 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.312966/  2.315967, val:  50.00%, val_best:  72.35%, tr:  90.10%, tr_best:  91.52%, epoch time: 142.39 seconds, 2.37 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.317876/  2.282937, val:  50.44%, val_best:  72.35%, tr:  90.75%, tr_best:  91.52%, epoch time: 147.36 seconds, 2.46 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.290483/  2.332393, val:  50.00%, val_best:  72.35%, tr:  85.19%, tr_best:  91.52%, epoch time: 148.27 seconds, 2.47 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.319345/  2.227382, val:  50.00%, val_best:  72.35%, tr:  84.90%, tr_best:  91.52%, epoch time: 147.69 seconds, 2.46 minutes\n",
      "train - Value 0: 2123 occurrences\n",
      "train - Value 1: 1909 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.322017/  2.348077, val:  50.00%, val_best:  72.35%, tr:  88.96%, tr_best:  91.52%, epoch time: 147.77 seconds, 2.46 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.322857/  2.247794, val:  50.00%, val_best:  72.35%, tr:  89.34%, tr_best:  91.52%, epoch time: 148.21 seconds, 2.47 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.305507/  2.356046, val:  50.00%, val_best:  72.35%, tr:  89.06%, tr_best:  91.52%, epoch time: 148.55 seconds, 2.48 minutes\n",
      "train - Value 0: 2146 occurrences\n",
      "train - Value 1: 1886 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.305814/  2.260977, val:  50.22%, val_best:  72.35%, tr:  82.09%, tr_best:  91.52%, epoch time: 148.24 seconds, 2.47 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.308834/  2.234789, val:  50.00%, val_best:  72.35%, tr:  89.14%, tr_best:  91.52%, epoch time: 148.91 seconds, 2.48 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.296656/  2.278775, val:  53.10%, val_best:  72.35%, tr:  84.82%, tr_best:  91.52%, epoch time: 147.03 seconds, 2.45 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.297019/  2.286908, val:  66.15%, val_best:  72.35%, tr:  89.16%, tr_best:  91.52%, epoch time: 147.30 seconds, 2.46 minutes\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.300975/  2.325398, val:  50.00%, val_best:  72.35%, tr:  87.38%, tr_best:  91.52%, epoch time: 148.31 seconds, 2.47 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.312187/  2.297855, val:  50.00%, val_best:  72.35%, tr:  86.19%, tr_best:  91.52%, epoch time: 146.03 seconds, 2.43 minutes\n",
      "train - Value 0: 2074 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.315924/  2.277281, val:  50.00%, val_best:  72.35%, tr:  89.38%, tr_best:  91.52%, epoch time: 146.73 seconds, 2.45 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.314559/  2.386704, val:  50.00%, val_best:  72.35%, tr:  87.72%, tr_best:  91.52%, epoch time: 147.67 seconds, 2.46 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.330793/  2.368407, val:  50.00%, val_best:  72.35%, tr:  76.71%, tr_best:  91.52%, epoch time: 148.04 seconds, 2.47 minutes\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.320543/  2.348511, val:  50.00%, val_best:  72.35%, tr:  86.19%, tr_best:  91.52%, epoch time: 148.07 seconds, 2.47 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.332842/  2.312507, val:  50.22%, val_best:  72.35%, tr:  86.66%, tr_best:  91.52%, epoch time: 147.79 seconds, 2.46 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.306989/  2.334372, val:  57.30%, val_best:  72.35%, tr:  86.78%, tr_best:  91.52%, epoch time: 148.58 seconds, 2.48 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.317288/  2.360206, val:  49.78%, val_best:  72.35%, tr:  89.41%, tr_best:  91.52%, epoch time: 148.13 seconds, 2.47 minutes\n",
      "train - Value 0: 1909 occurrences\n",
      "train - Value 1: 2123 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.326603/  2.281448, val:  50.00%, val_best:  72.35%, tr:  87.67%, tr_best:  91.52%, epoch time: 148.38 seconds, 2.47 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.328773/  2.303011, val:  50.22%, val_best:  72.35%, tr:  84.25%, tr_best:  91.52%, epoch time: 148.38 seconds, 2.47 minutes\n",
      "train - Value 0: 1877 occurrences\n",
      "train - Value 1: 2155 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.314242/  2.234554, val:  50.00%, val_best:  72.35%, tr:  83.56%, tr_best:  91.52%, epoch time: 148.59 seconds, 2.48 minutes\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.299843/  2.251847, val:  51.11%, val_best:  72.35%, tr:  85.57%, tr_best:  91.52%, epoch time: 144.00 seconds, 2.40 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.302830/  2.322558, val:  73.45%, val_best:  73.45%, tr:  85.49%, tr_best:  91.52%, epoch time: 144.29 seconds, 2.40 minutes\n",
      "train - Value 0: 1642 occurrences\n",
      "train - Value 1: 2390 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.335227/  2.304292, val:  50.00%, val_best:  73.45%, tr:  82.09%, tr_best:  91.52%, epoch time: 148.27 seconds, 2.47 minutes\n",
      "train - Value 0: 2117 occurrences\n",
      "train - Value 1: 1915 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.312260/  2.282403, val:  50.22%, val_best:  73.45%, tr:  86.53%, tr_best:  91.52%, epoch time: 148.08 seconds, 2.47 minutes\n",
      "train - Value 0: 1888 occurrences\n",
      "train - Value 1: 2144 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.324107/  2.227846, val:  50.00%, val_best:  73.45%, tr:  84.92%, tr_best:  91.52%, epoch time: 146.29 seconds, 2.44 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.305357/  2.281320, val:  58.41%, val_best:  73.45%, tr:  90.33%, tr_best:  91.52%, epoch time: 147.85 seconds, 2.46 minutes\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.326136/  2.198555, val:  50.00%, val_best:  73.45%, tr:  83.98%, tr_best:  91.52%, epoch time: 149.08 seconds, 2.48 minutes\n",
      "train - Value 0: 2117 occurrences\n",
      "train - Value 1: 1915 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.318835/  2.312348, val:  70.13%, val_best:  73.45%, tr:  88.42%, tr_best:  91.52%, epoch time: 146.01 seconds, 2.43 minutes\n",
      "train - Value 0: 1876 occurrences\n",
      "train - Value 1: 2156 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.318830/  2.410844, val:  50.00%, val_best:  73.45%, tr:  90.13%, tr_best:  91.52%, epoch time: 147.78 seconds, 2.46 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.327490/  2.277152, val:  50.44%, val_best:  73.45%, tr:  79.61%, tr_best:  91.52%, epoch time: 148.29 seconds, 2.47 minutes\n",
      "train - Value 0: 1766 occurrences\n",
      "train - Value 1: 2266 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.311077/  2.340857, val:  51.77%, val_best:  73.45%, tr:  83.48%, tr_best:  91.52%, epoch time: 147.94 seconds, 2.47 minutes\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2201 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.330906/  2.379213, val:  53.10%, val_best:  73.45%, tr:  83.80%, tr_best:  91.52%, epoch time: 147.80 seconds, 2.46 minutes\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.318174/  2.310804, val:  50.00%, val_best:  73.45%, tr:  88.24%, tr_best:  91.52%, epoch time: 148.10 seconds, 2.47 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.302299/  2.352756, val:  53.10%, val_best:  73.45%, tr:  88.79%, tr_best:  91.52%, epoch time: 148.75 seconds, 2.48 minutes\n",
      "train - Value 0: 2060 occurrences\n",
      "train - Value 1: 1972 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.301012/  2.314810, val:  50.00%, val_best:  73.45%, tr:  86.95%, tr_best:  91.52%, epoch time: 147.84 seconds, 2.46 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.304085/  2.267936, val:  50.00%, val_best:  73.45%, tr:  89.68%, tr_best:  91.52%, epoch time: 148.73 seconds, 2.48 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.341435/  2.363012, val:  52.65%, val_best:  73.45%, tr:  81.15%, tr_best:  91.52%, epoch time: 148.53 seconds, 2.48 minutes\n",
      "train - Value 0: 2139 occurrences\n",
      "train - Value 1: 1893 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.319011/  2.336438, val:  55.31%, val_best:  73.45%, tr:  87.18%, tr_best:  91.52%, epoch time: 148.29 seconds, 2.47 minutes\n",
      "train - Value 0: 2117 occurrences\n",
      "train - Value 1: 1915 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.319618/  2.306681, val:  50.00%, val_best:  73.45%, tr:  79.99%, tr_best:  91.52%, epoch time: 149.02 seconds, 2.48 minutes\n",
      "train - Value 0: 2159 occurrences\n",
      "train - Value 1: 1873 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.315678/  2.266189, val:  50.00%, val_best:  73.45%, tr:  85.39%, tr_best:  91.52%, epoch time: 148.32 seconds, 2.47 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.317808/  2.373029, val:  50.00%, val_best:  73.45%, tr:  88.07%, tr_best:  91.52%, epoch time: 148.32 seconds, 2.47 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.318634/  2.207562, val:  50.00%, val_best:  73.45%, tr:  91.64%, tr_best:  91.64%, epoch time: 147.86 seconds, 2.46 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.299958/  2.307910, val:  50.00%, val_best:  73.45%, tr:  93.11%, tr_best:  93.11%, epoch time: 146.98 seconds, 2.45 minutes\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.316556/  2.312807, val:  50.00%, val_best:  73.45%, tr:  89.01%, tr_best:  93.11%, epoch time: 146.65 seconds, 2.44 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.304234/  2.349143, val:  50.00%, val_best:  73.45%, tr:  90.95%, tr_best:  93.11%, epoch time: 143.66 seconds, 2.39 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.311820/  2.333386, val:  50.00%, val_best:  73.45%, tr:  90.77%, tr_best:  93.11%, epoch time: 142.52 seconds, 2.38 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.304693/  2.303356, val:  50.00%, val_best:  73.45%, tr:  93.23%, tr_best:  93.23%, epoch time: 146.76 seconds, 2.45 minutes\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.304487/  2.296228, val:  63.05%, val_best:  73.45%, tr:  87.25%, tr_best:  93.23%, epoch time: 148.63 seconds, 2.48 minutes\n",
      "train - Value 0: 2190 occurrences\n",
      "train - Value 1: 1842 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.305896/  2.383318, val:  50.00%, val_best:  73.45%, tr:  78.92%, tr_best:  93.23%, epoch time: 148.66 seconds, 2.48 minutes\n",
      "train - Value 0: 1845 occurrences\n",
      "train - Value 1: 2187 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.307599/  2.363896, val:  50.00%, val_best:  73.45%, tr:  80.48%, tr_best:  93.23%, epoch time: 148.54 seconds, 2.48 minutes\n",
      "train - Value 0: 2191 occurrences\n",
      "train - Value 1: 1841 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.294906/  2.372495, val:  50.00%, val_best:  73.45%, tr:  79.44%, tr_best:  93.23%, epoch time: 148.55 seconds, 2.48 minutes\n",
      "train - Value 0: 2322 occurrences\n",
      "train - Value 1: 1710 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.299919/  2.294375, val:  50.00%, val_best:  73.45%, tr:  84.47%, tr_best:  93.23%, epoch time: 147.84 seconds, 2.46 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.303594/  2.289054, val:  50.44%, val_best:  73.45%, tr:  84.08%, tr_best:  93.23%, epoch time: 149.19 seconds, 2.49 minutes\n",
      "train - Value 0: 2294 occurrences\n",
      "train - Value 1: 1738 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.277877/  2.349228, val:  50.66%, val_best:  73.45%, tr:  85.37%, tr_best:  93.23%, epoch time: 147.77 seconds, 2.46 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.285187/  2.288652, val:  50.00%, val_best:  73.45%, tr:  92.56%, tr_best:  93.23%, epoch time: 149.27 seconds, 2.49 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.293373/  2.330508, val:  50.00%, val_best:  73.45%, tr:  89.41%, tr_best:  93.23%, epoch time: 147.91 seconds, 2.47 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.318457/  2.297005, val:  50.22%, val_best:  73.45%, tr:  84.28%, tr_best:  93.23%, epoch time: 148.85 seconds, 2.48 minutes\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1934 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.328585/  2.394449, val:  54.42%, val_best:  73.45%, tr:  86.66%, tr_best:  93.23%, epoch time: 148.95 seconds, 2.48 minutes\n",
      "train - Value 0: 2359 occurrences\n",
      "train - Value 1: 1673 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.305182/  2.353150, val:  50.00%, val_best:  73.45%, tr:  85.79%, tr_best:  93.23%, epoch time: 148.42 seconds, 2.47 minutes\n",
      "train - Value 0: 1908 occurrences\n",
      "train - Value 1: 2124 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.303746/  2.222799, val:  50.00%, val_best:  73.45%, tr:  87.05%, tr_best:  93.23%, epoch time: 147.83 seconds, 2.46 minutes\n",
      "train - Value 0: 1834 occurrences\n",
      "train - Value 1: 2198 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.305347/  2.264104, val:  50.22%, val_best:  73.45%, tr:  86.90%, tr_best:  93.23%, epoch time: 147.02 seconds, 2.45 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.331440/  2.384516, val:  50.44%, val_best:  73.45%, tr:  82.19%, tr_best:  93.23%, epoch time: 149.23 seconds, 2.49 minutes\n",
      "train - Value 0: 2104 occurrences\n",
      "train - Value 1: 1928 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.364321/  2.296589, val:  50.22%, val_best:  73.45%, tr:  78.57%, tr_best:  93.23%, epoch time: 147.88 seconds, 2.46 minutes\n",
      "train - Value 0: 2390 occurrences\n",
      "train - Value 1: 1642 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.358053/  2.374527, val:  50.22%, val_best:  73.45%, tr:  75.35%, tr_best:  93.23%, epoch time: 147.37 seconds, 2.46 minutes\n",
      "train - Value 0: 2145 occurrences\n",
      "train - Value 1: 1887 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.337138/  2.270191, val:  50.00%, val_best:  73.45%, tr:  84.20%, tr_best:  93.23%, epoch time: 148.28 seconds, 2.47 minutes\n",
      "train - Value 0: 2296 occurrences\n",
      "train - Value 1: 1736 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.307682/  2.290101, val:  50.00%, val_best:  73.45%, tr:  87.10%, tr_best:  93.23%, epoch time: 147.68 seconds, 2.46 minutes\n",
      "train - Value 0: 2104 occurrences\n",
      "train - Value 1: 1928 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.276437/  2.371963, val:  50.00%, val_best:  73.45%, tr:  87.95%, tr_best:  93.23%, epoch time: 148.71 seconds, 2.48 minutes\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.309522/  2.376319, val:  50.00%, val_best:  73.45%, tr:  81.15%, tr_best:  93.23%, epoch time: 148.20 seconds, 2.47 minutes\n",
      "train - Value 0: 1890 occurrences\n",
      "train - Value 1: 2142 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.325336/  2.365963, val:  50.00%, val_best:  73.45%, tr:  77.38%, tr_best:  93.23%, epoch time: 144.77 seconds, 2.41 minutes\n",
      "train - Value 0: 1907 occurrences\n",
      "train - Value 1: 2125 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.337263/  2.292540, val:  52.43%, val_best:  73.45%, tr:  80.78%, tr_best:  93.23%, epoch time: 145.91 seconds, 2.43 minutes\n",
      "train - Value 0: 1848 occurrences\n",
      "train - Value 1: 2184 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.308655/  2.314816, val:  50.00%, val_best:  73.45%, tr:  83.13%, tr_best:  93.23%, epoch time: 148.82 seconds, 2.48 minutes\n",
      "train - Value 0: 1619 occurrences\n",
      "train - Value 1: 2413 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.334399/  2.418354, val:  50.00%, val_best:  73.45%, tr:  83.56%, tr_best:  93.23%, epoch time: 148.32 seconds, 2.47 minutes\n",
      "train - Value 0: 2115 occurrences\n",
      "train - Value 1: 1917 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.313377/  2.276641, val:  53.32%, val_best:  73.45%, tr:  81.37%, tr_best:  93.23%, epoch time: 149.05 seconds, 2.48 minutes\n",
      "train - Value 0: 2252 occurrences\n",
      "train - Value 1: 1780 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.292772/  2.258218, val:  50.00%, val_best:  73.45%, tr:  82.29%, tr_best:  93.23%, epoch time: 147.85 seconds, 2.46 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.290358/  2.282135, val:  59.96%, val_best:  73.45%, tr:  80.51%, tr_best:  93.23%, epoch time: 149.62 seconds, 2.49 minutes\n",
      "train - Value 0: 2243 occurrences\n",
      "train - Value 1: 1789 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.291831/  2.282499, val:  50.00%, val_best:  73.45%, tr:  83.46%, tr_best:  93.23%, epoch time: 148.60 seconds, 2.48 minutes\n",
      "train - Value 0: 2090 occurrences\n",
      "train - Value 1: 1942 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.317268/  2.284478, val:  50.00%, val_best:  73.45%, tr:  83.38%, tr_best:  93.23%, epoch time: 150.06 seconds, 2.50 minutes\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.321425/  2.250211, val:  53.32%, val_best:  73.45%, tr:  81.20%, tr_best:  93.23%, epoch time: 150.01 seconds, 2.50 minutes\n",
      "train - Value 0: 2260 occurrences\n",
      "train - Value 1: 1772 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.294198/  2.329581, val:  50.00%, val_best:  73.45%, tr:  78.27%, tr_best:  93.23%, epoch time: 146.32 seconds, 2.44 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.332447/  2.353240, val:  50.00%, val_best:  73.45%, tr:  90.03%, tr_best:  93.23%, epoch time: 148.02 seconds, 2.47 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2247 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.336323/  2.344834, val:  50.00%, val_best:  73.45%, tr:  83.11%, tr_best:  93.23%, epoch time: 149.60 seconds, 2.49 minutes\n",
      "train - Value 0: 1753 occurrences\n",
      "train - Value 1: 2279 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.343555/  2.246179, val:  50.00%, val_best:  73.45%, tr:  78.60%, tr_best:  93.23%, epoch time: 146.63 seconds, 2.44 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.309051/  2.328037, val:  50.00%, val_best:  73.45%, tr:  87.62%, tr_best:  93.23%, epoch time: 148.07 seconds, 2.47 minutes\n",
      "train - Value 0: 2212 occurrences\n",
      "train - Value 1: 1820 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.305224/  2.374048, val:  50.00%, val_best:  73.45%, tr:  81.05%, tr_best:  93.23%, epoch time: 149.15 seconds, 2.49 minutes\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.314580/  2.354915, val:  50.00%, val_best:  73.45%, tr:  84.82%, tr_best:  93.23%, epoch time: 149.21 seconds, 2.49 minutes\n",
      "train - Value 0: 1695 occurrences\n",
      "train - Value 1: 2337 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.334803/  2.308497, val:  71.46%, val_best:  73.45%, tr:  83.51%, tr_best:  93.23%, epoch time: 148.47 seconds, 2.47 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.285378/  2.267326, val:  50.00%, val_best:  73.45%, tr:  80.11%, tr_best:  93.23%, epoch time: 148.88 seconds, 2.48 minutes\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2201 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.288531/  2.286714, val:  50.00%, val_best:  73.45%, tr:  83.31%, tr_best:  93.23%, epoch time: 149.51 seconds, 2.49 minutes\n",
      "train - Value 0: 2117 occurrences\n",
      "train - Value 1: 1915 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.305120/  2.339137, val:  50.00%, val_best:  73.45%, tr:  88.22%, tr_best:  93.23%, epoch time: 147.70 seconds, 2.46 minutes\n",
      "train - Value 0: 2161 occurrences\n",
      "train - Value 1: 1871 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.317856/  2.235345, val:  50.00%, val_best:  73.45%, tr:  87.28%, tr_best:  93.23%, epoch time: 147.92 seconds, 2.47 minutes\n",
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2132 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.330692/  2.300339, val:  50.00%, val_best:  73.45%, tr:  80.26%, tr_best:  93.23%, epoch time: 149.58 seconds, 2.49 minutes\n",
      "train - Value 0: 1903 occurrences\n",
      "train - Value 1: 2129 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.315387/  2.264572, val:  50.00%, val_best:  73.45%, tr:  84.15%, tr_best:  93.23%, epoch time: 146.32 seconds, 2.44 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.309892/  2.280011, val:  50.00%, val_best:  73.45%, tr:  87.23%, tr_best:  93.23%, epoch time: 144.88 seconds, 2.41 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.304643/  2.375845, val:  50.00%, val_best:  73.45%, tr:  86.11%, tr_best:  93.23%, epoch time: 147.36 seconds, 2.46 minutes\n",
      "train - Value 0: 2095 occurrences\n",
      "train - Value 1: 1937 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.314343/  2.313865, val:  50.00%, val_best:  73.45%, tr:  88.12%, tr_best:  93.23%, epoch time: 149.25 seconds, 2.49 minutes\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.281042/  2.349192, val:  50.00%, val_best:  73.45%, tr:  83.80%, tr_best:  93.23%, epoch time: 147.52 seconds, 2.46 minutes\n",
      "train - Value 0: 2116 occurrences\n",
      "train - Value 1: 1916 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.278808/  2.332556, val:  50.00%, val_best:  73.45%, tr:  87.35%, tr_best:  93.23%, epoch time: 146.91 seconds, 2.45 minutes\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.281732/  2.242674, val:  50.22%, val_best:  73.45%, tr:  85.81%, tr_best:  93.23%, epoch time: 148.34 seconds, 2.47 minutes\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.296758/  2.209734, val:  50.00%, val_best:  73.45%, tr:  90.38%, tr_best:  93.23%, epoch time: 148.54 seconds, 2.48 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.301551/  2.292640, val:  50.00%, val_best:  73.45%, tr:  89.38%, tr_best:  93.23%, epoch time: 146.07 seconds, 2.43 minutes\n",
      "train - Value 0: 1687 occurrences\n",
      "train - Value 1: 2345 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.313228/  2.362391, val:  50.00%, val_best:  73.45%, tr:  79.34%, tr_best:  93.23%, epoch time: 149.70 seconds, 2.49 minutes\n",
      "train - Value 0: 2106 occurrences\n",
      "train - Value 1: 1926 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.302337/  2.280997, val:  50.00%, val_best:  73.45%, tr:  78.22%, tr_best:  93.23%, epoch time: 149.32 seconds, 2.49 minutes\n",
      "train - Value 0: 2312 occurrences\n",
      "train - Value 1: 1720 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.293421/  2.304352, val:  50.00%, val_best:  73.45%, tr:  77.83%, tr_best:  93.23%, epoch time: 147.94 seconds, 2.47 minutes\n",
      "train - Value 0: 2291 occurrences\n",
      "train - Value 1: 1741 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.309908/  2.314075, val:  50.66%, val_best:  73.45%, tr:  82.07%, tr_best:  93.23%, epoch time: 148.29 seconds, 2.47 minutes\n",
      "train - Value 0: 2345 occurrences\n",
      "train - Value 1: 1687 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.325612/  2.277544, val:  50.00%, val_best:  73.45%, tr:  84.40%, tr_best:  93.23%, epoch time: 148.92 seconds, 2.48 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.342175/  2.358767, val:  50.00%, val_best:  73.45%, tr:  81.82%, tr_best:  93.23%, epoch time: 148.51 seconds, 2.48 minutes\n",
      "train - Value 0: 2234 occurrences\n",
      "train - Value 1: 1798 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.306598/  2.233452, val:  50.88%, val_best:  73.45%, tr:  81.55%, tr_best:  93.23%, epoch time: 148.47 seconds, 2.47 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.309005/  2.280215, val:  50.00%, val_best:  73.45%, tr:  83.93%, tr_best:  93.23%, epoch time: 148.34 seconds, 2.47 minutes\n",
      "train - Value 0: 1906 occurrences\n",
      "train - Value 1: 2126 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.311304/  2.320405, val:  50.00%, val_best:  73.45%, tr:  81.75%, tr_best:  93.23%, epoch time: 148.38 seconds, 2.47 minutes\n",
      "train - Value 0: 2087 occurrences\n",
      "train - Value 1: 1945 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.283760/  2.293420, val:  50.00%, val_best:  73.45%, tr:  87.67%, tr_best:  93.23%, epoch time: 147.16 seconds, 2.45 minutes\n",
      "train - Value 0: 2111 occurrences\n",
      "train - Value 1: 1921 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.293981/  2.330183, val:  50.00%, val_best:  73.45%, tr:  83.90%, tr_best:  93.23%, epoch time: 148.18 seconds, 2.47 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.325844/  2.251628, val:  54.87%, val_best:  73.45%, tr:  81.67%, tr_best:  93.23%, epoch time: 149.17 seconds, 2.49 minutes\n",
      "train - Value 0: 2362 occurrences\n",
      "train - Value 1: 1670 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.286305/  2.246663, val:  51.55%, val_best:  73.45%, tr:  74.95%, tr_best:  93.23%, epoch time: 148.08 seconds, 2.47 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2264 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.296694/  2.267252, val:  51.55%, val_best:  73.45%, tr:  77.33%, tr_best:  93.23%, epoch time: 149.48 seconds, 2.49 minutes\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.287004/  2.311348, val:  50.00%, val_best:  73.45%, tr:  85.81%, tr_best:  93.23%, epoch time: 147.24 seconds, 2.45 minutes\n",
      "train - Value 0: 2108 occurrences\n",
      "train - Value 1: 1924 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 35 occurrences\n",
      "test - Value 1: 417 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.300606/  2.283665, val:  56.42%, val_best:  73.45%, tr:  85.37%, tr_best:  93.23%, epoch time: 144.13 seconds, 2.40 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.323963/  2.349906, val:  51.33%, val_best:  73.45%, tr:  88.79%, tr_best:  93.23%, epoch time: 143.10 seconds, 2.38 minutes\n",
      "train - Value 0: 1923 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.301237/  2.264266, val:  50.00%, val_best:  73.45%, tr:  84.70%, tr_best:  93.23%, epoch time: 145.23 seconds, 2.42 minutes\n",
      "train - Value 0: 2182 occurrences\n",
      "train - Value 1: 1850 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.275671/  2.249991, val:  50.00%, val_best:  73.45%, tr:  88.34%, tr_best:  93.23%, epoch time: 148.64 seconds, 2.48 minutes\n",
      "train - Value 0: 2171 occurrences\n",
      "train - Value 1: 1861 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.337538/  2.303353, val:  50.44%, val_best:  73.45%, tr:  79.89%, tr_best:  93.23%, epoch time: 148.05 seconds, 2.47 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.314878/  2.274124, val:  50.00%, val_best:  73.45%, tr:  82.84%, tr_best:  93.23%, epoch time: 148.72 seconds, 2.48 minutes\n",
      "train - Value 0: 2251 occurrences\n",
      "train - Value 1: 1781 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.308298/  2.397018, val:  50.22%, val_best:  73.45%, tr:  85.49%, tr_best:  93.23%, epoch time: 148.68 seconds, 2.48 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.322685/  2.325939, val:  50.00%, val_best:  73.45%, tr:  87.45%, tr_best:  93.23%, epoch time: 147.77 seconds, 2.46 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.306327/  2.325145, val:  50.00%, val_best:  73.45%, tr:  87.92%, tr_best:  93.23%, epoch time: 148.56 seconds, 2.48 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.338160/  2.314635, val:  50.22%, val_best:  73.45%, tr:  79.74%, tr_best:  93.23%, epoch time: 148.62 seconds, 2.48 minutes\n",
      "train - Value 0: 2351 occurrences\n",
      "train - Value 1: 1681 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.303081/  2.244288, val:  50.00%, val_best:  73.45%, tr:  80.78%, tr_best:  93.23%, epoch time: 148.99 seconds, 2.48 minutes\n",
      "train - Value 0: 2149 occurrences\n",
      "train - Value 1: 1883 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.287598/  2.324650, val:  50.00%, val_best:  73.45%, tr:  89.16%, tr_best:  93.23%, epoch time: 147.32 seconds, 2.46 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.272756/  2.337451, val:  51.11%, val_best:  73.45%, tr:  93.48%, tr_best:  93.48%, epoch time: 148.18 seconds, 2.47 minutes\n",
      "train - Value 0: 2246 occurrences\n",
      "train - Value 1: 1786 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.262950/  2.349050, val:  50.00%, val_best:  73.45%, tr:  85.81%, tr_best:  93.48%, epoch time: 148.87 seconds, 2.48 minutes\n",
      "train - Value 0: 2198 occurrences\n",
      "train - Value 1: 1834 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.301584/  2.298079, val:  50.66%, val_best:  73.45%, tr:  79.46%, tr_best:  93.48%, epoch time: 147.59 seconds, 2.46 minutes\n",
      "train - Value 0: 1845 occurrences\n",
      "train - Value 1: 2187 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.302686/  2.359173, val:  50.00%, val_best:  73.45%, tr:  86.04%, tr_best:  93.48%, epoch time: 148.25 seconds, 2.47 minutes\n",
      "train - Value 0: 1818 occurrences\n",
      "train - Value 1: 2214 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.329765/  2.242361, val:  50.00%, val_best:  73.45%, tr:  82.24%, tr_best:  93.48%, epoch time: 147.94 seconds, 2.47 minutes\n",
      "train - Value 0: 1835 occurrences\n",
      "train - Value 1: 2197 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.314984/  2.357097, val:  50.00%, val_best:  73.45%, tr:  87.72%, tr_best:  93.48%, epoch time: 147.35 seconds, 2.46 minutes\n",
      "train - Value 0: 1818 occurrences\n",
      "train - Value 1: 2214 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.322181/  2.262810, val:  50.88%, val_best:  73.45%, tr:  86.61%, tr_best:  93.48%, epoch time: 147.42 seconds, 2.46 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 21 occurrences\n",
      "test - Value 1: 431 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.351997/  2.382304, val:  54.20%, val_best:  73.45%, tr:  90.58%, tr_best:  93.48%, epoch time: 147.60 seconds, 2.46 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.370658/  2.327984, val:  50.66%, val_best:  73.45%, tr:  89.09%, tr_best:  93.48%, epoch time: 146.17 seconds, 2.44 minutes\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.348902/  2.359523, val:  50.00%, val_best:  73.45%, tr:  81.92%, tr_best:  93.48%, epoch time: 147.02 seconds, 2.45 minutes\n",
      "train - Value 0: 2216 occurrences\n",
      "train - Value 1: 1816 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.322581/  2.228015, val:  50.00%, val_best:  73.45%, tr:  82.19%, tr_best:  93.48%, epoch time: 147.73 seconds, 2.46 minutes\n",
      "train - Value 0: 2214 occurrences\n",
      "train - Value 1: 1818 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.294748/  2.280208, val:  50.00%, val_best:  73.45%, tr:  82.09%, tr_best:  93.48%, epoch time: 148.03 seconds, 2.47 minutes\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.328608/  2.262964, val:  50.66%, val_best:  73.45%, tr:  90.30%, tr_best:  93.48%, epoch time: 143.53 seconds, 2.39 minutes\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.314617/  2.232199, val:  50.00%, val_best:  73.45%, tr:  89.98%, tr_best:  93.48%, epoch time: 143.90 seconds, 2.40 minutes\n",
      "train - Value 0: 2296 occurrences\n",
      "train - Value 1: 1736 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.291911/  2.281003, val:  50.00%, val_best:  73.45%, tr:  83.73%, tr_best:  93.48%, epoch time: 147.98 seconds, 2.47 minutes\n",
      "train - Value 0: 2186 occurrences\n",
      "train - Value 1: 1846 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.278830/  2.230499, val:  50.00%, val_best:  73.45%, tr:  85.37%, tr_best:  93.48%, epoch time: 148.08 seconds, 2.47 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.310558/  2.363635, val:  52.65%, val_best:  73.45%, tr:  94.59%, tr_best:  94.59%, epoch time: 147.72 seconds, 2.46 minutes\n",
      "train - Value 0: 1880 occurrences\n",
      "train - Value 1: 2152 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.317514/  2.268350, val:  71.68%, val_best:  73.45%, tr:  92.21%, tr_best:  94.59%, epoch time: 148.70 seconds, 2.48 minutes\n",
      "train - Value 0: 1887 occurrences\n",
      "train - Value 1: 2145 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.301887/  2.295204, val:  71.02%, val_best:  73.45%, tr:  82.81%, tr_best:  94.59%, epoch time: 148.17 seconds, 2.47 minutes\n",
      "train - Value 0: 2181 occurrences\n",
      "train - Value 1: 1851 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.280204/  2.384557, val:  50.00%, val_best:  73.45%, tr:  79.54%, tr_best:  94.59%, epoch time: 148.67 seconds, 2.48 minutes\n",
      "train - Value 0: 2235 occurrences\n",
      "train - Value 1: 1797 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.297192/  2.300743, val:  50.00%, val_best:  73.45%, tr:  83.95%, tr_best:  94.59%, epoch time: 148.49 seconds, 2.47 minutes\n",
      "train - Value 0: 2159 occurrences\n",
      "train - Value 1: 1873 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.310098/  2.204759, val:  50.00%, val_best:  73.45%, tr:  83.80%, tr_best:  94.59%, epoch time: 148.73 seconds, 2.48 minutes\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.287517/  2.386568, val:  50.00%, val_best:  73.45%, tr:  82.39%, tr_best:  94.59%, epoch time: 146.77 seconds, 2.45 minutes\n",
      "train - Value 0: 1894 occurrences\n",
      "train - Value 1: 2138 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.291207/  2.298279, val:  50.22%, val_best:  73.45%, tr:  80.46%, tr_best:  94.59%, epoch time: 146.60 seconds, 2.44 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.308122/  2.357537, val:  54.87%, val_best:  73.45%, tr:  80.18%, tr_best:  94.59%, epoch time: 147.01 seconds, 2.45 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.311453/  2.289692, val:  51.11%, val_best:  73.45%, tr:  87.40%, tr_best:  94.59%, epoch time: 147.96 seconds, 2.47 minutes\n",
      "train - Value 0: 2218 occurrences\n",
      "train - Value 1: 1814 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.298265/  2.263198, val:  50.00%, val_best:  73.45%, tr:  85.07%, tr_best:  94.59%, epoch time: 146.87 seconds, 2.45 minutes\n",
      "train - Value 0: 2196 occurrences\n",
      "train - Value 1: 1836 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.316530/  2.314257, val:  53.98%, val_best:  73.45%, tr:  85.81%, tr_best:  94.59%, epoch time: 148.74 seconds, 2.48 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.313937/  2.296025, val:  50.00%, val_best:  73.45%, tr:  88.52%, tr_best:  94.59%, epoch time: 149.56 seconds, 2.49 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.305249/  2.312695, val:  50.22%, val_best:  73.45%, tr:  87.48%, tr_best:  94.59%, epoch time: 148.86 seconds, 2.48 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.323998/  2.304568, val:  50.00%, val_best:  73.45%, tr:  89.36%, tr_best:  94.59%, epoch time: 148.08 seconds, 2.47 minutes\n",
      "train - Value 0: 2137 occurrences\n",
      "train - Value 1: 1895 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.283704/  2.250873, val:  60.18%, val_best:  73.45%, tr:  81.52%, tr_best:  94.59%, epoch time: 148.63 seconds, 2.48 minutes\n",
      "train - Value 0: 2196 occurrences\n",
      "train - Value 1: 1836 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 21 occurrences\n",
      "test - Value 1: 431 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.304883/  2.266895, val:  54.65%, val_best:  73.45%, tr:  84.33%, tr_best:  94.59%, epoch time: 149.76 seconds, 2.50 minutes\n",
      "train - Value 0: 2365 occurrences\n",
      "train - Value 1: 1667 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.296905/  2.346578, val:  50.00%, val_best:  73.45%, tr:  80.28%, tr_best:  94.59%, epoch time: 148.74 seconds, 2.48 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.307282/  2.285688, val:  50.44%, val_best:  73.45%, tr:  83.51%, tr_best:  94.59%, epoch time: 149.30 seconds, 2.49 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edfebe7a7134e70ad2d90f29597b6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>███▁▁████████▁███▁██▁███████▁█▁█████▁███</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁█▁▁▁▁▆▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▃▁▁▁▁▁█▁▁▁</td></tr><tr><td>tr_acc</td><td>▆█▇█▆▆██▇▇▆▇▆▃▇▆▇▃▆▆▁▄▄█▄▇▅█▄▇▆▃▄▃▇█▄▄▇▅</td></tr><tr><td>tr_epoch_loss</td><td>▃▃▄▅▄▄▁▄▃▃▄▅▄▅▃▄▄▃▁▃▇▆▂▅▃▄▂▃▆▂▃▆▃▃█▅▃▂▄▃</td></tr><tr><td>val_acc_best</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁█▁▁▁▁▆▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▃▁▁▁▁▁█▁▁▁</td></tr><tr><td>val_loss</td><td>▃▄█▃▄▅▄▅▇▄▆▃▃▃▆▃▅▇▆▁▇▄▂▆▇▂▆▄▇▄▄▄▂▄▅▃▄█▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.83507</td></tr><tr><td>tr_epoch_loss</td><td>2.30728</td></tr><tr><td>val_acc_best</td><td>0.73451</td></tr><tr><td>val_acc_now</td><td>0.50442</td></tr><tr><td>val_loss</td><td>2.28569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">treasured-sweep-5</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/8wo2zp42' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/8wo2zp42</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_145243-8wo2zp42/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: isyxlbo9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009765625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_230633-isyxlbo9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/isyxlbo9' target=\"_blank\">skilled-sweep-6</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/isyxlbo9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/isyxlbo9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250806_230641_688', 'my_seed': 42, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 15, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0009765625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0009765625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-0   lr=['0.0009766'], tr/val_loss:  2.302613/  2.277692, val:  50.22%, val_best:  50.22%, tr:  79.09%, tr_best:  79.09%, epoch time: 192.06 seconds, 3.20 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['0.0009766'], tr/val_loss:  2.304530/  2.301447, val:  50.00%, val_best:  50.22%, tr:  87.00%, tr_best:  87.00%, epoch time: 186.54 seconds, 3.11 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['0.0009766'], tr/val_loss:  2.306860/  2.343498, val:  50.00%, val_best:  50.22%, tr:  88.54%, tr_best:  88.54%, epoch time: 192.94 seconds, 3.22 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['0.0009766'], tr/val_loss:  2.304755/  2.336388, val:  50.00%, val_best:  50.22%, tr:  90.08%, tr_best:  90.08%, epoch time: 195.16 seconds, 3.25 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 330 occurrences\n",
      "test - Value 1: 122 occurrences\n",
      "epoch-4   lr=['0.0009766'], tr/val_loss:  2.306547/  2.249338, val:  70.80%, val_best:  70.80%, tr:  91.12%, tr_best:  91.12%, epoch time: 194.46 seconds, 3.24 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['0.0009766'], tr/val_loss:  2.305793/  2.356005, val:  50.00%, val_best:  70.80%, tr:  91.39%, tr_best:  91.39%, epoch time: 192.22 seconds, 3.20 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-6   lr=['0.0009766'], tr/val_loss:  2.300876/  2.316124, val:  51.11%, val_best:  70.80%, tr:  91.74%, tr_best:  91.74%, epoch time: 192.65 seconds, 3.21 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 421 occurrences\n",
      "test - Value 1: 31 occurrences\n",
      "epoch-7   lr=['0.0009766'], tr/val_loss:  2.305572/  2.252837, val:  56.86%, val_best:  70.80%, tr:  92.83%, tr_best:  92.83%, epoch time: 192.26 seconds, 3.20 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-8   lr=['0.0009766'], tr/val_loss:  2.305394/  2.295112, val:  76.55%, val_best:  76.55%, tr:  92.81%, tr_best:  92.83%, epoch time: 193.42 seconds, 3.22 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['0.0009766'], tr/val_loss:  2.305137/  2.348918, val:  50.00%, val_best:  76.55%, tr:  93.45%, tr_best:  93.45%, epoch time: 193.22 seconds, 3.22 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-10  lr=['0.0009766'], tr/val_loss:  2.304052/  2.261585, val:  58.63%, val_best:  76.55%, tr:  93.40%, tr_best:  93.45%, epoch time: 192.78 seconds, 3.21 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-11  lr=['0.0009766'], tr/val_loss:  2.305791/  2.337951, val:  53.32%, val_best:  76.55%, tr:  93.60%, tr_best:  93.60%, epoch time: 193.19 seconds, 3.22 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-12  lr=['0.0009766'], tr/val_loss:  2.304993/  2.325192, val:  50.88%, val_best:  76.55%, tr:  94.89%, tr_best:  94.89%, epoch time: 194.23 seconds, 3.24 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-13  lr=['0.0009766'], tr/val_loss:  2.306796/  2.317911, val:  50.66%, val_best:  76.55%, tr:  95.29%, tr_best:  95.29%, epoch time: 192.18 seconds, 3.20 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 346 occurrences\n",
      "test - Value 1: 106 occurrences\n",
      "epoch-14  lr=['0.0009766'], tr/val_loss:  2.305442/  2.256038, val:  70.35%, val_best:  76.55%, tr:  94.74%, tr_best:  95.29%, epoch time: 192.51 seconds, 3.21 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-15  lr=['0.0009766'], tr/val_loss:  2.303673/  2.257294, val:  53.32%, val_best:  76.55%, tr:  94.82%, tr_best:  95.29%, epoch time: 193.52 seconds, 3.23 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-16  lr=['0.0009766'], tr/val_loss:  2.304292/  2.285081, val:  64.16%, val_best:  76.55%, tr:  94.25%, tr_best:  95.29%, epoch time: 193.64 seconds, 3.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-17  lr=['0.0009766'], tr/val_loss:  2.303872/  2.306054, val:  51.33%, val_best:  76.55%, tr:  94.37%, tr_best:  95.29%, epoch time: 192.73 seconds, 3.21 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['0.0009766'], tr/val_loss:  2.306073/  2.356455, val:  50.00%, val_best:  76.55%, tr:  95.09%, tr_best:  95.29%, epoch time: 191.79 seconds, 3.20 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-19  lr=['0.0009766'], tr/val_loss:  2.305715/  2.281853, val:  50.88%, val_best:  76.55%, tr:  94.69%, tr_best:  95.29%, epoch time: 186.14 seconds, 3.10 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-20  lr=['0.0009766'], tr/val_loss:  2.298596/  2.287225, val:  51.33%, val_best:  76.55%, tr:  95.26%, tr_best:  95.29%, epoch time: 190.16 seconds, 3.17 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-21  lr=['0.0009766'], tr/val_loss:  2.305412/  2.357357, val:  75.44%, val_best:  76.55%, tr:  95.14%, tr_best:  95.29%, epoch time: 190.19 seconds, 3.17 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-22  lr=['0.0009766'], tr/val_loss:  2.301957/  2.293531, val:  53.32%, val_best:  76.55%, tr:  95.16%, tr_best:  95.29%, epoch time: 192.41 seconds, 3.21 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 377 occurrences\n",
      "test - Value 1: 75 occurrences\n",
      "epoch-23  lr=['0.0009766'], tr/val_loss:  2.302662/  2.264035, val:  65.27%, val_best:  76.55%, tr:  95.09%, tr_best:  95.29%, epoch time: 193.49 seconds, 3.22 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-24  lr=['0.0009766'], tr/val_loss:  2.303322/  2.230490, val:  54.42%, val_best:  76.55%, tr:  95.83%, tr_best:  95.83%, epoch time: 192.55 seconds, 3.21 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-25  lr=['0.0009766'], tr/val_loss:  2.306373/  2.350024, val:  56.64%, val_best:  76.55%, tr:  95.66%, tr_best:  95.83%, epoch time: 191.69 seconds, 3.19 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-26  lr=['0.0009766'], tr/val_loss:  2.312560/  2.303263, val:  56.19%, val_best:  76.55%, tr:  95.88%, tr_best:  95.88%, epoch time: 191.25 seconds, 3.19 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-27  lr=['0.0009766'], tr/val_loss:  2.308599/  2.343929, val:  51.33%, val_best:  76.55%, tr:  95.31%, tr_best:  95.88%, epoch time: 191.54 seconds, 3.19 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-28  lr=['0.0009766'], tr/val_loss:  2.307017/  2.304412, val:  78.10%, val_best:  78.10%, tr:  96.11%, tr_best:  96.11%, epoch time: 193.17 seconds, 3.22 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-29  lr=['0.0009766'], tr/val_loss:  2.301944/  2.351575, val:  50.22%, val_best:  78.10%, tr:  96.30%, tr_best:  96.30%, epoch time: 193.97 seconds, 3.23 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-30  lr=['0.0009766'], tr/val_loss:  2.304105/  2.294864, val:  51.99%, val_best:  78.10%, tr:  96.63%, tr_best:  96.63%, epoch time: 192.48 seconds, 3.21 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-31  lr=['0.0009766'], tr/val_loss:  2.308160/  2.260115, val:  63.27%, val_best:  78.10%, tr:  96.55%, tr_best:  96.63%, epoch time: 193.39 seconds, 3.22 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 407 occurrences\n",
      "test - Value 1: 45 occurrences\n",
      "epoch-32  lr=['0.0009766'], tr/val_loss:  2.310097/  2.314170, val:  59.51%, val_best:  78.10%, tr:  96.65%, tr_best:  96.65%, epoch time: 191.93 seconds, 3.20 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-33  lr=['0.0009766'], tr/val_loss:  2.310059/  2.334228, val:  76.77%, val_best:  78.10%, tr:  96.25%, tr_best:  96.65%, epoch time: 193.56 seconds, 3.23 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-34  lr=['0.0009766'], tr/val_loss:  2.304576/  2.280990, val:  80.09%, val_best:  80.09%, tr:  96.33%, tr_best:  96.65%, epoch time: 192.57 seconds, 3.21 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-35  lr=['0.0009766'], tr/val_loss:  2.307068/  2.321526, val:  50.22%, val_best:  80.09%, tr:  96.73%, tr_best:  96.73%, epoch time: 191.70 seconds, 3.20 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 382 occurrences\n",
      "test - Value 1: 70 occurrences\n",
      "epoch-36  lr=['0.0009766'], tr/val_loss:  2.304401/  2.318740, val:  64.16%, val_best:  80.09%, tr:  95.98%, tr_best:  96.73%, epoch time: 194.55 seconds, 3.24 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-37  lr=['0.0009766'], tr/val_loss:  2.305196/  2.318072, val:  50.22%, val_best:  80.09%, tr:  95.96%, tr_best:  96.73%, epoch time: 189.05 seconds, 3.15 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 287 occurrences\n",
      "test - Value 1: 165 occurrences\n",
      "epoch-38  lr=['0.0009766'], tr/val_loss:  2.303361/  2.307497, val:  78.54%, val_best:  80.09%, tr:  96.28%, tr_best:  96.73%, epoch time: 190.61 seconds, 3.18 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-39  lr=['0.0009766'], tr/val_loss:  2.305330/  2.340723, val:  50.22%, val_best:  80.09%, tr:  97.35%, tr_best:  97.35%, epoch time: 193.65 seconds, 3.23 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-40  lr=['0.0009766'], tr/val_loss:  2.302776/  2.303517, val:  75.66%, val_best:  80.09%, tr:  97.45%, tr_best:  97.45%, epoch time: 192.78 seconds, 3.21 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 244 occurrences\n",
      "test - Value 1: 208 occurrences\n",
      "epoch-41  lr=['0.0009766'], tr/val_loss:  2.306391/  2.294131, val:  80.97%, val_best:  80.97%, tr:  96.60%, tr_best:  97.45%, epoch time: 194.56 seconds, 3.24 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-42  lr=['0.0009766'], tr/val_loss:  2.302755/  2.214997, val:  59.51%, val_best:  80.97%, tr:  97.47%, tr_best:  97.47%, epoch time: 193.93 seconds, 3.23 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 294 occurrences\n",
      "test - Value 1: 158 occurrences\n",
      "epoch-43  lr=['0.0009766'], tr/val_loss:  2.305207/  2.298056, val:  78.32%, val_best:  80.97%, tr:  97.67%, tr_best:  97.67%, epoch time: 193.25 seconds, 3.22 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-44  lr=['0.0009766'], tr/val_loss:  2.301747/  2.343368, val:  53.10%, val_best:  80.97%, tr:  96.73%, tr_best:  97.67%, epoch time: 194.35 seconds, 3.24 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-45  lr=['0.0009766'], tr/val_loss:  2.300256/  2.363506, val:  82.08%, val_best:  82.08%, tr:  97.07%, tr_best:  97.67%, epoch time: 194.00 seconds, 3.23 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-46  lr=['0.0009766'], tr/val_loss:  2.305234/  2.298906, val:  53.76%, val_best:  82.08%, tr:  97.12%, tr_best:  97.67%, epoch time: 195.26 seconds, 3.25 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-47  lr=['0.0009766'], tr/val_loss:  2.311572/  2.286452, val:  51.55%, val_best:  82.08%, tr:  97.12%, tr_best:  97.67%, epoch time: 187.37 seconds, 3.12 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-48  lr=['0.0009766'], tr/val_loss:  2.306361/  2.331893, val:  80.53%, val_best:  82.08%, tr:  97.45%, tr_best:  97.67%, epoch time: 183.91 seconds, 3.07 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-49  lr=['0.0009766'], tr/val_loss:  2.308209/  2.324425, val:  60.84%, val_best:  82.08%, tr:  97.57%, tr_best:  97.67%, epoch time: 186.40 seconds, 3.11 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-50  lr=['0.0009766'], tr/val_loss:  2.309902/  2.364755, val:  57.08%, val_best:  82.08%, tr:  97.79%, tr_best:  97.79%, epoch time: 188.11 seconds, 3.14 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-51  lr=['0.0009766'], tr/val_loss:  2.305535/  2.329089, val:  81.64%, val_best:  82.08%, tr:  97.57%, tr_best:  97.79%, epoch time: 187.14 seconds, 3.12 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-52  lr=['0.0009766'], tr/val_loss:  2.309223/  2.354200, val:  50.22%, val_best:  82.08%, tr:  97.89%, tr_best:  97.89%, epoch time: 187.31 seconds, 3.12 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-53  lr=['0.0009766'], tr/val_loss:  2.307867/  2.316079, val:  61.95%, val_best:  82.08%, tr:  97.30%, tr_best:  97.89%, epoch time: 187.21 seconds, 3.12 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-54  lr=['0.0009766'], tr/val_loss:  2.305633/  2.288982, val:  65.71%, val_best:  82.08%, tr:  97.69%, tr_best:  97.89%, epoch time: 188.02 seconds, 3.13 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 307 occurrences\n",
      "test - Value 1: 145 occurrences\n",
      "epoch-55  lr=['0.0009766'], tr/val_loss:  2.303649/  2.270052, val:  77.21%, val_best:  82.08%, tr:  98.19%, tr_best:  98.19%, epoch time: 187.08 seconds, 3.12 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-56  lr=['0.0009766'], tr/val_loss:  2.311208/  2.313475, val:  54.87%, val_best:  82.08%, tr:  98.14%, tr_best:  98.19%, epoch time: 182.45 seconds, 3.04 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 350 occurrences\n",
      "test - Value 1: 102 occurrences\n",
      "epoch-57  lr=['0.0009766'], tr/val_loss:  2.305547/  2.258718, val:  69.47%, val_best:  82.08%, tr:  98.04%, tr_best:  98.19%, epoch time: 187.65 seconds, 3.13 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 388 occurrences\n",
      "test - Value 1: 64 occurrences\n",
      "epoch-58  lr=['0.0009766'], tr/val_loss:  2.309805/  2.331655, val:  63.72%, val_best:  82.08%, tr:  97.92%, tr_best:  98.19%, epoch time: 189.29 seconds, 3.15 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 31 occurrences\n",
      "test - Value 1: 421 occurrences\n",
      "epoch-59  lr=['0.0009766'], tr/val_loss:  2.310937/  2.319936, val:  56.86%, val_best:  82.08%, tr:  98.34%, tr_best:  98.34%, epoch time: 187.00 seconds, 3.12 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-60  lr=['0.0009766'], tr/val_loss:  2.311582/  2.243834, val:  59.07%, val_best:  82.08%, tr:  98.31%, tr_best:  98.34%, epoch time: 187.81 seconds, 3.13 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-61  lr=['0.0009766'], tr/val_loss:  2.309684/  2.318604, val:  53.54%, val_best:  82.08%, tr:  98.24%, tr_best:  98.34%, epoch time: 189.22 seconds, 3.15 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-62  lr=['0.0009766'], tr/val_loss:  2.307424/  2.277037, val:  81.64%, val_best:  82.08%, tr:  98.19%, tr_best:  98.34%, epoch time: 184.37 seconds, 3.07 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-63  lr=['0.0009766'], tr/val_loss:  2.307233/  2.307604, val:  79.65%, val_best:  82.08%, tr:  98.36%, tr_best:  98.36%, epoch time: 184.95 seconds, 3.08 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 336 occurrences\n",
      "test - Value 1: 116 occurrences\n",
      "epoch-64  lr=['0.0009766'], tr/val_loss:  2.307545/  2.274838, val:  73.45%, val_best:  82.08%, tr:  98.34%, tr_best:  98.36%, epoch time: 186.27 seconds, 3.10 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-65  lr=['0.0009766'], tr/val_loss:  2.299926/  2.380827, val:  50.22%, val_best:  82.08%, tr:  98.21%, tr_best:  98.36%, epoch time: 186.92 seconds, 3.12 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-66  lr=['0.0009766'], tr/val_loss:  2.304906/  2.295182, val:  57.30%, val_best:  82.08%, tr:  98.29%, tr_best:  98.36%, epoch time: 186.58 seconds, 3.11 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-67  lr=['0.0009766'], tr/val_loss:  2.313128/  2.293127, val:  72.79%, val_best:  82.08%, tr:  97.67%, tr_best:  98.36%, epoch time: 187.44 seconds, 3.12 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 38 occurrences\n",
      "test - Value 1: 414 occurrences\n",
      "epoch-68  lr=['0.0009766'], tr/val_loss:  2.305218/  2.293014, val:  57.52%, val_best:  82.08%, tr:  97.59%, tr_best:  98.36%, epoch time: 187.31 seconds, 3.12 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-69  lr=['0.0009766'], tr/val_loss:  2.310369/  2.298447, val:  83.19%, val_best:  83.19%, tr:  97.79%, tr_best:  98.36%, epoch time: 187.26 seconds, 3.12 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-70  lr=['0.0009766'], tr/val_loss:  2.305453/  2.300596, val:  75.66%, val_best:  83.19%, tr:  97.74%, tr_best:  98.36%, epoch time: 186.78 seconds, 3.11 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-71  lr=['0.0009766'], tr/val_loss:  2.305396/  2.314454, val:  67.48%, val_best:  83.19%, tr:  97.27%, tr_best:  98.36%, epoch time: 185.98 seconds, 3.10 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-72  lr=['0.0009766'], tr/val_loss:  2.301832/  2.380281, val:  52.21%, val_best:  83.19%, tr:  98.07%, tr_best:  98.36%, epoch time: 186.91 seconds, 3.12 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-73  lr=['0.0009766'], tr/val_loss:  2.306825/  2.326743, val:  55.75%, val_best:  83.19%, tr:  98.39%, tr_best:  98.39%, epoch time: 186.82 seconds, 3.11 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-74  lr=['0.0009766'], tr/val_loss:  2.303108/  2.328622, val:  52.65%, val_best:  83.19%, tr:  97.77%, tr_best:  98.39%, epoch time: 183.22 seconds, 3.05 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-75  lr=['0.0009766'], tr/val_loss:  2.306677/  2.324549, val:  74.34%, val_best:  83.19%, tr:  97.84%, tr_best:  98.39%, epoch time: 183.99 seconds, 3.07 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 358 occurrences\n",
      "test - Value 1: 94 occurrences\n",
      "epoch-76  lr=['0.0009766'], tr/val_loss:  2.307278/  2.335683, val:  67.70%, val_best:  83.19%, tr:  97.87%, tr_best:  98.39%, epoch time: 185.28 seconds, 3.09 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 408 occurrences\n",
      "test - Value 1: 44 occurrences\n",
      "epoch-77  lr=['0.0009766'], tr/val_loss:  2.299699/  2.261327, val:  58.85%, val_best:  83.19%, tr:  97.17%, tr_best:  98.39%, epoch time: 189.19 seconds, 3.15 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['0.0009766'], tr/val_loss:  2.311683/  2.350896, val:  50.00%, val_best:  83.19%, tr:  98.14%, tr_best:  98.39%, epoch time: 187.64 seconds, 3.13 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-79  lr=['0.0009766'], tr/val_loss:  2.309749/  2.315709, val:  78.10%, val_best:  83.19%, tr:  98.21%, tr_best:  98.39%, epoch time: 191.44 seconds, 3.19 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-80  lr=['0.0009766'], tr/val_loss:  2.311213/  2.268962, val:  69.25%, val_best:  83.19%, tr:  98.34%, tr_best:  98.39%, epoch time: 189.20 seconds, 3.15 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-81  lr=['0.0009766'], tr/val_loss:  2.307028/  2.338231, val:  59.07%, val_best:  83.19%, tr:  98.66%, tr_best:  98.66%, epoch time: 186.28 seconds, 3.10 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-82  lr=['0.0009766'], tr/val_loss:  2.309355/  2.329132, val:  59.51%, val_best:  83.19%, tr:  98.51%, tr_best:  98.66%, epoch time: 186.98 seconds, 3.12 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-83  lr=['0.0009766'], tr/val_loss:  2.310221/  2.308666, val:  61.50%, val_best:  83.19%, tr:  98.26%, tr_best:  98.66%, epoch time: 186.84 seconds, 3.11 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-84  lr=['0.0009766'], tr/val_loss:  2.307608/  2.373421, val:  61.73%, val_best:  83.19%, tr:  98.12%, tr_best:  98.66%, epoch time: 187.21 seconds, 3.12 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-85  lr=['0.0009766'], tr/val_loss:  2.309257/  2.329981, val:  68.36%, val_best:  83.19%, tr:  98.26%, tr_best:  98.66%, epoch time: 186.70 seconds, 3.11 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-86  lr=['0.0009766'], tr/val_loss:  2.311420/  2.350883, val:  50.88%, val_best:  83.19%, tr:  98.49%, tr_best:  98.66%, epoch time: 185.80 seconds, 3.10 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-87  lr=['0.0009766'], tr/val_loss:  2.307604/  2.309822, val:  80.75%, val_best:  83.19%, tr:  98.31%, tr_best:  98.66%, epoch time: 188.81 seconds, 3.15 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-88  lr=['0.0009766'], tr/val_loss:  2.310348/  2.402152, val:  51.55%, val_best:  83.19%, tr:  98.64%, tr_best:  98.66%, epoch time: 186.73 seconds, 3.11 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-89  lr=['0.0009766'], tr/val_loss:  2.307664/  2.268091, val:  64.82%, val_best:  83.19%, tr:  98.09%, tr_best:  98.66%, epoch time: 186.82 seconds, 3.11 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-90  lr=['0.0009766'], tr/val_loss:  2.307033/  2.322870, val:  58.19%, val_best:  83.19%, tr:  98.54%, tr_best:  98.66%, epoch time: 185.93 seconds, 3.10 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-91  lr=['0.0009766'], tr/val_loss:  2.308867/  2.314979, val:  77.43%, val_best:  83.19%, tr:  98.41%, tr_best:  98.66%, epoch time: 183.49 seconds, 3.06 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-92  lr=['0.0009766'], tr/val_loss:  2.304381/  2.358486, val:  52.65%, val_best:  83.19%, tr:  98.36%, tr_best:  98.66%, epoch time: 187.68 seconds, 3.13 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-93  lr=['0.0009766'], tr/val_loss:  2.303198/  2.279505, val:  79.65%, val_best:  83.19%, tr:  98.61%, tr_best:  98.66%, epoch time: 183.08 seconds, 3.05 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-94  lr=['0.0009766'], tr/val_loss:  2.301126/  2.324951, val:  75.66%, val_best:  83.19%, tr:  98.46%, tr_best:  98.66%, epoch time: 183.58 seconds, 3.06 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-95  lr=['0.0009766'], tr/val_loss:  2.305727/  2.305447, val:  75.66%, val_best:  83.19%, tr:  98.59%, tr_best:  98.66%, epoch time: 188.51 seconds, 3.14 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-96  lr=['0.0009766'], tr/val_loss:  2.308385/  2.370059, val:  53.54%, val_best:  83.19%, tr:  98.46%, tr_best:  98.66%, epoch time: 189.23 seconds, 3.15 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-97  lr=['0.0009766'], tr/val_loss:  2.312285/  2.323337, val:  57.74%, val_best:  83.19%, tr:  98.86%, tr_best:  98.86%, epoch time: 187.12 seconds, 3.12 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-98  lr=['0.0009766'], tr/val_loss:  2.314714/  2.282127, val:  79.20%, val_best:  83.19%, tr:  98.49%, tr_best:  98.86%, epoch time: 188.86 seconds, 3.15 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-99  lr=['0.0009766'], tr/val_loss:  2.311461/  2.322325, val:  54.20%, val_best:  83.19%, tr:  98.56%, tr_best:  98.86%, epoch time: 188.47 seconds, 3.14 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-100 lr=['0.0009766'], tr/val_loss:  2.309278/  2.327214, val:  59.07%, val_best:  83.19%, tr:  98.14%, tr_best:  98.86%, epoch time: 186.23 seconds, 3.10 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-101 lr=['0.0009766'], tr/val_loss:  2.313340/  2.295575, val:  71.90%, val_best:  83.19%, tr:  98.04%, tr_best:  98.86%, epoch time: 186.85 seconds, 3.11 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-102 lr=['0.0009766'], tr/val_loss:  2.311050/  2.323123, val:  73.45%, val_best:  83.19%, tr:  98.39%, tr_best:  98.86%, epoch time: 186.13 seconds, 3.10 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-103 lr=['0.0009766'], tr/val_loss:  2.307606/  2.362355, val:  74.78%, val_best:  83.19%, tr:  98.86%, tr_best:  98.86%, epoch time: 187.80 seconds, 3.13 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-104 lr=['0.0009766'], tr/val_loss:  2.309148/  2.341009, val:  57.96%, val_best:  83.19%, tr:  98.86%, tr_best:  98.86%, epoch time: 188.23 seconds, 3.14 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-105 lr=['0.0009766'], tr/val_loss:  2.313689/  2.364535, val:  63.50%, val_best:  83.19%, tr:  98.96%, tr_best:  98.96%, epoch time: 185.22 seconds, 3.09 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-106 lr=['0.0009766'], tr/val_loss:  2.312355/  2.325543, val:  53.76%, val_best:  83.19%, tr:  98.21%, tr_best:  98.96%, epoch time: 186.88 seconds, 3.11 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-107 lr=['0.0009766'], tr/val_loss:  2.307663/  2.362588, val:  53.98%, val_best:  83.19%, tr:  97.37%, tr_best:  98.96%, epoch time: 188.50 seconds, 3.14 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 249 occurrences\n",
      "test - Value 1: 203 occurrences\n",
      "epoch-108 lr=['0.0009766'], tr/val_loss:  2.303024/  2.311306, val:  78.54%, val_best:  83.19%, tr:  97.69%, tr_best:  98.96%, epoch time: 194.01 seconds, 3.23 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-109 lr=['0.0009766'], tr/val_loss:  2.305363/  2.332078, val:  66.37%, val_best:  83.19%, tr:  98.24%, tr_best:  98.96%, epoch time: 188.69 seconds, 3.14 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-110 lr=['0.0009766'], tr/val_loss:  2.305507/  2.309220, val:  53.32%, val_best:  83.19%, tr:  98.46%, tr_best:  98.96%, epoch time: 187.87 seconds, 3.13 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-111 lr=['0.0009766'], tr/val_loss:  2.309187/  2.306742, val:  80.97%, val_best:  83.19%, tr:  97.79%, tr_best:  98.96%, epoch time: 186.43 seconds, 3.11 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-112 lr=['0.0009766'], tr/val_loss:  2.307148/  2.343047, val:  55.97%, val_best:  83.19%, tr:  98.26%, tr_best:  98.96%, epoch time: 182.44 seconds, 3.04 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-113 lr=['0.0009766'], tr/val_loss:  2.301602/  2.294351, val:  53.10%, val_best:  83.19%, tr:  98.34%, tr_best:  98.96%, epoch time: 185.70 seconds, 3.09 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-114 lr=['0.0009766'], tr/val_loss:  2.308550/  2.292962, val:  55.75%, val_best:  83.19%, tr:  98.54%, tr_best:  98.96%, epoch time: 187.46 seconds, 3.12 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-115 lr=['0.0009766'], tr/val_loss:  2.309875/  2.321297, val:  77.21%, val_best:  83.19%, tr:  98.56%, tr_best:  98.96%, epoch time: 186.49 seconds, 3.11 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-116 lr=['0.0009766'], tr/val_loss:  2.310364/  2.280180, val:  77.43%, val_best:  83.19%, tr:  98.14%, tr_best:  98.96%, epoch time: 188.49 seconds, 3.14 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-117 lr=['0.0009766'], tr/val_loss:  2.307221/  2.346950, val:  62.39%, val_best:  83.19%, tr:  98.24%, tr_best:  98.96%, epoch time: 186.47 seconds, 3.11 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-118 lr=['0.0009766'], tr/val_loss:  2.310154/  2.335213, val:  69.47%, val_best:  83.19%, tr:  98.04%, tr_best:  98.96%, epoch time: 188.92 seconds, 3.15 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-119 lr=['0.0009766'], tr/val_loss:  2.305152/  2.318484, val:  59.96%, val_best:  83.19%, tr:  97.94%, tr_best:  98.96%, epoch time: 183.86 seconds, 3.06 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-120 lr=['0.0009766'], tr/val_loss:  2.305839/  2.354122, val:  52.88%, val_best:  83.19%, tr:  98.59%, tr_best:  98.96%, epoch time: 182.76 seconds, 3.05 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-121 lr=['0.0009766'], tr/val_loss:  2.309185/  2.404534, val:  50.66%, val_best:  83.19%, tr:  98.46%, tr_best:  98.96%, epoch time: 185.80 seconds, 3.10 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-122 lr=['0.0009766'], tr/val_loss:  2.311248/  2.387940, val:  53.10%, val_best:  83.19%, tr:  98.29%, tr_best:  98.96%, epoch time: 188.57 seconds, 3.14 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-123 lr=['0.0009766'], tr/val_loss:  2.309087/  2.319867, val:  67.70%, val_best:  83.19%, tr:  98.56%, tr_best:  98.96%, epoch time: 186.83 seconds, 3.11 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 296 occurrences\n",
      "test - Value 1: 156 occurrences\n",
      "epoch-124 lr=['0.0009766'], tr/val_loss:  2.313852/  2.295596, val:  76.55%, val_best:  83.19%, tr:  98.21%, tr_best:  98.96%, epoch time: 185.97 seconds, 3.10 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-125 lr=['0.0009766'], tr/val_loss:  2.312647/  2.334384, val:  54.87%, val_best:  83.19%, tr:  98.07%, tr_best:  98.96%, epoch time: 187.43 seconds, 3.12 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-126 lr=['0.0009766'], tr/val_loss:  2.305694/  2.343337, val:  50.88%, val_best:  83.19%, tr:  97.99%, tr_best:  98.96%, epoch time: 188.06 seconds, 3.13 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-127 lr=['0.0009766'], tr/val_loss:  2.309157/  2.322023, val:  69.69%, val_best:  83.19%, tr:  98.07%, tr_best:  98.96%, epoch time: 196.12 seconds, 3.27 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-128 lr=['0.0009766'], tr/val_loss:  2.306035/  2.295346, val:  50.00%, val_best:  83.19%, tr:  98.81%, tr_best:  98.96%, epoch time: 192.92 seconds, 3.22 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-129 lr=['0.0009766'], tr/val_loss:  2.309951/  2.285239, val:  73.23%, val_best:  83.19%, tr:  97.87%, tr_best:  98.96%, epoch time: 190.46 seconds, 3.17 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-130 lr=['0.0009766'], tr/val_loss:  2.306997/  2.306828, val:  77.88%, val_best:  83.19%, tr:  98.24%, tr_best:  98.96%, epoch time: 185.87 seconds, 3.10 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-131 lr=['0.0009766'], tr/val_loss:  2.302109/  2.337378, val:  55.75%, val_best:  83.19%, tr:  98.24%, tr_best:  98.96%, epoch time: 186.04 seconds, 3.10 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-132 lr=['0.0009766'], tr/val_loss:  2.306033/  2.283996, val:  76.11%, val_best:  83.19%, tr:  98.66%, tr_best:  98.96%, epoch time: 186.07 seconds, 3.10 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-133 lr=['0.0009766'], tr/val_loss:  2.308438/  2.318448, val:  69.03%, val_best:  83.19%, tr:  98.44%, tr_best:  98.96%, epoch time: 187.56 seconds, 3.13 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-134 lr=['0.0009766'], tr/val_loss:  2.304684/  2.419716, val:  53.76%, val_best:  83.19%, tr:  98.41%, tr_best:  98.96%, epoch time: 182.27 seconds, 3.04 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-135 lr=['0.0009766'], tr/val_loss:  2.304171/  2.242910, val:  54.20%, val_best:  83.19%, tr:  98.31%, tr_best:  98.96%, epoch time: 185.21 seconds, 3.09 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-136 lr=['0.0009766'], tr/val_loss:  2.299054/  2.327802, val:  78.10%, val_best:  83.19%, tr:  97.99%, tr_best:  98.96%, epoch time: 186.72 seconds, 3.11 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-137 lr=['0.0009766'], tr/val_loss:  2.309952/  2.314218, val:  72.35%, val_best:  83.19%, tr:  98.29%, tr_best:  98.96%, epoch time: 186.95 seconds, 3.12 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-138 lr=['0.0009766'], tr/val_loss:  2.306657/  2.280072, val:  53.98%, val_best:  83.19%, tr:  98.39%, tr_best:  98.96%, epoch time: 186.06 seconds, 3.10 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-139 lr=['0.0009766'], tr/val_loss:  2.303989/  2.331479, val:  63.94%, val_best:  83.19%, tr:  97.79%, tr_best:  98.96%, epoch time: 188.02 seconds, 3.13 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 350 occurrences\n",
      "test - Value 1: 102 occurrences\n",
      "epoch-140 lr=['0.0009766'], tr/val_loss:  2.306827/  2.335088, val:  69.47%, val_best:  83.19%, tr:  98.14%, tr_best:  98.96%, epoch time: 186.52 seconds, 3.11 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-141 lr=['0.0009766'], tr/val_loss:  2.308514/  2.322076, val:  59.51%, val_best:  83.19%, tr:  98.61%, tr_best:  98.96%, epoch time: 188.71 seconds, 3.15 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 379 occurrences\n",
      "test - Value 1: 73 occurrences\n",
      "epoch-142 lr=['0.0009766'], tr/val_loss:  2.304173/  2.307230, val:  64.38%, val_best:  83.19%, tr:  98.86%, tr_best:  98.96%, epoch time: 187.98 seconds, 3.13 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 304 occurrences\n",
      "test - Value 1: 148 occurrences\n",
      "epoch-143 lr=['0.0009766'], tr/val_loss:  2.299877/  2.290223, val:  75.66%, val_best:  83.19%, tr:  98.24%, tr_best:  98.96%, epoch time: 186.97 seconds, 3.12 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-144 lr=['0.0009766'], tr/val_loss:  2.307802/  2.320954, val:  69.03%, val_best:  83.19%, tr:  98.81%, tr_best:  98.96%, epoch time: 187.15 seconds, 3.12 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-145 lr=['0.0009766'], tr/val_loss:  2.306323/  2.340127, val:  63.05%, val_best:  83.19%, tr:  98.36%, tr_best:  98.96%, epoch time: 191.97 seconds, 3.20 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-146 lr=['0.0009766'], tr/val_loss:  2.308221/  2.327750, val:  78.10%, val_best:  83.19%, tr:  98.19%, tr_best:  98.96%, epoch time: 188.67 seconds, 3.14 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-147 lr=['0.0009766'], tr/val_loss:  2.306431/  2.280214, val:  78.10%, val_best:  83.19%, tr:  98.71%, tr_best:  98.96%, epoch time: 187.79 seconds, 3.13 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-148 lr=['0.0009766'], tr/val_loss:  2.308391/  2.378973, val:  50.66%, val_best:  83.19%, tr:  98.93%, tr_best:  98.96%, epoch time: 185.28 seconds, 3.09 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-149 lr=['0.0009766'], tr/val_loss:  2.309151/  2.310620, val:  78.32%, val_best:  83.19%, tr:  98.76%, tr_best:  98.96%, epoch time: 180.96 seconds, 3.02 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 269 occurrences\n",
      "test - Value 1: 183 occurrences\n",
      "epoch-150 lr=['0.0009766'], tr/val_loss:  2.305943/  2.283387, val:  78.10%, val_best:  83.19%, tr:  98.83%, tr_best:  98.96%, epoch time: 184.84 seconds, 3.08 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-151 lr=['0.0009766'], tr/val_loss:  2.304506/  2.351795, val:  53.76%, val_best:  83.19%, tr:  98.02%, tr_best:  98.96%, epoch time: 186.56 seconds, 3.11 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 378 occurrences\n",
      "test - Value 1: 74 occurrences\n",
      "epoch-152 lr=['0.0009766'], tr/val_loss:  2.302166/  2.272343, val:  64.16%, val_best:  83.19%, tr:  98.36%, tr_best:  98.96%, epoch time: 186.04 seconds, 3.10 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-153 lr=['0.0009766'], tr/val_loss:  2.304992/  2.395705, val:  53.32%, val_best:  83.19%, tr:  98.29%, tr_best:  98.96%, epoch time: 186.48 seconds, 3.11 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-154 lr=['0.0009766'], tr/val_loss:  2.306280/  2.337424, val:  57.52%, val_best:  83.19%, tr:  98.21%, tr_best:  98.96%, epoch time: 185.36 seconds, 3.09 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-155 lr=['0.0009766'], tr/val_loss:  2.308110/  2.276175, val:  64.60%, val_best:  83.19%, tr:  98.66%, tr_best:  98.96%, epoch time: 185.83 seconds, 3.10 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-156 lr=['0.0009766'], tr/val_loss:  2.311012/  2.325269, val:  57.96%, val_best:  83.19%, tr:  98.54%, tr_best:  98.96%, epoch time: 185.10 seconds, 3.09 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-157 lr=['0.0009766'], tr/val_loss:  2.301216/  2.281382, val:  77.88%, val_best:  83.19%, tr:  98.86%, tr_best:  98.96%, epoch time: 185.03 seconds, 3.08 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-158 lr=['0.0009766'], tr/val_loss:  2.306198/  2.267965, val:  65.49%, val_best:  83.19%, tr:  98.88%, tr_best:  98.96%, epoch time: 186.98 seconds, 3.12 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-159 lr=['0.0009766'], tr/val_loss:  2.308388/  2.350167, val:  58.41%, val_best:  83.19%, tr:  98.76%, tr_best:  98.96%, epoch time: 184.76 seconds, 3.08 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-160 lr=['0.0009766'], tr/val_loss:  2.300366/  2.343224, val:  68.36%, val_best:  83.19%, tr:  98.71%, tr_best:  98.96%, epoch time: 184.83 seconds, 3.08 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-161 lr=['0.0009766'], tr/val_loss:  2.305238/  2.345728, val:  53.32%, val_best:  83.19%, tr:  98.83%, tr_best:  98.96%, epoch time: 184.75 seconds, 3.08 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-162 lr=['0.0009766'], tr/val_loss:  2.303889/  2.281749, val:  58.19%, val_best:  83.19%, tr:  98.98%, tr_best:  98.98%, epoch time: 182.68 seconds, 3.04 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-163 lr=['0.0009766'], tr/val_loss:  2.300995/  2.346170, val:  55.75%, val_best:  83.19%, tr:  98.74%, tr_best:  98.98%, epoch time: 182.00 seconds, 3.03 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-164 lr=['0.0009766'], tr/val_loss:  2.308171/  2.321374, val:  80.09%, val_best:  83.19%, tr:  98.76%, tr_best:  98.98%, epoch time: 182.30 seconds, 3.04 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-165 lr=['0.0009766'], tr/val_loss:  2.306313/  2.326803, val:  76.33%, val_best:  83.19%, tr:  98.41%, tr_best:  98.98%, epoch time: 184.57 seconds, 3.08 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-166 lr=['0.0009766'], tr/val_loss:  2.305813/  2.342509, val:  50.44%, val_best:  83.19%, tr:  98.96%, tr_best:  98.98%, epoch time: 186.00 seconds, 3.10 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-167 lr=['0.0009766'], tr/val_loss:  2.306535/  2.382757, val:  50.00%, val_best:  83.19%, tr:  98.56%, tr_best:  98.98%, epoch time: 184.58 seconds, 3.08 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-168 lr=['0.0009766'], tr/val_loss:  2.301452/  2.364332, val:  50.88%, val_best:  83.19%, tr:  98.86%, tr_best:  98.98%, epoch time: 181.34 seconds, 3.02 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-169 lr=['0.0009766'], tr/val_loss:  2.304207/  2.302164, val:  78.98%, val_best:  83.19%, tr:  98.96%, tr_best:  98.98%, epoch time: 183.80 seconds, 3.06 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-170 lr=['0.0009766'], tr/val_loss:  2.306775/  2.384866, val:  51.33%, val_best:  83.19%, tr:  98.83%, tr_best:  98.98%, epoch time: 183.52 seconds, 3.06 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-171 lr=['0.0009766'], tr/val_loss:  2.309274/  2.285327, val:  81.42%, val_best:  83.19%, tr:  99.11%, tr_best:  99.11%, epoch time: 184.76 seconds, 3.08 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-172 lr=['0.0009766'], tr/val_loss:  2.303618/  2.406053, val:  50.22%, val_best:  83.19%, tr:  98.36%, tr_best:  99.11%, epoch time: 185.94 seconds, 3.10 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-173 lr=['0.0009766'], tr/val_loss:  2.308901/  2.304528, val:  82.52%, val_best:  83.19%, tr:  98.83%, tr_best:  99.11%, epoch time: 183.55 seconds, 3.06 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-174 lr=['0.0009766'], tr/val_loss:  2.307522/  2.336293, val:  65.04%, val_best:  83.19%, tr:  98.59%, tr_best:  99.11%, epoch time: 185.74 seconds, 3.10 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-175 lr=['0.0009766'], tr/val_loss:  2.310349/  2.287295, val:  72.79%, val_best:  83.19%, tr:  98.34%, tr_best:  99.11%, epoch time: 185.65 seconds, 3.09 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 368 occurrences\n",
      "test - Value 1: 84 occurrences\n",
      "epoch-176 lr=['0.0009766'], tr/val_loss:  2.303350/  2.287345, val:  67.70%, val_best:  83.19%, tr:  98.66%, tr_best:  99.11%, epoch time: 184.30 seconds, 3.07 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-177 lr=['0.0009766'], tr/val_loss:  2.311283/  2.317223, val:  75.66%, val_best:  83.19%, tr:  98.69%, tr_best:  99.11%, epoch time: 181.28 seconds, 3.02 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-178 lr=['0.0009766'], tr/val_loss:  2.305670/  2.252198, val:  54.42%, val_best:  83.19%, tr:  98.34%, tr_best:  99.11%, epoch time: 183.94 seconds, 3.07 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-179 lr=['0.0009766'], tr/val_loss:  2.301126/  2.378468, val:  52.43%, val_best:  83.19%, tr:  98.21%, tr_best:  99.11%, epoch time: 183.58 seconds, 3.06 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-180 lr=['0.0009766'], tr/val_loss:  2.308058/  2.345912, val:  71.90%, val_best:  83.19%, tr:  98.61%, tr_best:  99.11%, epoch time: 185.53 seconds, 3.09 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 302 occurrences\n",
      "test - Value 1: 150 occurrences\n",
      "epoch-181 lr=['0.0009766'], tr/val_loss:  2.306954/  2.300251, val:  77.88%, val_best:  83.19%, tr:  98.34%, tr_best:  99.11%, epoch time: 184.53 seconds, 3.08 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-182 lr=['0.0009766'], tr/val_loss:  2.299521/  2.307819, val:  78.10%, val_best:  83.19%, tr:  98.66%, tr_best:  99.11%, epoch time: 184.79 seconds, 3.08 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-183 lr=['0.0009766'], tr/val_loss:  2.300499/  2.308018, val:  80.97%, val_best:  83.19%, tr:  99.08%, tr_best:  99.11%, epoch time: 184.13 seconds, 3.07 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['0.0009766'], tr/val_loss:  2.304391/  2.357194, val:  50.00%, val_best:  83.19%, tr:  98.74%, tr_best:  99.11%, epoch time: 184.44 seconds, 3.07 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-185 lr=['0.0009766'], tr/val_loss:  2.308751/  2.301840, val:  77.88%, val_best:  83.19%, tr:  98.64%, tr_best:  99.11%, epoch time: 184.42 seconds, 3.07 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-186 lr=['0.0009766'], tr/val_loss:  2.310179/  2.270412, val:  74.34%, val_best:  83.19%, tr:  98.93%, tr_best:  99.11%, epoch time: 183.97 seconds, 3.07 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-187 lr=['0.0009766'], tr/val_loss:  2.304895/  2.363268, val:  63.05%, val_best:  83.19%, tr:  99.16%, tr_best:  99.16%, epoch time: 181.39 seconds, 3.02 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-188 lr=['0.0009766'], tr/val_loss:  2.309202/  2.299065, val:  76.33%, val_best:  83.19%, tr:  99.11%, tr_best:  99.16%, epoch time: 182.16 seconds, 3.04 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-189 lr=['0.0009766'], tr/val_loss:  2.307763/  2.313427, val:  72.79%, val_best:  83.19%, tr:  98.96%, tr_best:  99.16%, epoch time: 184.48 seconds, 3.07 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-190 lr=['0.0009766'], tr/val_loss:  2.305683/  2.344823, val:  63.94%, val_best:  83.19%, tr:  98.88%, tr_best:  99.16%, epoch time: 184.14 seconds, 3.07 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-191 lr=['0.0009766'], tr/val_loss:  2.312017/  2.314256, val:  76.33%, val_best:  83.19%, tr:  99.01%, tr_best:  99.16%, epoch time: 181.05 seconds, 3.02 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-192 lr=['0.0009766'], tr/val_loss:  2.309814/  2.317401, val:  80.09%, val_best:  83.19%, tr:  98.98%, tr_best:  99.16%, epoch time: 182.78 seconds, 3.05 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-193 lr=['0.0009766'], tr/val_loss:  2.304359/  2.372185, val:  54.87%, val_best:  83.19%, tr:  99.01%, tr_best:  99.16%, epoch time: 184.04 seconds, 3.07 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-194 lr=['0.0009766'], tr/val_loss:  2.302868/  2.324464, val:  53.32%, val_best:  83.19%, tr:  99.11%, tr_best:  99.16%, epoch time: 184.19 seconds, 3.07 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-195 lr=['0.0009766'], tr/val_loss:  2.308527/  2.345635, val:  59.29%, val_best:  83.19%, tr:  99.21%, tr_best:  99.21%, epoch time: 183.25 seconds, 3.05 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 404 occurrences\n",
      "test - Value 1: 48 occurrences\n",
      "epoch-196 lr=['0.0009766'], tr/val_loss:  2.308720/  2.295120, val:  60.62%, val_best:  83.19%, tr:  99.16%, tr_best:  99.21%, epoch time: 183.88 seconds, 3.06 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-197 lr=['0.0009766'], tr/val_loss:  2.308948/  2.322830, val:  64.82%, val_best:  83.19%, tr:  98.78%, tr_best:  99.21%, epoch time: 185.17 seconds, 3.09 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-198 lr=['0.0009766'], tr/val_loss:  2.306850/  2.333690, val:  59.96%, val_best:  83.19%, tr:  99.38%, tr_best:  99.38%, epoch time: 185.43 seconds, 3.09 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-199 lr=['0.0009766'], tr/val_loss:  2.312059/  2.336658, val:  55.75%, val_best:  83.19%, tr:  98.96%, tr_best:  99.38%, epoch time: 185.12 seconds, 3.09 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25df49a0016f47d9a47234dc69954a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>██████▁█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▂▆▂▄▁███▇▂▆▅▃▃█▇▃▆▂█▄▁▅▅▆▇▇▂▇▂▁█▇█▄▂▂</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▇▇▇█▇██▇███████████</td></tr><tr><td>tr_epoch_loss</td><td>▃▄▄▃▄▄▅▅▄▁▄▃▆█▄▁▅▅▆▇█▅▆▅▆▆▅▆▁▄▄▂▂▅▆▇▁▄▃▇</td></tr><tr><td>val_acc_best</td><td>▁▅▇▇▇▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▂▆▂▄▁███▇▂▆▅▃▃█▇▃▆▂█▄▁▅▅▆▇▇▂▇▂▁█▇█▄▂▂</td></tr><tr><td>val_loss</td><td>▃▆▅▁▆▅▁▄▃▆▄▂▄▃▄▁▅▃▄▄▃▆▃▅█▄▄▄▃▂█▂▅▇▃▄▃▆▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98958</td></tr><tr><td>tr_epoch_loss</td><td>2.31206</td></tr><tr><td>val_acc_best</td><td>0.83186</td></tr><tr><td>val_acc_now</td><td>0.55752</td></tr><tr><td>val_loss</td><td>2.33666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-sweep-6</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/isyxlbo9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/isyxlbo9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_230633-isyxlbo9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: icsgg8uq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250807_093250-icsgg8uq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/icsgg8uq' target=\"_blank\">zesty-sweep-7</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/wvrv58g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/icsgg8uq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/icsgg8uq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20250807_093258_473', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 10, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-13, -13], [-13, -13], [-12, -12]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=10, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=10, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "작은걸크게\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.302138/  2.273684, val:  51.77%, val_best:  51.77%, tr:  72.00%, tr_best:  72.00%, epoch time: 98.60 seconds, 1.64 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2093 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.303711/  2.298847, val:  50.88%, val_best:  51.77%, tr:  74.53%, tr_best:  74.53%, epoch time: 98.88 seconds, 1.65 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.304490/  2.350367, val:  50.00%, val_best:  51.77%, tr:  77.26%, tr_best:  77.26%, epoch time: 99.47 seconds, 1.66 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.303352/  2.303042, val:  54.42%, val_best:  54.42%, tr:  79.86%, tr_best:  79.86%, epoch time: 99.30 seconds, 1.66 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.303397/  2.280055, val:  54.65%, val_best:  54.65%, tr:  79.14%, tr_best:  79.86%, epoch time: 100.74 seconds, 1.68 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.300883/  2.319400, val:  50.00%, val_best:  54.65%, tr:  79.02%, tr_best:  79.86%, epoch time: 99.34 seconds, 1.66 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.305110/  2.316116, val:  51.33%, val_best:  54.65%, tr:  78.87%, tr_best:  79.86%, epoch time: 100.46 seconds, 1.67 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.305549/  2.304885, val:  54.42%, val_best:  54.65%, tr:  78.40%, tr_best:  79.86%, epoch time: 101.99 seconds, 1.70 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.308438/  2.273822, val:  52.88%, val_best:  54.65%, tr:  79.99%, tr_best:  79.99%, epoch time: 105.91 seconds, 1.77 minutes\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.304367/  2.315782, val:  51.55%, val_best:  54.65%, tr:  82.47%, tr_best:  82.47%, epoch time: 100.85 seconds, 1.68 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.309542/  2.253540, val:  53.10%, val_best:  54.65%, tr:  80.80%, tr_best:  82.47%, epoch time: 97.94 seconds, 1.63 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.302475/  2.288272, val:  63.05%, val_best:  63.05%, tr:  80.41%, tr_best:  82.47%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.306448/  2.341615, val:  50.00%, val_best:  63.05%, tr:  78.99%, tr_best:  82.47%, epoch time: 98.55 seconds, 1.64 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.304169/  2.346859, val:  50.00%, val_best:  63.05%, tr:  79.56%, tr_best:  82.47%, epoch time: 99.28 seconds, 1.65 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.307124/  2.298503, val:  61.06%, val_best:  63.05%, tr:  82.07%, tr_best:  82.47%, epoch time: 101.21 seconds, 1.69 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.309217/  2.305819, val:  75.88%, val_best:  75.88%, tr:  81.85%, tr_best:  82.47%, epoch time: 98.39 seconds, 1.64 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.303744/  2.271327, val:  55.53%, val_best:  75.88%, tr:  81.27%, tr_best:  82.47%, epoch time: 99.56 seconds, 1.66 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.308488/  2.310364, val:  50.00%, val_best:  75.88%, tr:  81.42%, tr_best:  82.47%, epoch time: 104.24 seconds, 1.74 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.306649/  2.371595, val:  50.00%, val_best:  75.88%, tr:  80.88%, tr_best:  82.47%, epoch time: 105.47 seconds, 1.76 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.307381/  2.307617, val:  50.00%, val_best:  75.88%, tr:  80.06%, tr_best:  82.47%, epoch time: 104.63 seconds, 1.74 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.302971/  2.298443, val:  51.33%, val_best:  75.88%, tr:  80.75%, tr_best:  82.47%, epoch time: 103.46 seconds, 1.72 minutes\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1940 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.302769/  2.270147, val:  74.78%, val_best:  75.88%, tr:  79.07%, tr_best:  82.47%, epoch time: 102.27 seconds, 1.70 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.304917/  2.289881, val:  54.42%, val_best:  75.88%, tr:  79.44%, tr_best:  82.47%, epoch time: 101.18 seconds, 1.69 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 369 occurrences\n",
      "test - Value 1: 83 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.303996/  2.298037, val:  63.94%, val_best:  75.88%, tr:  78.72%, tr_best:  82.47%, epoch time: 100.48 seconds, 1.67 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.304273/  2.254168, val:  50.22%, val_best:  75.88%, tr:  77.50%, tr_best:  82.47%, epoch time: 100.43 seconds, 1.67 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.304478/  2.344281, val:  53.54%, val_best:  75.88%, tr:  77.90%, tr_best:  82.47%, epoch time: 99.58 seconds, 1.66 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.301402/  2.318578, val:  50.00%, val_best:  75.88%, tr:  78.57%, tr_best:  82.47%, epoch time: 98.21 seconds, 1.64 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.303067/  2.327475, val:  55.09%, val_best:  75.88%, tr:  80.78%, tr_best:  82.47%, epoch time: 99.77 seconds, 1.66 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 383 occurrences\n",
      "test - Value 1: 69 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.306737/  2.317475, val:  63.05%, val_best:  75.88%, tr:  80.73%, tr_best:  82.47%, epoch time: 99.55 seconds, 1.66 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.305832/  2.345356, val:  50.22%, val_best:  75.88%, tr:  79.71%, tr_best:  82.47%, epoch time: 100.76 seconds, 1.68 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.305459/  2.246046, val:  51.99%, val_best:  75.88%, tr:  78.77%, tr_best:  82.47%, epoch time: 99.79 seconds, 1.66 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.302166/  2.260515, val:  57.30%, val_best:  75.88%, tr:  79.84%, tr_best:  82.47%, epoch time: 100.73 seconds, 1.68 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 427 occurrences\n",
      "test - Value 1: 25 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.304041/  2.287603, val:  55.53%, val_best:  75.88%, tr:  80.31%, tr_best:  82.47%, epoch time: 101.01 seconds, 1.68 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.309649/  2.295195, val:  61.28%, val_best:  75.88%, tr:  79.94%, tr_best:  82.47%, epoch time: 100.77 seconds, 1.68 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.307273/  2.262493, val:  71.90%, val_best:  75.88%, tr:  80.23%, tr_best:  82.47%, epoch time: 99.61 seconds, 1.66 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.301412/  2.314315, val:  50.00%, val_best:  75.88%, tr:  80.83%, tr_best:  82.47%, epoch time: 99.21 seconds, 1.65 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.308918/  2.299250, val:  73.89%, val_best:  75.88%, tr:  81.35%, tr_best:  82.47%, epoch time: 98.83 seconds, 1.65 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.303784/  2.299570, val:  50.00%, val_best:  75.88%, tr:  80.41%, tr_best:  82.47%, epoch time: 101.91 seconds, 1.70 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.303742/  2.239537, val:  50.00%, val_best:  75.88%, tr:  80.36%, tr_best:  82.47%, epoch time: 99.89 seconds, 1.66 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.304249/  2.284914, val:  54.20%, val_best:  75.88%, tr:  81.37%, tr_best:  82.47%, epoch time: 99.99 seconds, 1.67 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.305078/  2.333128, val:  67.26%, val_best:  75.88%, tr:  80.33%, tr_best:  82.47%, epoch time: 99.90 seconds, 1.67 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.307004/  2.354042, val:  50.22%, val_best:  75.88%, tr:  77.55%, tr_best:  82.47%, epoch time: 99.60 seconds, 1.66 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 350 occurrences\n",
      "test - Value 1: 102 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.305336/  2.288345, val:  68.14%, val_best:  75.88%, tr:  77.73%, tr_best:  82.47%, epoch time: 98.70 seconds, 1.65 minutes\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 421 occurrences\n",
      "test - Value 1: 31 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.304166/  2.314569, val:  56.42%, val_best:  75.88%, tr:  79.27%, tr_best:  82.47%, epoch time: 98.66 seconds, 1.64 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.304248/  2.304291, val:  55.75%, val_best:  75.88%, tr:  79.24%, tr_best:  82.47%, epoch time: 101.43 seconds, 1.69 minutes\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1943 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 393 occurrences\n",
      "test - Value 1: 59 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.304920/  2.289438, val:  62.61%, val_best:  75.88%, tr:  79.69%, tr_best:  82.47%, epoch time: 97.85 seconds, 1.63 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 374 occurrences\n",
      "test - Value 1: 78 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.306234/  2.297659, val:  65.49%, val_best:  75.88%, tr:  79.89%, tr_best:  82.47%, epoch time: 97.95 seconds, 1.63 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.307976/  2.271683, val:  50.00%, val_best:  75.88%, tr:  79.89%, tr_best:  82.47%, epoch time: 97.35 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 342 occurrences\n",
      "test - Value 1: 110 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.307230/  2.295918, val:  71.24%, val_best:  75.88%, tr:  80.11%, tr_best:  82.47%, epoch time: 99.80 seconds, 1.66 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.307366/  2.335573, val:  50.00%, val_best:  75.88%, tr:  79.24%, tr_best:  82.47%, epoch time: 100.64 seconds, 1.68 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.303468/  2.350682, val:  51.11%, val_best:  75.88%, tr:  81.08%, tr_best:  82.47%, epoch time: 100.56 seconds, 1.68 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.303659/  2.365238, val:  52.21%, val_best:  75.88%, tr:  80.08%, tr_best:  82.47%, epoch time: 101.31 seconds, 1.69 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.301897/  2.291103, val:  54.87%, val_best:  75.88%, tr:  80.75%, tr_best:  82.47%, epoch time: 100.70 seconds, 1.68 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.304494/  2.318385, val:  54.42%, val_best:  75.88%, tr:  80.01%, tr_best:  82.47%, epoch time: 100.56 seconds, 1.68 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.310626/  2.272749, val:  53.76%, val_best:  75.88%, tr:  78.50%, tr_best:  82.47%, epoch time: 100.16 seconds, 1.67 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.302841/  2.263014, val:  57.52%, val_best:  75.88%, tr:  79.44%, tr_best:  82.47%, epoch time: 101.04 seconds, 1.68 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.308696/  2.301496, val:  61.50%, val_best:  75.88%, tr:  81.65%, tr_best:  82.47%, epoch time: 100.51 seconds, 1.68 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.312154/  2.256220, val:  51.77%, val_best:  75.88%, tr:  81.72%, tr_best:  82.47%, epoch time: 99.45 seconds, 1.66 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.304468/  2.295379, val:  50.88%, val_best:  75.88%, tr:  79.74%, tr_best:  82.47%, epoch time: 100.49 seconds, 1.67 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.308706/  2.312667, val:  55.75%, val_best:  75.88%, tr:  80.75%, tr_best:  82.47%, epoch time: 99.77 seconds, 1.66 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.309138/  2.312069, val:  47.12%, val_best:  75.88%, tr:  80.65%, tr_best:  82.47%, epoch time: 98.86 seconds, 1.65 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.309251/  2.307363, val:  50.00%, val_best:  75.88%, tr:  81.00%, tr_best:  82.47%, epoch time: 100.54 seconds, 1.68 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.308138/  2.269399, val:  57.74%, val_best:  75.88%, tr:  80.95%, tr_best:  82.47%, epoch time: 99.36 seconds, 1.66 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.308201/  2.276014, val:  62.83%, val_best:  75.88%, tr:  79.07%, tr_best:  82.47%, epoch time: 99.63 seconds, 1.66 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.306957/  2.290642, val:  63.05%, val_best:  75.88%, tr:  79.24%, tr_best:  82.47%, epoch time: 98.91 seconds, 1.65 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.310765/  2.336241, val:  62.39%, val_best:  75.88%, tr:  80.90%, tr_best:  82.47%, epoch time: 98.10 seconds, 1.64 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 406 occurrences\n",
      "test - Value 1: 46 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.306206/  2.287951, val:  60.18%, val_best:  75.88%, tr:  80.13%, tr_best:  82.47%, epoch time: 100.25 seconds, 1.67 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.304929/  2.272121, val:  70.58%, val_best:  75.88%, tr:  80.23%, tr_best:  82.47%, epoch time: 100.17 seconds, 1.67 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.302743/  2.362303, val:  50.00%, val_best:  75.88%, tr:  78.47%, tr_best:  82.47%, epoch time: 100.29 seconds, 1.67 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.305136/  2.299913, val:  70.58%, val_best:  75.88%, tr:  78.89%, tr_best:  82.47%, epoch time: 98.99 seconds, 1.65 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.303771/  2.312150, val:  75.00%, val_best:  75.88%, tr:  78.25%, tr_best:  82.47%, epoch time: 98.63 seconds, 1.64 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.305409/  2.292881, val:  59.51%, val_best:  75.88%, tr:  78.79%, tr_best:  82.47%, epoch time: 100.56 seconds, 1.68 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.303797/  2.354252, val:  50.66%, val_best:  75.88%, tr:  79.71%, tr_best:  82.47%, epoch time: 100.64 seconds, 1.68 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.306314/  2.312600, val:  78.76%, val_best:  78.76%, tr:  80.03%, tr_best:  82.47%, epoch time: 100.60 seconds, 1.68 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.307371/  2.311835, val:  50.66%, val_best:  78.76%, tr:  80.16%, tr_best:  82.47%, epoch time: 101.05 seconds, 1.68 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 390 occurrences\n",
      "test - Value 1: 62 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.304221/  2.297976, val:  63.72%, val_best:  78.76%, tr:  79.84%, tr_best:  82.47%, epoch time: 99.37 seconds, 1.66 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.306152/  2.300182, val:  59.29%, val_best:  78.76%, tr:  78.99%, tr_best:  82.47%, epoch time: 100.11 seconds, 1.67 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.301342/  2.251489, val:  52.88%, val_best:  78.76%, tr:  82.12%, tr_best:  82.47%, epoch time: 99.31 seconds, 1.66 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 35 occurrences\n",
      "test - Value 1: 417 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.303864/  2.340412, val:  57.30%, val_best:  78.76%, tr:  79.84%, tr_best:  82.47%, epoch time: 99.77 seconds, 1.66 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 355 occurrences\n",
      "test - Value 1: 97 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.303499/  2.275258, val:  68.81%, val_best:  78.76%, tr:  79.51%, tr_best:  82.47%, epoch time: 100.16 seconds, 1.67 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.305232/  2.309384, val:  65.04%, val_best:  78.76%, tr:  81.08%, tr_best:  82.47%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.304966/  2.333996, val:  54.87%, val_best:  78.76%, tr:  80.90%, tr_best:  82.47%, epoch time: 92.62 seconds, 1.54 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.302729/  2.352374, val:  50.00%, val_best:  78.76%, tr:  81.37%, tr_best:  82.47%, epoch time: 92.23 seconds, 1.54 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.301808/  2.358667, val:  50.22%, val_best:  78.76%, tr:  80.56%, tr_best:  82.47%, epoch time: 94.76 seconds, 1.58 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.303742/  2.290252, val:  50.88%, val_best:  78.76%, tr:  80.46%, tr_best:  82.47%, epoch time: 95.63 seconds, 1.59 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.308601/  2.284667, val:  71.02%, val_best:  78.76%, tr:  79.66%, tr_best:  82.47%, epoch time: 98.62 seconds, 1.64 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.302261/  2.279790, val:  50.00%, val_best:  78.76%, tr:  79.14%, tr_best:  82.47%, epoch time: 99.29 seconds, 1.65 minutes\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.310847/  2.347701, val:  51.77%, val_best:  78.76%, tr:  79.91%, tr_best:  82.47%, epoch time: 98.83 seconds, 1.65 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.306206/  2.326191, val:  51.11%, val_best:  78.76%, tr:  80.31%, tr_best:  82.47%, epoch time: 99.56 seconds, 1.66 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 397 occurrences\n",
      "test - Value 1: 55 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.307141/  2.310881, val:  62.17%, val_best:  78.76%, tr:  79.12%, tr_best:  82.47%, epoch time: 99.60 seconds, 1.66 minutes\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.301832/  2.313249, val:  53.54%, val_best:  78.76%, tr:  77.93%, tr_best:  82.47%, epoch time: 100.52 seconds, 1.68 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 375 occurrences\n",
      "test - Value 1: 77 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.303114/  2.303880, val:  65.27%, val_best:  78.76%, tr:  77.50%, tr_best:  82.47%, epoch time: 99.28 seconds, 1.65 minutes\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "target_word=0\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_targetword{target_word}_작은걸크게',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [4,6,8]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [8]},\n",
    "        \"which_data\": {\"values\": ['n_tidigits_tonic']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.03125, 0.0625, 0.125, 0.25, 0.5]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [4.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [1/512, 1/1024, 1/2048, 1/4096, 1/8192]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [1]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [target_word]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [False]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [8]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "        \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "        \"scale_exp_1w\": {\"values\": [-10,-11,-12,-13,-14]},\n",
    "        # # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "\n",
    "        # \"scale_exp_2w\": {\"values\": [-10]},\n",
    "        # # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "\n",
    "        # \"scale_exp_3w\": {\"values\": [-9]},\n",
    "        # # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"timestep_sums_threshold\": {\"values\": [0]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"5\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "\n",
    "        quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "        scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w+1,wandb.config.scale_exp_1w+1]],\n",
    "        timestep_sums_threshold  =  wandb.config.timestep_sums_threshold,\n",
    "                        ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = 'zuwbbaku'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn NTIDIGITS SWEEP')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn NTIDIGITS SWEEP')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
