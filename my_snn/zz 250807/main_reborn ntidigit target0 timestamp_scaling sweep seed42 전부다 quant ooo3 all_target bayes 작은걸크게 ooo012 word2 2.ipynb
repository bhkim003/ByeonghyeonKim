{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40719/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "    #         return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    input_argmin = input_slice.argmin(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient Î∞©Ìñ•ÏùÑ argmin Ï™ΩÏúºÎ°ú\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    \n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                            \n",
    "                    \n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "            #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "            #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 Ï§ë ÌïòÎÇò ÏÑ†ÌÉù\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                    optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch ÌÅ¨Í∏∞ ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "                        #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "                        #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "\n",
    "# unique_name = 'main'\n",
    "# run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 4, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "#                 BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 # n_tidigits_tonic 8\n",
    "\n",
    "#                 # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "#                 which_data = 'n_tidigits_tonic',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.03125,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "#                 lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "#                 synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = [200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "#                 # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "#                 # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 1000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 1, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 0, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "#                 # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "#                 # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 9, \n",
    "\n",
    "#                 num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "#                 chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = False, # True # False \n",
    "\n",
    "#                 last_lif = False, # True # False \n",
    "\n",
    "#                 temporal_filter = 8, \n",
    "#                 initial_pooling = 1,\n",
    "\n",
    "#                 temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "#                 quantize_bit_list=[8,8,8],\n",
    "#                 scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "#                 # quantize_bit_list=[],\n",
    "#                 # scale_exp=[], \n",
    "#                 timestep_sums_threshold = 0,\n",
    "# # 1w -11~-9\n",
    "# # 1b -11~ -7\n",
    "# # 2w -10~-8\n",
    "# # 2b -10~-8\n",
    "# # 3w -10\n",
    "# # 3b -10\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# # average pooling  \n",
    "# # Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8cjdxj7i\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ldso7xp1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250805_135358-ldso7xp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ldso7xp1' target=\"_blank\">wild-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ldso7xp1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ldso7xp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250805_135405_264', 'my_seed': 42, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 6, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-14, -14], [-14, -14], [-13, -13]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -14 -14\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -14\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -14 -14\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -14\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.304360/  2.350467, val:  50.00%, val_best:  50.00%, tr:  84.74%, tr_best:  84.74%, epoch time: 161.62 seconds, 2.69 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.304858/  2.342761, val:  50.00%, val_best:  50.00%, tr:  84.94%, tr_best:  84.94%, epoch time: 173.39 seconds, 2.89 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.306122/  2.251298, val:  50.00%, val_best:  50.00%, tr:  88.01%, tr_best:  88.01%, epoch time: 173.69 seconds, 2.89 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.305339/  2.327223, val:  50.00%, val_best:  50.00%, tr:  85.53%, tr_best:  88.01%, epoch time: 182.41 seconds, 3.04 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.309609/  2.305462, val:  50.00%, val_best:  50.00%, tr:  86.70%, tr_best:  88.01%, epoch time: 181.41 seconds, 3.02 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.308504/  2.293195, val:  50.22%, val_best:  50.22%, tr:  87.99%, tr_best:  88.01%, epoch time: 179.44 seconds, 2.99 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.299248/  2.269588, val:  50.00%, val_best:  50.22%, tr:  87.47%, tr_best:  88.01%, epoch time: 182.46 seconds, 3.04 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.302667/  2.375069, val:  54.65%, val_best:  54.65%, tr:  87.74%, tr_best:  88.01%, epoch time: 181.28 seconds, 3.02 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.303149/  2.325709, val:  50.00%, val_best:  54.65%, tr:  86.35%, tr_best:  88.01%, epoch time: 179.54 seconds, 2.99 minutes\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.307840/  2.302417, val:  71.46%, val_best:  71.46%, tr:  86.82%, tr_best:  88.01%, epoch time: 181.46 seconds, 3.02 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.302106/  2.273742, val:  50.00%, val_best:  71.46%, tr:  86.08%, tr_best:  88.01%, epoch time: 181.78 seconds, 3.03 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.308964/  2.247200, val:  50.00%, val_best:  71.46%, tr:  86.70%, tr_best:  88.01%, epoch time: 181.25 seconds, 3.02 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.306877/  2.266212, val:  50.00%, val_best:  71.46%, tr:  86.23%, tr_best:  88.01%, epoch time: 181.01 seconds, 3.02 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.305888/  2.373058, val:  50.00%, val_best:  71.46%, tr:  86.33%, tr_best:  88.01%, epoch time: 182.71 seconds, 3.05 minutes\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.306858/  2.316056, val:  50.00%, val_best:  71.46%, tr:  85.81%, tr_best:  88.01%, epoch time: 183.48 seconds, 3.06 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.301397/  2.314729, val:  50.00%, val_best:  71.46%, tr:  85.83%, tr_best:  88.01%, epoch time: 182.24 seconds, 3.04 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.309132/  2.254297, val:  50.00%, val_best:  71.46%, tr:  86.20%, tr_best:  88.01%, epoch time: 181.89 seconds, 3.03 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.299860/  2.298320, val:  50.00%, val_best:  71.46%, tr:  88.06%, tr_best:  88.06%, epoch time: 181.38 seconds, 3.02 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.305834/  2.316172, val:  49.78%, val_best:  71.46%, tr:  86.13%, tr_best:  88.06%, epoch time: 182.39 seconds, 3.04 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.307164/  2.370111, val:  50.00%, val_best:  71.46%, tr:  87.62%, tr_best:  88.06%, epoch time: 179.92 seconds, 3.00 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.303377/  2.317858, val:  50.00%, val_best:  71.46%, tr:  85.46%, tr_best:  88.06%, epoch time: 176.08 seconds, 2.93 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.307714/  2.290897, val:  49.78%, val_best:  71.46%, tr:  86.03%, tr_best:  88.06%, epoch time: 173.60 seconds, 2.89 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.306143/  2.369240, val:  50.00%, val_best:  71.46%, tr:  87.27%, tr_best:  88.06%, epoch time: 181.23 seconds, 3.02 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 332 occurrences\n",
      "test - Value 1: 120 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.305684/  2.301612, val:  68.14%, val_best:  71.46%, tr:  85.96%, tr_best:  88.06%, epoch time: 178.90 seconds, 2.98 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.302058/  2.231419, val:  50.00%, val_best:  71.46%, tr:  87.22%, tr_best:  88.06%, epoch time: 182.16 seconds, 3.04 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.309655/  2.323641, val:  50.00%, val_best:  71.46%, tr:  87.67%, tr_best:  88.06%, epoch time: 181.61 seconds, 3.03 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.308337/  2.307070, val:  49.56%, val_best:  71.46%, tr:  87.17%, tr_best:  88.06%, epoch time: 181.93 seconds, 3.03 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.304236/  2.285222, val:  61.95%, val_best:  71.46%, tr:  87.30%, tr_best:  88.06%, epoch time: 181.73 seconds, 3.03 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.307653/  2.292212, val:  53.10%, val_best:  71.46%, tr:  85.81%, tr_best:  88.06%, epoch time: 180.87 seconds, 3.01 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.302746/  2.316946, val:  51.11%, val_best:  71.46%, tr:  85.78%, tr_best:  88.06%, epoch time: 182.53 seconds, 3.04 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.304320/  2.323146, val:  50.00%, val_best:  71.46%, tr:  86.65%, tr_best:  88.06%, epoch time: 181.39 seconds, 3.02 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.310863/  2.310414, val:  70.13%, val_best:  71.46%, tr:  86.77%, tr_best:  88.06%, epoch time: 180.96 seconds, 3.02 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.311198/  2.343682, val:  50.00%, val_best:  71.46%, tr:  85.61%, tr_best:  88.06%, epoch time: 180.57 seconds, 3.01 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.302359/  2.248384, val:  50.00%, val_best:  71.46%, tr:  87.59%, tr_best:  88.06%, epoch time: 182.05 seconds, 3.03 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.307316/  2.293541, val:  50.00%, val_best:  71.46%, tr:  85.46%, tr_best:  88.06%, epoch time: 179.53 seconds, 2.99 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.304038/  2.308904, val:  60.84%, val_best:  71.46%, tr:  86.08%, tr_best:  88.06%, epoch time: 179.15 seconds, 2.99 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.301982/  2.271189, val:  50.00%, val_best:  71.46%, tr:  85.76%, tr_best:  88.06%, epoch time: 171.43 seconds, 2.86 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.302114/  2.271117, val:  50.88%, val_best:  71.46%, tr:  86.00%, tr_best:  88.06%, epoch time: 173.85 seconds, 2.90 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.303402/  2.301765, val:  50.00%, val_best:  71.46%, tr:  88.29%, tr_best:  88.29%, epoch time: 179.42 seconds, 2.99 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.299530/  2.311314, val:  66.37%, val_best:  71.46%, tr:  87.42%, tr_best:  88.29%, epoch time: 179.68 seconds, 2.99 minutes\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.311709/  2.302061, val:  50.00%, val_best:  71.46%, tr:  85.33%, tr_best:  88.29%, epoch time: 171.21 seconds, 2.85 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.302523/  2.298068, val:  50.00%, val_best:  71.46%, tr:  87.57%, tr_best:  88.29%, epoch time: 175.48 seconds, 2.92 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.306613/  2.307466, val:  50.00%, val_best:  71.46%, tr:  85.09%, tr_best:  88.29%, epoch time: 180.74 seconds, 3.01 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.307283/  2.296058, val:  48.01%, val_best:  71.46%, tr:  87.10%, tr_best:  88.29%, epoch time: 180.93 seconds, 3.02 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.303919/  2.281414, val:  50.88%, val_best:  71.46%, tr:  87.39%, tr_best:  88.29%, epoch time: 181.13 seconds, 3.02 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.305637/  2.317560, val:  53.32%, val_best:  71.46%, tr:  87.42%, tr_best:  88.29%, epoch time: 180.95 seconds, 3.02 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.306065/  2.308121, val:  49.78%, val_best:  71.46%, tr:  87.82%, tr_best:  88.29%, epoch time: 181.17 seconds, 3.02 minutes\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.306135/  2.285467, val:  50.00%, val_best:  71.46%, tr:  87.99%, tr_best:  88.29%, epoch time: 179.45 seconds, 2.99 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.301415/  2.335863, val:  50.00%, val_best:  71.46%, tr:  86.53%, tr_best:  88.29%, epoch time: 180.34 seconds, 3.01 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.302245/  2.320765, val:  50.00%, val_best:  71.46%, tr:  85.91%, tr_best:  88.29%, epoch time: 177.74 seconds, 2.96 minutes\n",
      "train - Value 0: 1940 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.305102/  2.319590, val:  50.00%, val_best:  71.46%, tr:  86.92%, tr_best:  88.29%, epoch time: 177.28 seconds, 2.95 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.303994/  2.341586, val:  49.78%, val_best:  71.46%, tr:  86.28%, tr_best:  88.29%, epoch time: 180.21 seconds, 3.00 minutes\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.304564/  2.309454, val:  50.00%, val_best:  71.46%, tr:  87.34%, tr_best:  88.29%, epoch time: 177.60 seconds, 2.96 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.307540/  2.315340, val:  54.65%, val_best:  71.46%, tr:  86.60%, tr_best:  88.29%, epoch time: 176.28 seconds, 2.94 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.304455/  2.316361, val:  56.42%, val_best:  71.46%, tr:  86.28%, tr_best:  88.29%, epoch time: 177.98 seconds, 2.97 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.307393/  2.315489, val:  50.00%, val_best:  71.46%, tr:  87.84%, tr_best:  88.29%, epoch time: 176.79 seconds, 2.95 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.303906/  2.331522, val:  52.43%, val_best:  71.46%, tr:  86.28%, tr_best:  88.29%, epoch time: 180.57 seconds, 3.01 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.311502/  2.240399, val:  50.00%, val_best:  71.46%, tr:  86.82%, tr_best:  88.29%, epoch time: 180.68 seconds, 3.01 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.303542/  2.244046, val:  50.00%, val_best:  71.46%, tr:  88.91%, tr_best:  88.91%, epoch time: 179.74 seconds, 3.00 minutes\n",
      "train - Value 0: 1918 occurrences\n",
      "train - Value 1: 2112 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.305156/  2.286149, val:  50.00%, val_best:  71.46%, tr:  87.42%, tr_best:  88.91%, epoch time: 175.05 seconds, 2.92 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.313166/  2.298814, val:  68.14%, val_best:  71.46%, tr:  87.94%, tr_best:  88.91%, epoch time: 173.48 seconds, 2.89 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.306242/  2.222985, val:  50.00%, val_best:  71.46%, tr:  88.11%, tr_best:  88.91%, epoch time: 178.57 seconds, 2.98 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.308555/  2.245216, val:  50.00%, val_best:  71.46%, tr:  87.42%, tr_best:  88.91%, epoch time: 179.31 seconds, 2.99 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.306177/  2.304213, val:  50.00%, val_best:  71.46%, tr:  87.00%, tr_best:  88.91%, epoch time: 180.50 seconds, 3.01 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.304651/  2.270762, val:  50.00%, val_best:  71.46%, tr:  87.42%, tr_best:  88.91%, epoch time: 177.33 seconds, 2.96 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.302503/  2.245006, val:  50.00%, val_best:  71.46%, tr:  86.15%, tr_best:  88.91%, epoch time: 180.45 seconds, 3.01 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.310386/  2.316834, val:  49.56%, val_best:  71.46%, tr:  86.85%, tr_best:  88.91%, epoch time: 178.97 seconds, 2.98 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.303448/  2.337302, val:  50.00%, val_best:  71.46%, tr:  85.83%, tr_best:  88.91%, epoch time: 177.97 seconds, 2.97 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.304744/  2.282457, val:  49.78%, val_best:  71.46%, tr:  85.58%, tr_best:  88.91%, epoch time: 179.97 seconds, 3.00 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.302567/  2.298201, val:  43.14%, val_best:  71.46%, tr:  86.23%, tr_best:  88.91%, epoch time: 180.42 seconds, 3.01 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.304014/  2.315706, val:  67.70%, val_best:  71.46%, tr:  87.07%, tr_best:  88.91%, epoch time: 180.24 seconds, 3.00 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.305393/  2.285953, val:  52.43%, val_best:  71.46%, tr:  86.30%, tr_best:  88.91%, epoch time: 179.47 seconds, 2.99 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.310323/  2.264245, val:  50.00%, val_best:  71.46%, tr:  87.92%, tr_best:  88.91%, epoch time: 181.03 seconds, 3.02 minutes\n",
      "train - Value 0: 1912 occurrences\n",
      "train - Value 1: 2118 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.304114/  2.257408, val:  50.00%, val_best:  71.46%, tr:  87.07%, tr_best:  88.91%, epoch time: 179.58 seconds, 2.99 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.305348/  2.273299, val:  50.00%, val_best:  71.46%, tr:  86.38%, tr_best:  88.91%, epoch time: 179.98 seconds, 3.00 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.305099/  2.292912, val:  50.00%, val_best:  71.46%, tr:  86.25%, tr_best:  88.91%, epoch time: 180.17 seconds, 3.00 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.301737/  2.331573, val:  50.00%, val_best:  71.46%, tr:  87.20%, tr_best:  88.91%, epoch time: 180.12 seconds, 3.00 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.302726/  2.270546, val:  50.00%, val_best:  71.46%, tr:  86.10%, tr_best:  88.91%, epoch time: 183.18 seconds, 3.05 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.305891/  2.340060, val:  50.00%, val_best:  71.46%, tr:  86.97%, tr_best:  88.91%, epoch time: 176.56 seconds, 2.94 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.306510/  2.312771, val:  50.00%, val_best:  71.46%, tr:  85.36%, tr_best:  88.91%, epoch time: 171.98 seconds, 2.87 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.306253/  2.325369, val:  51.33%, val_best:  71.46%, tr:  86.40%, tr_best:  88.91%, epoch time: 177.23 seconds, 2.95 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.304988/  2.379061, val:  50.00%, val_best:  71.46%, tr:  86.43%, tr_best:  88.91%, epoch time: 178.56 seconds, 2.98 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.303885/  2.317932, val:  49.78%, val_best:  71.46%, tr:  88.41%, tr_best:  88.91%, epoch time: 178.74 seconds, 2.98 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.305312/  2.308629, val:  58.41%, val_best:  71.46%, tr:  88.73%, tr_best:  88.91%, epoch time: 179.91 seconds, 3.00 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 370 occurrences\n",
      "test - Value 1: 82 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.307468/  2.285894, val:  66.81%, val_best:  71.46%, tr:  87.02%, tr_best:  88.91%, epoch time: 180.40 seconds, 3.01 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.304977/  2.258916, val:  50.00%, val_best:  71.46%, tr:  88.61%, tr_best:  88.91%, epoch time: 179.89 seconds, 3.00 minutes\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.295949/  2.335374, val:  50.00%, val_best:  71.46%, tr:  86.77%, tr_best:  88.91%, epoch time: 180.08 seconds, 3.00 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.304135/  2.308336, val:  50.00%, val_best:  71.46%, tr:  87.79%, tr_best:  88.91%, epoch time: 179.61 seconds, 2.99 minutes\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.307939/  2.352364, val:  50.00%, val_best:  71.46%, tr:  86.48%, tr_best:  88.91%, epoch time: 181.14 seconds, 3.02 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.308598/  2.291826, val:  50.00%, val_best:  71.46%, tr:  88.51%, tr_best:  88.91%, epoch time: 179.67 seconds, 2.99 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.303279/  2.314566, val:  50.00%, val_best:  71.46%, tr:  87.77%, tr_best:  88.91%, epoch time: 181.69 seconds, 3.03 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.302505/  2.311701, val:  62.83%, val_best:  71.46%, tr:  87.49%, tr_best:  88.91%, epoch time: 180.92 seconds, 3.02 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.308022/  2.345333, val:  50.00%, val_best:  71.46%, tr:  87.30%, tr_best:  88.91%, epoch time: 179.93 seconds, 3.00 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.302700/  2.318811, val:  50.00%, val_best:  71.46%, tr:  84.91%, tr_best:  88.91%, epoch time: 180.60 seconds, 3.01 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.306724/  2.286160, val:  50.22%, val_best:  71.46%, tr:  86.48%, tr_best:  88.91%, epoch time: 178.84 seconds, 2.98 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.306872/  2.377381, val:  50.00%, val_best:  71.46%, tr:  87.89%, tr_best:  88.91%, epoch time: 179.66 seconds, 2.99 minutes\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.306132/  2.320483, val:  50.00%, val_best:  71.46%, tr:  86.63%, tr_best:  88.91%, epoch time: 180.29 seconds, 3.00 minutes\n",
      "train - Value 0: 1913 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.304956/  2.309129, val:  50.88%, val_best:  71.46%, tr:  85.71%, tr_best:  88.91%, epoch time: 177.49 seconds, 2.96 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.305683/  2.302611, val:  49.78%, val_best:  71.46%, tr:  87.22%, tr_best:  88.91%, epoch time: 174.13 seconds, 2.90 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.306218/  2.309584, val:  50.00%, val_best:  71.46%, tr:  85.33%, tr_best:  88.91%, epoch time: 176.64 seconds, 2.94 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.303529/  2.354232, val:  50.00%, val_best:  71.46%, tr:  87.67%, tr_best:  88.91%, epoch time: 180.74 seconds, 3.01 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.304173/  2.330903, val:  49.34%, val_best:  71.46%, tr:  87.17%, tr_best:  88.91%, epoch time: 179.59 seconds, 2.99 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.304398/  2.304479, val:  67.26%, val_best:  71.46%, tr:  86.87%, tr_best:  88.91%, epoch time: 180.69 seconds, 3.01 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.306356/  2.327984, val:  49.34%, val_best:  71.46%, tr:  86.20%, tr_best:  88.91%, epoch time: 180.35 seconds, 3.01 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.308132/  2.254775, val:  50.00%, val_best:  71.46%, tr:  87.79%, tr_best:  88.91%, epoch time: 180.41 seconds, 3.01 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.301645/  2.317484, val:  50.00%, val_best:  71.46%, tr:  88.26%, tr_best:  88.91%, epoch time: 180.64 seconds, 3.01 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.303698/  2.288659, val:  50.00%, val_best:  71.46%, tr:  87.15%, tr_best:  88.91%, epoch time: 178.88 seconds, 2.98 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.304964/  2.275097, val:  50.00%, val_best:  71.46%, tr:  86.13%, tr_best:  88.91%, epoch time: 178.41 seconds, 2.97 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.305849/  2.318544, val:  49.56%, val_best:  71.46%, tr:  86.77%, tr_best:  88.91%, epoch time: 180.41 seconds, 3.01 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.309947/  2.263826, val:  50.44%, val_best:  71.46%, tr:  88.54%, tr_best:  88.91%, epoch time: 178.27 seconds, 2.97 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.303665/  2.312276, val:  50.44%, val_best:  71.46%, tr:  85.48%, tr_best:  88.91%, epoch time: 180.77 seconds, 3.01 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.305199/  2.334300, val:  49.12%, val_best:  71.46%, tr:  86.97%, tr_best:  88.91%, epoch time: 180.93 seconds, 3.02 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.302908/  2.293811, val:  62.39%, val_best:  71.46%, tr:  86.90%, tr_best:  88.91%, epoch time: 177.84 seconds, 2.96 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.306943/  2.309777, val:  50.22%, val_best:  71.46%, tr:  86.72%, tr_best:  88.91%, epoch time: 181.42 seconds, 3.02 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.304590/  2.293491, val:  50.00%, val_best:  71.46%, tr:  85.53%, tr_best:  88.91%, epoch time: 180.01 seconds, 3.00 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.304115/  2.329386, val:  50.00%, val_best:  71.46%, tr:  87.05%, tr_best:  88.91%, epoch time: 178.65 seconds, 2.98 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.307133/  2.303312, val:  50.22%, val_best:  71.46%, tr:  87.82%, tr_best:  88.91%, epoch time: 177.17 seconds, 2.95 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.308041/  2.214196, val:  50.00%, val_best:  71.46%, tr:  87.69%, tr_best:  88.91%, epoch time: 176.12 seconds, 2.94 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.314424/  2.319130, val:  50.00%, val_best:  71.46%, tr:  88.91%, tr_best:  88.91%, epoch time: 173.11 seconds, 2.89 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.306270/  2.285920, val:  50.00%, val_best:  71.46%, tr:  88.11%, tr_best:  88.91%, epoch time: 180.18 seconds, 3.00 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.304817/  2.336289, val:  50.00%, val_best:  71.46%, tr:  84.44%, tr_best:  88.91%, epoch time: 178.68 seconds, 2.98 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.303447/  2.289042, val:  51.33%, val_best:  71.46%, tr:  87.05%, tr_best:  88.91%, epoch time: 178.56 seconds, 2.98 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.308588/  2.311215, val:  50.00%, val_best:  71.46%, tr:  87.15%, tr_best:  88.91%, epoch time: 179.93 seconds, 3.00 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.305110/  2.309399, val:  47.35%, val_best:  71.46%, tr:  86.50%, tr_best:  88.91%, epoch time: 179.47 seconds, 2.99 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.302977/  2.301212, val:  50.00%, val_best:  71.46%, tr:  86.25%, tr_best:  88.91%, epoch time: 178.63 seconds, 2.98 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.304734/  2.279128, val:  50.00%, val_best:  71.46%, tr:  88.76%, tr_best:  88.91%, epoch time: 178.98 seconds, 2.98 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.303614/  2.258703, val:  50.00%, val_best:  71.46%, tr:  86.80%, tr_best:  88.91%, epoch time: 178.23 seconds, 2.97 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.302927/  2.339185, val:  50.00%, val_best:  71.46%, tr:  85.71%, tr_best:  88.91%, epoch time: 179.09 seconds, 2.98 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.304923/  2.236752, val:  50.00%, val_best:  71.46%, tr:  86.65%, tr_best:  88.91%, epoch time: 179.42 seconds, 2.99 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.302661/  2.309105, val:  50.00%, val_best:  71.46%, tr:  87.92%, tr_best:  88.91%, epoch time: 180.13 seconds, 3.00 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.306907/  2.322628, val:  50.00%, val_best:  71.46%, tr:  87.05%, tr_best:  88.91%, epoch time: 178.73 seconds, 2.98 minutes\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.300532/  2.324324, val:  50.00%, val_best:  71.46%, tr:  86.70%, tr_best:  88.91%, epoch time: 177.93 seconds, 2.97 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.306278/  2.276171, val:  50.00%, val_best:  71.46%, tr:  86.97%, tr_best:  88.91%, epoch time: 181.48 seconds, 3.02 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.301630/  2.286897, val:  49.78%, val_best:  71.46%, tr:  89.45%, tr_best:  89.45%, epoch time: 180.02 seconds, 3.00 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.305155/  2.305515, val:  50.00%, val_best:  71.46%, tr:  86.48%, tr_best:  89.45%, epoch time: 178.27 seconds, 2.97 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.306373/  2.291157, val:  50.00%, val_best:  71.46%, tr:  86.72%, tr_best:  89.45%, epoch time: 180.57 seconds, 3.01 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.306935/  2.333172, val:  50.00%, val_best:  71.46%, tr:  87.59%, tr_best:  89.45%, epoch time: 178.66 seconds, 2.98 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.306528/  2.358991, val:  49.56%, val_best:  71.46%, tr:  88.11%, tr_best:  89.45%, epoch time: 171.82 seconds, 2.86 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.302831/  2.295862, val:  53.10%, val_best:  71.46%, tr:  87.74%, tr_best:  89.45%, epoch time: 175.73 seconds, 2.93 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.310414/  2.315905, val:  50.00%, val_best:  71.46%, tr:  85.98%, tr_best:  89.45%, epoch time: 179.38 seconds, 2.99 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.304805/  2.344571, val:  50.00%, val_best:  71.46%, tr:  86.53%, tr_best:  89.45%, epoch time: 180.41 seconds, 3.01 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.307527/  2.281450, val:  50.00%, val_best:  71.46%, tr:  88.11%, tr_best:  89.45%, epoch time: 179.60 seconds, 2.99 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.308484/  2.350947, val:  49.56%, val_best:  71.46%, tr:  87.72%, tr_best:  89.45%, epoch time: 177.50 seconds, 2.96 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.310424/  2.298422, val:  50.00%, val_best:  71.46%, tr:  86.55%, tr_best:  89.45%, epoch time: 179.87 seconds, 3.00 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.305115/  2.315251, val:  50.00%, val_best:  71.46%, tr:  88.01%, tr_best:  89.45%, epoch time: 179.69 seconds, 2.99 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.305659/  2.283624, val:  50.00%, val_best:  71.46%, tr:  86.33%, tr_best:  89.45%, epoch time: 178.94 seconds, 2.98 minutes\n",
      "train - Value 0: 2104 occurrences\n",
      "train - Value 1: 1926 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.302691/  2.309855, val:  50.00%, val_best:  71.46%, tr:  85.88%, tr_best:  89.45%, epoch time: 179.33 seconds, 2.99 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.303291/  2.308228, val:  50.00%, val_best:  71.46%, tr:  88.73%, tr_best:  89.45%, epoch time: 179.84 seconds, 3.00 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.305138/  2.350118, val:  46.02%, val_best:  71.46%, tr:  86.20%, tr_best:  89.45%, epoch time: 179.48 seconds, 2.99 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.303465/  2.326750, val:  50.66%, val_best:  71.46%, tr:  84.24%, tr_best:  89.45%, epoch time: 180.80 seconds, 3.01 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.301137/  2.283157, val:  49.78%, val_best:  71.46%, tr:  85.88%, tr_best:  89.45%, epoch time: 180.08 seconds, 3.00 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.306948/  2.290622, val:  50.00%, val_best:  71.46%, tr:  85.66%, tr_best:  89.45%, epoch time: 179.60 seconds, 2.99 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.305564/  2.319190, val:  51.99%, val_best:  71.46%, tr:  86.80%, tr_best:  89.45%, epoch time: 180.99 seconds, 3.02 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.304789/  2.277409, val:  50.00%, val_best:  71.46%, tr:  86.92%, tr_best:  89.45%, epoch time: 177.52 seconds, 2.96 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.303213/  2.274893, val:  50.00%, val_best:  71.46%, tr:  87.47%, tr_best:  89.45%, epoch time: 178.16 seconds, 2.97 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.300578/  2.297840, val:  50.00%, val_best:  71.46%, tr:  87.22%, tr_best:  89.45%, epoch time: 180.11 seconds, 3.00 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.306064/  2.335814, val:  50.00%, val_best:  71.46%, tr:  87.22%, tr_best:  89.45%, epoch time: 175.72 seconds, 2.93 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.306994/  2.299831, val:  53.98%, val_best:  71.46%, tr:  88.26%, tr_best:  89.45%, epoch time: 172.82 seconds, 2.88 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.303302/  2.296771, val:  50.00%, val_best:  71.46%, tr:  88.56%, tr_best:  89.45%, epoch time: 180.21 seconds, 3.00 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.304615/  2.306409, val:  50.00%, val_best:  71.46%, tr:  88.73%, tr_best:  89.45%, epoch time: 180.98 seconds, 3.02 minutes\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.304349/  2.300949, val:  50.00%, val_best:  71.46%, tr:  87.82%, tr_best:  89.45%, epoch time: 181.55 seconds, 3.03 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.308201/  2.345898, val:  50.00%, val_best:  71.46%, tr:  87.27%, tr_best:  89.45%, epoch time: 182.57 seconds, 3.04 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.300101/  2.304487, val:  50.00%, val_best:  71.46%, tr:  88.54%, tr_best:  89.45%, epoch time: 180.50 seconds, 3.01 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.304133/  2.367691, val:  50.00%, val_best:  71.46%, tr:  88.86%, tr_best:  89.45%, epoch time: 182.23 seconds, 3.04 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.306440/  2.318248, val:  50.00%, val_best:  71.46%, tr:  88.46%, tr_best:  89.45%, epoch time: 182.41 seconds, 3.04 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.304161/  2.262838, val:  50.00%, val_best:  71.46%, tr:  87.12%, tr_best:  89.45%, epoch time: 181.49 seconds, 3.02 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.306721/  2.332084, val:  50.00%, val_best:  71.46%, tr:  86.18%, tr_best:  89.45%, epoch time: 182.28 seconds, 3.04 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.305597/  2.298764, val:  50.00%, val_best:  71.46%, tr:  85.91%, tr_best:  89.45%, epoch time: 181.42 seconds, 3.02 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.307350/  2.246419, val:  50.00%, val_best:  71.46%, tr:  87.89%, tr_best:  89.45%, epoch time: 179.76 seconds, 3.00 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.306817/  2.307534, val:  50.00%, val_best:  71.46%, tr:  87.72%, tr_best:  89.45%, epoch time: 181.15 seconds, 3.02 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.306849/  2.308886, val:  50.00%, val_best:  71.46%, tr:  86.85%, tr_best:  89.45%, epoch time: 180.93 seconds, 3.02 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.297733/  2.288552, val:  50.22%, val_best:  71.46%, tr:  87.99%, tr_best:  89.45%, epoch time: 178.25 seconds, 2.97 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.304332/  2.291709, val:  50.88%, val_best:  71.46%, tr:  85.93%, tr_best:  89.45%, epoch time: 182.31 seconds, 3.04 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.302371/  2.251064, val:  50.00%, val_best:  71.46%, tr:  86.20%, tr_best:  89.45%, epoch time: 181.96 seconds, 3.03 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.304902/  2.294473, val:  50.00%, val_best:  71.46%, tr:  86.38%, tr_best:  89.45%, epoch time: 180.57 seconds, 3.01 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.305739/  2.336511, val:  50.00%, val_best:  71.46%, tr:  85.98%, tr_best:  89.45%, epoch time: 178.75 seconds, 2.98 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.306032/  2.289024, val:  50.00%, val_best:  71.46%, tr:  85.58%, tr_best:  89.45%, epoch time: 174.89 seconds, 2.91 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.307713/  2.411283, val:  50.00%, val_best:  71.46%, tr:  85.81%, tr_best:  89.45%, epoch time: 180.08 seconds, 3.00 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.304684/  2.314420, val:  50.00%, val_best:  71.46%, tr:  87.79%, tr_best:  89.45%, epoch time: 181.46 seconds, 3.02 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.304918/  2.302559, val:  50.22%, val_best:  71.46%, tr:  83.25%, tr_best:  89.45%, epoch time: 181.35 seconds, 3.02 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.304823/  2.301196, val:  50.00%, val_best:  71.46%, tr:  87.59%, tr_best:  89.45%, epoch time: 182.82 seconds, 3.05 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.307361/  2.310648, val:  61.73%, val_best:  71.46%, tr:  85.48%, tr_best:  89.45%, epoch time: 181.11 seconds, 3.02 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.305178/  2.303087, val:  51.77%, val_best:  71.46%, tr:  87.54%, tr_best:  89.45%, epoch time: 180.67 seconds, 3.01 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.302560/  2.286884, val:  53.98%, val_best:  71.46%, tr:  87.02%, tr_best:  89.45%, epoch time: 179.54 seconds, 2.99 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.302589/  2.308527, val:  50.00%, val_best:  71.46%, tr:  86.80%, tr_best:  89.45%, epoch time: 181.32 seconds, 3.02 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.305985/  2.302869, val:  50.00%, val_best:  71.46%, tr:  86.60%, tr_best:  89.45%, epoch time: 180.71 seconds, 3.01 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.303365/  2.294635, val:  50.00%, val_best:  71.46%, tr:  88.04%, tr_best:  89.45%, epoch time: 179.98 seconds, 3.00 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.300134/  2.305767, val:  50.00%, val_best:  71.46%, tr:  88.86%, tr_best:  89.45%, epoch time: 180.64 seconds, 3.01 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.301809/  2.286783, val:  49.56%, val_best:  71.46%, tr:  86.50%, tr_best:  89.45%, epoch time: 181.12 seconds, 3.02 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.305977/  2.363852, val:  50.00%, val_best:  71.46%, tr:  87.32%, tr_best:  89.45%, epoch time: 181.92 seconds, 3.03 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.304814/  2.311609, val:  50.00%, val_best:  71.46%, tr:  87.47%, tr_best:  89.45%, epoch time: 181.65 seconds, 3.03 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.302546/  2.320362, val:  50.00%, val_best:  71.46%, tr:  87.07%, tr_best:  89.45%, epoch time: 182.91 seconds, 3.05 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.302317/  2.299887, val:  50.00%, val_best:  71.46%, tr:  87.30%, tr_best:  89.45%, epoch time: 180.90 seconds, 3.01 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.303977/  2.312115, val:  50.00%, val_best:  71.46%, tr:  87.82%, tr_best:  89.45%, epoch time: 181.12 seconds, 3.02 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.300181/  2.318933, val:  50.00%, val_best:  71.46%, tr:  85.14%, tr_best:  89.45%, epoch time: 181.93 seconds, 3.03 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.307050/  2.260861, val:  50.00%, val_best:  71.46%, tr:  87.34%, tr_best:  89.45%, epoch time: 173.67 seconds, 2.89 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.302506/  2.286396, val:  50.00%, val_best:  71.46%, tr:  87.87%, tr_best:  89.45%, epoch time: 176.78 seconds, 2.95 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.302675/  2.285089, val:  50.00%, val_best:  71.46%, tr:  88.06%, tr_best:  89.45%, epoch time: 180.04 seconds, 3.00 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.306678/  2.237472, val:  50.00%, val_best:  71.46%, tr:  87.32%, tr_best:  89.45%, epoch time: 178.47 seconds, 2.97 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1972 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.305104/  2.316454, val:  50.00%, val_best:  71.46%, tr:  86.23%, tr_best:  89.45%, epoch time: 182.93 seconds, 3.05 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e36e846ef6b44058414629a531a93db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÉ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÑ‚ñÜ‚ñá‚ñÇ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÑ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.86228</td></tr><tr><td>tr_epoch_loss</td><td>2.3051</td></tr><tr><td>val_acc_best</td><td>0.7146</td></tr><tr><td>val_acc_now</td><td>0.5</td></tr><tr><td>val_loss</td><td>2.31645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ldso7xp1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/ldso7xp1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250805_135358-ldso7xp1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pcpie2t1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009765625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250805_235257-pcpie2t1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pcpie2t1' target=\"_blank\">cosmic-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pcpie2t1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pcpie2t1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250805_235305_964', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0009765625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-12, -12], [-12, -12], [-11, -11]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0009765625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-0   lr=['0.0009766'], tr/val_loss:  2.304399/  2.304244, val:  64.16%, val_best:  64.16%, tr:  64.59%, tr_best:  64.59%, epoch time: 96.06 seconds, 1.60 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2117 occurrences\n",
      "train - Value 1: 1913 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-1   lr=['0.0009766'], tr/val_loss:  2.301445/  2.301327, val:  76.99%, val_best:  76.99%, tr:  78.21%, tr_best:  78.21%, epoch time: 95.95 seconds, 1.60 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 350 occurrences\n",
      "test - Value 1: 102 occurrences\n",
      "epoch-2   lr=['0.0009766'], tr/val_loss:  2.301621/  2.294019, val:  70.35%, val_best:  76.99%, tr:  83.75%, tr_best:  83.75%, epoch time: 96.19 seconds, 1.60 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-3   lr=['0.0009766'], tr/val_loss:  2.302940/  2.305295, val:  79.65%, val_best:  79.65%, tr:  87.00%, tr_best:  87.00%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-4   lr=['0.0009766'], tr/val_loss:  2.302740/  2.301096, val:  82.30%, val_best:  82.30%, tr:  89.11%, tr_best:  89.11%, epoch time: 97.03 seconds, 1.62 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-5   lr=['0.0009766'], tr/val_loss:  2.303218/  2.320071, val:  51.77%, val_best:  82.30%, tr:  90.35%, tr_best:  90.35%, epoch time: 95.69 seconds, 1.59 minutes\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-6   lr=['0.0009766'], tr/val_loss:  2.304336/  2.292536, val:  65.93%, val_best:  82.30%, tr:  90.32%, tr_best:  90.35%, epoch time: 97.63 seconds, 1.63 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-7   lr=['0.0009766'], tr/val_loss:  2.304564/  2.302644, val:  64.38%, val_best:  82.30%, tr:  92.41%, tr_best:  92.41%, epoch time: 96.74 seconds, 1.61 minutes\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-8   lr=['0.0009766'], tr/val_loss:  2.304593/  2.309919, val:  78.98%, val_best:  82.30%, tr:  91.84%, tr_best:  92.41%, epoch time: 97.57 seconds, 1.63 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-9   lr=['0.0009766'], tr/val_loss:  2.303352/  2.305504, val:  86.95%, val_best:  86.95%, tr:  92.16%, tr_best:  92.41%, epoch time: 93.75 seconds, 1.56 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-10  lr=['0.0009766'], tr/val_loss:  2.304128/  2.302020, val:  84.73%, val_best:  86.95%, tr:  92.03%, tr_best:  92.41%, epoch time: 96.49 seconds, 1.61 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-11  lr=['0.0009766'], tr/val_loss:  2.304930/  2.298630, val:  82.08%, val_best:  86.95%, tr:  93.45%, tr_best:  93.45%, epoch time: 96.39 seconds, 1.61 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-12  lr=['0.0009766'], tr/val_loss:  2.304205/  2.302823, val:  85.62%, val_best:  86.95%, tr:  93.37%, tr_best:  93.45%, epoch time: 96.36 seconds, 1.61 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-13  lr=['0.0009766'], tr/val_loss:  2.304103/  2.315584, val:  70.13%, val_best:  86.95%, tr:  94.64%, tr_best:  94.64%, epoch time: 97.02 seconds, 1.62 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-14  lr=['0.0009766'], tr/val_loss:  2.304285/  2.305231, val:  56.42%, val_best:  86.95%, tr:  94.79%, tr_best:  94.79%, epoch time: 98.12 seconds, 1.64 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-15  lr=['0.0009766'], tr/val_loss:  2.306053/  2.309715, val:  65.93%, val_best:  86.95%, tr:  94.67%, tr_best:  94.79%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-16  lr=['0.0009766'], tr/val_loss:  2.306221/  2.308935, val:  68.58%, val_best:  86.95%, tr:  96.15%, tr_best:  96.15%, epoch time: 97.53 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-17  lr=['0.0009766'], tr/val_loss:  2.307056/  2.308649, val:  76.55%, val_best:  86.95%, tr:  96.58%, tr_best:  96.58%, epoch time: 95.95 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-18  lr=['0.0009766'], tr/val_loss:  2.307241/  2.322594, val:  69.91%, val_best:  86.95%, tr:  95.26%, tr_best:  96.58%, epoch time: 97.84 seconds, 1.63 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-19  lr=['0.0009766'], tr/val_loss:  2.308088/  2.314341, val:  74.12%, val_best:  86.95%, tr:  95.66%, tr_best:  96.58%, epoch time: 97.69 seconds, 1.63 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-20  lr=['0.0009766'], tr/val_loss:  2.308116/  2.303805, val:  86.73%, val_best:  86.95%, tr:  95.71%, tr_best:  96.58%, epoch time: 97.06 seconds, 1.62 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-21  lr=['0.0009766'], tr/val_loss:  2.306676/  2.312032, val:  86.95%, val_best:  86.95%, tr:  95.63%, tr_best:  96.58%, epoch time: 97.57 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-22  lr=['0.0009766'], tr/val_loss:  2.308612/  2.327759, val:  73.45%, val_best:  86.95%, tr:  95.81%, tr_best:  96.58%, epoch time: 96.00 seconds, 1.60 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-23  lr=['0.0009766'], tr/val_loss:  2.306216/  2.318594, val:  86.73%, val_best:  86.95%, tr:  96.15%, tr_best:  96.58%, epoch time: 96.53 seconds, 1.61 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-24  lr=['0.0009766'], tr/val_loss:  2.304008/  2.317701, val:  67.70%, val_best:  86.95%, tr:  96.63%, tr_best:  96.63%, epoch time: 96.41 seconds, 1.61 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-25  lr=['0.0009766'], tr/val_loss:  2.307034/  2.313114, val:  80.53%, val_best:  86.95%, tr:  97.05%, tr_best:  97.05%, epoch time: 98.42 seconds, 1.64 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-26  lr=['0.0009766'], tr/val_loss:  2.308324/  2.318582, val:  84.29%, val_best:  86.95%, tr:  96.95%, tr_best:  97.05%, epoch time: 95.63 seconds, 1.59 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-27  lr=['0.0009766'], tr/val_loss:  2.307384/  2.315415, val:  85.40%, val_best:  86.95%, tr:  97.17%, tr_best:  97.17%, epoch time: 94.25 seconds, 1.57 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 308 occurrences\n",
      "test - Value 1: 144 occurrences\n",
      "epoch-28  lr=['0.0009766'], tr/val_loss:  2.305910/  2.305606, val:  80.97%, val_best:  86.95%, tr:  97.64%, tr_best:  97.64%, epoch time: 93.09 seconds, 1.55 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-29  lr=['0.0009766'], tr/val_loss:  2.307496/  2.313189, val:  87.17%, val_best:  87.17%, tr:  97.17%, tr_best:  97.64%, epoch time: 94.99 seconds, 1.58 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-30  lr=['0.0009766'], tr/val_loss:  2.307367/  2.306154, val:  87.39%, val_best:  87.39%, tr:  97.77%, tr_best:  97.77%, epoch time: 97.76 seconds, 1.63 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-31  lr=['0.0009766'], tr/val_loss:  2.308166/  2.295036, val:  86.50%, val_best:  87.39%, tr:  98.01%, tr_best:  98.01%, epoch time: 97.80 seconds, 1.63 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-32  lr=['0.0009766'], tr/val_loss:  2.308036/  2.315171, val:  62.83%, val_best:  87.39%, tr:  97.12%, tr_best:  98.01%, epoch time: 97.06 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-33  lr=['0.0009766'], tr/val_loss:  2.306378/  2.306944, val:  88.27%, val_best:  88.27%, tr:  97.69%, tr_best:  98.01%, epoch time: 97.33 seconds, 1.62 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-34  lr=['0.0009766'], tr/val_loss:  2.306946/  2.315242, val:  86.95%, val_best:  88.27%, tr:  97.72%, tr_best:  98.01%, epoch time: 96.72 seconds, 1.61 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-35  lr=['0.0009766'], tr/val_loss:  2.308673/  2.305322, val:  86.73%, val_best:  88.27%, tr:  97.97%, tr_best:  98.01%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-36  lr=['0.0009766'], tr/val_loss:  2.310150/  2.330159, val:  83.85%, val_best:  88.27%, tr:  97.99%, tr_best:  98.01%, epoch time: 97.68 seconds, 1.63 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-37  lr=['0.0009766'], tr/val_loss:  2.308423/  2.332916, val:  57.96%, val_best:  88.27%, tr:  97.82%, tr_best:  98.01%, epoch time: 97.36 seconds, 1.62 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-38  lr=['0.0009766'], tr/val_loss:  2.310196/  2.309023, val:  82.96%, val_best:  88.27%, tr:  97.94%, tr_best:  98.01%, epoch time: 96.03 seconds, 1.60 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-39  lr=['0.0009766'], tr/val_loss:  2.310200/  2.304600, val:  86.95%, val_best:  88.27%, tr:  98.26%, tr_best:  98.26%, epoch time: 97.60 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-40  lr=['0.0009766'], tr/val_loss:  2.311354/  2.319041, val:  76.33%, val_best:  88.27%, tr:  97.99%, tr_best:  98.26%, epoch time: 98.00 seconds, 1.63 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-41  lr=['0.0009766'], tr/val_loss:  2.313773/  2.323253, val:  83.19%, val_best:  88.27%, tr:  98.34%, tr_best:  98.34%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-42  lr=['0.0009766'], tr/val_loss:  2.313111/  2.314257, val:  82.74%, val_best:  88.27%, tr:  98.36%, tr_best:  98.36%, epoch time: 97.94 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-43  lr=['0.0009766'], tr/val_loss:  2.309090/  2.308178, val:  77.65%, val_best:  88.27%, tr:  98.56%, tr_best:  98.56%, epoch time: 96.83 seconds, 1.61 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-44  lr=['0.0009766'], tr/val_loss:  2.310302/  2.323558, val:  73.45%, val_best:  88.27%, tr:  98.36%, tr_best:  98.56%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-45  lr=['0.0009766'], tr/val_loss:  2.308252/  2.322691, val:  63.72%, val_best:  88.27%, tr:  98.34%, tr_best:  98.56%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-46  lr=['0.0009766'], tr/val_loss:  2.309311/  2.342375, val:  60.84%, val_best:  88.27%, tr:  98.51%, tr_best:  98.56%, epoch time: 98.59 seconds, 1.64 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-47  lr=['0.0009766'], tr/val_loss:  2.312855/  2.318238, val:  81.42%, val_best:  88.27%, tr:  98.64%, tr_best:  98.64%, epoch time: 97.40 seconds, 1.62 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-48  lr=['0.0009766'], tr/val_loss:  2.311534/  2.319078, val:  63.94%, val_best:  88.27%, tr:  98.78%, tr_best:  98.78%, epoch time: 97.39 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-49  lr=['0.0009766'], tr/val_loss:  2.313530/  2.317838, val:  61.73%, val_best:  88.27%, tr:  98.64%, tr_best:  98.78%, epoch time: 98.06 seconds, 1.63 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-50  lr=['0.0009766'], tr/val_loss:  2.312417/  2.314350, val:  83.41%, val_best:  88.27%, tr:  98.76%, tr_best:  98.78%, epoch time: 96.68 seconds, 1.61 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-51  lr=['0.0009766'], tr/val_loss:  2.312413/  2.342610, val:  55.97%, val_best:  88.27%, tr:  98.59%, tr_best:  98.78%, epoch time: 96.39 seconds, 1.61 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-52  lr=['0.0009766'], tr/val_loss:  2.311431/  2.331034, val:  82.96%, val_best:  88.27%, tr:  98.73%, tr_best:  98.78%, epoch time: 97.36 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-53  lr=['0.0009766'], tr/val_loss:  2.311611/  2.309388, val:  80.75%, val_best:  88.27%, tr:  98.64%, tr_best:  98.78%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-54  lr=['0.0009766'], tr/val_loss:  2.312518/  2.322864, val:  83.63%, val_best:  88.27%, tr:  98.78%, tr_best:  98.78%, epoch time: 99.02 seconds, 1.65 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-55  lr=['0.0009766'], tr/val_loss:  2.312254/  2.320132, val:  78.10%, val_best:  88.27%, tr:  99.18%, tr_best:  99.18%, epoch time: 96.07 seconds, 1.60 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 35 occurrences\n",
      "test - Value 1: 417 occurrences\n",
      "epoch-56  lr=['0.0009766'], tr/val_loss:  2.311058/  2.347759, val:  57.74%, val_best:  88.27%, tr:  99.16%, tr_best:  99.18%, epoch time: 95.97 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-57  lr=['0.0009766'], tr/val_loss:  2.312773/  2.323204, val:  82.30%, val_best:  88.27%, tr:  98.98%, tr_best:  99.18%, epoch time: 97.23 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-58  lr=['0.0009766'], tr/val_loss:  2.308853/  2.300098, val:  87.39%, val_best:  88.27%, tr:  99.21%, tr_best:  99.21%, epoch time: 96.41 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-59  lr=['0.0009766'], tr/val_loss:  2.311842/  2.320115, val:  80.53%, val_best:  88.27%, tr:  99.31%, tr_best:  99.31%, epoch time: 98.03 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-60  lr=['0.0009766'], tr/val_loss:  2.314420/  2.300595, val:  83.19%, val_best:  88.27%, tr:  99.43%, tr_best:  99.43%, epoch time: 97.48 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-61  lr=['0.0009766'], tr/val_loss:  2.312645/  2.331306, val:  63.27%, val_best:  88.27%, tr:  99.06%, tr_best:  99.43%, epoch time: 98.18 seconds, 1.64 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-62  lr=['0.0009766'], tr/val_loss:  2.310871/  2.315062, val:  82.74%, val_best:  88.27%, tr:  99.13%, tr_best:  99.43%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-63  lr=['0.0009766'], tr/val_loss:  2.306909/  2.330261, val:  65.27%, val_best:  88.27%, tr:  98.98%, tr_best:  99.43%, epoch time: 93.86 seconds, 1.56 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-64  lr=['0.0009766'], tr/val_loss:  2.311231/  2.326822, val:  82.08%, val_best:  88.27%, tr:  99.21%, tr_best:  99.43%, epoch time: 94.10 seconds, 1.57 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-65  lr=['0.0009766'], tr/val_loss:  2.311931/  2.319584, val:  82.30%, val_best:  88.27%, tr:  99.28%, tr_best:  99.43%, epoch time: 94.21 seconds, 1.57 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-66  lr=['0.0009766'], tr/val_loss:  2.310076/  2.327409, val:  80.75%, val_best:  88.27%, tr:  99.28%, tr_best:  99.43%, epoch time: 96.76 seconds, 1.61 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-67  lr=['0.0009766'], tr/val_loss:  2.312743/  2.327190, val:  73.01%, val_best:  88.27%, tr:  98.64%, tr_best:  99.43%, epoch time: 98.18 seconds, 1.64 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-68  lr=['0.0009766'], tr/val_loss:  2.311855/  2.311643, val:  86.73%, val_best:  88.27%, tr:  98.59%, tr_best:  99.43%, epoch time: 96.82 seconds, 1.61 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-69  lr=['0.0009766'], tr/val_loss:  2.310919/  2.317065, val:  86.06%, val_best:  88.27%, tr:  98.91%, tr_best:  99.43%, epoch time: 96.42 seconds, 1.61 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-70  lr=['0.0009766'], tr/val_loss:  2.312693/  2.340101, val:  61.73%, val_best:  88.27%, tr:  98.96%, tr_best:  99.43%, epoch time: 97.63 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-71  lr=['0.0009766'], tr/val_loss:  2.312778/  2.304077, val:  84.73%, val_best:  88.27%, tr:  99.28%, tr_best:  99.43%, epoch time: 97.32 seconds, 1.62 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-72  lr=['0.0009766'], tr/val_loss:  2.314240/  2.312671, val:  80.09%, val_best:  88.27%, tr:  99.08%, tr_best:  99.43%, epoch time: 97.04 seconds, 1.62 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-73  lr=['0.0009766'], tr/val_loss:  2.316049/  2.327498, val:  72.35%, val_best:  88.27%, tr:  99.11%, tr_best:  99.43%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-74  lr=['0.0009766'], tr/val_loss:  2.315227/  2.322699, val:  80.97%, val_best:  88.27%, tr:  99.48%, tr_best:  99.48%, epoch time: 96.77 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-75  lr=['0.0009766'], tr/val_loss:  2.311346/  2.319957, val:  76.33%, val_best:  88.27%, tr:  99.01%, tr_best:  99.48%, epoch time: 96.50 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-76  lr=['0.0009766'], tr/val_loss:  2.309829/  2.317562, val:  81.42%, val_best:  88.27%, tr:  99.31%, tr_best:  99.48%, epoch time: 98.10 seconds, 1.64 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-77  lr=['0.0009766'], tr/val_loss:  2.309110/  2.334780, val:  72.57%, val_best:  88.27%, tr:  99.23%, tr_best:  99.48%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-78  lr=['0.0009766'], tr/val_loss:  2.308938/  2.329291, val:  64.38%, val_best:  88.27%, tr:  99.16%, tr_best:  99.48%, epoch time: 95.40 seconds, 1.59 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-79  lr=['0.0009766'], tr/val_loss:  2.315950/  2.330761, val:  78.98%, val_best:  88.27%, tr:  99.06%, tr_best:  99.48%, epoch time: 96.64 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-80  lr=['0.0009766'], tr/val_loss:  2.318177/  2.327118, val:  85.84%, val_best:  88.27%, tr:  99.38%, tr_best:  99.48%, epoch time: 97.34 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-81  lr=['0.0009766'], tr/val_loss:  2.312660/  2.317145, val:  82.30%, val_best:  88.27%, tr:  99.58%, tr_best:  99.58%, epoch time: 97.68 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-82  lr=['0.0009766'], tr/val_loss:  2.316556/  2.315850, val:  76.77%, val_best:  88.27%, tr:  99.43%, tr_best:  99.58%, epoch time: 96.19 seconds, 1.60 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-83  lr=['0.0009766'], tr/val_loss:  2.315464/  2.337496, val:  74.78%, val_best:  88.27%, tr:  99.48%, tr_best:  99.58%, epoch time: 95.45 seconds, 1.59 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-84  lr=['0.0009766'], tr/val_loss:  2.317396/  2.321684, val:  73.23%, val_best:  88.27%, tr:  99.40%, tr_best:  99.58%, epoch time: 95.18 seconds, 1.59 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-85  lr=['0.0009766'], tr/val_loss:  2.315092/  2.313392, val:  80.97%, val_best:  88.27%, tr:  99.50%, tr_best:  99.58%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-86  lr=['0.0009766'], tr/val_loss:  2.315912/  2.317325, val:  68.58%, val_best:  88.27%, tr:  99.73%, tr_best:  99.73%, epoch time: 97.44 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-87  lr=['0.0009766'], tr/val_loss:  2.317096/  2.314558, val:  77.65%, val_best:  88.27%, tr:  99.50%, tr_best:  99.73%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-88  lr=['0.0009766'], tr/val_loss:  2.311808/  2.297653, val:  86.95%, val_best:  88.27%, tr:  99.38%, tr_best:  99.73%, epoch time: 97.56 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-89  lr=['0.0009766'], tr/val_loss:  2.312949/  2.336401, val:  71.02%, val_best:  88.27%, tr:  99.78%, tr_best:  99.78%, epoch time: 97.09 seconds, 1.62 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-90  lr=['0.0009766'], tr/val_loss:  2.313704/  2.333723, val:  83.63%, val_best:  88.27%, tr:  99.48%, tr_best:  99.78%, epoch time: 97.13 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-91  lr=['0.0009766'], tr/val_loss:  2.317074/  2.324239, val:  71.68%, val_best:  88.27%, tr:  99.48%, tr_best:  99.78%, epoch time: 97.84 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-92  lr=['0.0009766'], tr/val_loss:  2.314854/  2.362285, val:  63.05%, val_best:  88.27%, tr:  99.63%, tr_best:  99.78%, epoch time: 97.42 seconds, 1.62 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-93  lr=['0.0009766'], tr/val_loss:  2.314456/  2.331638, val:  74.12%, val_best:  88.27%, tr:  99.78%, tr_best:  99.78%, epoch time: 97.93 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-94  lr=['0.0009766'], tr/val_loss:  2.314472/  2.315668, val:  78.10%, val_best:  88.27%, tr:  99.73%, tr_best:  99.78%, epoch time: 96.86 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 50 occurrences\n",
      "test - Value 1: 402 occurrences\n",
      "epoch-95  lr=['0.0009766'], tr/val_loss:  2.314734/  2.329490, val:  61.06%, val_best:  88.27%, tr:  99.45%, tr_best:  99.78%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-96  lr=['0.0009766'], tr/val_loss:  2.314462/  2.326687, val:  73.23%, val_best:  88.27%, tr:  99.43%, tr_best:  99.78%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-97  lr=['0.0009766'], tr/val_loss:  2.316176/  2.352482, val:  66.15%, val_best:  88.27%, tr:  99.63%, tr_best:  99.78%, epoch time: 97.31 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-98  lr=['0.0009766'], tr/val_loss:  2.317838/  2.343549, val:  63.05%, val_best:  88.27%, tr:  99.65%, tr_best:  99.78%, epoch time: 97.31 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-99  lr=['0.0009766'], tr/val_loss:  2.314526/  2.326027, val:  75.44%, val_best:  88.27%, tr:  99.85%, tr_best:  99.85%, epoch time: 96.26 seconds, 1.60 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-100 lr=['0.0009766'], tr/val_loss:  2.309603/  2.348660, val:  61.50%, val_best:  88.27%, tr:  99.50%, tr_best:  99.85%, epoch time: 94.20 seconds, 1.57 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-101 lr=['0.0009766'], tr/val_loss:  2.310724/  2.306595, val:  87.17%, val_best:  88.27%, tr:  99.50%, tr_best:  99.85%, epoch time: 94.83 seconds, 1.58 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-102 lr=['0.0009766'], tr/val_loss:  2.310528/  2.319308, val:  82.52%, val_best:  88.27%, tr:  99.50%, tr_best:  99.85%, epoch time: 95.29 seconds, 1.59 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-103 lr=['0.0009766'], tr/val_loss:  2.315188/  2.344586, val:  55.31%, val_best:  88.27%, tr:  99.45%, tr_best:  99.85%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-104 lr=['0.0009766'], tr/val_loss:  2.316666/  2.320139, val:  81.19%, val_best:  88.27%, tr:  99.45%, tr_best:  99.85%, epoch time: 98.63 seconds, 1.64 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-105 lr=['0.0009766'], tr/val_loss:  2.311910/  2.330587, val:  69.69%, val_best:  88.27%, tr:  99.63%, tr_best:  99.85%, epoch time: 96.33 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-106 lr=['0.0009766'], tr/val_loss:  2.312634/  2.322598, val:  71.68%, val_best:  88.27%, tr:  99.60%, tr_best:  99.85%, epoch time: 96.36 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-107 lr=['0.0009766'], tr/val_loss:  2.310086/  2.318918, val:  81.86%, val_best:  88.27%, tr:  99.63%, tr_best:  99.85%, epoch time: 96.86 seconds, 1.61 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-108 lr=['0.0009766'], tr/val_loss:  2.310707/  2.343481, val:  69.25%, val_best:  88.27%, tr:  99.58%, tr_best:  99.85%, epoch time: 98.15 seconds, 1.64 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-109 lr=['0.0009766'], tr/val_loss:  2.316316/  2.327975, val:  74.78%, val_best:  88.27%, tr:  99.58%, tr_best:  99.85%, epoch time: 97.23 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-110 lr=['0.0009766'], tr/val_loss:  2.316413/  2.328148, val:  85.84%, val_best:  88.27%, tr:  99.65%, tr_best:  99.85%, epoch time: 95.20 seconds, 1.59 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-111 lr=['0.0009766'], tr/val_loss:  2.314428/  2.343702, val:  76.55%, val_best:  88.27%, tr:  99.58%, tr_best:  99.85%, epoch time: 96.06 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-112 lr=['0.0009766'], tr/val_loss:  2.317137/  2.345792, val:  73.67%, val_best:  88.27%, tr:  99.68%, tr_best:  99.85%, epoch time: 98.00 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-113 lr=['0.0009766'], tr/val_loss:  2.313743/  2.326295, val:  78.76%, val_best:  88.27%, tr:  99.48%, tr_best:  99.85%, epoch time: 98.21 seconds, 1.64 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-114 lr=['0.0009766'], tr/val_loss:  2.315037/  2.318459, val:  88.27%, val_best:  88.27%, tr:  99.55%, tr_best:  99.85%, epoch time: 97.85 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-115 lr=['0.0009766'], tr/val_loss:  2.316308/  2.352427, val:  64.16%, val_best:  88.27%, tr:  99.53%, tr_best:  99.85%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-116 lr=['0.0009766'], tr/val_loss:  2.316529/  2.330134, val:  76.77%, val_best:  88.27%, tr:  99.73%, tr_best:  99.85%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-117 lr=['0.0009766'], tr/val_loss:  2.320045/  2.333174, val:  75.88%, val_best:  88.27%, tr:  99.78%, tr_best:  99.85%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-118 lr=['0.0009766'], tr/val_loss:  2.315387/  2.335317, val:  75.66%, val_best:  88.27%, tr:  99.55%, tr_best:  99.85%, epoch time: 98.73 seconds, 1.65 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-119 lr=['0.0009766'], tr/val_loss:  2.314011/  2.319288, val:  80.53%, val_best:  88.27%, tr:  99.63%, tr_best:  99.85%, epoch time: 98.12 seconds, 1.64 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-120 lr=['0.0009766'], tr/val_loss:  2.313557/  2.329696, val:  69.47%, val_best:  88.27%, tr:  99.75%, tr_best:  99.85%, epoch time: 97.52 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-121 lr=['0.0009766'], tr/val_loss:  2.317258/  2.315632, val:  77.21%, val_best:  88.27%, tr:  99.68%, tr_best:  99.85%, epoch time: 98.06 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-122 lr=['0.0009766'], tr/val_loss:  2.315098/  2.333739, val:  69.25%, val_best:  88.27%, tr:  99.68%, tr_best:  99.85%, epoch time: 98.19 seconds, 1.64 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-123 lr=['0.0009766'], tr/val_loss:  2.314250/  2.339246, val:  75.66%, val_best:  88.27%, tr:  99.63%, tr_best:  99.85%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-124 lr=['0.0009766'], tr/val_loss:  2.316317/  2.319112, val:  77.43%, val_best:  88.27%, tr:  99.70%, tr_best:  99.85%, epoch time: 98.14 seconds, 1.64 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-125 lr=['0.0009766'], tr/val_loss:  2.316380/  2.342396, val:  81.86%, val_best:  88.27%, tr:  99.58%, tr_best:  99.85%, epoch time: 97.34 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-126 lr=['0.0009766'], tr/val_loss:  2.321125/  2.326879, val:  80.53%, val_best:  88.27%, tr:  99.78%, tr_best:  99.85%, epoch time: 96.04 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-127 lr=['0.0009766'], tr/val_loss:  2.320115/  2.322524, val:  79.65%, val_best:  88.27%, tr:  99.63%, tr_best:  99.85%, epoch time: 97.97 seconds, 1.63 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-128 lr=['0.0009766'], tr/val_loss:  2.317250/  2.332874, val:  76.11%, val_best:  88.27%, tr:  99.75%, tr_best:  99.85%, epoch time: 96.82 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-129 lr=['0.0009766'], tr/val_loss:  2.317658/  2.327240, val:  76.55%, val_best:  88.27%, tr:  99.88%, tr_best:  99.88%, epoch time: 97.83 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-130 lr=['0.0009766'], tr/val_loss:  2.317392/  2.316608, val:  81.19%, val_best:  88.27%, tr:  99.68%, tr_best:  99.88%, epoch time: 97.79 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-131 lr=['0.0009766'], tr/val_loss:  2.319201/  2.330024, val:  75.00%, val_best:  88.27%, tr:  99.65%, tr_best:  99.88%, epoch time: 97.23 seconds, 1.62 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-132 lr=['0.0009766'], tr/val_loss:  2.317947/  2.345841, val:  69.03%, val_best:  88.27%, tr:  99.68%, tr_best:  99.88%, epoch time: 97.18 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-133 lr=['0.0009766'], tr/val_loss:  2.316299/  2.325052, val:  89.38%, val_best:  89.38%, tr:  99.73%, tr_best:  99.88%, epoch time: 96.40 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-134 lr=['0.0009766'], tr/val_loss:  2.318860/  2.326544, val:  78.54%, val_best:  89.38%, tr:  99.70%, tr_best:  99.88%, epoch time: 96.49 seconds, 1.61 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-135 lr=['0.0009766'], tr/val_loss:  2.320425/  2.332841, val:  75.88%, val_best:  89.38%, tr:  99.70%, tr_best:  99.88%, epoch time: 96.79 seconds, 1.61 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-136 lr=['0.0009766'], tr/val_loss:  2.322468/  2.339650, val:  69.91%, val_best:  89.38%, tr:  99.70%, tr_best:  99.88%, epoch time: 94.84 seconds, 1.58 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-137 lr=['0.0009766'], tr/val_loss:  2.314576/  2.320779, val:  86.50%, val_best:  89.38%, tr:  99.78%, tr_best:  99.88%, epoch time: 93.38 seconds, 1.56 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-138 lr=['0.0009766'], tr/val_loss:  2.318925/  2.310222, val:  78.76%, val_best:  89.38%, tr:  99.75%, tr_best:  99.88%, epoch time: 93.66 seconds, 1.56 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-139 lr=['0.0009766'], tr/val_loss:  2.314136/  2.330124, val:  87.61%, val_best:  89.38%, tr:  99.78%, tr_best:  99.88%, epoch time: 96.77 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-140 lr=['0.0009766'], tr/val_loss:  2.316517/  2.345308, val:  71.02%, val_best:  89.38%, tr:  99.83%, tr_best:  99.88%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-141 lr=['0.0009766'], tr/val_loss:  2.322521/  2.365978, val:  62.61%, val_best:  89.38%, tr:  99.70%, tr_best:  99.88%, epoch time: 96.28 seconds, 1.60 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-142 lr=['0.0009766'], tr/val_loss:  2.322254/  2.325057, val:  80.53%, val_best:  89.38%, tr:  99.85%, tr_best:  99.88%, epoch time: 97.27 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-143 lr=['0.0009766'], tr/val_loss:  2.319231/  2.332730, val:  81.42%, val_best:  89.38%, tr:  99.78%, tr_best:  99.88%, epoch time: 97.51 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-144 lr=['0.0009766'], tr/val_loss:  2.320696/  2.325719, val:  84.73%, val_best:  89.38%, tr:  99.73%, tr_best:  99.88%, epoch time: 97.01 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-145 lr=['0.0009766'], tr/val_loss:  2.317853/  2.333780, val:  84.73%, val_best:  89.38%, tr:  99.63%, tr_best:  99.88%, epoch time: 97.39 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-146 lr=['0.0009766'], tr/val_loss:  2.312672/  2.317819, val:  72.12%, val_best:  89.38%, tr:  99.73%, tr_best:  99.88%, epoch time: 96.01 seconds, 1.60 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-147 lr=['0.0009766'], tr/val_loss:  2.315773/  2.332511, val:  75.88%, val_best:  89.38%, tr:  99.75%, tr_best:  99.88%, epoch time: 97.76 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-148 lr=['0.0009766'], tr/val_loss:  2.314075/  2.321023, val:  81.19%, val_best:  89.38%, tr:  99.68%, tr_best:  99.88%, epoch time: 97.51 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-149 lr=['0.0009766'], tr/val_loss:  2.311828/  2.340612, val:  79.65%, val_best:  89.38%, tr:  99.85%, tr_best:  99.88%, epoch time: 96.48 seconds, 1.61 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-150 lr=['0.0009766'], tr/val_loss:  2.317495/  2.332778, val:  77.43%, val_best:  89.38%, tr:  99.78%, tr_best:  99.88%, epoch time: 97.40 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-151 lr=['0.0009766'], tr/val_loss:  2.321185/  2.325787, val:  76.11%, val_best:  89.38%, tr:  99.90%, tr_best:  99.90%, epoch time: 96.39 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-152 lr=['0.0009766'], tr/val_loss:  2.321434/  2.333876, val:  73.45%, val_best:  89.38%, tr:  99.88%, tr_best:  99.90%, epoch time: 97.41 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-153 lr=['0.0009766'], tr/val_loss:  2.318927/  2.343238, val:  67.70%, val_best:  89.38%, tr:  99.75%, tr_best:  99.90%, epoch time: 96.87 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-154 lr=['0.0009766'], tr/val_loss:  2.320183/  2.333080, val:  78.10%, val_best:  89.38%, tr:  99.83%, tr_best:  99.90%, epoch time: 98.38 seconds, 1.64 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-155 lr=['0.0009766'], tr/val_loss:  2.320441/  2.333167, val:  79.65%, val_best:  89.38%, tr:  99.78%, tr_best:  99.90%, epoch time: 97.81 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-156 lr=['0.0009766'], tr/val_loss:  2.321870/  2.323608, val:  79.42%, val_best:  89.38%, tr:  99.80%, tr_best:  99.90%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-157 lr=['0.0009766'], tr/val_loss:  2.321411/  2.327359, val:  85.62%, val_best:  89.38%, tr:  99.83%, tr_best:  99.90%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-158 lr=['0.0009766'], tr/val_loss:  2.322502/  2.351048, val:  73.45%, val_best:  89.38%, tr:  99.90%, tr_best:  99.90%, epoch time: 97.85 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-159 lr=['0.0009766'], tr/val_loss:  2.323279/  2.331862, val:  79.42%, val_best:  89.38%, tr:  99.90%, tr_best:  99.90%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-160 lr=['0.0009766'], tr/val_loss:  2.321311/  2.338167, val:  77.21%, val_best:  89.38%, tr:  99.80%, tr_best:  99.90%, epoch time: 95.92 seconds, 1.60 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-161 lr=['0.0009766'], tr/val_loss:  2.321275/  2.334751, val:  70.13%, val_best:  89.38%, tr:  99.80%, tr_best:  99.90%, epoch time: 95.69 seconds, 1.59 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-162 lr=['0.0009766'], tr/val_loss:  2.316679/  2.332910, val:  73.67%, val_best:  89.38%, tr:  99.93%, tr_best:  99.93%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-163 lr=['0.0009766'], tr/val_loss:  2.316684/  2.340697, val:  69.69%, val_best:  89.38%, tr:  99.80%, tr_best:  99.93%, epoch time: 98.12 seconds, 1.64 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-164 lr=['0.0009766'], tr/val_loss:  2.319405/  2.342907, val:  75.66%, val_best:  89.38%, tr:  99.83%, tr_best:  99.93%, epoch time: 96.01 seconds, 1.60 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-165 lr=['0.0009766'], tr/val_loss:  2.323514/  2.331270, val:  76.99%, val_best:  89.38%, tr:  99.75%, tr_best:  99.93%, epoch time: 96.36 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-166 lr=['0.0009766'], tr/val_loss:  2.320742/  2.323463, val:  82.30%, val_best:  89.38%, tr:  99.90%, tr_best:  99.93%, epoch time: 95.56 seconds, 1.59 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-167 lr=['0.0009766'], tr/val_loss:  2.320729/  2.342273, val:  71.46%, val_best:  89.38%, tr:  99.85%, tr_best:  99.93%, epoch time: 97.13 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-168 lr=['0.0009766'], tr/val_loss:  2.317882/  2.339055, val:  79.65%, val_best:  89.38%, tr:  99.80%, tr_best:  99.93%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-169 lr=['0.0009766'], tr/val_loss:  2.317018/  2.341807, val:  75.44%, val_best:  89.38%, tr:  99.93%, tr_best:  99.93%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-170 lr=['0.0009766'], tr/val_loss:  2.317647/  2.335222, val:  67.26%, val_best:  89.38%, tr: 100.00%, tr_best: 100.00%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-171 lr=['0.0009766'], tr/val_loss:  2.323178/  2.334864, val:  76.55%, val_best:  89.38%, tr:  99.93%, tr_best: 100.00%, epoch time: 97.98 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-172 lr=['0.0009766'], tr/val_loss:  2.326962/  2.345321, val:  78.32%, val_best:  89.38%, tr:  99.90%, tr_best: 100.00%, epoch time: 95.18 seconds, 1.59 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-173 lr=['0.0009766'], tr/val_loss:  2.323847/  2.343538, val:  79.87%, val_best:  89.38%, tr:  99.98%, tr_best: 100.00%, epoch time: 94.30 seconds, 1.57 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-174 lr=['0.0009766'], tr/val_loss:  2.322079/  2.344137, val:  77.88%, val_best:  89.38%, tr:  99.90%, tr_best: 100.00%, epoch time: 93.77 seconds, 1.56 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-175 lr=['0.0009766'], tr/val_loss:  2.324055/  2.359512, val:  64.38%, val_best:  89.38%, tr:  99.85%, tr_best: 100.00%, epoch time: 95.09 seconds, 1.58 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-176 lr=['0.0009766'], tr/val_loss:  2.324633/  2.344954, val:  73.45%, val_best:  89.38%, tr:  99.80%, tr_best: 100.00%, epoch time: 97.90 seconds, 1.63 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-177 lr=['0.0009766'], tr/val_loss:  2.319456/  2.355152, val:  71.90%, val_best:  89.38%, tr:  99.85%, tr_best: 100.00%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-178 lr=['0.0009766'], tr/val_loss:  2.320226/  2.340982, val:  71.02%, val_best:  89.38%, tr:  99.90%, tr_best: 100.00%, epoch time: 97.03 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-179 lr=['0.0009766'], tr/val_loss:  2.320514/  2.340420, val:  81.42%, val_best:  89.38%, tr:  99.93%, tr_best: 100.00%, epoch time: 98.09 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-180 lr=['0.0009766'], tr/val_loss:  2.316873/  2.342558, val:  80.09%, val_best:  89.38%, tr:  99.85%, tr_best: 100.00%, epoch time: 96.49 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-181 lr=['0.0009766'], tr/val_loss:  2.320735/  2.340189, val:  84.29%, val_best:  89.38%, tr:  99.88%, tr_best: 100.00%, epoch time: 97.71 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-182 lr=['0.0009766'], tr/val_loss:  2.321161/  2.349785, val:  73.01%, val_best:  89.38%, tr:  99.85%, tr_best: 100.00%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-183 lr=['0.0009766'], tr/val_loss:  2.327313/  2.338586, val:  82.08%, val_best:  89.38%, tr:  99.85%, tr_best: 100.00%, epoch time: 97.62 seconds, 1.63 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-184 lr=['0.0009766'], tr/val_loss:  2.317947/  2.324453, val:  82.96%, val_best:  89.38%, tr:  99.80%, tr_best: 100.00%, epoch time: 97.73 seconds, 1.63 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 85 occurrences\n",
      "test - Value 1: 367 occurrences\n",
      "epoch-185 lr=['0.0009766'], tr/val_loss:  2.317389/  2.348542, val:  68.81%, val_best:  89.38%, tr:  99.88%, tr_best: 100.00%, epoch time: 96.49 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-186 lr=['0.0009766'], tr/val_loss:  2.323144/  2.343061, val:  71.24%, val_best:  89.38%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.20 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-187 lr=['0.0009766'], tr/val_loss:  2.326092/  2.358353, val:  75.22%, val_best:  89.38%, tr: 100.00%, tr_best: 100.00%, epoch time: 96.42 seconds, 1.61 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-188 lr=['0.0009766'], tr/val_loss:  2.324155/  2.333860, val:  77.88%, val_best:  89.38%, tr:  99.95%, tr_best: 100.00%, epoch time: 96.64 seconds, 1.61 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-189 lr=['0.0009766'], tr/val_loss:  2.324759/  2.352545, val:  67.92%, val_best:  89.38%, tr:  99.95%, tr_best: 100.00%, epoch time: 96.24 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-190 lr=['0.0009766'], tr/val_loss:  2.327331/  2.326066, val:  83.41%, val_best:  89.38%, tr:  99.93%, tr_best: 100.00%, epoch time: 97.78 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-191 lr=['0.0009766'], tr/val_loss:  2.327865/  2.338473, val:  72.35%, val_best:  89.38%, tr:  99.93%, tr_best: 100.00%, epoch time: 97.73 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-192 lr=['0.0009766'], tr/val_loss:  2.326020/  2.362288, val:  72.35%, val_best:  89.38%, tr:  99.88%, tr_best: 100.00%, epoch time: 95.89 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-193 lr=['0.0009766'], tr/val_loss:  2.319108/  2.331161, val:  80.31%, val_best:  89.38%, tr:  99.83%, tr_best: 100.00%, epoch time: 94.94 seconds, 1.58 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-194 lr=['0.0009766'], tr/val_loss:  2.322528/  2.318147, val:  81.86%, val_best:  89.38%, tr:  99.83%, tr_best: 100.00%, epoch time: 97.69 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-195 lr=['0.0009766'], tr/val_loss:  2.323811/  2.347255, val:  75.66%, val_best:  89.38%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-196 lr=['0.0009766'], tr/val_loss:  2.326517/  2.335956, val:  74.56%, val_best:  89.38%, tr:  99.93%, tr_best: 100.00%, epoch time: 96.83 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-197 lr=['0.0009766'], tr/val_loss:  2.320080/  2.361651, val:  65.71%, val_best:  89.38%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.91 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-198 lr=['0.0009766'], tr/val_loss:  2.328966/  2.339468, val:  76.99%, val_best:  89.38%, tr:  99.93%, tr_best: 100.00%, epoch time: 96.90 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-199 lr=['0.0009766'], tr/val_loss:  2.323821/  2.345324, val:  83.85%, val_best:  89.38%, tr:  99.90%, tr_best: 100.00%, epoch time: 97.57 seconds, 1.63 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceb9af8969c41b1a8fc5de07ea461b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÜ‚ñÅ‚ñá‚ñÑ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñÜ‚ñá</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÜ‚ñÅ‚ñá‚ñÑ‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñÖ‚ñá</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99901</td></tr><tr><td>tr_epoch_loss</td><td>2.32382</td></tr><tr><td>val_acc_best</td><td>0.89381</td></tr><tr><td>val_acc_now</td><td>0.8385</td></tr><tr><td>val_loss</td><td>2.34532</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-2</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pcpie2t1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/pcpie2t1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250805_235257-pcpie2t1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9b4rih76 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00048828125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_051704-9b4rih76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/9b4rih76' target=\"_blank\">deft-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/9b4rih76' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/9b4rih76</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250806_051712_919', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.03125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00048828125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-12, -12], [-12, -12], [-11, -11]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.03125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00048828125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-0   lr=['0.0004883'], tr/val_loss:  2.307143/  2.315368, val:  67.04%, val_best:  67.04%, tr:  68.56%, tr_best:  68.56%, epoch time: 98.05 seconds, 1.63 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-1   lr=['0.0004883'], tr/val_loss:  2.304245/  2.303405, val:  75.88%, val_best:  75.88%, tr:  82.23%, tr_best:  82.23%, epoch time: 98.77 seconds, 1.65 minutes\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-2   lr=['0.0004883'], tr/val_loss:  2.303979/  2.289195, val:  73.01%, val_best:  75.88%, tr:  87.77%, tr_best:  87.77%, epoch time: 96.82 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-3   lr=['0.0004883'], tr/val_loss:  2.303951/  2.332205, val:  68.36%, val_best:  75.88%, tr:  91.32%, tr_best:  91.32%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-4   lr=['0.0004883'], tr/val_loss:  2.304697/  2.301692, val:  78.76%, val_best:  78.76%, tr:  92.53%, tr_best:  92.53%, epoch time: 97.85 seconds, 1.63 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 21 occurrences\n",
      "test - Value 1: 431 occurrences\n",
      "epoch-5   lr=['0.0004883'], tr/val_loss:  2.302842/  2.316729, val:  54.65%, val_best:  78.76%, tr:  94.19%, tr_best:  94.19%, epoch time: 98.29 seconds, 1.64 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-6   lr=['0.0004883'], tr/val_loss:  2.305261/  2.323383, val:  76.55%, val_best:  78.76%, tr:  93.97%, tr_best:  94.19%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-7   lr=['0.0004883'], tr/val_loss:  2.305554/  2.304406, val:  86.50%, val_best:  86.50%, tr:  95.36%, tr_best:  95.36%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-8   lr=['0.0004883'], tr/val_loss:  2.305240/  2.316414, val:  83.63%, val_best:  86.50%, tr:  95.86%, tr_best:  95.86%, epoch time: 95.51 seconds, 1.59 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-9   lr=['0.0004883'], tr/val_loss:  2.302709/  2.303303, val:  79.87%, val_best:  86.50%, tr:  95.88%, tr_best:  95.88%, epoch time: 93.78 seconds, 1.56 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-10  lr=['0.0004883'], tr/val_loss:  2.306251/  2.290444, val:  83.85%, val_best:  86.50%, tr:  97.17%, tr_best:  97.17%, epoch time: 94.23 seconds, 1.57 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-11  lr=['0.0004883'], tr/val_loss:  2.304010/  2.314265, val:  69.91%, val_best:  86.50%, tr:  96.72%, tr_best:  97.17%, epoch time: 95.81 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-12  lr=['0.0004883'], tr/val_loss:  2.305857/  2.321690, val:  86.73%, val_best:  86.73%, tr:  96.35%, tr_best:  97.17%, epoch time: 98.72 seconds, 1.65 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-13  lr=['0.0004883'], tr/val_loss:  2.306493/  2.308418, val:  87.17%, val_best:  87.17%, tr:  96.53%, tr_best:  97.17%, epoch time: 96.99 seconds, 1.62 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-14  lr=['0.0004883'], tr/val_loss:  2.303915/  2.325130, val:  63.72%, val_best:  87.17%, tr:  97.44%, tr_best:  97.44%, epoch time: 97.29 seconds, 1.62 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-15  lr=['0.0004883'], tr/val_loss:  2.307183/  2.322496, val:  65.93%, val_best:  87.17%, tr:  97.89%, tr_best:  97.89%, epoch time: 95.36 seconds, 1.59 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-16  lr=['0.0004883'], tr/val_loss:  2.306007/  2.307975, val:  73.23%, val_best:  87.17%, tr:  98.16%, tr_best:  98.16%, epoch time: 97.35 seconds, 1.62 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-17  lr=['0.0004883'], tr/val_loss:  2.304910/  2.328265, val:  74.78%, val_best:  87.17%, tr:  97.79%, tr_best:  98.16%, epoch time: 96.93 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-18  lr=['0.0004883'], tr/val_loss:  2.310005/  2.324833, val:  63.94%, val_best:  87.17%, tr:  97.92%, tr_best:  98.16%, epoch time: 96.61 seconds, 1.61 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-19  lr=['0.0004883'], tr/val_loss:  2.308440/  2.322912, val:  64.16%, val_best:  87.17%, tr:  98.19%, tr_best:  98.19%, epoch time: 96.76 seconds, 1.61 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-20  lr=['0.0004883'], tr/val_loss:  2.304862/  2.302225, val:  86.28%, val_best:  87.17%, tr:  98.49%, tr_best:  98.49%, epoch time: 96.57 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-21  lr=['0.0004883'], tr/val_loss:  2.305092/  2.307018, val:  85.62%, val_best:  87.17%, tr:  98.36%, tr_best:  98.49%, epoch time: 97.89 seconds, 1.63 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-22  lr=['0.0004883'], tr/val_loss:  2.311375/  2.324977, val:  69.69%, val_best:  87.17%, tr:  98.41%, tr_best:  98.49%, epoch time: 97.21 seconds, 1.62 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-23  lr=['0.0004883'], tr/val_loss:  2.309449/  2.312011, val:  80.53%, val_best:  87.17%, tr:  98.39%, tr_best:  98.49%, epoch time: 96.68 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-24  lr=['0.0004883'], tr/val_loss:  2.308234/  2.309932, val:  84.96%, val_best:  87.17%, tr:  98.59%, tr_best:  98.59%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-25  lr=['0.0004883'], tr/val_loss:  2.306607/  2.301554, val:  81.42%, val_best:  87.17%, tr:  98.29%, tr_best:  98.59%, epoch time: 97.40 seconds, 1.62 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-26  lr=['0.0004883'], tr/val_loss:  2.307109/  2.322904, val:  78.98%, val_best:  87.17%, tr:  98.59%, tr_best:  98.59%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-27  lr=['0.0004883'], tr/val_loss:  2.308624/  2.300132, val:  88.50%, val_best:  88.50%, tr:  98.98%, tr_best:  98.98%, epoch time: 97.54 seconds, 1.63 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-28  lr=['0.0004883'], tr/val_loss:  2.308100/  2.313970, val:  81.19%, val_best:  88.50%, tr:  98.73%, tr_best:  98.98%, epoch time: 96.03 seconds, 1.60 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-29  lr=['0.0004883'], tr/val_loss:  2.308666/  2.309304, val:  79.87%, val_best:  88.50%, tr:  99.06%, tr_best:  99.06%, epoch time: 97.21 seconds, 1.62 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-30  lr=['0.0004883'], tr/val_loss:  2.310085/  2.312569, val:  86.73%, val_best:  88.50%, tr:  98.93%, tr_best:  99.06%, epoch time: 97.18 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-31  lr=['0.0004883'], tr/val_loss:  2.306438/  2.316588, val:  63.72%, val_best:  88.50%, tr:  99.16%, tr_best:  99.16%, epoch time: 98.51 seconds, 1.64 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-32  lr=['0.0004883'], tr/val_loss:  2.309205/  2.325188, val:  68.58%, val_best:  88.50%, tr:  98.64%, tr_best:  99.16%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-33  lr=['0.0004883'], tr/val_loss:  2.308202/  2.319031, val:  82.08%, val_best:  88.50%, tr:  99.13%, tr_best:  99.16%, epoch time: 96.46 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-34  lr=['0.0004883'], tr/val_loss:  2.307597/  2.333796, val:  77.43%, val_best:  88.50%, tr:  99.16%, tr_best:  99.16%, epoch time: 96.55 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-35  lr=['0.0004883'], tr/val_loss:  2.307220/  2.315392, val:  69.91%, val_best:  88.50%, tr:  99.11%, tr_best:  99.16%, epoch time: 97.45 seconds, 1.62 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-36  lr=['0.0004883'], tr/val_loss:  2.308604/  2.317859, val:  82.74%, val_best:  88.50%, tr:  98.88%, tr_best:  99.16%, epoch time: 96.87 seconds, 1.61 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-37  lr=['0.0004883'], tr/val_loss:  2.308928/  2.326543, val:  54.87%, val_best:  88.50%, tr:  99.21%, tr_best:  99.21%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-38  lr=['0.0004883'], tr/val_loss:  2.310680/  2.323778, val:  84.51%, val_best:  88.50%, tr:  99.31%, tr_best:  99.31%, epoch time: 96.80 seconds, 1.61 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-39  lr=['0.0004883'], tr/val_loss:  2.307641/  2.313753, val:  81.19%, val_best:  88.50%, tr:  99.18%, tr_best:  99.31%, epoch time: 96.46 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-40  lr=['0.0004883'], tr/val_loss:  2.309500/  2.337375, val:  72.57%, val_best:  88.50%, tr:  99.50%, tr_best:  99.50%, epoch time: 96.88 seconds, 1.61 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-41  lr=['0.0004883'], tr/val_loss:  2.310786/  2.331746, val:  76.55%, val_best:  88.50%, tr:  99.40%, tr_best:  99.50%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-42  lr=['0.0004883'], tr/val_loss:  2.310127/  2.320058, val:  81.64%, val_best:  88.50%, tr:  99.43%, tr_best:  99.50%, epoch time: 96.37 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-43  lr=['0.0004883'], tr/val_loss:  2.317075/  2.307717, val:  82.30%, val_best:  88.50%, tr:  99.75%, tr_best:  99.75%, epoch time: 96.27 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-44  lr=['0.0004883'], tr/val_loss:  2.314561/  2.333340, val:  74.12%, val_best:  88.50%, tr:  99.58%, tr_best:  99.75%, epoch time: 95.15 seconds, 1.59 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-45  lr=['0.0004883'], tr/val_loss:  2.311076/  2.323547, val:  70.58%, val_best:  88.50%, tr:  99.50%, tr_best:  99.75%, epoch time: 95.29 seconds, 1.59 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-46  lr=['0.0004883'], tr/val_loss:  2.305609/  2.331589, val:  67.26%, val_best:  88.50%, tr:  99.63%, tr_best:  99.75%, epoch time: 93.40 seconds, 1.56 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-47  lr=['0.0004883'], tr/val_loss:  2.311338/  2.329282, val:  75.44%, val_best:  88.50%, tr:  99.33%, tr_best:  99.75%, epoch time: 94.10 seconds, 1.57 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-48  lr=['0.0004883'], tr/val_loss:  2.311132/  2.341869, val:  67.92%, val_best:  88.50%, tr:  99.40%, tr_best:  99.75%, epoch time: 96.45 seconds, 1.61 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-49  lr=['0.0004883'], tr/val_loss:  2.309031/  2.331848, val:  65.04%, val_best:  88.50%, tr:  99.60%, tr_best:  99.75%, epoch time: 96.50 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-50  lr=['0.0004883'], tr/val_loss:  2.308496/  2.328097, val:  69.69%, val_best:  88.50%, tr:  99.58%, tr_best:  99.75%, epoch time: 98.27 seconds, 1.64 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-51  lr=['0.0004883'], tr/val_loss:  2.310350/  2.309249, val:  75.22%, val_best:  88.50%, tr:  99.28%, tr_best:  99.75%, epoch time: 96.95 seconds, 1.62 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-52  lr=['0.0004883'], tr/val_loss:  2.311667/  2.311800, val:  79.65%, val_best:  88.50%, tr:  99.43%, tr_best:  99.75%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-53  lr=['0.0004883'], tr/val_loss:  2.313753/  2.328440, val:  77.43%, val_best:  88.50%, tr:  99.45%, tr_best:  99.75%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-54  lr=['0.0004883'], tr/val_loss:  2.313881/  2.331309, val:  78.10%, val_best:  88.50%, tr:  99.68%, tr_best:  99.75%, epoch time: 95.93 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-55  lr=['0.0004883'], tr/val_loss:  2.316322/  2.328126, val:  71.02%, val_best:  88.50%, tr:  99.58%, tr_best:  99.75%, epoch time: 97.99 seconds, 1.63 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-56  lr=['0.0004883'], tr/val_loss:  2.317210/  2.333509, val:  74.12%, val_best:  88.50%, tr:  99.45%, tr_best:  99.75%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-57  lr=['0.0004883'], tr/val_loss:  2.314278/  2.335791, val:  71.46%, val_best:  88.50%, tr:  99.68%, tr_best:  99.75%, epoch time: 97.86 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-58  lr=['0.0004883'], tr/val_loss:  2.316558/  2.328557, val:  73.67%, val_best:  88.50%, tr:  99.73%, tr_best:  99.75%, epoch time: 97.27 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-59  lr=['0.0004883'], tr/val_loss:  2.314261/  2.320790, val:  73.01%, val_best:  88.50%, tr:  99.75%, tr_best:  99.75%, epoch time: 96.76 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-60  lr=['0.0004883'], tr/val_loss:  2.312499/  2.323715, val:  71.24%, val_best:  88.50%, tr:  99.55%, tr_best:  99.75%, epoch time: 98.31 seconds, 1.64 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-61  lr=['0.0004883'], tr/val_loss:  2.313077/  2.355737, val:  72.79%, val_best:  88.50%, tr:  99.75%, tr_best:  99.75%, epoch time: 97.96 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-62  lr=['0.0004883'], tr/val_loss:  2.312150/  2.345931, val:  64.60%, val_best:  88.50%, tr:  99.68%, tr_best:  99.75%, epoch time: 98.02 seconds, 1.63 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-63  lr=['0.0004883'], tr/val_loss:  2.312751/  2.317065, val:  72.35%, val_best:  88.50%, tr:  99.58%, tr_best:  99.75%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-64  lr=['0.0004883'], tr/val_loss:  2.310981/  2.335438, val:  73.23%, val_best:  88.50%, tr:  99.73%, tr_best:  99.75%, epoch time: 97.56 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-65  lr=['0.0004883'], tr/val_loss:  2.316457/  2.338276, val:  76.11%, val_best:  88.50%, tr:  99.78%, tr_best:  99.78%, epoch time: 98.08 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-66  lr=['0.0004883'], tr/val_loss:  2.316676/  2.326343, val:  72.79%, val_best:  88.50%, tr:  99.70%, tr_best:  99.78%, epoch time: 97.72 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-67  lr=['0.0004883'], tr/val_loss:  2.316458/  2.329324, val:  71.02%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 97.79 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-68  lr=['0.0004883'], tr/val_loss:  2.316082/  2.318193, val:  75.66%, val_best:  88.50%, tr:  99.68%, tr_best:  99.83%, epoch time: 98.03 seconds, 1.63 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-69  lr=['0.0004883'], tr/val_loss:  2.315100/  2.329117, val:  86.50%, val_best:  88.50%, tr:  99.68%, tr_best:  99.83%, epoch time: 96.96 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-70  lr=['0.0004883'], tr/val_loss:  2.312791/  2.331612, val:  75.44%, val_best:  88.50%, tr:  99.75%, tr_best:  99.83%, epoch time: 95.55 seconds, 1.59 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-71  lr=['0.0004883'], tr/val_loss:  2.309851/  2.326882, val:  76.99%, val_best:  88.50%, tr:  99.78%, tr_best:  99.83%, epoch time: 96.26 seconds, 1.60 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-72  lr=['0.0004883'], tr/val_loss:  2.312209/  2.343230, val:  69.47%, val_best:  88.50%, tr:  99.78%, tr_best:  99.83%, epoch time: 96.87 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-73  lr=['0.0004883'], tr/val_loss:  2.314465/  2.326177, val:  68.58%, val_best:  88.50%, tr:  99.73%, tr_best:  99.83%, epoch time: 97.22 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-74  lr=['0.0004883'], tr/val_loss:  2.310285/  2.324797, val:  75.88%, val_best:  88.50%, tr:  99.80%, tr_best:  99.83%, epoch time: 95.55 seconds, 1.59 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 48 occurrences\n",
      "test - Value 1: 404 occurrences\n",
      "epoch-75  lr=['0.0004883'], tr/val_loss:  2.310614/  2.354183, val:  60.62%, val_best:  88.50%, tr:  99.80%, tr_best:  99.83%, epoch time: 95.27 seconds, 1.59 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-76  lr=['0.0004883'], tr/val_loss:  2.311838/  2.334887, val:  69.25%, val_best:  88.50%, tr:  99.65%, tr_best:  99.83%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-77  lr=['0.0004883'], tr/val_loss:  2.312294/  2.322360, val:  73.67%, val_best:  88.50%, tr:  99.70%, tr_best:  99.83%, epoch time: 97.36 seconds, 1.62 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-78  lr=['0.0004883'], tr/val_loss:  2.315139/  2.350051, val:  67.26%, val_best:  88.50%, tr:  99.53%, tr_best:  99.83%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-79  lr=['0.0004883'], tr/val_loss:  2.312028/  2.327404, val:  72.12%, val_best:  88.50%, tr:  99.80%, tr_best:  99.83%, epoch time: 97.40 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-80  lr=['0.0004883'], tr/val_loss:  2.312853/  2.344918, val:  55.31%, val_best:  88.50%, tr:  99.75%, tr_best:  99.83%, epoch time: 96.49 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-81  lr=['0.0004883'], tr/val_loss:  2.313162/  2.320810, val:  82.74%, val_best:  88.50%, tr:  99.90%, tr_best:  99.90%, epoch time: 93.93 seconds, 1.57 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-82  lr=['0.0004883'], tr/val_loss:  2.313693/  2.341675, val:  69.25%, val_best:  88.50%, tr:  99.83%, tr_best:  99.90%, epoch time: 93.98 seconds, 1.57 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-83  lr=['0.0004883'], tr/val_loss:  2.316952/  2.326004, val:  73.23%, val_best:  88.50%, tr:  99.93%, tr_best:  99.93%, epoch time: 94.97 seconds, 1.58 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-84  lr=['0.0004883'], tr/val_loss:  2.312021/  2.307055, val:  84.96%, val_best:  88.50%, tr:  99.83%, tr_best:  99.93%, epoch time: 96.93 seconds, 1.62 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-85  lr=['0.0004883'], tr/val_loss:  2.313746/  2.326378, val:  73.01%, val_best:  88.50%, tr:  99.83%, tr_best:  99.93%, epoch time: 96.85 seconds, 1.61 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-86  lr=['0.0004883'], tr/val_loss:  2.316986/  2.350016, val:  65.71%, val_best:  88.50%, tr:  99.90%, tr_best:  99.93%, epoch time: 97.26 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-87  lr=['0.0004883'], tr/val_loss:  2.314816/  2.310806, val:  74.78%, val_best:  88.50%, tr:  99.85%, tr_best:  99.93%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-88  lr=['0.0004883'], tr/val_loss:  2.305513/  2.328310, val:  75.88%, val_best:  88.50%, tr:  99.98%, tr_best:  99.98%, epoch time: 96.47 seconds, 1.61 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-89  lr=['0.0004883'], tr/val_loss:  2.309883/  2.348235, val:  66.59%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 97.35 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-90  lr=['0.0004883'], tr/val_loss:  2.310952/  2.311721, val:  79.65%, val_best:  88.50%, tr:  99.83%, tr_best:  99.98%, epoch time: 96.60 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-91  lr=['0.0004883'], tr/val_loss:  2.310876/  2.319649, val:  78.10%, val_best:  88.50%, tr:  99.83%, tr_best:  99.98%, epoch time: 97.13 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-92  lr=['0.0004883'], tr/val_loss:  2.313007/  2.334213, val:  75.88%, val_best:  88.50%, tr:  99.83%, tr_best:  99.98%, epoch time: 97.86 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-93  lr=['0.0004883'], tr/val_loss:  2.317115/  2.341171, val:  68.36%, val_best:  88.50%, tr:  99.98%, tr_best:  99.98%, epoch time: 97.19 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-94  lr=['0.0004883'], tr/val_loss:  2.310944/  2.330994, val:  82.74%, val_best:  88.50%, tr:  99.78%, tr_best:  99.98%, epoch time: 97.17 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-95  lr=['0.0004883'], tr/val_loss:  2.314357/  2.334947, val:  76.77%, val_best:  88.50%, tr:  99.83%, tr_best:  99.98%, epoch time: 96.65 seconds, 1.61 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-96  lr=['0.0004883'], tr/val_loss:  2.309798/  2.316775, val:  76.55%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 96.82 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-97  lr=['0.0004883'], tr/val_loss:  2.314795/  2.340844, val:  83.19%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 95.59 seconds, 1.59 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-98  lr=['0.0004883'], tr/val_loss:  2.313178/  2.338472, val:  81.19%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 95.94 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-99  lr=['0.0004883'], tr/val_loss:  2.312654/  2.327513, val:  69.91%, val_best:  88.50%, tr:  99.88%, tr_best:  99.98%, epoch time: 96.85 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-100 lr=['0.0004883'], tr/val_loss:  2.312884/  2.347210, val:  66.59%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-101 lr=['0.0004883'], tr/val_loss:  2.309458/  2.324273, val:  77.88%, val_best:  88.50%, tr:  99.88%, tr_best:  99.98%, epoch time: 95.62 seconds, 1.59 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-102 lr=['0.0004883'], tr/val_loss:  2.309345/  2.317766, val:  75.00%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 96.12 seconds, 1.60 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-103 lr=['0.0004883'], tr/val_loss:  2.308467/  2.326499, val:  74.12%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 96.69 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-104 lr=['0.0004883'], tr/val_loss:  2.312565/  2.332832, val:  80.53%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 97.17 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-105 lr=['0.0004883'], tr/val_loss:  2.314655/  2.339836, val:  76.99%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 97.02 seconds, 1.62 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-106 lr=['0.0004883'], tr/val_loss:  2.315730/  2.338432, val:  74.34%, val_best:  88.50%, tr:  99.78%, tr_best:  99.98%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-107 lr=['0.0004883'], tr/val_loss:  2.313709/  2.305892, val:  82.30%, val_best:  88.50%, tr:  99.83%, tr_best:  99.98%, epoch time: 97.65 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-108 lr=['0.0004883'], tr/val_loss:  2.308323/  2.355061, val:  60.84%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 97.54 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-109 lr=['0.0004883'], tr/val_loss:  2.312949/  2.334170, val:  71.02%, val_best:  88.50%, tr:  99.88%, tr_best:  99.98%, epoch time: 97.76 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-110 lr=['0.0004883'], tr/val_loss:  2.311682/  2.330595, val:  69.69%, val_best:  88.50%, tr:  99.88%, tr_best:  99.98%, epoch time: 96.61 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-111 lr=['0.0004883'], tr/val_loss:  2.309088/  2.326351, val:  76.33%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 97.06 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-112 lr=['0.0004883'], tr/val_loss:  2.309964/  2.340580, val:  68.36%, val_best:  88.50%, tr:  99.83%, tr_best:  99.98%, epoch time: 97.36 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-113 lr=['0.0004883'], tr/val_loss:  2.309316/  2.317418, val:  78.10%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-114 lr=['0.0004883'], tr/val_loss:  2.307428/  2.324363, val:  71.02%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 96.63 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-115 lr=['0.0004883'], tr/val_loss:  2.307681/  2.312319, val:  79.65%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 97.48 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-116 lr=['0.0004883'], tr/val_loss:  2.312582/  2.349922, val:  73.89%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 95.83 seconds, 1.60 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-117 lr=['0.0004883'], tr/val_loss:  2.310847/  2.341122, val:  77.65%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 96.00 seconds, 1.60 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-118 lr=['0.0004883'], tr/val_loss:  2.311141/  2.346265, val:  66.15%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 93.17 seconds, 1.55 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-119 lr=['0.0004883'], tr/val_loss:  2.311105/  2.300181, val:  85.18%, val_best:  88.50%, tr:  99.98%, tr_best:  99.98%, epoch time: 94.67 seconds, 1.58 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-120 lr=['0.0004883'], tr/val_loss:  2.314412/  2.355531, val:  66.15%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 95.03 seconds, 1.58 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-121 lr=['0.0004883'], tr/val_loss:  2.313821/  2.337006, val:  67.26%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-122 lr=['0.0004883'], tr/val_loss:  2.313564/  2.333340, val:  67.92%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 97.01 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-123 lr=['0.0004883'], tr/val_loss:  2.310904/  2.322224, val:  79.42%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 97.93 seconds, 1.63 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-124 lr=['0.0004883'], tr/val_loss:  2.312367/  2.356825, val:  63.05%, val_best:  88.50%, tr:  99.85%, tr_best:  99.98%, epoch time: 96.10 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-125 lr=['0.0004883'], tr/val_loss:  2.314338/  2.343360, val:  73.45%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 95.39 seconds, 1.59 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-126 lr=['0.0004883'], tr/val_loss:  2.313703/  2.337788, val:  74.78%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 95.50 seconds, 1.59 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-127 lr=['0.0004883'], tr/val_loss:  2.315831/  2.329453, val:  78.32%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 96.94 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-128 lr=['0.0004883'], tr/val_loss:  2.313874/  2.334955, val:  80.09%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 96.43 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-129 lr=['0.0004883'], tr/val_loss:  2.317081/  2.344592, val:  66.37%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 96.34 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-130 lr=['0.0004883'], tr/val_loss:  2.316777/  2.345795, val:  64.16%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 95.91 seconds, 1.60 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-131 lr=['0.0004883'], tr/val_loss:  2.311296/  2.346448, val:  76.11%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 95.69 seconds, 1.59 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-132 lr=['0.0004883'], tr/val_loss:  2.316142/  2.344967, val:  69.03%, val_best:  88.50%, tr:  99.88%, tr_best:  99.98%, epoch time: 97.72 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-133 lr=['0.0004883'], tr/val_loss:  2.317983/  2.343263, val:  82.08%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 97.50 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-134 lr=['0.0004883'], tr/val_loss:  2.315941/  2.358205, val:  65.04%, val_best:  88.50%, tr:  99.98%, tr_best:  99.98%, epoch time: 97.60 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-135 lr=['0.0004883'], tr/val_loss:  2.315381/  2.337700, val:  74.12%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 97.36 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-136 lr=['0.0004883'], tr/val_loss:  2.312367/  2.351670, val:  60.18%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-137 lr=['0.0004883'], tr/val_loss:  2.313028/  2.335634, val:  67.92%, val_best:  88.50%, tr:  99.90%, tr_best:  99.98%, epoch time: 97.04 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-138 lr=['0.0004883'], tr/val_loss:  2.316907/  2.321067, val:  77.21%, val_best:  88.50%, tr:  99.88%, tr_best:  99.98%, epoch time: 97.39 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-139 lr=['0.0004883'], tr/val_loss:  2.319284/  2.341545, val:  71.68%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-140 lr=['0.0004883'], tr/val_loss:  2.319187/  2.319026, val:  78.32%, val_best:  88.50%, tr:  99.98%, tr_best:  99.98%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-141 lr=['0.0004883'], tr/val_loss:  2.324014/  2.365246, val:  65.49%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 96.23 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-142 lr=['0.0004883'], tr/val_loss:  2.317067/  2.327898, val:  80.09%, val_best:  88.50%, tr:  99.93%, tr_best:  99.98%, epoch time: 96.64 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-143 lr=['0.0004883'], tr/val_loss:  2.318937/  2.339312, val:  81.64%, val_best:  88.50%, tr:  99.98%, tr_best:  99.98%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-144 lr=['0.0004883'], tr/val_loss:  2.314469/  2.343040, val:  68.58%, val_best:  88.50%, tr:  99.95%, tr_best:  99.98%, epoch time: 96.92 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-145 lr=['0.0004883'], tr/val_loss:  2.315042/  2.350943, val:  67.48%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 97.23 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-146 lr=['0.0004883'], tr/val_loss:  2.314571/  2.330451, val:  67.48%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.24 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-147 lr=['0.0004883'], tr/val_loss:  2.315901/  2.335273, val:  67.48%, val_best:  88.50%, tr:  99.93%, tr_best: 100.00%, epoch time: 96.42 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-148 lr=['0.0004883'], tr/val_loss:  2.318007/  2.341066, val:  63.72%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 96.90 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-149 lr=['0.0004883'], tr/val_loss:  2.325988/  2.357159, val:  66.15%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.23 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-150 lr=['0.0004883'], tr/val_loss:  2.321316/  2.352425, val:  66.15%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-151 lr=['0.0004883'], tr/val_loss:  2.316372/  2.327610, val:  72.12%, val_best:  88.50%, tr:  99.93%, tr_best: 100.00%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-152 lr=['0.0004883'], tr/val_loss:  2.320817/  2.350144, val:  69.69%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 94.37 seconds, 1.57 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-153 lr=['0.0004883'], tr/val_loss:  2.321620/  2.341271, val:  76.33%, val_best:  88.50%, tr:  99.93%, tr_best: 100.00%, epoch time: 95.06 seconds, 1.58 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-154 lr=['0.0004883'], tr/val_loss:  2.319997/  2.339157, val:  83.85%, val_best:  88.50%, tr:  99.85%, tr_best: 100.00%, epoch time: 93.83 seconds, 1.56 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-155 lr=['0.0004883'], tr/val_loss:  2.311437/  2.344586, val:  70.80%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 94.16 seconds, 1.57 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-156 lr=['0.0004883'], tr/val_loss:  2.312541/  2.343562, val:  72.79%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 93.31 seconds, 1.56 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-157 lr=['0.0004883'], tr/val_loss:  2.313706/  2.330196, val:  66.15%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 95.30 seconds, 1.59 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-158 lr=['0.0004883'], tr/val_loss:  2.312086/  2.341030, val:  74.56%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 96.75 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-159 lr=['0.0004883'], tr/val_loss:  2.312508/  2.345435, val:  69.25%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-160 lr=['0.0004883'], tr/val_loss:  2.320810/  2.356429, val:  67.04%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.03 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-161 lr=['0.0004883'], tr/val_loss:  2.318515/  2.357724, val:  68.36%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 97.06 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-162 lr=['0.0004883'], tr/val_loss:  2.319210/  2.343302, val:  71.46%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-163 lr=['0.0004883'], tr/val_loss:  2.321582/  2.349980, val:  63.72%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.13 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-164 lr=['0.0004883'], tr/val_loss:  2.323696/  2.341619, val:  80.31%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-165 lr=['0.0004883'], tr/val_loss:  2.316314/  2.332328, val:  75.44%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.69 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-166 lr=['0.0004883'], tr/val_loss:  2.320905/  2.361732, val:  66.59%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-167 lr=['0.0004883'], tr/val_loss:  2.321358/  2.350760, val:  66.15%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 96.37 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-168 lr=['0.0004883'], tr/val_loss:  2.318576/  2.349272, val:  71.46%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 96.85 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-169 lr=['0.0004883'], tr/val_loss:  2.324104/  2.358172, val:  67.92%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 98.53 seconds, 1.64 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-170 lr=['0.0004883'], tr/val_loss:  2.320137/  2.341631, val:  74.78%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 99.31 seconds, 1.66 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-171 lr=['0.0004883'], tr/val_loss:  2.318900/  2.337002, val:  65.71%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-172 lr=['0.0004883'], tr/val_loss:  2.323172/  2.359957, val:  69.47%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-173 lr=['0.0004883'], tr/val_loss:  2.321652/  2.340262, val:  75.66%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 98.32 seconds, 1.64 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-174 lr=['0.0004883'], tr/val_loss:  2.317434/  2.342357, val:  71.68%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 97.61 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-175 lr=['0.0004883'], tr/val_loss:  2.316703/  2.356291, val:  64.16%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 96.95 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-176 lr=['0.0004883'], tr/val_loss:  2.318075/  2.337982, val:  70.80%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 98.15 seconds, 1.64 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-177 lr=['0.0004883'], tr/val_loss:  2.323301/  2.352695, val:  78.98%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-178 lr=['0.0004883'], tr/val_loss:  2.324401/  2.349308, val:  71.24%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 98.35 seconds, 1.64 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-179 lr=['0.0004883'], tr/val_loss:  2.318039/  2.339154, val:  69.91%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 96.03 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-180 lr=['0.0004883'], tr/val_loss:  2.320314/  2.357420, val:  72.35%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 95.91 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-181 lr=['0.0004883'], tr/val_loss:  2.320005/  2.341738, val:  69.47%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.12 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-182 lr=['0.0004883'], tr/val_loss:  2.316510/  2.331239, val:  72.35%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.34 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-183 lr=['0.0004883'], tr/val_loss:  2.313753/  2.326710, val:  83.63%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 96.71 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-184 lr=['0.0004883'], tr/val_loss:  2.314296/  2.349722, val:  78.76%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 94.86 seconds, 1.58 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-185 lr=['0.0004883'], tr/val_loss:  2.313696/  2.339671, val:  67.04%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 95.67 seconds, 1.59 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-186 lr=['0.0004883'], tr/val_loss:  2.318064/  2.342235, val:  66.59%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 98.36 seconds, 1.64 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-187 lr=['0.0004883'], tr/val_loss:  2.320753/  2.342953, val:  70.80%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.92 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-188 lr=['0.0004883'], tr/val_loss:  2.318964/  2.360196, val:  66.37%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 94.44 seconds, 1.57 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-189 lr=['0.0004883'], tr/val_loss:  2.319086/  2.359097, val:  65.04%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 97.17 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-190 lr=['0.0004883'], tr/val_loss:  2.318906/  2.326372, val:  72.57%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 94.53 seconds, 1.58 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-191 lr=['0.0004883'], tr/val_loss:  2.318197/  2.366497, val:  71.24%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 94.41 seconds, 1.57 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-192 lr=['0.0004883'], tr/val_loss:  2.316779/  2.342487, val:  73.45%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 95.81 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-193 lr=['0.0004883'], tr/val_loss:  2.324982/  2.372864, val:  66.81%, val_best:  88.50%, tr:  99.98%, tr_best: 100.00%, epoch time: 95.91 seconds, 1.60 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-194 lr=['0.0004883'], tr/val_loss:  2.324507/  2.343935, val:  74.34%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-195 lr=['0.0004883'], tr/val_loss:  2.320798/  2.349739, val:  76.77%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 98.16 seconds, 1.64 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-196 lr=['0.0004883'], tr/val_loss:  2.319591/  2.348443, val:  69.91%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 98.33 seconds, 1.64 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-197 lr=['0.0004883'], tr/val_loss:  2.322185/  2.342558, val:  76.77%, val_best:  88.50%, tr:  99.95%, tr_best: 100.00%, epoch time: 97.73 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-198 lr=['0.0004883'], tr/val_loss:  2.316666/  2.338082, val:  78.76%, val_best:  88.50%, tr:  99.93%, tr_best: 100.00%, epoch time: 96.37 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-199 lr=['0.0004883'], tr/val_loss:  2.314375/  2.338532, val:  77.21%, val_best:  88.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 98.52 seconds, 1.64 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8e5e21e3c1494d93345f31c780641a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñà‚ñÖ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>2.31438</td></tr><tr><td>val_acc_best</td><td>0.88496</td></tr><tr><td>val_acc_now</td><td>0.77212</td></tr><tr><td>val_loss</td><td>2.33853</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-sweep-3</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/9b4rih76' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/9b4rih76</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_051704-9b4rih76/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c4qtsie3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_104037-c4qtsie3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/c4qtsie3' target=\"_blank\">drawn-sweep-4</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/c4qtsie3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/c4qtsie3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250806_104046_740', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 15, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-12, -12], [-12, -12], [-11, -11]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.303056/  2.314097, val:  56.86%, val_best:  56.86%, tr:  64.94%, tr_best:  64.94%, epoch time: 99.03 seconds, 1.65 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 1847 occurrences\n",
      "train - Value 1: 2183 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.303129/  2.302212, val:  75.66%, val_best:  75.66%, tr:  72.46%, tr_best:  72.46%, epoch time: 98.98 seconds, 1.65 minutes\n",
      "train - Value 0: 1925 occurrences\n",
      "train - Value 1: 2105 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.302587/  2.297525, val:  59.07%, val_best:  75.66%, tr:  76.13%, tr_best:  76.13%, epoch time: 98.49 seconds, 1.64 minutes\n",
      "train - Value 0: 1895 occurrences\n",
      "train - Value 1: 2135 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.303921/  2.307350, val:  76.33%, val_best:  76.33%, tr:  80.15%, tr_best:  80.15%, epoch time: 97.91 seconds, 1.63 minutes\n",
      "train - Value 0: 1864 occurrences\n",
      "train - Value 1: 2166 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 401 occurrences\n",
      "test - Value 1: 51 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.304607/  2.296640, val:  61.28%, val_best:  76.33%, tr:  82.26%, tr_best:  82.26%, epoch time: 98.95 seconds, 1.65 minutes\n",
      "train - Value 0: 1908 occurrences\n",
      "train - Value 1: 2122 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.303654/  2.302539, val:  68.14%, val_best:  76.33%, tr:  83.60%, tr_best:  83.60%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.303839/  2.303201, val:  85.84%, val_best:  85.84%, tr:  84.39%, tr_best:  84.39%, epoch time: 96.33 seconds, 1.61 minutes\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2114 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.303913/  2.302700, val:  81.64%, val_best:  85.84%, tr:  85.68%, tr_best:  85.68%, epoch time: 96.03 seconds, 1.60 minutes\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2119 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.304196/  2.306587, val:  63.50%, val_best:  85.84%, tr:  85.36%, tr_best:  85.68%, epoch time: 98.00 seconds, 1.63 minutes\n",
      "train - Value 0: 1881 occurrences\n",
      "train - Value 1: 2149 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.303871/  2.305111, val:  55.97%, val_best:  85.84%, tr:  86.10%, tr_best:  86.10%, epoch time: 97.90 seconds, 1.63 minutes\n",
      "train - Value 0: 1897 occurrences\n",
      "train - Value 1: 2133 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 311 occurrences\n",
      "test - Value 1: 141 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.304177/  2.307872, val:  77.21%, val_best:  85.84%, tr:  86.80%, tr_best:  86.80%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.304857/  2.299601, val:  80.75%, val_best:  85.84%, tr:  87.32%, tr_best:  87.32%, epoch time: 96.43 seconds, 1.61 minutes\n",
      "train - Value 0: 1917 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.304949/  2.297544, val:  83.85%, val_best:  85.84%, tr:  86.15%, tr_best:  87.32%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.305439/  2.312893, val:  62.61%, val_best:  85.84%, tr:  87.72%, tr_best:  87.72%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.305893/  2.315362, val:  68.36%, val_best:  85.84%, tr:  87.10%, tr_best:  87.72%, epoch time: 98.00 seconds, 1.63 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.304757/  2.306119, val:  80.09%, val_best:  85.84%, tr:  87.77%, tr_best:  87.77%, epoch time: 97.69 seconds, 1.63 minutes\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.305265/  2.317606, val:  73.67%, val_best:  85.84%, tr:  89.55%, tr_best:  89.55%, epoch time: 97.84 seconds, 1.63 minutes\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2115 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.305784/  2.316979, val:  55.75%, val_best:  85.84%, tr:  89.23%, tr_best:  89.55%, epoch time: 98.10 seconds, 1.64 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.304793/  2.320971, val:  53.98%, val_best:  85.84%, tr:  91.07%, tr_best:  91.07%, epoch time: 97.12 seconds, 1.62 minutes\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.304263/  2.332485, val:  52.88%, val_best:  85.84%, tr:  89.73%, tr_best:  91.07%, epoch time: 97.99 seconds, 1.63 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.305298/  2.309542, val:  85.62%, val_best:  85.84%, tr:  89.18%, tr_best:  91.07%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 1945 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.305479/  2.324590, val:  84.96%, val_best:  85.84%, tr:  89.58%, tr_best:  91.07%, epoch time: 98.30 seconds, 1.64 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.307573/  2.313847, val:  74.78%, val_best:  85.84%, tr:  89.58%, tr_best:  91.07%, epoch time: 98.07 seconds, 1.63 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.306077/  2.307884, val:  82.08%, val_best:  85.84%, tr:  91.51%, tr_best:  91.51%, epoch time: 97.82 seconds, 1.63 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.303596/  2.306995, val:  82.30%, val_best:  85.84%, tr:  91.27%, tr_best:  91.51%, epoch time: 96.41 seconds, 1.61 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.305575/  2.316106, val:  84.29%, val_best:  85.84%, tr:  91.56%, tr_best:  91.56%, epoch time: 98.70 seconds, 1.65 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.306458/  2.306962, val:  81.64%, val_best:  85.84%, tr:  91.07%, tr_best:  91.56%, epoch time: 95.92 seconds, 1.60 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.305426/  2.308705, val:  78.76%, val_best:  85.84%, tr:  91.44%, tr_best:  91.56%, epoch time: 95.10 seconds, 1.59 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 306 occurrences\n",
      "test - Value 1: 146 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.305437/  2.301184, val:  80.53%, val_best:  85.84%, tr:  90.97%, tr_best:  91.56%, epoch time: 95.11 seconds, 1.59 minutes\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.306120/  2.313112, val:  54.42%, val_best:  85.84%, tr:  91.12%, tr_best:  91.56%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 263 occurrences\n",
      "test - Value 1: 189 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.307569/  2.295070, val:  86.95%, val_best:  86.95%, tr:  91.32%, tr_best:  91.56%, epoch time: 97.40 seconds, 1.62 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.306694/  2.294320, val:  88.05%, val_best:  88.05%, tr:  92.08%, tr_best:  92.08%, epoch time: 97.61 seconds, 1.63 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.305605/  2.306373, val:  53.10%, val_best:  88.05%, tr:  93.60%, tr_best:  93.60%, epoch time: 97.55 seconds, 1.63 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.309151/  2.308393, val:  70.80%, val_best:  88.05%, tr:  92.66%, tr_best:  93.60%, epoch time: 95.99 seconds, 1.60 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.305698/  2.301973, val:  85.40%, val_best:  88.05%, tr:  92.70%, tr_best:  93.60%, epoch time: 95.07 seconds, 1.58 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.306484/  2.314823, val:  76.55%, val_best:  88.05%, tr:  91.99%, tr_best:  93.60%, epoch time: 97.69 seconds, 1.63 minutes\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.306592/  2.312007, val:  71.90%, val_best:  88.05%, tr:  91.74%, tr_best:  93.60%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.305106/  2.326108, val:  50.00%, val_best:  88.05%, tr:  92.28%, tr_best:  93.60%, epoch time: 97.19 seconds, 1.62 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 302 occurrences\n",
      "test - Value 1: 150 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.306676/  2.287240, val:  80.53%, val_best:  88.05%, tr:  92.08%, tr_best:  93.60%, epoch time: 95.74 seconds, 1.60 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.307074/  2.315454, val:  84.29%, val_best:  88.05%, tr:  92.63%, tr_best:  93.60%, epoch time: 96.43 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.306626/  2.317891, val:  56.64%, val_best:  88.05%, tr:  92.48%, tr_best:  93.60%, epoch time: 98.21 seconds, 1.64 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.307713/  2.307595, val:  85.62%, val_best:  88.05%, tr:  92.11%, tr_best:  93.60%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 321 occurrences\n",
      "test - Value 1: 131 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.308169/  2.311317, val:  77.65%, val_best:  88.05%, tr:  93.15%, tr_best:  93.60%, epoch time: 97.42 seconds, 1.62 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 382 occurrences\n",
      "test - Value 1: 70 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.308117/  2.279954, val:  65.49%, val_best:  88.05%, tr:  93.70%, tr_best:  93.70%, epoch time: 98.02 seconds, 1.63 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.308768/  2.314911, val:  80.53%, val_best:  88.05%, tr:  93.62%, tr_best:  93.70%, epoch time: 96.83 seconds, 1.61 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.308555/  2.332542, val:  52.21%, val_best:  88.05%, tr:  92.43%, tr_best:  93.70%, epoch time: 98.59 seconds, 1.64 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.311130/  2.320524, val:  61.50%, val_best:  88.05%, tr:  92.88%, tr_best:  93.70%, epoch time: 98.11 seconds, 1.64 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.307900/  2.303830, val:  87.39%, val_best:  88.05%, tr:  92.56%, tr_best:  93.70%, epoch time: 97.98 seconds, 1.63 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.306718/  2.339376, val:  55.31%, val_best:  88.05%, tr:  92.51%, tr_best:  93.70%, epoch time: 97.93 seconds, 1.63 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.307743/  2.310524, val:  55.31%, val_best:  88.05%, tr:  93.20%, tr_best:  93.70%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 346 occurrences\n",
      "test - Value 1: 106 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.307466/  2.304065, val:  72.57%, val_best:  88.05%, tr:  92.51%, tr_best:  93.70%, epoch time: 98.05 seconds, 1.63 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.309513/  2.300171, val:  75.88%, val_best:  88.05%, tr:  92.48%, tr_best:  93.70%, epoch time: 98.03 seconds, 1.63 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.304935/  2.313473, val:  85.84%, val_best:  88.05%, tr:  92.78%, tr_best:  93.70%, epoch time: 97.98 seconds, 1.63 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.306117/  2.291254, val:  78.54%, val_best:  88.05%, tr:  92.41%, tr_best:  93.70%, epoch time: 98.20 seconds, 1.64 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.310199/  2.321079, val:  72.35%, val_best:  88.05%, tr:  91.89%, tr_best:  93.70%, epoch time: 97.32 seconds, 1.62 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.309045/  2.354443, val:  52.65%, val_best:  88.05%, tr:  92.85%, tr_best:  93.70%, epoch time: 97.68 seconds, 1.63 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.305278/  2.320689, val:  55.31%, val_best:  88.05%, tr:  92.43%, tr_best:  93.70%, epoch time: 98.20 seconds, 1.64 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 263 occurrences\n",
      "test - Value 1: 189 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.306940/  2.310685, val:  85.62%, val_best:  88.05%, tr:  93.13%, tr_best:  93.70%, epoch time: 97.99 seconds, 1.63 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 311 occurrences\n",
      "test - Value 1: 141 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.308579/  2.289719, val:  78.54%, val_best:  88.05%, tr:  93.08%, tr_best:  93.70%, epoch time: 98.35 seconds, 1.64 minutes\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.308440/  2.308361, val:  82.52%, val_best:  88.05%, tr:  93.75%, tr_best:  93.75%, epoch time: 97.99 seconds, 1.63 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 278 occurrences\n",
      "test - Value 1: 174 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.307359/  2.294846, val:  84.07%, val_best:  88.05%, tr:  94.39%, tr_best:  94.39%, epoch time: 95.60 seconds, 1.59 minutes\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.308207/  2.305467, val:  85.62%, val_best:  88.05%, tr:  93.77%, tr_best:  94.39%, epoch time: 96.07 seconds, 1.60 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.306713/  2.310585, val:  82.96%, val_best:  88.05%, tr:  92.85%, tr_best:  94.39%, epoch time: 95.91 seconds, 1.60 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.306129/  2.305484, val:  87.17%, val_best:  88.05%, tr:  94.07%, tr_best:  94.39%, epoch time: 96.12 seconds, 1.60 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.309724/  2.301554, val:  84.51%, val_best:  88.05%, tr:  93.33%, tr_best:  94.39%, epoch time: 94.73 seconds, 1.58 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.307987/  2.306003, val:  84.96%, val_best:  88.05%, tr:  93.08%, tr_best:  94.39%, epoch time: 94.81 seconds, 1.58 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.306529/  2.299949, val:  87.17%, val_best:  88.05%, tr:  93.15%, tr_best:  94.39%, epoch time: 96.91 seconds, 1.62 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.305143/  2.329656, val:  51.55%, val_best:  88.05%, tr:  93.50%, tr_best:  94.39%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.307272/  2.316495, val:  86.28%, val_best:  88.05%, tr:  93.30%, tr_best:  94.39%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.305491/  2.292196, val:  85.40%, val_best:  88.05%, tr:  93.80%, tr_best:  94.39%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.309272/  2.314256, val:  70.80%, val_best:  88.05%, tr:  94.39%, tr_best:  94.39%, epoch time: 97.54 seconds, 1.63 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.309716/  2.307440, val:  86.73%, val_best:  88.05%, tr:  93.33%, tr_best:  94.39%, epoch time: 98.06 seconds, 1.63 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.309107/  2.327376, val:  76.77%, val_best:  88.05%, tr:  92.80%, tr_best:  94.39%, epoch time: 96.91 seconds, 1.62 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 323 occurrences\n",
      "test - Value 1: 129 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.307248/  2.296527, val:  75.88%, val_best:  88.05%, tr:  93.05%, tr_best:  94.39%, epoch time: 97.76 seconds, 1.63 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.305797/  2.305202, val:  70.13%, val_best:  88.05%, tr:  93.50%, tr_best:  94.39%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.310884/  2.321368, val:  73.45%, val_best:  88.05%, tr:  93.82%, tr_best:  94.39%, epoch time: 97.39 seconds, 1.62 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 281 occurrences\n",
      "test - Value 1: 171 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.310522/  2.299174, val:  84.73%, val_best:  88.05%, tr:  94.14%, tr_best:  94.39%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.308006/  2.311061, val:  81.19%, val_best:  88.05%, tr:  94.02%, tr_best:  94.39%, epoch time: 97.18 seconds, 1.62 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.305427/  2.318122, val:  69.69%, val_best:  88.05%, tr:  93.77%, tr_best:  94.39%, epoch time: 98.74 seconds, 1.65 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.308941/  2.304928, val:  87.17%, val_best:  88.05%, tr:  94.09%, tr_best:  94.39%, epoch time: 98.63 seconds, 1.64 minutes\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 31 occurrences\n",
      "test - Value 1: 421 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.312389/  2.309055, val:  56.42%, val_best:  88.05%, tr:  94.12%, tr_best:  94.39%, epoch time: 98.06 seconds, 1.63 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.310487/  2.321266, val:  80.09%, val_best:  88.05%, tr:  94.00%, tr_best:  94.39%, epoch time: 97.85 seconds, 1.63 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.309156/  2.313893, val:  67.92%, val_best:  88.05%, tr:  94.69%, tr_best:  94.69%, epoch time: 98.22 seconds, 1.64 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.304816/  2.309396, val:  83.41%, val_best:  88.05%, tr:  94.71%, tr_best:  94.71%, epoch time: 97.88 seconds, 1.63 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.304842/  2.312991, val:  74.56%, val_best:  88.05%, tr:  94.34%, tr_best:  94.71%, epoch time: 97.62 seconds, 1.63 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.310462/  2.309497, val:  73.67%, val_best:  88.05%, tr:  93.70%, tr_best:  94.71%, epoch time: 97.28 seconds, 1.62 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.309332/  2.301569, val:  82.74%, val_best:  88.05%, tr:  94.12%, tr_best:  94.71%, epoch time: 98.23 seconds, 1.64 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.308254/  2.309020, val:  72.79%, val_best:  88.05%, tr:  94.64%, tr_best:  94.71%, epoch time: 96.50 seconds, 1.61 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.308167/  2.292399, val:  86.28%, val_best:  88.05%, tr:  95.33%, tr_best:  95.33%, epoch time: 95.34 seconds, 1.59 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.309193/  2.319605, val:  60.84%, val_best:  88.05%, tr:  94.79%, tr_best:  95.33%, epoch time: 98.18 seconds, 1.64 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.308946/  2.309142, val:  76.55%, val_best:  88.05%, tr:  94.59%, tr_best:  95.33%, epoch time: 96.87 seconds, 1.61 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.308885/  2.300947, val:  87.17%, val_best:  88.05%, tr:  94.24%, tr_best:  95.33%, epoch time: 96.90 seconds, 1.62 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.307779/  2.342351, val:  81.64%, val_best:  88.05%, tr:  94.24%, tr_best:  95.33%, epoch time: 95.81 seconds, 1.60 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.309084/  2.301117, val:  58.85%, val_best:  88.05%, tr:  94.94%, tr_best:  95.33%, epoch time: 96.58 seconds, 1.61 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.313350/  2.316908, val:  85.40%, val_best:  88.05%, tr:  94.67%, tr_best:  95.33%, epoch time: 97.78 seconds, 1.63 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 38 occurrences\n",
      "test - Value 1: 414 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.306951/  2.334726, val:  58.41%, val_best:  88.05%, tr:  96.15%, tr_best:  96.15%, epoch time: 97.19 seconds, 1.62 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.309198/  2.329655, val:  67.48%, val_best:  88.05%, tr:  94.91%, tr_best:  96.15%, epoch time: 97.82 seconds, 1.63 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.310897/  2.319327, val:  76.77%, val_best:  88.05%, tr:  94.24%, tr_best:  96.15%, epoch time: 98.13 seconds, 1.64 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.308640/  2.319564, val:  69.69%, val_best:  88.05%, tr:  94.89%, tr_best:  96.15%, epoch time: 96.89 seconds, 1.61 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.307885/  2.314583, val:  66.59%, val_best:  88.05%, tr:  95.24%, tr_best:  96.15%, epoch time: 94.36 seconds, 1.57 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.311503/  2.320799, val:  62.61%, val_best:  88.05%, tr:  95.83%, tr_best:  96.15%, epoch time: 94.54 seconds, 1.58 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 284 occurrences\n",
      "test - Value 1: 168 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.310916/  2.314133, val:  82.30%, val_best:  88.05%, tr:  95.53%, tr_best:  96.15%, epoch time: 94.58 seconds, 1.58 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.310766/  2.323066, val:  63.27%, val_best:  88.05%, tr:  94.99%, tr_best:  96.15%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.308482/  2.305196, val:  87.61%, val_best:  88.05%, tr:  95.48%, tr_best:  96.15%, epoch time: 97.63 seconds, 1.63 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.308401/  2.311774, val:  87.39%, val_best:  88.05%, tr:  95.68%, tr_best:  96.15%, epoch time: 98.58 seconds, 1.64 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.309858/  2.317651, val:  79.20%, val_best:  88.05%, tr:  94.99%, tr_best:  96.15%, epoch time: 97.86 seconds, 1.63 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.311761/  2.305999, val:  85.62%, val_best:  88.05%, tr:  94.99%, tr_best:  96.15%, epoch time: 97.89 seconds, 1.63 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.309027/  2.302882, val:  88.05%, val_best:  88.05%, tr:  95.11%, tr_best:  96.15%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.308313/  2.317679, val:  86.95%, val_best:  88.05%, tr:  95.78%, tr_best:  96.15%, epoch time: 98.00 seconds, 1.63 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.310933/  2.313036, val:  67.92%, val_best:  88.05%, tr:  95.41%, tr_best:  96.15%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.309571/  2.317738, val:  75.00%, val_best:  88.05%, tr:  94.94%, tr_best:  96.15%, epoch time: 97.85 seconds, 1.63 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.310953/  2.310936, val:  79.87%, val_best:  88.05%, tr:  95.19%, tr_best:  96.15%, epoch time: 96.85 seconds, 1.61 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.310041/  2.321563, val:  83.85%, val_best:  88.05%, tr:  94.91%, tr_best:  96.15%, epoch time: 97.13 seconds, 1.62 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.310461/  2.328089, val:  62.17%, val_best:  88.05%, tr:  95.06%, tr_best:  96.15%, epoch time: 98.07 seconds, 1.63 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.313826/  2.305740, val:  87.17%, val_best:  88.05%, tr:  95.09%, tr_best:  96.15%, epoch time: 96.56 seconds, 1.61 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.307549/  2.333082, val:  53.10%, val_best:  88.05%, tr:  95.21%, tr_best:  96.15%, epoch time: 96.18 seconds, 1.60 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.309390/  2.319369, val:  78.32%, val_best:  88.05%, tr:  95.63%, tr_best:  96.15%, epoch time: 97.34 seconds, 1.62 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.307851/  2.329895, val:  74.34%, val_best:  88.05%, tr:  95.58%, tr_best:  96.15%, epoch time: 98.64 seconds, 1.64 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.308096/  2.301854, val:  86.73%, val_best:  88.05%, tr:  95.68%, tr_best:  96.15%, epoch time: 97.34 seconds, 1.62 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.311951/  2.315442, val:  83.41%, val_best:  88.05%, tr:  95.83%, tr_best:  96.15%, epoch time: 96.16 seconds, 1.60 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.308999/  2.308020, val:  71.68%, val_best:  88.05%, tr:  95.56%, tr_best:  96.15%, epoch time: 95.98 seconds, 1.60 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.310606/  2.307491, val:  84.51%, val_best:  88.05%, tr:  96.05%, tr_best:  96.15%, epoch time: 96.96 seconds, 1.62 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.312159/  2.327706, val:  72.35%, val_best:  88.05%, tr:  95.63%, tr_best:  96.15%, epoch time: 97.06 seconds, 1.62 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.311900/  2.313953, val:  71.68%, val_best:  88.05%, tr:  96.10%, tr_best:  96.15%, epoch time: 97.13 seconds, 1.62 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 232 occurrences\n",
      "test - Value 1: 220 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.314695/  2.317231, val:  88.94%, val_best:  88.94%, tr:  94.96%, tr_best:  96.15%, epoch time: 95.70 seconds, 1.60 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.308838/  2.313274, val:  84.51%, val_best:  88.94%, tr:  96.10%, tr_best:  96.15%, epoch time: 98.20 seconds, 1.64 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.307325/  2.295362, val:  85.84%, val_best:  88.94%, tr:  95.68%, tr_best:  96.15%, epoch time: 96.36 seconds, 1.61 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.308003/  2.317572, val:  62.83%, val_best:  88.94%, tr:  95.98%, tr_best:  96.15%, epoch time: 97.98 seconds, 1.63 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.311000/  2.309923, val:  88.27%, val_best:  88.94%, tr:  95.46%, tr_best:  96.15%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.311897/  2.326478, val:  88.50%, val_best:  88.94%, tr:  95.63%, tr_best:  96.15%, epoch time: 97.86 seconds, 1.63 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.308483/  2.319842, val:  85.18%, val_best:  88.94%, tr:  96.03%, tr_best:  96.15%, epoch time: 97.52 seconds, 1.63 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.308898/  2.315051, val:  85.62%, val_best:  88.94%, tr:  96.35%, tr_best:  96.35%, epoch time: 96.81 seconds, 1.61 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.309460/  2.317506, val:  79.65%, val_best:  88.94%, tr:  96.15%, tr_best:  96.35%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.309371/  2.303406, val:  87.17%, val_best:  88.94%, tr:  97.12%, tr_best:  97.12%, epoch time: 95.40 seconds, 1.59 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.311447/  2.310373, val:  87.83%, val_best:  88.94%, tr:  95.98%, tr_best:  97.12%, epoch time: 97.57 seconds, 1.63 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.308808/  2.307550, val:  87.83%, val_best:  88.94%, tr:  96.80%, tr_best:  97.12%, epoch time: 94.60 seconds, 1.58 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.309980/  2.310544, val:  67.92%, val_best:  88.94%, tr:  96.33%, tr_best:  97.12%, epoch time: 94.58 seconds, 1.58 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.312005/  2.319021, val:  85.18%, val_best:  88.94%, tr:  96.85%, tr_best:  97.12%, epoch time: 93.92 seconds, 1.57 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.310715/  2.310263, val:  78.54%, val_best:  88.94%, tr:  96.48%, tr_best:  97.12%, epoch time: 96.96 seconds, 1.62 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.308973/  2.313919, val:  84.96%, val_best:  88.94%, tr:  96.50%, tr_best:  97.12%, epoch time: 97.22 seconds, 1.62 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.310121/  2.323946, val:  72.57%, val_best:  88.94%, tr:  96.38%, tr_best:  97.12%, epoch time: 97.44 seconds, 1.62 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.309719/  2.301329, val:  86.06%, val_best:  88.94%, tr:  96.58%, tr_best:  97.12%, epoch time: 96.91 seconds, 1.62 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.310356/  2.307385, val:  80.09%, val_best:  88.94%, tr:  96.67%, tr_best:  97.12%, epoch time: 95.01 seconds, 1.58 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.313348/  2.329265, val:  84.51%, val_best:  88.94%, tr:  96.65%, tr_best:  97.12%, epoch time: 96.47 seconds, 1.61 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.310846/  2.306592, val:  80.97%, val_best:  88.94%, tr:  96.05%, tr_best:  97.12%, epoch time: 97.33 seconds, 1.62 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.313136/  2.320018, val:  78.10%, val_best:  88.94%, tr:  95.73%, tr_best:  97.12%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.308018/  2.315059, val:  83.63%, val_best:  88.94%, tr:  96.48%, tr_best:  97.12%, epoch time: 95.80 seconds, 1.60 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.308798/  2.306752, val:  74.56%, val_best:  88.94%, tr:  95.76%, tr_best:  97.12%, epoch time: 95.95 seconds, 1.60 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.308801/  2.315174, val:  73.67%, val_best:  88.94%, tr:  96.18%, tr_best:  97.12%, epoch time: 97.79 seconds, 1.63 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.311342/  2.304518, val:  87.17%, val_best:  88.94%, tr:  96.63%, tr_best:  97.12%, epoch time: 97.42 seconds, 1.62 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.310156/  2.316143, val:  87.39%, val_best:  88.94%, tr:  96.00%, tr_best:  97.12%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.313256/  2.316433, val:  85.62%, val_best:  88.94%, tr:  96.55%, tr_best:  97.12%, epoch time: 97.28 seconds, 1.62 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.310899/  2.317299, val:  73.67%, val_best:  88.94%, tr:  96.80%, tr_best:  97.12%, epoch time: 97.66 seconds, 1.63 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.308419/  2.316726, val:  82.96%, val_best:  88.94%, tr:  96.58%, tr_best:  97.12%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.313159/  2.297904, val:  87.39%, val_best:  88.94%, tr:  95.58%, tr_best:  97.12%, epoch time: 97.66 seconds, 1.63 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.313086/  2.313061, val:  86.50%, val_best:  88.94%, tr:  96.38%, tr_best:  97.12%, epoch time: 96.29 seconds, 1.60 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.311136/  2.339494, val:  57.30%, val_best:  88.94%, tr:  96.40%, tr_best:  97.12%, epoch time: 98.22 seconds, 1.64 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.310840/  2.309033, val:  85.62%, val_best:  88.94%, tr:  96.08%, tr_best:  97.12%, epoch time: 96.48 seconds, 1.61 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.309343/  2.299745, val:  83.85%, val_best:  88.94%, tr:  96.50%, tr_best:  97.12%, epoch time: 97.41 seconds, 1.62 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.312059/  2.326647, val:  68.81%, val_best:  88.94%, tr:  95.78%, tr_best:  97.12%, epoch time: 98.25 seconds, 1.64 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.308561/  2.311126, val:  88.05%, val_best:  88.94%, tr:  96.75%, tr_best:  97.12%, epoch time: 98.37 seconds, 1.64 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.308043/  2.318556, val:  59.73%, val_best:  88.94%, tr:  96.25%, tr_best:  97.12%, epoch time: 98.61 seconds, 1.64 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.310767/  2.312096, val:  86.73%, val_best:  88.94%, tr:  96.35%, tr_best:  97.12%, epoch time: 96.93 seconds, 1.62 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.307952/  2.328475, val:  64.82%, val_best:  88.94%, tr:  96.30%, tr_best:  97.12%, epoch time: 96.89 seconds, 1.61 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.311042/  2.297634, val:  84.96%, val_best:  88.94%, tr:  96.15%, tr_best:  97.12%, epoch time: 97.37 seconds, 1.62 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.314991/  2.311337, val:  84.07%, val_best:  88.94%, tr:  95.19%, tr_best:  97.12%, epoch time: 97.50 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.309178/  2.302882, val:  85.84%, val_best:  88.94%, tr:  96.63%, tr_best:  97.12%, epoch time: 96.24 seconds, 1.60 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.312631/  2.306498, val:  88.72%, val_best:  88.94%, tr:  96.48%, tr_best:  97.12%, epoch time: 96.12 seconds, 1.60 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.307518/  2.309979, val:  82.74%, val_best:  88.94%, tr:  95.26%, tr_best:  97.12%, epoch time: 96.47 seconds, 1.61 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.306703/  2.306437, val:  70.13%, val_best:  88.94%, tr:  96.20%, tr_best:  97.12%, epoch time: 96.02 seconds, 1.60 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.310433/  2.304789, val:  85.40%, val_best:  88.94%, tr:  95.91%, tr_best:  97.12%, epoch time: 96.42 seconds, 1.61 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.308491/  2.320580, val:  84.07%, val_best:  88.94%, tr:  95.16%, tr_best:  97.12%, epoch time: 96.29 seconds, 1.60 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 48 occurrences\n",
      "test - Value 1: 404 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.310521/  2.332671, val:  60.62%, val_best:  88.94%, tr:  95.68%, tr_best:  97.12%, epoch time: 94.68 seconds, 1.58 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.308329/  2.304174, val:  85.84%, val_best:  88.94%, tr:  96.23%, tr_best:  97.12%, epoch time: 93.80 seconds, 1.56 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.313520/  2.322690, val:  78.98%, val_best:  88.94%, tr:  95.33%, tr_best:  97.12%, epoch time: 94.25 seconds, 1.57 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.313346/  2.321162, val:  52.65%, val_best:  88.94%, tr:  96.75%, tr_best:  97.12%, epoch time: 97.22 seconds, 1.62 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.306869/  2.304338, val:  81.19%, val_best:  88.94%, tr:  96.28%, tr_best:  97.12%, epoch time: 98.00 seconds, 1.63 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.309355/  2.340696, val:  57.30%, val_best:  88.94%, tr:  96.72%, tr_best:  97.12%, epoch time: 98.02 seconds, 1.63 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.310318/  2.333094, val:  60.84%, val_best:  88.94%, tr:  96.10%, tr_best:  97.12%, epoch time: 97.45 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.310761/  2.291654, val:  85.40%, val_best:  88.94%, tr:  95.61%, tr_best:  97.12%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.313030/  2.307719, val:  79.42%, val_best:  88.94%, tr:  96.55%, tr_best:  97.12%, epoch time: 97.04 seconds, 1.62 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.312917/  2.327413, val:  78.98%, val_best:  88.94%, tr:  95.71%, tr_best:  97.12%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.311843/  2.314237, val:  84.73%, val_best:  88.94%, tr:  95.41%, tr_best:  97.12%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.309223/  2.314126, val:  87.61%, val_best:  88.94%, tr:  95.73%, tr_best:  97.12%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.310601/  2.295979, val:  87.83%, val_best:  88.94%, tr:  95.48%, tr_best:  97.12%, epoch time: 98.14 seconds, 1.64 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.309108/  2.325297, val:  59.73%, val_best:  88.94%, tr:  95.68%, tr_best:  97.12%, epoch time: 97.21 seconds, 1.62 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.308120/  2.289086, val:  88.27%, val_best:  88.94%, tr:  96.23%, tr_best:  97.12%, epoch time: 98.17 seconds, 1.64 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.309822/  2.314665, val:  85.40%, val_best:  88.94%, tr:  96.60%, tr_best:  97.12%, epoch time: 97.88 seconds, 1.63 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.311098/  2.297628, val:  83.19%, val_best:  88.94%, tr:  96.20%, tr_best:  97.12%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.309394/  2.319479, val:  72.79%, val_best:  88.94%, tr:  96.08%, tr_best:  97.12%, epoch time: 97.22 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 262 occurrences\n",
      "test - Value 1: 190 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.308469/  2.297811, val:  81.42%, val_best:  88.94%, tr:  96.80%, tr_best:  97.12%, epoch time: 92.72 seconds, 1.55 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.314490/  2.312172, val:  78.76%, val_best:  88.94%, tr:  96.28%, tr_best:  97.12%, epoch time: 95.39 seconds, 1.59 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.306659/  2.307753, val:  86.73%, val_best:  88.94%, tr:  95.71%, tr_best:  97.12%, epoch time: 94.36 seconds, 1.57 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.311682/  2.321466, val:  79.42%, val_best:  88.94%, tr:  95.38%, tr_best:  97.12%, epoch time: 93.92 seconds, 1.57 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.310349/  2.341890, val:  79.65%, val_best:  88.94%, tr:  95.61%, tr_best:  97.12%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.309388/  2.328017, val:  76.77%, val_best:  88.94%, tr:  95.66%, tr_best:  97.12%, epoch time: 96.20 seconds, 1.60 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.313316/  2.320987, val:  78.32%, val_best:  88.94%, tr:  95.26%, tr_best:  97.12%, epoch time: 95.87 seconds, 1.60 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.309793/  2.307126, val:  86.28%, val_best:  88.94%, tr:  95.26%, tr_best:  97.12%, epoch time: 95.20 seconds, 1.59 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.309119/  2.318251, val:  85.18%, val_best:  88.94%, tr:  96.05%, tr_best:  97.12%, epoch time: 96.50 seconds, 1.61 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.312920/  2.330903, val:  72.12%, val_best:  88.94%, tr:  95.63%, tr_best:  97.12%, epoch time: 96.39 seconds, 1.61 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5cc6dea8348a191239503ee218f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñÅ‚ñá‚ñÅ‚ñà‚ñá‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÉ‚ñà‚ñá‚ñÇ‚ñà‚ñá‚ñÜ‚ñÖ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñÅ‚ñá‚ñÅ‚ñà‚ñá‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÉ‚ñà‚ñá‚ñÇ‚ñà‚ñá‚ñÜ‚ñÖ</td></tr><tr><td>val_loss</td><td>‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñà‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.95633</td></tr><tr><td>tr_epoch_loss</td><td>2.31292</td></tr><tr><td>val_acc_best</td><td>0.88938</td></tr><tr><td>val_acc_now</td><td>0.72124</td></tr><tr><td>val_loss</td><td>2.3309</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-4</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/c4qtsie3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/c4qtsie3</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_104037-c4qtsie3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d48uyltp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_160502-d48uyltp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/d48uyltp' target=\"_blank\">happy-sweep-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/d48uyltp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/d48uyltp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250806_160510_823', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.303664/  2.300518, val:  51.11%, val_best:  51.11%, tr:  62.28%, tr_best:  62.28%, epoch time: 98.32 seconds, 1.64 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.302835/  2.311888, val:  65.71%, val_best:  65.71%, tr:  74.27%, tr_best:  74.27%, epoch time: 95.36 seconds, 1.59 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.304109/  2.294798, val:  54.20%, val_best:  65.71%, tr:  78.41%, tr_best:  78.41%, epoch time: 97.90 seconds, 1.63 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.303119/  2.302139, val:  51.33%, val_best:  65.71%, tr:  80.45%, tr_best:  80.45%, epoch time: 95.54 seconds, 1.59 minutes\n",
      "train - Value 0: 1894 occurrences\n",
      "train - Value 1: 2136 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 263 occurrences\n",
      "test - Value 1: 189 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.303602/  2.298292, val:  81.19%, val_best:  81.19%, tr:  83.95%, tr_best:  83.95%, epoch time: 97.15 seconds, 1.62 minutes\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2111 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.304360/  2.312346, val:  50.66%, val_best:  81.19%, tr:  85.96%, tr_best:  85.96%, epoch time: 97.14 seconds, 1.62 minutes\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.304241/  2.296063, val:  72.57%, val_best:  81.19%, tr:  87.17%, tr_best:  87.17%, epoch time: 96.86 seconds, 1.61 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.304032/  2.302596, val:  58.85%, val_best:  81.19%, tr:  88.68%, tr_best:  88.68%, epoch time: 95.15 seconds, 1.59 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.305280/  2.324398, val:  68.58%, val_best:  81.19%, tr:  86.90%, tr_best:  88.68%, epoch time: 93.65 seconds, 1.56 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.304302/  2.321332, val:  51.99%, val_best:  81.19%, tr:  88.54%, tr_best:  88.68%, epoch time: 92.92 seconds, 1.55 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 327 occurrences\n",
      "test - Value 1: 125 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.305441/  2.312778, val:  75.88%, val_best:  81.19%, tr:  89.90%, tr_best:  89.90%, epoch time: 94.99 seconds, 1.58 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.305295/  2.290339, val:  80.75%, val_best:  81.19%, tr:  89.93%, tr_best:  89.93%, epoch time: 97.28 seconds, 1.62 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.303291/  2.300596, val:  76.11%, val_best:  81.19%, tr:  91.44%, tr_best:  91.44%, epoch time: 97.74 seconds, 1.63 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.306597/  2.323200, val:  57.08%, val_best:  81.19%, tr:  92.16%, tr_best:  92.16%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.307372/  2.342602, val:  58.41%, val_best:  81.19%, tr:  92.23%, tr_best:  92.23%, epoch time: 96.46 seconds, 1.61 minutes\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.307909/  2.316885, val:  62.83%, val_best:  81.19%, tr:  92.23%, tr_best:  92.23%, epoch time: 97.14 seconds, 1.62 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.307006/  2.300159, val:  86.50%, val_best:  86.50%, tr:  92.31%, tr_best:  92.31%, epoch time: 96.74 seconds, 1.61 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.305062/  2.298155, val:  82.08%, val_best:  86.50%, tr:  93.05%, tr_best:  93.05%, epoch time: 96.99 seconds, 1.62 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.303794/  2.308207, val:  81.86%, val_best:  86.50%, tr:  93.87%, tr_best:  93.87%, epoch time: 97.28 seconds, 1.62 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.304382/  2.309017, val:  63.05%, val_best:  86.50%, tr:  93.18%, tr_best:  93.87%, epoch time: 96.41 seconds, 1.61 minutes\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2081 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.306132/  2.307364, val:  86.95%, val_best:  86.95%, tr:  93.25%, tr_best:  93.87%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 327 occurrences\n",
      "test - Value 1: 125 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.307116/  2.280968, val:  76.77%, val_best:  86.95%, tr:  94.34%, tr_best:  94.34%, epoch time: 97.46 seconds, 1.62 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 38 occurrences\n",
      "test - Value 1: 414 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.307203/  2.329405, val:  58.41%, val_best:  86.95%, tr:  93.85%, tr_best:  94.34%, epoch time: 97.04 seconds, 1.62 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.306634/  2.308755, val:  73.23%, val_best:  86.95%, tr:  93.52%, tr_best:  94.34%, epoch time: 95.75 seconds, 1.60 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.306762/  2.297458, val:  79.87%, val_best:  86.95%, tr:  94.22%, tr_best:  94.34%, epoch time: 95.94 seconds, 1.60 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.307311/  2.302408, val:  82.96%, val_best:  86.95%, tr:  94.89%, tr_best:  94.89%, epoch time: 97.52 seconds, 1.63 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.308685/  2.274019, val:  77.65%, val_best:  86.95%, tr:  95.09%, tr_best:  95.09%, epoch time: 96.80 seconds, 1.61 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.305120/  2.316432, val:  86.95%, val_best:  86.95%, tr:  95.19%, tr_best:  95.19%, epoch time: 96.12 seconds, 1.60 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.307922/  2.297979, val:  82.30%, val_best:  86.95%, tr:  94.71%, tr_best:  95.19%, epoch time: 95.06 seconds, 1.58 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.305861/  2.314886, val:  59.96%, val_best:  86.95%, tr:  95.73%, tr_best:  95.73%, epoch time: 95.56 seconds, 1.59 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.306177/  2.289516, val:  82.74%, val_best:  86.95%, tr:  94.99%, tr_best:  95.73%, epoch time: 96.57 seconds, 1.61 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.305999/  2.307150, val:  79.42%, val_best:  86.95%, tr:  96.50%, tr_best:  96.50%, epoch time: 96.60 seconds, 1.61 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.305402/  2.314164, val:  66.15%, val_best:  86.95%, tr:  95.81%, tr_best:  96.50%, epoch time: 97.19 seconds, 1.62 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.306366/  2.282812, val:  78.54%, val_best:  86.95%, tr:  95.66%, tr_best:  96.50%, epoch time: 96.81 seconds, 1.61 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.309078/  2.311576, val:  80.53%, val_best:  86.95%, tr:  95.88%, tr_best:  96.50%, epoch time: 97.17 seconds, 1.62 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.308650/  2.312831, val:  65.71%, val_best:  86.95%, tr:  95.56%, tr_best:  96.50%, epoch time: 96.09 seconds, 1.60 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.309539/  2.307865, val:  81.64%, val_best:  86.95%, tr:  95.83%, tr_best:  96.50%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.312495/  2.328273, val:  50.66%, val_best:  86.95%, tr:  95.83%, tr_best:  96.50%, epoch time: 97.60 seconds, 1.63 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.312824/  2.317256, val:  87.61%, val_best:  87.61%, tr:  95.93%, tr_best:  96.50%, epoch time: 96.65 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.310976/  2.314165, val:  85.84%, val_best:  87.61%, tr:  96.80%, tr_best:  96.80%, epoch time: 97.52 seconds, 1.63 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.309293/  2.345086, val:  62.39%, val_best:  87.61%, tr:  96.77%, tr_best:  96.80%, epoch time: 96.61 seconds, 1.61 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.310776/  2.347735, val:  79.65%, val_best:  87.61%, tr:  96.67%, tr_best:  96.80%, epoch time: 97.42 seconds, 1.62 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.311632/  2.304191, val:  78.32%, val_best:  87.61%, tr:  97.12%, tr_best:  97.12%, epoch time: 96.94 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.310009/  2.319586, val:  85.84%, val_best:  87.61%, tr:  97.05%, tr_best:  97.12%, epoch time: 97.00 seconds, 1.62 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.308746/  2.309280, val:  80.97%, val_best:  87.61%, tr:  96.00%, tr_best:  97.12%, epoch time: 93.47 seconds, 1.56 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.307674/  2.317072, val:  57.96%, val_best:  87.61%, tr:  96.90%, tr_best:  97.12%, epoch time: 93.66 seconds, 1.56 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.306798/  2.326510, val:  53.76%, val_best:  87.61%, tr:  97.12%, tr_best:  97.12%, epoch time: 93.76 seconds, 1.56 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.308668/  2.290481, val:  80.09%, val_best:  87.61%, tr:  96.48%, tr_best:  97.12%, epoch time: 97.18 seconds, 1.62 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.305975/  2.342205, val:  52.43%, val_best:  87.61%, tr:  96.70%, tr_best:  97.12%, epoch time: 96.99 seconds, 1.62 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.307625/  2.351810, val:  59.07%, val_best:  87.61%, tr:  96.85%, tr_best:  97.12%, epoch time: 96.75 seconds, 1.61 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.309896/  2.322428, val:  82.30%, val_best:  87.61%, tr:  96.97%, tr_best:  97.12%, epoch time: 95.36 seconds, 1.59 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.310217/  2.350860, val:  62.39%, val_best:  87.61%, tr:  97.39%, tr_best:  97.39%, epoch time: 96.60 seconds, 1.61 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.308960/  2.307630, val:  84.29%, val_best:  87.61%, tr:  97.22%, tr_best:  97.39%, epoch time: 96.89 seconds, 1.61 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.309169/  2.313463, val:  75.66%, val_best:  87.61%, tr:  96.58%, tr_best:  97.39%, epoch time: 97.65 seconds, 1.63 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.307844/  2.319813, val:  74.78%, val_best:  87.61%, tr:  96.50%, tr_best:  97.39%, epoch time: 97.12 seconds, 1.62 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.308467/  2.329992, val:  65.93%, val_best:  87.61%, tr:  97.00%, tr_best:  97.39%, epoch time: 95.61 seconds, 1.59 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.310333/  2.345476, val:  53.54%, val_best:  87.61%, tr:  97.32%, tr_best:  97.39%, epoch time: 95.85 seconds, 1.60 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.307698/  2.315457, val:  57.08%, val_best:  87.61%, tr:  96.65%, tr_best:  97.39%, epoch time: 97.02 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.310588/  2.306762, val:  81.42%, val_best:  87.61%, tr:  97.30%, tr_best:  97.39%, epoch time: 97.20 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.306306/  2.319825, val:  82.96%, val_best:  87.61%, tr:  97.87%, tr_best:  97.87%, epoch time: 96.77 seconds, 1.61 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.305322/  2.306924, val:  76.11%, val_best:  87.61%, tr:  97.12%, tr_best:  97.87%, epoch time: 96.91 seconds, 1.62 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.306057/  2.309082, val:  88.50%, val_best:  88.50%, tr:  97.82%, tr_best:  97.87%, epoch time: 96.85 seconds, 1.61 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 329 occurrences\n",
      "test - Value 1: 123 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.309916/  2.306246, val:  76.33%, val_best:  88.50%, tr:  97.84%, tr_best:  97.87%, epoch time: 96.47 seconds, 1.61 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.311682/  2.328100, val:  77.65%, val_best:  88.50%, tr:  97.67%, tr_best:  97.87%, epoch time: 96.96 seconds, 1.62 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.309765/  2.311099, val:  82.96%, val_best:  88.50%, tr:  97.97%, tr_best:  97.97%, epoch time: 97.15 seconds, 1.62 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.314846/  2.300998, val:  83.63%, val_best:  88.50%, tr:  98.26%, tr_best:  98.26%, epoch time: 96.89 seconds, 1.61 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.312768/  2.330419, val:  72.79%, val_best:  88.50%, tr:  97.79%, tr_best:  98.26%, epoch time: 95.85 seconds, 1.60 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.308768/  2.319856, val:  55.97%, val_best:  88.50%, tr:  97.94%, tr_best:  98.26%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.308599/  2.322132, val:  71.02%, val_best:  88.50%, tr:  98.19%, tr_best:  98.26%, epoch time: 96.68 seconds, 1.61 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.308910/  2.319317, val:  82.30%, val_best:  88.50%, tr:  98.76%, tr_best:  98.76%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.306233/  2.330777, val:  69.25%, val_best:  88.50%, tr:  98.61%, tr_best:  98.76%, epoch time: 97.03 seconds, 1.62 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.309103/  2.323120, val:  85.18%, val_best:  88.50%, tr:  98.19%, tr_best:  98.76%, epoch time: 96.87 seconds, 1.61 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.309683/  2.317090, val:  63.50%, val_best:  88.50%, tr:  98.59%, tr_best:  98.76%, epoch time: 97.51 seconds, 1.63 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.306695/  2.289753, val:  79.42%, val_best:  88.50%, tr:  97.99%, tr_best:  98.76%, epoch time: 96.24 seconds, 1.60 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.304331/  2.290729, val:  83.63%, val_best:  88.50%, tr:  98.59%, tr_best:  98.76%, epoch time: 97.37 seconds, 1.62 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.307794/  2.316723, val:  77.43%, val_best:  88.50%, tr:  98.88%, tr_best:  98.88%, epoch time: 96.89 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.310989/  2.321935, val:  84.29%, val_best:  88.50%, tr:  98.44%, tr_best:  98.88%, epoch time: 96.51 seconds, 1.61 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.311793/  2.292565, val:  86.73%, val_best:  88.50%, tr:  98.93%, tr_best:  98.93%, epoch time: 96.38 seconds, 1.61 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.307751/  2.325626, val:  73.23%, val_best:  88.50%, tr:  98.96%, tr_best:  98.96%, epoch time: 96.54 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.310701/  2.330310, val:  73.23%, val_best:  88.50%, tr:  98.86%, tr_best:  98.96%, epoch time: 96.23 seconds, 1.60 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.310625/  2.337900, val:  66.59%, val_best:  88.50%, tr:  98.19%, tr_best:  98.96%, epoch time: 93.83 seconds, 1.56 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.306835/  2.309528, val:  85.62%, val_best:  88.50%, tr:  99.08%, tr_best:  99.08%, epoch time: 93.74 seconds, 1.56 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.315413/  2.341591, val:  63.05%, val_best:  88.50%, tr:  99.13%, tr_best:  99.13%, epoch time: 92.81 seconds, 1.55 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.309474/  2.331553, val:  88.05%, val_best:  88.50%, tr:  98.93%, tr_best:  99.13%, epoch time: 93.59 seconds, 1.56 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.309664/  2.323115, val:  80.09%, val_best:  88.50%, tr:  98.96%, tr_best:  99.13%, epoch time: 95.76 seconds, 1.60 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.310349/  2.344945, val:  73.45%, val_best:  88.50%, tr:  98.83%, tr_best:  99.13%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.312179/  2.336381, val:  87.39%, val_best:  88.50%, tr:  98.41%, tr_best:  99.13%, epoch time: 97.08 seconds, 1.62 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.311642/  2.314110, val:  70.58%, val_best:  88.50%, tr:  98.59%, tr_best:  99.13%, epoch time: 95.94 seconds, 1.60 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.311339/  2.336080, val:  70.35%, val_best:  88.50%, tr:  98.64%, tr_best:  99.13%, epoch time: 97.16 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 55 occurrences\n",
      "test - Value 1: 397 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.309468/  2.337851, val:  62.17%, val_best:  88.50%, tr:  98.78%, tr_best:  99.13%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.308914/  2.310602, val:  81.64%, val_best:  88.50%, tr:  98.64%, tr_best:  99.13%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.310891/  2.297845, val:  88.05%, val_best:  88.50%, tr:  99.18%, tr_best:  99.18%, epoch time: 96.58 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.312247/  2.324056, val:  73.45%, val_best:  88.50%, tr:  99.08%, tr_best:  99.18%, epoch time: 96.89 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.313208/  2.340184, val:  64.60%, val_best:  88.50%, tr:  98.83%, tr_best:  99.18%, epoch time: 96.80 seconds, 1.61 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.312189/  2.346872, val:  80.53%, val_best:  88.50%, tr:  98.81%, tr_best:  99.18%, epoch time: 96.58 seconds, 1.61 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.317600/  2.322088, val:  63.05%, val_best:  88.50%, tr:  99.11%, tr_best:  99.18%, epoch time: 96.68 seconds, 1.61 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.312504/  2.318793, val:  67.48%, val_best:  88.50%, tr:  98.76%, tr_best:  99.18%, epoch time: 96.96 seconds, 1.62 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.312396/  2.354086, val:  67.26%, val_best:  88.50%, tr:  98.96%, tr_best:  99.18%, epoch time: 96.40 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.315919/  2.330883, val:  65.49%, val_best:  88.50%, tr:  98.91%, tr_best:  99.18%, epoch time: 96.67 seconds, 1.61 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.313100/  2.329903, val:  76.33%, val_best:  88.50%, tr:  98.96%, tr_best:  99.18%, epoch time: 96.57 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.314517/  2.334260, val:  62.83%, val_best:  88.50%, tr:  99.18%, tr_best:  99.18%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.310014/  2.324992, val:  73.67%, val_best:  88.50%, tr:  99.18%, tr_best:  99.18%, epoch time: 97.39 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.310138/  2.327857, val:  73.45%, val_best:  88.50%, tr:  99.28%, tr_best:  99.28%, epoch time: 96.18 seconds, 1.60 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.312134/  2.372068, val:  64.82%, val_best:  88.50%, tr:  99.01%, tr_best:  99.28%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.311736/  2.299394, val:  82.52%, val_best:  88.50%, tr:  99.23%, tr_best:  99.28%, epoch time: 97.27 seconds, 1.62 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.313044/  2.332218, val:  83.19%, val_best:  88.50%, tr:  99.21%, tr_best:  99.28%, epoch time: 97.56 seconds, 1.63 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.312542/  2.327857, val:  83.63%, val_best:  88.50%, tr:  99.26%, tr_best:  99.28%, epoch time: 95.75 seconds, 1.60 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.314454/  2.326548, val:  75.22%, val_best:  88.50%, tr:  99.21%, tr_best:  99.28%, epoch time: 97.00 seconds, 1.62 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.314436/  2.347440, val:  57.96%, val_best:  88.50%, tr:  99.23%, tr_best:  99.28%, epoch time: 96.67 seconds, 1.61 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.313365/  2.350768, val:  67.70%, val_best:  88.50%, tr:  99.48%, tr_best:  99.48%, epoch time: 96.57 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.320905/  2.319230, val:  79.42%, val_best:  88.50%, tr:  99.45%, tr_best:  99.48%, epoch time: 95.63 seconds, 1.59 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.315909/  2.336082, val:  67.92%, val_best:  88.50%, tr:  99.28%, tr_best:  99.48%, epoch time: 96.34 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.312084/  2.299581, val:  73.01%, val_best:  88.50%, tr:  99.23%, tr_best:  99.48%, epoch time: 97.71 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.309621/  2.341218, val:  71.02%, val_best:  88.50%, tr:  99.28%, tr_best:  99.48%, epoch time: 96.71 seconds, 1.61 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.315005/  2.331992, val:  78.10%, val_best:  88.50%, tr:  99.08%, tr_best:  99.48%, epoch time: 96.56 seconds, 1.61 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.313664/  2.387538, val:  55.97%, val_best:  88.50%, tr:  99.45%, tr_best:  99.48%, epoch time: 97.24 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.314984/  2.334578, val:  78.54%, val_best:  88.50%, tr:  99.31%, tr_best:  99.48%, epoch time: 97.31 seconds, 1.62 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.312655/  2.338419, val:  69.91%, val_best:  88.50%, tr:  99.18%, tr_best:  99.48%, epoch time: 95.30 seconds, 1.59 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.310834/  2.353072, val:  66.15%, val_best:  88.50%, tr:  99.35%, tr_best:  99.48%, epoch time: 93.20 seconds, 1.55 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.315590/  2.329730, val:  73.01%, val_best:  88.50%, tr:  99.50%, tr_best:  99.50%, epoch time: 94.43 seconds, 1.57 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.320121/  2.342543, val:  70.35%, val_best:  88.50%, tr:  99.26%, tr_best:  99.50%, epoch time: 97.11 seconds, 1.62 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.314970/  2.342289, val:  78.76%, val_best:  88.50%, tr:  99.38%, tr_best:  99.50%, epoch time: 96.61 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.313277/  2.325473, val:  79.87%, val_best:  88.50%, tr:  99.26%, tr_best:  99.50%, epoch time: 97.45 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.316792/  2.341999, val:  67.04%, val_best:  88.50%, tr:  99.43%, tr_best:  99.50%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.319400/  2.352711, val:  78.76%, val_best:  88.50%, tr:  99.43%, tr_best:  99.50%, epoch time: 97.72 seconds, 1.63 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.314367/  2.317143, val:  78.54%, val_best:  88.50%, tr:  99.45%, tr_best:  99.50%, epoch time: 95.63 seconds, 1.59 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.312412/  2.325745, val:  76.33%, val_best:  88.50%, tr:  99.43%, tr_best:  99.50%, epoch time: 96.74 seconds, 1.61 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.313325/  2.347322, val:  75.88%, val_best:  88.50%, tr:  99.45%, tr_best:  99.50%, epoch time: 97.29 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.312868/  2.318725, val:  68.58%, val_best:  88.50%, tr:  99.50%, tr_best:  99.50%, epoch time: 97.24 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.312667/  2.300929, val:  82.08%, val_best:  88.50%, tr:  99.23%, tr_best:  99.50%, epoch time: 97.71 seconds, 1.63 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.311163/  2.334787, val:  67.70%, val_best:  88.50%, tr:  99.08%, tr_best:  99.50%, epoch time: 97.89 seconds, 1.63 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.309248/  2.333573, val:  72.35%, val_best:  88.50%, tr:  99.33%, tr_best:  99.50%, epoch time: 98.18 seconds, 1.64 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.306758/  2.334402, val:  80.53%, val_best:  88.50%, tr:  99.45%, tr_best:  99.50%, epoch time: 97.18 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.313976/  2.340039, val:  87.83%, val_best:  88.50%, tr:  99.43%, tr_best:  99.50%, epoch time: 95.42 seconds, 1.59 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.316387/  2.339251, val:  75.88%, val_best:  88.50%, tr:  99.45%, tr_best:  99.50%, epoch time: 95.54 seconds, 1.59 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.318278/  2.325844, val:  72.57%, val_best:  88.50%, tr:  99.65%, tr_best:  99.65%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.314397/  2.348661, val:  76.77%, val_best:  88.50%, tr:  99.65%, tr_best:  99.65%, epoch time: 97.80 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.321756/  2.338176, val:  79.20%, val_best:  88.50%, tr:  99.58%, tr_best:  99.65%, epoch time: 96.26 seconds, 1.60 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.319996/  2.344557, val:  71.90%, val_best:  88.50%, tr:  99.68%, tr_best:  99.68%, epoch time: 95.91 seconds, 1.60 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.313263/  2.337445, val:  72.12%, val_best:  88.50%, tr:  99.60%, tr_best:  99.68%, epoch time: 97.45 seconds, 1.62 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.316607/  2.319406, val:  75.88%, val_best:  88.50%, tr:  99.58%, tr_best:  99.68%, epoch time: 97.44 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.312552/  2.344019, val:  79.42%, val_best:  88.50%, tr:  99.50%, tr_best:  99.68%, epoch time: 97.71 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.324804/  2.333089, val:  72.12%, val_best:  88.50%, tr:  99.68%, tr_best:  99.68%, epoch time: 97.41 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.322960/  2.330527, val:  71.02%, val_best:  88.50%, tr:  99.65%, tr_best:  99.68%, epoch time: 97.23 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.330113/  2.329168, val:  79.65%, val_best:  88.50%, tr:  99.58%, tr_best:  99.68%, epoch time: 96.46 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.324944/  2.337153, val:  76.99%, val_best:  88.50%, tr:  99.43%, tr_best:  99.68%, epoch time: 97.51 seconds, 1.63 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.323009/  2.324937, val:  78.98%, val_best:  88.50%, tr:  99.60%, tr_best:  99.68%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.315263/  2.325206, val:  83.85%, val_best:  88.50%, tr:  99.40%, tr_best:  99.68%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.310770/  2.323119, val:  70.13%, val_best:  88.50%, tr:  99.26%, tr_best:  99.68%, epoch time: 97.29 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.312766/  2.318792, val:  75.22%, val_best:  88.50%, tr:  99.38%, tr_best:  99.68%, epoch time: 96.04 seconds, 1.60 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.307255/  2.341880, val:  78.10%, val_best:  88.50%, tr:  99.31%, tr_best:  99.68%, epoch time: 96.73 seconds, 1.61 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.309043/  2.360527, val:  70.58%, val_best:  88.50%, tr:  99.28%, tr_best:  99.68%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.310279/  2.312724, val:  65.49%, val_best:  88.50%, tr:  99.63%, tr_best:  99.68%, epoch time: 97.79 seconds, 1.63 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.307134/  2.341818, val:  75.44%, val_best:  88.50%, tr:  99.31%, tr_best:  99.68%, epoch time: 95.08 seconds, 1.58 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.303032/  2.329324, val:  76.33%, val_best:  88.50%, tr:  99.48%, tr_best:  99.68%, epoch time: 94.12 seconds, 1.57 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.311195/  2.346945, val:  73.45%, val_best:  88.50%, tr:  99.40%, tr_best:  99.68%, epoch time: 94.49 seconds, 1.57 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.305881/  2.307578, val:  81.19%, val_best:  88.50%, tr:  99.40%, tr_best:  99.68%, epoch time: 96.88 seconds, 1.61 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.305183/  2.310652, val:  85.62%, val_best:  88.50%, tr:  99.53%, tr_best:  99.68%, epoch time: 97.50 seconds, 1.62 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.309887/  2.299756, val:  84.73%, val_best:  88.50%, tr:  99.55%, tr_best:  99.68%, epoch time: 97.76 seconds, 1.63 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.318367/  2.340893, val:  77.88%, val_best:  88.50%, tr:  99.63%, tr_best:  99.68%, epoch time: 96.82 seconds, 1.61 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 85 occurrences\n",
      "test - Value 1: 367 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.315125/  2.334021, val:  68.36%, val_best:  88.50%, tr:  99.38%, tr_best:  99.68%, epoch time: 96.06 seconds, 1.60 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.310694/  2.339077, val:  59.73%, val_best:  88.50%, tr:  99.63%, tr_best:  99.68%, epoch time: 95.42 seconds, 1.59 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.316422/  2.376950, val:  72.35%, val_best:  88.50%, tr:  99.63%, tr_best:  99.68%, epoch time: 97.39 seconds, 1.62 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.315756/  2.334195, val:  73.01%, val_best:  88.50%, tr:  99.53%, tr_best:  99.68%, epoch time: 97.27 seconds, 1.62 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.316717/  2.281043, val:  83.19%, val_best:  88.50%, tr:  99.60%, tr_best:  99.68%, epoch time: 96.01 seconds, 1.60 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.311975/  2.330999, val:  68.36%, val_best:  88.50%, tr:  99.58%, tr_best:  99.68%, epoch time: 95.12 seconds, 1.59 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.321110/  2.312772, val:  79.42%, val_best:  88.50%, tr:  99.55%, tr_best:  99.68%, epoch time: 97.19 seconds, 1.62 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.320890/  2.375827, val:  83.85%, val_best:  88.50%, tr:  99.65%, tr_best:  99.68%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.312588/  2.315228, val:  73.23%, val_best:  88.50%, tr:  99.48%, tr_best:  99.68%, epoch time: 97.75 seconds, 1.63 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.311218/  2.334198, val:  58.85%, val_best:  88.50%, tr:  99.31%, tr_best:  99.68%, epoch time: 96.84 seconds, 1.61 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.310930/  2.352671, val:  66.59%, val_best:  88.50%, tr:  99.40%, tr_best:  99.68%, epoch time: 96.91 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.307405/  2.359777, val:  67.48%, val_best:  88.50%, tr:  99.45%, tr_best:  99.68%, epoch time: 96.87 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.309810/  2.328791, val:  64.82%, val_best:  88.50%, tr:  99.33%, tr_best:  99.68%, epoch time: 97.84 seconds, 1.63 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.310449/  2.352180, val:  84.07%, val_best:  88.50%, tr:  99.40%, tr_best:  99.68%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.313716/  2.325299, val:  72.12%, val_best:  88.50%, tr:  99.43%, tr_best:  99.68%, epoch time: 97.63 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.315453/  2.337421, val:  66.81%, val_best:  88.50%, tr:  99.58%, tr_best:  99.68%, epoch time: 96.43 seconds, 1.61 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.321230/  2.373891, val:  62.83%, val_best:  88.50%, tr:  99.60%, tr_best:  99.68%, epoch time: 97.59 seconds, 1.63 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.320775/  2.370423, val:  65.49%, val_best:  88.50%, tr:  99.70%, tr_best:  99.70%, epoch time: 96.99 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.319041/  2.318872, val:  74.56%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.328372/  2.328501, val:  76.99%, val_best:  88.50%, tr:  99.75%, tr_best:  99.83%, epoch time: 96.75 seconds, 1.61 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.321293/  2.350591, val:  72.79%, val_best:  88.50%, tr:  99.63%, tr_best:  99.83%, epoch time: 95.66 seconds, 1.59 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.326514/  2.345817, val:  73.45%, val_best:  88.50%, tr:  99.75%, tr_best:  99.83%, epoch time: 96.59 seconds, 1.61 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.331231/  2.333971, val:  75.44%, val_best:  88.50%, tr:  99.78%, tr_best:  99.83%, epoch time: 96.76 seconds, 1.61 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.322562/  2.357719, val:  54.20%, val_best:  88.50%, tr:  99.80%, tr_best:  99.83%, epoch time: 98.10 seconds, 1.64 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.325932/  2.330040, val:  75.88%, val_best:  88.50%, tr:  99.68%, tr_best:  99.83%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.322389/  2.360569, val:  59.51%, val_best:  88.50%, tr:  99.73%, tr_best:  99.83%, epoch time: 96.37 seconds, 1.61 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.324808/  2.355877, val:  69.91%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 97.65 seconds, 1.63 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.323376/  2.357682, val:  75.44%, val_best:  88.50%, tr:  99.78%, tr_best:  99.83%, epoch time: 97.25 seconds, 1.62 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.320252/  2.385193, val:  67.48%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 96.24 seconds, 1.60 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.315365/  2.343036, val:  71.24%, val_best:  88.50%, tr:  99.65%, tr_best:  99.83%, epoch time: 95.56 seconds, 1.59 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.326603/  2.323142, val:  75.66%, val_best:  88.50%, tr:  99.75%, tr_best:  99.83%, epoch time: 93.24 seconds, 1.55 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.320231/  2.358954, val:  73.45%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 93.46 seconds, 1.56 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.323543/  2.363580, val:  64.82%, val_best:  88.50%, tr:  99.78%, tr_best:  99.83%, epoch time: 93.27 seconds, 1.55 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.322314/  2.329917, val:  76.11%, val_best:  88.50%, tr:  99.78%, tr_best:  99.83%, epoch time: 95.02 seconds, 1.58 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.316015/  2.337440, val:  72.57%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 97.47 seconds, 1.62 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.315928/  2.324228, val:  66.15%, val_best:  88.50%, tr:  99.65%, tr_best:  99.83%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.321829/  2.342451, val:  68.14%, val_best:  88.50%, tr:  99.83%, tr_best:  99.83%, epoch time: 96.35 seconds, 1.61 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.315840/  2.351275, val:  70.35%, val_best:  88.50%, tr:  99.93%, tr_best:  99.93%, epoch time: 97.31 seconds, 1.62 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.318198/  2.320031, val:  78.54%, val_best:  88.50%, tr:  99.75%, tr_best:  99.93%, epoch time: 96.85 seconds, 1.61 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.318562/  2.333702, val:  82.52%, val_best:  88.50%, tr:  99.88%, tr_best:  99.93%, epoch time: 97.25 seconds, 1.62 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f28d563184a99869751a55d538885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñá‚ñà‚ñá‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñÜ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñá‚ñà‚ñá‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñÖ‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99876</td></tr><tr><td>tr_epoch_loss</td><td>2.31856</td></tr><tr><td>val_acc_best</td><td>0.88496</td></tr><tr><td>val_acc_now</td><td>0.82522</td></tr><tr><td>val_loss</td><td>2.3337</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-5</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/d48uyltp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/d48uyltp</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_160502-d48uyltp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mumgbfkh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001220703125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250806_212757-mumgbfkh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/mumgbfkh' target=\"_blank\">major-sweep-6</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/mumgbfkh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/mumgbfkh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250806_212806_917', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0001220703125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0001220703125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-0   lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 102.05 seconds, 1.70 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-1   lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.10 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-2   lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.27 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-3   lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.56 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-4   lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.87 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-5   lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.73 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-6   lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.20 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-7   lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.61 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-8   lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.65 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-9   lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.38 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-10  lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.65 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-11  lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.89 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-12  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.56 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-13  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-14  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.50 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-15  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.00 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-16  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.51 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-17  lr=['0.0001221'], tr/val_loss:  2.307398/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.69 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-18  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.91 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-19  lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.90 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-20  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.98 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-21  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.84 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-22  lr=['0.0001221'], tr/val_loss:  2.307397/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.27 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-23  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.23 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-24  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.73 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-25  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.27 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-26  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 94.66 seconds, 1.58 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-27  lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 94.51 seconds, 1.58 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-28  lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.90 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-29  lr=['0.0001221'], tr/val_loss:  2.307388/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.88 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-30  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.25 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-31  lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.59 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-32  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.66 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-33  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.09 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-34  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.93 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-35  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.96 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-36  lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.84 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-37  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.36 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-38  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.93 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-39  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.59 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-40  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.33 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-41  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-42  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.49 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-43  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.66 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-44  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.48 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-45  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.05 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-46  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.14 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-47  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.21 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-48  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.04 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-49  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.95 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-50  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.36 seconds, 1.66 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-51  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.86 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-52  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.02 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-53  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.10 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-54  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.20 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-55  lr=['0.0001221'], tr/val_loss:  2.307397/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.94 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-56  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.99 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-57  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.73 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-58  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.96 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-59  lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.06 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-60  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.72 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-61  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.86 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-62  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.03 seconds, 1.58 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-63  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 94.38 seconds, 1.57 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-64  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.76 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-65  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.60 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-66  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.33 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-67  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.73 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-68  lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.76 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-69  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.36 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-70  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.62 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-71  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.19 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-72  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.02 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-73  lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.66 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-74  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.48 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-75  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.45 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-76  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.80 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-77  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.10 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-78  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.88 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-79  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.70 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-80  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.33 seconds, 1.59 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-81  lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.61 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-82  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.03 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-83  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.88 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-84  lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.06 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-85  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.09 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-86  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.51 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-87  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.21 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-88  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.74 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-89  lr=['0.0001221'], tr/val_loss:  2.307397/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.05 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-90  lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.80 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-91  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.17 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-92  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-93  lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.50 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-94  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-95  lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.49 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-96  lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.56 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-97  lr=['0.0001221'], tr/val_loss:  2.307397/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.75 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-98  lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 94.24 seconds, 1.57 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-99  lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 94.29 seconds, 1.57 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-100 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.88 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-101 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.32 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-102 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.16 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-103 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.31 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-104 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.90 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-105 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.21 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-106 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.95 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-107 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.68 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-108 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.10 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-109 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.37 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-110 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.75 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-111 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.50 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-112 lr=['0.0001221'], tr/val_loss:  2.307397/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.91 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-113 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.80 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-114 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-115 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.64 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-116 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.77 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-117 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.18 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-118 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.37 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-119 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.17 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-120 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.29 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-121 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.24 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-122 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.35 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-123 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.81 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-124 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.07 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-125 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.97 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-126 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.98 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-127 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.67 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-128 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.57 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-129 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.83 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-130 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-131 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.50 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-132 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.13 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-133 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.71 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-134 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.19 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-135 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.16 seconds, 1.59 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-136 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.28 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-137 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.66 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-138 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.22 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-139 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.32 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-140 lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.45 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-141 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 100.39 seconds, 1.67 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-142 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 100.02 seconds, 1.67 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-143 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.18 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-144 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.88 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-145 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.17 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-146 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.62 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-147 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.39 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-148 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.95 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-149 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-150 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.09 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-151 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-152 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.14 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-153 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.67 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-154 lr=['0.0001221'], tr/val_loss:  2.307398/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.07 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-155 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.00 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-156 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.82 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-157 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-158 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-159 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.47 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-160 lr=['0.0001221'], tr/val_loss:  2.307398/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.86 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-161 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.77 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-162 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.05 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-163 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.39 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-164 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.62 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-165 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.25 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-166 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-167 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.52 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-168 lr=['0.0001221'], tr/val_loss:  2.307389/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.32 seconds, 1.62 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-169 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 95.26 seconds, 1.59 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-170 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 94.40 seconds, 1.57 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-171 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 93.87 seconds, 1.56 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-172 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.91 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-173 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 99.30 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-174 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.86 seconds, 1.65 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-175 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.15 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-176 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.22 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-177 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.10 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-178 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.72 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-179 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.64 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-180 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.31 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-181 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.60 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-182 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.73 seconds, 1.61 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-183 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 96.28 seconds, 1.60 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-184 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.68 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-185 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.83 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-186 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.91 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-187 lr=['0.0001221'], tr/val_loss:  2.307395/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.73 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-188 lr=['0.0001221'], tr/val_loss:  2.307392/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.55 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-189 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.28 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-190 lr=['0.0001221'], tr/val_loss:  2.307390/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.26 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-191 lr=['0.0001221'], tr/val_loss:  2.307394/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.03 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-192 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.60 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-193 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.36 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-194 lr=['0.0001221'], tr/val_loss:  2.307391/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.49 seconds, 1.64 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-195 lr=['0.0001221'], tr/val_loss:  2.307397/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.62 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-196 lr=['0.0001221'], tr/val_loss:  2.307393/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.88 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-197 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.01 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-198 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 97.80 seconds, 1.63 minutes\n",
      "train - Value 0: 2641 occurrences\n",
      "train - Value 1: 1389 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-199 lr=['0.0001221'], tr/val_loss:  2.307396/  2.304761, val:  51.11%, val_best:  51.11%, tr:  51.27%, tr_best:  51.27%, epoch time: 98.38 seconds, 1.64 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169e052d74de46a5b2ef75afa94b14c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñá</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.51266</td></tr><tr><td>tr_epoch_loss</td><td>2.3074</td></tr><tr><td>val_acc_best</td><td>0.51106</td></tr><tr><td>val_acc_now</td><td>0.51106</td></tr><tr><td>val_loss</td><td>2.30476</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sweep-6</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/mumgbfkh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/mumgbfkh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250806_212757-mumgbfkh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4oeuq2fg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250807_025429-4oeuq2fg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/4oeuq2fg' target=\"_blank\">honest-sweep-7</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/4oeuq2fg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/4oeuq2fg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250807_025438_430', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-12, -12], [-12, -12], [-11, -11]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.304646/  2.340930, val:  50.00%, val_best:  50.00%, tr:  75.38%, tr_best:  75.38%, epoch time: 141.36 seconds, 2.36 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.305270/  2.280127, val:  78.54%, val_best:  78.54%, tr:  85.78%, tr_best:  85.78%, epoch time: 139.84 seconds, 2.33 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.304751/  2.303958, val:  50.22%, val_best:  78.54%, tr:  87.72%, tr_best:  87.72%, epoch time: 141.00 seconds, 2.35 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.305898/  2.305829, val:  78.32%, val_best:  78.54%, tr:  89.03%, tr_best:  89.03%, epoch time: 136.35 seconds, 2.27 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 388 occurrences\n",
      "test - Value 1: 64 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.308169/  2.305999, val:  63.27%, val_best:  78.54%, tr:  90.87%, tr_best:  90.87%, epoch time: 136.40 seconds, 2.27 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.310487/  2.346478, val:  61.50%, val_best:  78.54%, tr:  92.06%, tr_best:  92.06%, epoch time: 136.52 seconds, 2.28 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 378 occurrences\n",
      "test - Value 1: 74 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.306240/  2.261214, val:  66.37%, val_best:  78.54%, tr:  92.21%, tr_best:  92.21%, epoch time: 138.05 seconds, 2.30 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.312059/  2.342014, val:  63.27%, val_best:  78.54%, tr:  93.30%, tr_best:  93.30%, epoch time: 137.86 seconds, 2.30 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.309849/  2.340132, val:  67.26%, val_best:  78.54%, tr:  93.95%, tr_best:  93.95%, epoch time: 140.01 seconds, 2.33 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.311839/  2.353815, val:  64.16%, val_best:  78.54%, tr:  93.47%, tr_best:  93.95%, epoch time: 139.63 seconds, 2.33 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 320 occurrences\n",
      "test - Value 1: 132 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.308818/  2.308173, val:  76.11%, val_best:  78.54%, tr:  94.84%, tr_best:  94.84%, epoch time: 140.34 seconds, 2.34 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 327 occurrences\n",
      "test - Value 1: 125 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.312793/  2.279426, val:  76.77%, val_best:  78.54%, tr:  95.38%, tr_best:  95.38%, epoch time: 140.50 seconds, 2.34 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 320 occurrences\n",
      "test - Value 1: 132 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.308131/  2.290178, val:  75.22%, val_best:  78.54%, tr:  95.21%, tr_best:  95.38%, epoch time: 139.39 seconds, 2.32 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.308726/  2.342667, val:  56.42%, val_best:  78.54%, tr:  94.34%, tr_best:  95.38%, epoch time: 139.49 seconds, 2.32 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.313523/  2.301216, val:  53.98%, val_best:  78.54%, tr:  93.97%, tr_best:  95.38%, epoch time: 139.90 seconds, 2.33 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.313602/  2.318942, val:  52.65%, val_best:  78.54%, tr:  95.04%, tr_best:  95.38%, epoch time: 140.46 seconds, 2.34 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.313974/  2.350146, val:  82.08%, val_best:  82.08%, tr:  94.91%, tr_best:  95.38%, epoch time: 139.38 seconds, 2.32 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.313435/  2.315886, val:  82.52%, val_best:  82.52%, tr:  95.26%, tr_best:  95.38%, epoch time: 139.81 seconds, 2.33 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 28 occurrences\n",
      "test - Value 1: 424 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.315660/  2.309047, val:  55.75%, val_best:  82.52%, tr:  95.36%, tr_best:  95.38%, epoch time: 139.43 seconds, 2.32 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.317115/  2.308838, val:  55.09%, val_best:  82.52%, tr:  94.09%, tr_best:  95.38%, epoch time: 139.24 seconds, 2.32 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 393 occurrences\n",
      "test - Value 1: 59 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.318590/  2.298743, val:  63.05%, val_best:  82.52%, tr:  95.48%, tr_best:  95.48%, epoch time: 139.67 seconds, 2.33 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.312714/  2.311264, val:  65.93%, val_best:  82.52%, tr:  95.51%, tr_best:  95.51%, epoch time: 140.00 seconds, 2.33 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.316133/  2.350597, val:  56.19%, val_best:  82.52%, tr:  94.76%, tr_best:  95.51%, epoch time: 139.67 seconds, 2.33 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 314 occurrences\n",
      "test - Value 1: 138 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.316589/  2.313524, val:  72.57%, val_best:  82.52%, tr:  95.56%, tr_best:  95.56%, epoch time: 138.84 seconds, 2.31 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 269 occurrences\n",
      "test - Value 1: 183 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.316383/  2.334928, val:  80.75%, val_best:  82.52%, tr:  96.05%, tr_best:  96.05%, epoch time: 139.76 seconds, 2.33 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.313689/  2.286544, val:  72.12%, val_best:  82.52%, tr:  95.58%, tr_best:  96.05%, epoch time: 137.82 seconds, 2.30 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.313386/  2.325291, val:  50.00%, val_best:  82.52%, tr:  95.83%, tr_best:  96.05%, epoch time: 137.78 seconds, 2.30 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.314368/  2.337970, val:  52.88%, val_best:  82.52%, tr:  95.73%, tr_best:  96.05%, epoch time: 140.87 seconds, 2.35 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.316824/  2.283436, val:  79.65%, val_best:  82.52%, tr:  95.86%, tr_best:  96.05%, epoch time: 137.62 seconds, 2.29 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.314902/  2.327629, val:  61.95%, val_best:  82.52%, tr:  95.46%, tr_best:  96.05%, epoch time: 135.26 seconds, 2.25 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 318 occurrences\n",
      "test - Value 1: 134 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.316304/  2.291356, val:  75.66%, val_best:  82.52%, tr:  95.38%, tr_best:  96.05%, epoch time: 135.70 seconds, 2.26 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.316629/  2.281626, val:  80.31%, val_best:  82.52%, tr:  96.03%, tr_best:  96.05%, epoch time: 141.15 seconds, 2.35 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.318556/  2.359572, val:  50.00%, val_best:  82.52%, tr:  94.69%, tr_best:  96.05%, epoch time: 140.31 seconds, 2.34 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 277 occurrences\n",
      "test - Value 1: 175 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.315785/  2.312724, val:  82.96%, val_best:  82.96%, tr:  95.86%, tr_best:  96.05%, epoch time: 141.58 seconds, 2.36 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.318780/  2.335452, val:  80.31%, val_best:  82.96%, tr:  95.76%, tr_best:  96.05%, epoch time: 141.19 seconds, 2.35 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.320129/  2.343576, val:  79.87%, val_best:  82.96%, tr:  95.04%, tr_best:  96.05%, epoch time: 141.42 seconds, 2.36 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.321427/  2.326147, val:  62.83%, val_best:  82.96%, tr:  95.76%, tr_best:  96.05%, epoch time: 141.08 seconds, 2.35 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.321147/  2.341151, val:  68.81%, val_best:  82.96%, tr:  95.63%, tr_best:  96.05%, epoch time: 141.39 seconds, 2.36 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 402 occurrences\n",
      "test - Value 1: 50 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.317195/  2.328918, val:  61.06%, val_best:  82.96%, tr:  96.82%, tr_best:  96.82%, epoch time: 139.99 seconds, 2.33 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.317830/  2.355807, val:  65.04%, val_best:  82.96%, tr:  96.60%, tr_best:  96.82%, epoch time: 140.06 seconds, 2.33 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.315638/  2.362752, val:  50.22%, val_best:  82.96%, tr:  96.13%, tr_best:  96.82%, epoch time: 139.06 seconds, 2.32 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.317784/  2.305644, val:  80.31%, val_best:  82.96%, tr:  96.33%, tr_best:  96.82%, epoch time: 139.73 seconds, 2.33 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 399 occurrences\n",
      "test - Value 1: 53 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.315929/  2.280026, val:  61.73%, val_best:  82.96%, tr:  95.51%, tr_best:  96.82%, epoch time: 141.11 seconds, 2.35 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.312184/  2.313545, val:  64.38%, val_best:  82.96%, tr:  96.10%, tr_best:  96.82%, epoch time: 139.17 seconds, 2.32 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.311301/  2.355105, val:  75.88%, val_best:  82.96%, tr:  96.08%, tr_best:  96.82%, epoch time: 140.23 seconds, 2.34 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.311983/  2.336863, val:  50.00%, val_best:  82.96%, tr:  96.40%, tr_best:  96.82%, epoch time: 136.59 seconds, 2.28 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.314058/  2.318876, val:  62.39%, val_best:  82.96%, tr:  95.53%, tr_best:  96.82%, epoch time: 138.86 seconds, 2.31 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.316798/  2.308660, val:  80.75%, val_best:  82.96%, tr:  96.58%, tr_best:  96.82%, epoch time: 140.94 seconds, 2.35 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.314535/  2.300718, val:  68.36%, val_best:  82.96%, tr:  96.53%, tr_best:  96.82%, epoch time: 140.86 seconds, 2.35 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.308642/  2.372974, val:  51.11%, val_best:  82.96%, tr:  96.30%, tr_best:  96.82%, epoch time: 140.78 seconds, 2.35 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 359 occurrences\n",
      "test - Value 1: 93 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.309961/  2.309409, val:  69.25%, val_best:  82.96%, tr:  96.30%, tr_best:  96.82%, epoch time: 141.29 seconds, 2.35 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.313838/  2.350691, val:  65.49%, val_best:  82.96%, tr:  95.76%, tr_best:  96.82%, epoch time: 141.42 seconds, 2.36 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.317466/  2.279199, val:  62.39%, val_best:  82.96%, tr:  95.83%, tr_best:  96.82%, epoch time: 139.85 seconds, 2.33 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.319337/  2.306300, val:  76.55%, val_best:  82.96%, tr:  96.05%, tr_best:  96.82%, epoch time: 138.79 seconds, 2.31 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.315993/  2.362076, val:  72.12%, val_best:  82.96%, tr:  96.28%, tr_best:  96.82%, epoch time: 133.48 seconds, 2.22 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.319295/  2.348768, val:  62.39%, val_best:  82.96%, tr:  96.53%, tr_best:  96.82%, epoch time: 136.28 seconds, 2.27 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.323385/  2.366639, val:  59.73%, val_best:  82.96%, tr:  96.18%, tr_best:  96.82%, epoch time: 139.21 seconds, 2.32 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.317767/  2.276743, val:  68.58%, val_best:  82.96%, tr:  95.68%, tr_best:  96.82%, epoch time: 139.45 seconds, 2.32 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.311655/  2.302078, val:  84.96%, val_best:  84.96%, tr:  96.03%, tr_best:  96.82%, epoch time: 139.61 seconds, 2.33 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.317706/  2.283723, val:  72.79%, val_best:  84.96%, tr:  95.71%, tr_best:  96.82%, epoch time: 139.13 seconds, 2.32 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.318467/  2.293791, val:  78.54%, val_best:  84.96%, tr:  95.46%, tr_best:  96.82%, epoch time: 139.71 seconds, 2.33 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.308938/  2.333784, val:  55.31%, val_best:  84.96%, tr:  96.15%, tr_best:  96.82%, epoch time: 139.78 seconds, 2.33 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.311782/  2.264658, val:  68.14%, val_best:  84.96%, tr:  96.03%, tr_best:  96.82%, epoch time: 140.34 seconds, 2.34 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 323 occurrences\n",
      "test - Value 1: 129 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.320085/  2.273741, val:  75.00%, val_best:  84.96%, tr:  96.75%, tr_best:  96.82%, epoch time: 138.83 seconds, 2.31 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.321173/  2.326365, val:  75.44%, val_best:  84.96%, tr:  96.13%, tr_best:  96.82%, epoch time: 137.95 seconds, 2.30 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.332752/  2.309842, val:  77.65%, val_best:  84.96%, tr:  96.82%, tr_best:  96.82%, epoch time: 135.77 seconds, 2.26 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.316001/  2.324077, val:  52.88%, val_best:  84.96%, tr:  96.28%, tr_best:  96.82%, epoch time: 139.91 seconds, 2.33 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.314540/  2.341203, val:  50.22%, val_best:  84.96%, tr:  96.13%, tr_best:  96.82%, epoch time: 139.54 seconds, 2.33 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.321835/  2.298056, val:  84.51%, val_best:  84.96%, tr:  96.38%, tr_best:  96.82%, epoch time: 140.17 seconds, 2.34 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.318516/  2.350271, val:  83.19%, val_best:  84.96%, tr:  96.20%, tr_best:  96.82%, epoch time: 141.68 seconds, 2.36 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.310987/  2.370717, val:  59.07%, val_best:  84.96%, tr:  95.61%, tr_best:  96.82%, epoch time: 139.29 seconds, 2.32 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.322743/  2.281553, val:  82.74%, val_best:  84.96%, tr:  96.82%, tr_best:  96.82%, epoch time: 141.06 seconds, 2.35 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 393 occurrences\n",
      "test - Value 1: 59 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.314739/  2.259948, val:  63.05%, val_best:  84.96%, tr:  95.71%, tr_best:  96.82%, epoch time: 140.22 seconds, 2.34 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 385 occurrences\n",
      "test - Value 1: 67 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.314508/  2.336887, val:  63.94%, val_best:  84.96%, tr:  96.08%, tr_best:  96.82%, epoch time: 140.32 seconds, 2.34 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.306523/  2.248240, val:  71.02%, val_best:  84.96%, tr:  95.63%, tr_best:  96.82%, epoch time: 140.08 seconds, 2.33 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.322409/  2.330226, val:  50.66%, val_best:  84.96%, tr:  95.68%, tr_best:  96.82%, epoch time: 140.29 seconds, 2.34 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 408 occurrences\n",
      "test - Value 1: 44 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.309453/  2.267889, val:  59.73%, val_best:  84.96%, tr:  95.58%, tr_best:  96.82%, epoch time: 140.41 seconds, 2.34 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.317287/  2.279056, val:  75.44%, val_best:  84.96%, tr:  95.98%, tr_best:  96.82%, epoch time: 140.28 seconds, 2.34 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.319640/  2.313325, val:  59.51%, val_best:  84.96%, tr:  96.58%, tr_best:  96.82%, epoch time: 138.77 seconds, 2.31 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.315284/  2.336895, val:  84.29%, val_best:  84.96%, tr:  96.55%, tr_best:  96.82%, epoch time: 135.23 seconds, 2.25 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.301708/  2.306421, val:  58.19%, val_best:  84.96%, tr:  96.10%, tr_best:  96.82%, epoch time: 134.91 seconds, 2.25 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.309510/  2.333766, val:  70.80%, val_best:  84.96%, tr:  95.71%, tr_best:  96.82%, epoch time: 139.13 seconds, 2.32 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.318289/  2.332318, val:  54.42%, val_best:  84.96%, tr:  96.75%, tr_best:  96.82%, epoch time: 140.77 seconds, 2.35 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.323869/  2.294060, val:  75.44%, val_best:  84.96%, tr:  96.90%, tr_best:  96.90%, epoch time: 138.45 seconds, 2.31 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.314860/  2.321966, val:  78.32%, val_best:  84.96%, tr:  96.75%, tr_best:  96.90%, epoch time: 136.28 seconds, 2.27 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.305836/  2.347821, val:  69.25%, val_best:  84.96%, tr:  96.30%, tr_best:  96.90%, epoch time: 137.67 seconds, 2.29 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.314056/  2.367403, val:  50.00%, val_best:  84.96%, tr:  97.00%, tr_best:  97.00%, epoch time: 139.81 seconds, 2.33 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.309510/  2.315357, val:  76.55%, val_best:  84.96%, tr:  96.05%, tr_best:  97.00%, epoch time: 139.75 seconds, 2.33 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.315213/  2.332003, val:  63.05%, val_best:  84.96%, tr:  96.85%, tr_best:  97.00%, epoch time: 138.65 seconds, 2.31 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.310422/  2.385955, val:  50.22%, val_best:  84.96%, tr:  95.81%, tr_best:  97.00%, epoch time: 139.88 seconds, 2.33 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.317381/  2.340406, val:  80.97%, val_best:  84.96%, tr:  95.78%, tr_best:  97.00%, epoch time: 139.48 seconds, 2.32 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 358 occurrences\n",
      "test - Value 1: 94 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.313417/  2.260438, val:  68.58%, val_best:  84.96%, tr:  95.88%, tr_best:  97.00%, epoch time: 139.66 seconds, 2.33 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.318532/  2.341130, val:  81.86%, val_best:  84.96%, tr:  96.30%, tr_best:  97.00%, epoch time: 138.98 seconds, 2.32 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.322077/  2.346694, val:  50.00%, val_best:  84.96%, tr:  96.67%, tr_best:  97.00%, epoch time: 139.87 seconds, 2.33 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.322707/  2.292760, val:  84.73%, val_best:  84.96%, tr:  96.25%, tr_best:  97.00%, epoch time: 140.60 seconds, 2.34 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.320587/  2.380508, val:  51.11%, val_best:  84.96%, tr:  96.95%, tr_best:  97.00%, epoch time: 140.77 seconds, 2.35 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 417 occurrences\n",
      "test - Value 1: 35 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.318827/  2.248257, val:  57.30%, val_best:  84.96%, tr:  97.05%, tr_best:  97.05%, epoch time: 140.09 seconds, 2.33 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.309908/  2.331503, val:  80.75%, val_best:  84.96%, tr:  95.73%, tr_best:  97.05%, epoch time: 139.83 seconds, 2.33 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.319851/  2.316745, val:  58.63%, val_best:  84.96%, tr:  96.72%, tr_best:  97.05%, epoch time: 139.52 seconds, 2.33 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.318017/  2.355084, val:  74.34%, val_best:  84.96%, tr:  96.23%, tr_best:  97.05%, epoch time: 139.96 seconds, 2.33 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.318865/  2.342304, val:  50.00%, val_best:  84.96%, tr:  96.30%, tr_best:  97.05%, epoch time: 141.13 seconds, 2.35 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.320325/  2.313437, val:  68.58%, val_best:  84.96%, tr:  96.43%, tr_best:  97.05%, epoch time: 140.02 seconds, 2.33 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.320824/  2.362007, val:  55.97%, val_best:  84.96%, tr:  96.87%, tr_best:  97.05%, epoch time: 139.51 seconds, 2.33 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.312077/  2.340719, val:  50.44%, val_best:  84.96%, tr:  95.78%, tr_best:  97.05%, epoch time: 137.11 seconds, 2.29 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 351 occurrences\n",
      "test - Value 1: 101 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.310163/  2.251244, val:  71.02%, val_best:  84.96%, tr:  96.48%, tr_best:  97.05%, epoch time: 134.65 seconds, 2.24 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.319537/  2.324702, val:  70.58%, val_best:  84.96%, tr:  96.53%, tr_best:  97.05%, epoch time: 134.43 seconds, 2.24 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.314651/  2.338563, val:  75.22%, val_best:  84.96%, tr:  96.33%, tr_best:  97.05%, epoch time: 139.80 seconds, 2.33 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.311100/  2.280393, val:  80.97%, val_best:  84.96%, tr:  96.65%, tr_best:  97.05%, epoch time: 139.44 seconds, 2.32 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.322139/  2.394246, val:  50.00%, val_best:  84.96%, tr:  96.00%, tr_best:  97.05%, epoch time: 139.44 seconds, 2.32 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.316569/  2.341608, val:  77.65%, val_best:  84.96%, tr:  97.05%, tr_best:  97.05%, epoch time: 139.90 seconds, 2.33 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.313974/  2.346844, val:  51.77%, val_best:  84.96%, tr:  95.76%, tr_best:  97.05%, epoch time: 139.18 seconds, 2.32 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.319081/  2.326309, val:  63.50%, val_best:  84.96%, tr:  96.80%, tr_best:  97.05%, epoch time: 139.40 seconds, 2.32 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.321276/  2.341654, val:  56.42%, val_best:  84.96%, tr:  96.80%, tr_best:  97.05%, epoch time: 140.12 seconds, 2.34 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.318710/  2.316099, val:  76.99%, val_best:  84.96%, tr:  96.38%, tr_best:  97.05%, epoch time: 139.13 seconds, 2.32 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.328903/  2.297957, val:  83.63%, val_best:  84.96%, tr:  96.35%, tr_best:  97.05%, epoch time: 138.17 seconds, 2.30 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.324263/  2.332855, val:  52.43%, val_best:  84.96%, tr:  96.90%, tr_best:  97.05%, epoch time: 139.25 seconds, 2.32 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.323702/  2.259409, val:  72.79%, val_best:  84.96%, tr:  96.48%, tr_best:  97.05%, epoch time: 140.22 seconds, 2.34 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 393 occurrences\n",
      "test - Value 1: 59 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.316729/  2.266137, val:  63.05%, val_best:  84.96%, tr:  96.38%, tr_best:  97.05%, epoch time: 137.68 seconds, 2.29 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.318376/  2.343632, val:  57.08%, val_best:  84.96%, tr:  96.28%, tr_best:  97.05%, epoch time: 139.30 seconds, 2.32 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.321069/  2.311342, val:  83.85%, val_best:  84.96%, tr:  96.97%, tr_best:  97.05%, epoch time: 140.33 seconds, 2.34 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.313084/  2.356553, val:  57.08%, val_best:  84.96%, tr:  96.63%, tr_best:  97.05%, epoch time: 140.48 seconds, 2.34 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.315333/  2.329143, val:  77.88%, val_best:  84.96%, tr:  96.40%, tr_best:  97.05%, epoch time: 139.13 seconds, 2.32 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.328732/  2.361713, val:  76.55%, val_best:  84.96%, tr:  96.40%, tr_best:  97.05%, epoch time: 137.27 seconds, 2.29 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.317666/  2.389874, val:  50.22%, val_best:  84.96%, tr:  95.98%, tr_best:  97.05%, epoch time: 138.64 seconds, 2.31 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.314957/  2.338535, val:  65.71%, val_best:  84.96%, tr:  97.32%, tr_best:  97.32%, epoch time: 138.62 seconds, 2.31 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.323769/  2.237196, val:  60.84%, val_best:  84.96%, tr:  96.58%, tr_best:  97.32%, epoch time: 139.72 seconds, 2.33 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.327577/  2.327957, val:  85.40%, val_best:  85.40%, tr:  96.85%, tr_best:  97.32%, epoch time: 140.64 seconds, 2.34 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.326521/  2.344797, val:  50.22%, val_best:  85.40%, tr:  95.73%, tr_best:  97.32%, epoch time: 141.25 seconds, 2.35 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.321120/  2.325861, val:  83.19%, val_best:  85.40%, tr:  96.03%, tr_best:  97.32%, epoch time: 139.55 seconds, 2.33 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.325595/  2.265105, val:  67.48%, val_best:  85.40%, tr:  95.68%, tr_best:  97.32%, epoch time: 136.01 seconds, 2.27 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.322373/  2.355898, val:  53.32%, val_best:  85.40%, tr:  96.38%, tr_best:  97.32%, epoch time: 136.70 seconds, 2.28 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 284 occurrences\n",
      "test - Value 1: 168 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.315240/  2.311291, val:  77.43%, val_best:  85.40%, tr:  96.10%, tr_best:  97.32%, epoch time: 140.93 seconds, 2.35 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.322114/  2.308745, val:  82.96%, val_best:  85.40%, tr:  96.48%, tr_best:  97.32%, epoch time: 138.98 seconds, 2.32 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.325787/  2.277275, val:  79.87%, val_best:  85.40%, tr:  96.65%, tr_best:  97.32%, epoch time: 140.45 seconds, 2.34 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.323774/  2.355278, val:  78.98%, val_best:  85.40%, tr:  96.55%, tr_best:  97.32%, epoch time: 140.66 seconds, 2.34 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.320391/  2.324391, val:  81.64%, val_best:  85.40%, tr:  96.60%, tr_best:  97.32%, epoch time: 140.07 seconds, 2.33 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.329891/  2.357368, val:  59.29%, val_best:  85.40%, tr:  96.92%, tr_best:  97.32%, epoch time: 140.12 seconds, 2.34 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.320373/  2.309441, val:  84.29%, val_best:  85.40%, tr:  96.53%, tr_best:  97.32%, epoch time: 141.86 seconds, 2.36 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.315071/  2.350216, val:  74.56%, val_best:  85.40%, tr:  96.40%, tr_best:  97.32%, epoch time: 140.87 seconds, 2.35 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.306798/  2.320332, val:  67.92%, val_best:  85.40%, tr:  95.51%, tr_best:  97.32%, epoch time: 141.03 seconds, 2.35 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.313850/  2.314348, val:  66.59%, val_best:  85.40%, tr:  96.23%, tr_best:  97.32%, epoch time: 140.46 seconds, 2.34 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.315720/  2.346392, val:  60.84%, val_best:  85.40%, tr:  95.76%, tr_best:  97.32%, epoch time: 136.99 seconds, 2.28 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.310258/  2.321285, val:  74.12%, val_best:  85.40%, tr:  96.20%, tr_best:  97.32%, epoch time: 140.36 seconds, 2.34 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 314 occurrences\n",
      "test - Value 1: 138 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.306301/  2.313746, val:  76.99%, val_best:  85.40%, tr:  95.73%, tr_best:  97.32%, epoch time: 137.34 seconds, 2.29 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.307788/  2.290317, val:  85.84%, val_best:  85.84%, tr:  95.66%, tr_best:  97.32%, epoch time: 139.91 seconds, 2.33 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.321122/  2.325958, val:  75.66%, val_best:  85.84%, tr:  96.80%, tr_best:  97.32%, epoch time: 141.29 seconds, 2.35 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.319997/  2.330999, val:  72.12%, val_best:  85.84%, tr:  96.20%, tr_best:  97.32%, epoch time: 139.49 seconds, 2.32 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 374 occurrences\n",
      "test - Value 1: 78 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.311291/  2.267075, val:  67.26%, val_best:  85.84%, tr:  96.00%, tr_best:  97.32%, epoch time: 139.55 seconds, 2.33 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.321099/  2.355554, val:  53.54%, val_best:  85.84%, tr:  97.12%, tr_best:  97.32%, epoch time: 139.68 seconds, 2.33 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.322798/  2.347242, val:  73.67%, val_best:  85.84%, tr:  96.05%, tr_best:  97.32%, epoch time: 140.14 seconds, 2.34 minutes\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.320422/  2.287498, val:  52.21%, val_best:  85.84%, tr:  95.91%, tr_best:  97.32%, epoch time: 139.08 seconds, 2.32 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.316197/  2.367276, val:  50.66%, val_best:  85.84%, tr:  96.08%, tr_best:  97.32%, epoch time: 139.92 seconds, 2.33 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.316355/  2.303088, val:  79.65%, val_best:  85.84%, tr:  96.40%, tr_best:  97.32%, epoch time: 139.83 seconds, 2.33 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.316193/  2.278861, val:  87.17%, val_best:  87.17%, tr:  96.28%, tr_best:  97.32%, epoch time: 139.46 seconds, 2.32 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.311921/  2.315542, val:  86.06%, val_best:  87.17%, tr:  96.23%, tr_best:  97.32%, epoch time: 135.04 seconds, 2.25 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.312177/  2.353230, val:  80.09%, val_best:  87.17%, tr:  95.83%, tr_best:  97.32%, epoch time: 135.52 seconds, 2.26 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.317722/  2.344286, val:  57.96%, val_best:  87.17%, tr:  95.81%, tr_best:  97.32%, epoch time: 138.23 seconds, 2.30 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.317727/  2.241991, val:  73.23%, val_best:  87.17%, tr:  95.81%, tr_best:  97.32%, epoch time: 140.37 seconds, 2.34 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.321340/  2.245804, val:  54.65%, val_best:  87.17%, tr:  95.41%, tr_best:  97.32%, epoch time: 140.55 seconds, 2.34 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.316593/  2.336656, val:  81.19%, val_best:  87.17%, tr:  95.96%, tr_best:  97.32%, epoch time: 138.54 seconds, 2.31 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.315710/  2.295744, val:  87.17%, val_best:  87.17%, tr:  95.04%, tr_best:  97.32%, epoch time: 136.29 seconds, 2.27 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.318399/  2.367886, val:  51.99%, val_best:  87.17%, tr:  95.48%, tr_best:  97.32%, epoch time: 138.83 seconds, 2.31 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 390 occurrences\n",
      "test - Value 1: 62 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.319015/  2.291519, val:  63.72%, val_best:  87.17%, tr:  96.43%, tr_best:  97.32%, epoch time: 139.20 seconds, 2.32 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.319800/  2.337216, val:  53.10%, val_best:  87.17%, tr:  96.03%, tr_best:  97.32%, epoch time: 138.19 seconds, 2.30 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.318435/  2.328907, val:  73.67%, val_best:  87.17%, tr:  96.60%, tr_best:  97.32%, epoch time: 139.71 seconds, 2.33 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.314262/  2.310424, val:  79.87%, val_best:  87.17%, tr:  96.50%, tr_best:  97.32%, epoch time: 139.28 seconds, 2.32 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.314606/  2.308728, val:  80.09%, val_best:  87.17%, tr:  96.38%, tr_best:  97.32%, epoch time: 139.52 seconds, 2.33 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.316958/  2.384320, val:  50.44%, val_best:  87.17%, tr:  95.41%, tr_best:  97.32%, epoch time: 140.11 seconds, 2.34 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.313653/  2.212816, val:  50.44%, val_best:  87.17%, tr:  95.11%, tr_best:  97.32%, epoch time: 139.90 seconds, 2.33 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.316663/  2.334757, val:  78.54%, val_best:  87.17%, tr:  96.38%, tr_best:  97.32%, epoch time: 139.92 seconds, 2.33 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.318574/  2.341151, val:  54.20%, val_best:  87.17%, tr:  96.58%, tr_best:  97.32%, epoch time: 140.65 seconds, 2.34 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.311031/  2.329606, val:  83.63%, val_best:  87.17%, tr:  95.71%, tr_best:  97.32%, epoch time: 138.17 seconds, 2.30 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.314008/  2.289352, val:  80.97%, val_best:  87.17%, tr:  95.58%, tr_best:  97.32%, epoch time: 139.23 seconds, 2.32 minutes\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.314575/  2.246868, val:  50.00%, val_best:  87.17%, tr:  94.49%, tr_best:  97.32%, epoch time: 141.36 seconds, 2.36 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 349 occurrences\n",
      "test - Value 1: 103 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.315524/  2.289581, val:  71.90%, val_best:  87.17%, tr:  95.48%, tr_best:  97.32%, epoch time: 141.06 seconds, 2.35 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.309302/  2.304674, val:  62.39%, val_best:  87.17%, tr:  95.09%, tr_best:  97.32%, epoch time: 139.23 seconds, 2.32 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 351 occurrences\n",
      "test - Value 1: 101 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.309200/  2.288377, val:  71.46%, val_best:  87.17%, tr:  95.48%, tr_best:  97.32%, epoch time: 140.06 seconds, 2.33 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 28 occurrences\n",
      "test - Value 1: 424 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.316124/  2.337731, val:  55.75%, val_best:  87.17%, tr:  96.48%, tr_best:  97.32%, epoch time: 140.15 seconds, 2.34 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.318140/  2.366380, val:  50.00%, val_best:  87.17%, tr:  95.58%, tr_best:  97.32%, epoch time: 137.72 seconds, 2.30 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.312936/  2.320826, val:  50.00%, val_best:  87.17%, tr:  95.48%, tr_best:  97.32%, epoch time: 134.33 seconds, 2.24 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.314165/  2.309896, val:  76.55%, val_best:  87.17%, tr:  95.83%, tr_best:  97.32%, epoch time: 133.49 seconds, 2.22 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.311225/  2.307971, val:  72.35%, val_best:  87.17%, tr:  95.73%, tr_best:  97.32%, epoch time: 136.83 seconds, 2.28 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.307961/  2.328143, val:  70.35%, val_best:  87.17%, tr:  95.58%, tr_best:  97.32%, epoch time: 136.17 seconds, 2.27 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.307643/  2.338581, val:  58.63%, val_best:  87.17%, tr:  96.40%, tr_best:  97.32%, epoch time: 137.55 seconds, 2.29 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.316094/  2.315298, val:  72.57%, val_best:  87.17%, tr:  95.19%, tr_best:  97.32%, epoch time: 139.57 seconds, 2.33 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.313123/  2.306449, val:  81.86%, val_best:  87.17%, tr:  94.91%, tr_best:  97.32%, epoch time: 139.24 seconds, 2.32 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.315771/  2.321078, val:  80.09%, val_best:  87.17%, tr:  96.48%, tr_best:  97.32%, epoch time: 138.87 seconds, 2.31 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.312737/  2.357120, val:  50.00%, val_best:  87.17%, tr:  94.76%, tr_best:  97.32%, epoch time: 137.78 seconds, 2.30 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 325 occurrences\n",
      "test - Value 1: 127 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.315068/  2.264440, val:  75.00%, val_best:  87.17%, tr:  96.18%, tr_best:  97.32%, epoch time: 139.69 seconds, 2.33 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.312644/  2.342578, val:  81.64%, val_best:  87.17%, tr:  95.31%, tr_best:  97.32%, epoch time: 138.65 seconds, 2.31 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.306702/  2.297040, val:  83.63%, val_best:  87.17%, tr:  95.46%, tr_best:  97.32%, epoch time: 138.18 seconds, 2.30 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.313709/  2.315241, val:  64.82%, val_best:  87.17%, tr:  95.76%, tr_best:  97.32%, epoch time: 138.58 seconds, 2.31 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.317323/  2.317509, val:  74.78%, val_best:  87.17%, tr:  96.13%, tr_best:  97.32%, epoch time: 139.17 seconds, 2.32 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.317228/  2.343196, val:  73.45%, val_best:  87.17%, tr:  96.20%, tr_best:  97.32%, epoch time: 138.60 seconds, 2.31 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.306797/  2.325197, val:  73.67%, val_best:  87.17%, tr:  93.97%, tr_best:  97.32%, epoch time: 139.82 seconds, 2.33 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.305304/  2.239626, val:  50.00%, val_best:  87.17%, tr:  95.19%, tr_best:  97.32%, epoch time: 139.56 seconds, 2.33 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.304648/  2.298586, val:  76.77%, val_best:  87.17%, tr:  95.16%, tr_best:  97.32%, epoch time: 138.09 seconds, 2.30 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.316107/  2.311331, val:  85.62%, val_best:  87.17%, tr:  95.16%, tr_best:  97.32%, epoch time: 137.47 seconds, 2.29 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.316415/  2.301337, val:  75.22%, val_best:  87.17%, tr:  95.14%, tr_best:  97.32%, epoch time: 137.64 seconds, 2.29 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.312378/  2.323255, val:  59.07%, val_best:  87.17%, tr:  95.56%, tr_best:  97.32%, epoch time: 138.72 seconds, 2.31 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c99fdd495f478c9b906392e1ab323f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÅ‚ñá‚ñá‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÉ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÉ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÅ‚ñá‚ñá‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÉ</td></tr><tr><td>val_loss</td><td>‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.95558</td></tr><tr><td>tr_epoch_loss</td><td>2.31238</td></tr><tr><td>val_acc_best</td><td>0.87168</td></tr><tr><td>val_acc_now</td><td>0.59071</td></tr><tr><td>val_loss</td><td>2.32326</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-7</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/4oeuq2fg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/4oeuq2fg</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250807_025429-4oeuq2fg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qahmb57j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250807_103916-qahmb57j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/qahmb57j' target=\"_blank\">logical-sweep-8</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/sweeps/8cjdxj7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/qahmb57j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP/runs/qahmb57j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250807_103924_695', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-14, -14], [-14, -14], [-13, -13]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -14 -14\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -14\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -14 -14\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -14\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.302451/  2.302605, val:  50.44%, val_best:  50.44%, tr:  73.15%, tr_best:  73.15%, epoch time: 96.10 seconds, 1.60 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2131 occurrences\n",
      "train - Value 1: 1899 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.301365/  2.306941, val:  51.33%, val_best:  51.33%, tr:  73.05%, tr_best:  73.15%, epoch time: 97.53 seconds, 1.63 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.302513/  2.301080, val:  50.00%, val_best:  51.33%, tr:  74.81%, tr_best:  74.81%, epoch time: 95.28 seconds, 1.59 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.299848/  2.301501, val:  62.83%, val_best:  62.83%, tr:  76.30%, tr_best:  76.30%, epoch time: 94.83 seconds, 1.58 minutes\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.302845/  2.282044, val:  50.22%, val_best:  62.83%, tr:  75.71%, tr_best:  76.30%, epoch time: 96.53 seconds, 1.61 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.303200/  2.319357, val:  50.44%, val_best:  62.83%, tr:  75.53%, tr_best:  76.30%, epoch time: 97.75 seconds, 1.63 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.302387/  2.305604, val:  50.22%, val_best:  62.83%, tr:  72.18%, tr_best:  76.30%, epoch time: 92.53 seconds, 1.54 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.304410/  2.295524, val:  51.77%, val_best:  62.83%, tr:  77.32%, tr_best:  77.32%, epoch time: 93.14 seconds, 1.55 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.301350/  2.312722, val:  50.66%, val_best:  62.83%, tr:  76.08%, tr_best:  77.32%, epoch time: 92.56 seconds, 1.54 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.303913/  2.300643, val:  71.68%, val_best:  71.68%, tr:  76.10%, tr_best:  77.32%, epoch time: 97.34 seconds, 1.62 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 382 occurrences\n",
      "test - Value 1: 70 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.305438/  2.303452, val:  63.72%, val_best:  71.68%, tr:  76.20%, tr_best:  77.32%, epoch time: 97.52 seconds, 1.63 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.305538/  2.282351, val:  50.00%, val_best:  71.68%, tr:  74.29%, tr_best:  77.32%, epoch time: 97.04 seconds, 1.62 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.304401/  2.296492, val:  51.55%, val_best:  71.68%, tr:  76.63%, tr_best:  77.32%, epoch time: 98.51 seconds, 1.64 minutes\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.304746/  2.315876, val:  52.21%, val_best:  71.68%, tr:  76.05%, tr_best:  77.32%, epoch time: 97.82 seconds, 1.63 minutes\n",
      "train - Value 0: 1917 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.304404/  2.324324, val:  50.22%, val_best:  71.68%, tr:  77.77%, tr_best:  77.77%, epoch time: 97.50 seconds, 1.63 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.305077/  2.328752, val:  50.00%, val_best:  71.68%, tr:  75.33%, tr_best:  77.77%, epoch time: 97.58 seconds, 1.63 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.306303/  2.315341, val:  50.88%, val_best:  71.68%, tr:  76.13%, tr_best:  77.77%, epoch time: 97.14 seconds, 1.62 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.308180/  2.280253, val:  56.42%, val_best:  71.68%, tr:  78.11%, tr_best:  78.11%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.304269/  2.308933, val:  71.24%, val_best:  71.68%, tr:  75.63%, tr_best:  78.11%, epoch time: 97.52 seconds, 1.63 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.303559/  2.325686, val:  50.00%, val_best:  71.68%, tr:  75.46%, tr_best:  78.11%, epoch time: 98.59 seconds, 1.64 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.305706/  2.271529, val:  50.00%, val_best:  71.68%, tr:  76.20%, tr_best:  78.11%, epoch time: 97.26 seconds, 1.62 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.303410/  2.277231, val:  53.76%, val_best:  71.68%, tr:  76.65%, tr_best:  78.11%, epoch time: 96.96 seconds, 1.62 minutes\n",
      "train - Value 0: 1910 occurrences\n",
      "train - Value 1: 2120 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.307555/  2.290218, val:  53.10%, val_best:  71.68%, tr:  76.40%, tr_best:  78.11%, epoch time: 97.62 seconds, 1.63 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.303921/  2.284156, val:  50.00%, val_best:  71.68%, tr:  73.55%, tr_best:  78.11%, epoch time: 97.67 seconds, 1.63 minutes\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.302322/  2.290738, val:  50.22%, val_best:  71.68%, tr:  75.33%, tr_best:  78.11%, epoch time: 96.77 seconds, 1.61 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.304683/  2.290988, val:  59.29%, val_best:  71.68%, tr:  76.80%, tr_best:  78.11%, epoch time: 96.11 seconds, 1.60 minutes\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.302279/  2.302227, val:  50.00%, val_best:  71.68%, tr:  77.34%, tr_best:  78.11%, epoch time: 95.85 seconds, 1.60 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.304924/  2.309770, val:  50.00%, val_best:  71.68%, tr:  77.89%, tr_best:  78.11%, epoch time: 97.72 seconds, 1.63 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.303609/  2.293589, val:  50.00%, val_best:  71.68%, tr:  75.38%, tr_best:  78.11%, epoch time: 97.54 seconds, 1.63 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.303101/  2.330624, val:  50.00%, val_best:  71.68%, tr:  77.12%, tr_best:  78.11%, epoch time: 97.45 seconds, 1.62 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.303453/  2.293715, val:  50.00%, val_best:  71.68%, tr:  77.97%, tr_best:  78.11%, epoch time: 96.25 seconds, 1.60 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.308956/  2.308974, val:  50.00%, val_best:  71.68%, tr:  79.11%, tr_best:  79.11%, epoch time: 96.35 seconds, 1.61 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.306509/  2.302797, val:  50.44%, val_best:  71.68%, tr:  78.54%, tr_best:  79.11%, epoch time: 97.40 seconds, 1.62 minutes\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.304197/  2.267925, val:  50.00%, val_best:  71.68%, tr:  74.57%, tr_best:  79.11%, epoch time: 98.93 seconds, 1.65 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.302633/  2.293848, val:  67.04%, val_best:  71.68%, tr:  74.74%, tr_best:  79.11%, epoch time: 97.74 seconds, 1.63 minutes\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.304557/  2.277973, val:  50.00%, val_best:  71.68%, tr:  75.63%, tr_best:  79.11%, epoch time: 98.64 seconds, 1.64 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 427 occurrences\n",
      "test - Value 1: 25 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.304035/  2.309164, val:  51.55%, val_best:  71.68%, tr:  75.68%, tr_best:  79.11%, epoch time: 97.38 seconds, 1.62 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.303885/  2.353782, val:  50.00%, val_best:  71.68%, tr:  77.47%, tr_best:  79.11%, epoch time: 97.75 seconds, 1.63 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.304643/  2.229467, val:  50.00%, val_best:  71.68%, tr:  76.30%, tr_best:  79.11%, epoch time: 96.62 seconds, 1.61 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.304936/  2.313223, val:  51.33%, val_best:  71.68%, tr:  74.67%, tr_best:  79.11%, epoch time: 98.34 seconds, 1.64 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.304416/  2.319867, val:  50.00%, val_best:  71.68%, tr:  75.98%, tr_best:  79.11%, epoch time: 97.41 seconds, 1.62 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.306755/  2.301140, val:  60.40%, val_best:  71.68%, tr:  78.09%, tr_best:  79.11%, epoch time: 97.43 seconds, 1.62 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.304681/  2.271707, val:  50.00%, val_best:  71.68%, tr:  76.65%, tr_best:  79.11%, epoch time: 93.21 seconds, 1.55 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.305045/  2.273745, val:  50.00%, val_best:  71.68%, tr:  76.48%, tr_best:  79.11%, epoch time: 93.11 seconds, 1.55 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.303482/  2.304904, val:  50.22%, val_best:  71.68%, tr:  75.81%, tr_best:  79.11%, epoch time: 93.91 seconds, 1.57 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.306055/  2.381282, val:  50.00%, val_best:  71.68%, tr:  75.68%, tr_best:  79.11%, epoch time: 97.87 seconds, 1.63 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.303906/  2.330706, val:  50.22%, val_best:  71.68%, tr:  77.17%, tr_best:  79.11%, epoch time: 95.99 seconds, 1.60 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.302119/  2.292891, val:  52.43%, val_best:  71.68%, tr:  76.90%, tr_best:  79.11%, epoch time: 97.70 seconds, 1.63 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.303318/  2.322297, val:  50.66%, val_best:  71.68%, tr:  76.80%, tr_best:  79.11%, epoch time: 96.53 seconds, 1.61 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.303097/  2.327256, val:  50.00%, val_best:  71.68%, tr:  75.96%, tr_best:  79.11%, epoch time: 96.36 seconds, 1.61 minutes\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.303735/  2.304853, val:  50.66%, val_best:  71.68%, tr:  74.94%, tr_best:  79.11%, epoch time: 97.65 seconds, 1.63 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.306314/  2.326846, val:  50.00%, val_best:  71.68%, tr:  75.31%, tr_best:  79.11%, epoch time: 97.30 seconds, 1.62 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.304867/  2.296711, val:  50.00%, val_best:  71.68%, tr:  76.70%, tr_best:  79.11%, epoch time: 98.01 seconds, 1.63 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.301343/  2.281418, val:  76.33%, val_best:  76.33%, tr:  74.47%, tr_best:  79.11%, epoch time: 97.12 seconds, 1.62 minutes\n"
     ]
    }
   ],
   "source": [
    "# sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "target_word=2\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_targetword{target_word}_ÏûëÏùÄÍ±∏ÌÅ¨Í≤å',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [4,6,8]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [8]},\n",
    "        \"which_data\": {\"values\": ['n_tidigits_tonic']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.03125, 0.0625, 0.125, 0.25, 0.5]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [4.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [1/512, 1/1024, 1/2048, 1/4096, 1/8192]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [1]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [target_word]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [False]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [8]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "        \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "        \"scale_exp_1w\": {\"values\": [-10,-11,-12,-13,-14]},\n",
    "        # # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "\n",
    "        # \"scale_exp_2w\": {\"values\": [-10]},\n",
    "        # # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "\n",
    "        # \"scale_exp_3w\": {\"values\": [-9]},\n",
    "        # # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"timestep_sums_threshold\": {\"values\": [0]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"2\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "\n",
    "        quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "        scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w+1,wandb.config.scale_exp_1w+1]],\n",
    "        timestep_sums_threshold  =  wandb.config.timestep_sums_threshold,\n",
    "                        ) \n",
    "    # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "    # average pooling\n",
    "    # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "    # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = '4xy74m7d'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn NTIDIGITS SWEEP')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn NTIDIGITS SWEEP')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
