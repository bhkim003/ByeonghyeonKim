{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    seed_assign(my_seed)\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "        \n",
    "        if(epoch == max_epoch - 1): \n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i in range(num_cluster):\n",
    "                        spike_torch = torch.from_numpy(spike_template[i, :])\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                        else:\n",
    "                            spike_torch = spike_torch.unsqueeze(0)\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        # if 'SAE' in net.module.__class__.__name__:\n",
    "                        #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                        #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                        #     print(all_equal, inner_inf)\n",
    "\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.view(1,-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        Cluster[i, :] = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i in range(len(spike)):\n",
    "                        spike_torch = torch.from_numpy(spike[i, :])\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                        else:\n",
    "                            spike_torch = spike_torch.unsqueeze(0)\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.view(1,-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[i, :] = inner_inf.cpu().detach().numpy()\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "\n",
    "\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "                        # print(np.linalg.norm(spike_hidden[spike_index, :]))\n",
    "                        # print(np.linalg.norm(Cluster[q, :]))\n",
    "                    # tau = np.dot(Cluster, spike_hidden[spike_index, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "\n",
    "                    for i in range(num_cluster): # l2 distance\n",
    "                        distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                                \n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "\n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "        \n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 3\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 10 # SAE일 때만 유효\n",
    "# v_decay = 0.5\n",
    "# v_threshold = 0.5\n",
    "# v_reset = 10000.0 # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True\n",
    "\n",
    "# SAE_hidden_nomean = True\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD'\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: pmyp0i7x\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zg3k5wim with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.25\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_004144-zg3k5wim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/zg3k5wim' target=\"_blank\">fine-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/zg3k5wim' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/zg3k5wim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 1, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 16, 'max_epoch': 1, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 6, 'v_decay': 0.75, 'v_threshold': 0.25, 'v_reset': 0, 'BPTT_on': False, 'SAE_hidden_nomean': False, 'current_time': '20250102_004150_262', 'optimizer': 'Adam'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_004150_262\n",
      "\n",
      "epoch-0 loss : 0.19596\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97019868 0.97078228 0.96148291 0.93297975 0.93432836 0.74858491\n",
      " 0.7652909  0.67074318 0.66011094 0.65673828 0.63320463 0.56305859\n",
      " 0.93940937 0.8942774  0.77352941 0.68036312]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.05%, post_traincycle_acc : 79.72%, total_acc : 79.05%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.72%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46639df91794356b502e065849a3e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>▁</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset2</td><td>▁</td></tr><tr><td>mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.19596</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>0.79719</td></tr><tr><td>mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>0.79719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/zg3k5wim' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/zg3k5wim</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250102_004144-zg3k5wim/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tz9czd3x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 2400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.5\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_004616-tz9czd3x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/tz9czd3x' target=\"_blank\">rose-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/tz9czd3x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/tz9czd3x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 1, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 1, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 6, 'v_decay': 0.25, 'v_threshold': 0.5, 'v_reset': 10000, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250102_004623_357', 'optimizer': 'SGD'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_004623_357\n",
      "\n",
      "epoch-0 loss : 0.38010\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.74057451 0.77807487 0.69452182 0.62104283 0.79405941 0.76785714\n",
      " 0.74777448 0.56039076 0.40590031 0.4379771  0.38339552 0.4112426\n",
      " 0.71991701 0.60263653 0.55288462 0.54071363]\n",
      "mean_cluster_accuracy_during_training_cycle : 61.34%, post_traincycle_acc : 60.99%, total_acc : 61.22%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 60.99%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45639398fde44d69af20a344ddcb0a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▁</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>▁</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset2</td><td>▁</td></tr><tr><td>mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.3801</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>0.60994</td></tr><tr><td>mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>0.60994</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-2</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/tz9czd3x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/tz9czd3x</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250102_004616-tz9czd3x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: esgsssf2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.75\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_005053-esgsssf2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/esgsssf2' target=\"_blank\">cosmic-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/pmyp0i7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/esgsssf2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/esgsssf2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 1, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 16, 'max_epoch': 1, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 6, 'v_decay': 0.5, 'v_threshold': 0.75, 'v_reset': 0, 'BPTT_on': True, 'SAE_hidden_nomean': False, 'current_time': '20250102_005100_170', 'optimizer': 'SGD'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (3): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (5): LIF_layer()\n",
      "      (6): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (8): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (9): LIF_layer()\n",
      "      (10): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (11): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (12): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (13): LIF_layer()\n",
      "      (14): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (15): SSBH_DimChanger_for_fc()\n",
      "      (16): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (17): SSBH_L2NormLayer()\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_005100_170\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True, False]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  1\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {dataset_num}, Conv {Conv_net}, SAE {SAE_net}, Current time {current_time}, Spike Length: {spike_length}, Num Cluster: {num_cluster}, \"\n",
    "#     f\"Training Cycle: {training_cycle}, Batch Size: {batch_size}, Max Epoch: {max_epoch}, \\n\"\n",
    "#     f\"Learning Rate: {learning_rate}, Input Normalize: {normalize_on}, Need Bias: {need_bias}, \"\n",
    "#     f\"LIF Add at First: {lif_add_at_first}, TIME: {TIME}, Seed: {my_seed}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
